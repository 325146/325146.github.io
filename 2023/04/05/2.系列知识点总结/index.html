<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no"><title>2.系统知识点整理 | ♪张小佑</title><meta name="keywords" content="C++"><meta name="author" content="🎵张小佑♪"><meta name="copyright" content="🎵张小佑♪"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#f7f9fe"><meta name="mobile-web-app-capable" content="yes"><meta name="apple-touch-fullscreen" content="yes"><meta name="apple-mobile-web-app-title" content="2.系统知识点整理"><meta name="application-name" content="2.系统知识点整理"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-status-bar-style" content="#f7f9fe"><meta name="description" content="积极学习C++吧！">
<meta property="og:type" content="article">
<meta property="og:title" content="2.系统知识点整理">
<meta property="og:url" content="http://acall.love/2023/04/05/2.%E7%B3%BB%E5%88%97%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93/index.html">
<meta property="og:site_name" content="♪张小佑">
<meta property="og:description" content="积极学习C++吧！">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://acallcf.oss-cn-qingdao.aliyuncs.com/images/mpxy18.webp">
<meta property="article:published_time" content="2023-04-04T16:00:00.000Z">
<meta property="article:modified_time" content="2023-04-04T16:00:00.000Z">
<meta property="article:author" content="🎵张小佑♪">
<meta property="article:tag" content="C++">
<meta property="article:tag" content="后端开发">
<meta property="article:tag" content="面试">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://acallcf.oss-cn-qingdao.aliyuncs.com/images/mpxy18.webp"><link rel="shortcut icon" href="/img/favicon.ico"><link rel="canonical" href="http://acall.love/2023/04/05/2.%E7%B3%BB%E5%88%97%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93/"><link rel="preconnect" href="//npm.elemecdn.com"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><meta name="google-site-verification" content="xxx"/><meta name="baidu-site-verification" content="code-xxx"/><meta name="msvalidate.01" content="xxx"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://npm.elemecdn.com/node-snackbar@0.1.16/dist/snackbar.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://npm.elemecdn.com/@fancyapps/ui@4.0.31/dist/fancybox.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = { 
  root: '/',
  friends_vue_info: undefined,
  navMusic: true,
  changeMainColorPost: undefined,
  algolia: undefined,
  localSearch: undefined,
  translate: {"defaultEncoding":2,"translateDelay":0,"msgToTraditionalChinese":"繁","msgToSimplifiedChinese":"简","rightMenuMsgToTraditionalChinese":"转为繁体","rightMenuMsgToSimplifiedChinese":"转为简体"},
  noticeOutdate: {"limitDay":365,"position":"top","messagePrev":"It has been","messageNext":"days since the last update, the content of the article may be outdated."},
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":330},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '天',
  date_suffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: {"chs_to_cht":"你已切换为繁体","cht_to_chs":"你已切换为简体","day_to_night":"你已切换为深色模式","night_to_day":"你已切换为浅色模式","bgLight":"#3b70fc","bgDark":"#1f1f1f","position":"top-center"},
  source: {
    justifiedGallery: {
      js: 'https://npm.elemecdn.com/flickr-justified-gallery@2.1.2/dist/fjGallery.min.js',
      css: 'https://npm.elemecdn.com/flickr-justified-gallery@2.1.2/dist/fjGallery.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isAnchor: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: '2.系统知识点整理',
  isPost: true,
  isHome: false,
  isHighlightShrink: true,
  isToc: true,
  postUpdate: '2023-04-05 00:00:00'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
    win.getCSS = (url,id = false) => new Promise((resolve, reject) => {
      const link = document.createElement('link')
      link.rel = 'stylesheet'
      link.href = url
      if (id) link.id = id
      link.onerror = reject
      link.onload = link.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        link.onload = link.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(link)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#18171d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#f7f9fe')
        }
      }
      const t = saveToLocal.get('theme')
    
          const isDarkMode = window.matchMedia('(prefers-color-scheme: dark)').matches
          const isLightMode = window.matchMedia('(prefers-color-scheme: light)').matches
          const isNotSpecified = window.matchMedia('(prefers-color-scheme: no-preference)').matches
          const hasNoSupport = !isDarkMode && !isLightMode && !isNotSpecified

          if (t === undefined) {
            if (isLightMode) activateLightMode()
            else if (isDarkMode) activateDarkMode()
            else if (isNotSpecified || hasNoSupport) {
              const now = new Date()
              const hour = now.getHours()
              const isNight = hour <= 6 || hour >= 18
              isNight ? activateDarkMode() : activateLightMode()
            }
            window.matchMedia('(prefers-color-scheme: dark)').addListener(function (e) {
              if (saveToLocal.get('theme') === undefined) {
                e.matches ? activateDarkMode() : activateLightMode()
              }
            })
          } else if (t === 'light') activateLightMode()
          else activateDarkMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const detectApple = () => {
      if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
    })(window)</script><meta name="generator" content="Hexo 6.3.0"></head><body data-type="anzhiyu"><div id="web_bg"></div><div id="an_music_bg"></div><div id="loading-box" onclick="document.getElementById(&quot;loading-box&quot;).classList.add(&quot;loaded&quot;)"><div class="loading-bg"><img class="loading-img nolazyload" alt="加载头像" src="https://acallcf.oss-cn-qingdao.aliyuncs.com/images/1.jpg"/><div class="loading-image-dot"></div><div id="loading-percentage">0%</div></div></div><script>const loadingPercentage = document.getElementById("loading-percentage");
let loadingPercentageTimer = setInterval(function() {
  var progressBar = document.querySelector(".pace-progress");
  if (!progressBar) return
  var currentValue = progressBar.getAttribute("data-progress-text");
  if (currentValue !== loadingPercentage.textContent) {
    loadingPercentage.textContent = currentValue;
    if (currentValue === "100%") {
      clearInterval(loadingPercentageTimer);
    }
  }
}, 100);
const preloader = {
  endLoading: () => {
    document.body.style.overflow = 'auto';
    document.getElementById('loading-box').classList.add("loaded")
    Pace.restart()
  },
  initLoading: () => {
    document.body.style.overflow = '';
    document.getElementById('loading-box').classList.remove("loaded")
  }
}
window.addEventListener('load',()=> { preloader.endLoading() })

if (true) {
  document.addEventListener('pjax:send', () => { preloader.initLoading() })
  document.addEventListener('pjax:complete', () => { preloader.endLoading() })
}</script><link rel="stylesheet" href="https://npm.elemecdn.com/anzhiyu-theme-static@1.0.0/progress_bar/progress_bar.css"/><script async="async" src="https://npm.elemecdn.com/pace-js@1.2.4/pace.min.js" data-pace-options="{ &quot;restartOnRequestAfter&quot;:false,&quot;eventLag&quot;:false}"></script><div id="web_box"><div id="web_container"><div id="menu-mask"></div><div class="post" id="body-wrap"><header class="not-top-img" id="page-header"><nav id="nav"><div id="nav-group"><span id="blog_name"><div class="back-home-button"><i class="anzhiyufont anzhiyu-icon-grip-vertical"></i><div class="back-menu-list-groups"><div class="back-menu-list-group"><div class="back-menu-list-title">网页</div><div class="back-menu-list"><a class="back-menu-item" href="https://acall.love/" title="博客" target="_blank"><img class="back-menu-item-icon" src="/img/favicon.ico" alt="博客"/><span class="back-menu-item-text">博客</span></a></div></div><div class="back-menu-list-group"><div class="back-menu-list-title">项目</div><div class="back-menu-list"><a class="back-menu-item" href="https://image.anheyu.com/" title="安知鱼图床" target="_blank"><img class="back-menu-item-icon" src="https://image.anheyu.com/favicon.ico" alt="安知鱼图床"/><span class="back-menu-item-text">安知鱼图床</span></a></div></div></div></div><a id="site-name" href="/" accesskey="h"><div class="title">♪张小佑</div><i class="anzhiyufont anzhiyu-icon-house-chimney"></i></a></span><div class="mask-name-container"><div id="name-container"><a id="page-name" href="javascript:anzhiyu.scrollToDest(0, 500)">PAGE_NAME</a></div></div><div id="menus"><div class="menus_items"><div class="menus_item"><a class="site-page faa-parent animated-hover" href="javascript:void(0);"><span> 文章</span></a><ul class="menus_item_child" style="left:-79px;"><li><a class="site-page child faa-parent animated-hover" href="/archives/"><i class="anzhiyufont anzhiyu-icon-box-archive faa-tada" style="font-size: 0.9em;"></i><span> 隧道</span></a></li><li><a class="site-page child faa-parent animated-hover" href="/categories/"><i class="anzhiyufont anzhiyu-icon-shapes faa-tada" style="font-size: 0.9em;"></i><span> 分类</span></a></li><li><a class="site-page child faa-parent animated-hover" href="/tags/"><i class="anzhiyufont anzhiyu-icon-tags faa-tada" style="font-size: 0.9em;"></i><span> 标签</span></a></li></ul></div><div class="menus_item"><a class="site-page faa-parent animated-hover" href="javascript:void(0);"><span> 友链</span></a><ul class="menus_item_child" style="left:17px;"><li><a class="site-page child faa-parent animated-hover" href="/comments/"><i class="anzhiyufont anzhiyu-icon-envelope faa-tada" style="font-size: 0.9em;"></i><span> 留言板</span></a></li></ul></div><div class="menus_item"><a class="site-page faa-parent animated-hover" href="javascript:void(0);"><span> 我的</span></a><ul class="menus_item_child" style="left:-79px;"><li><a class="site-page child faa-parent animated-hover" href="/music/"><i class="anzhiyufont anzhiyu-icon-music faa-tada" style="font-size: 0.9em;"></i><span> 音乐馆</span></a></li><li><a class="site-page child faa-parent animated-hover" href="/bangumis/"><i class="anzhiyufont anzhiyu-icon-bilibili faa-tada" style="font-size: 0.9em;"></i><span> 追番页</span></a></li><li><a class="site-page child faa-parent animated-hover" href="/album/"><i class="anzhiyufont anzhiyu-icon-images faa-tada" style="font-size: 0.9em;"></i><span> 相册集</span></a></li></ul></div><div class="menus_item"><a class="site-page faa-parent animated-hover" href="javascript:void(0);"><span> 关于</span></a><ul class="menus_item_child" style="left:-79px;"><li><a class="site-page child faa-parent animated-hover" href="/about/"><i class="anzhiyufont anzhiyu-icon-paper-plane faa-tada" style="font-size: 0.9em;"></i><span> 关于本人</span></a></li><li><a class="site-page child faa-parent animated-hover" href="/essay/"><i class="anzhiyufont anzhiyu-icon-lightbulb faa-tada" style="font-size: 0.9em;"></i><span> 闲言碎语</span></a></li><li><a class="site-page child faa-parent animated-hover" href="/equipment/"><i class="anzhiyufont anzhiyu-icon-dice-d20 faa-tada" style="font-size: 0.9em;"></i><span> 我的装备</span></a></li></ul></div></div></div><div id="nav-right"><div class="nav-button only-home" id="travellings_button" title="随机前往一个开往项目网站"><a class="site-page" onclick="anzhiyu.totraveling()" title="随机前往一个开往项目网站" href="javascript:void(0);" rel="external nofollow" data-pjax-state="external"><i class="anzhiyufont anzhiyu-icon-train"></i></a></div><div class="nav-button" id="randomPost_button"><a class="site-page" onclick="toRandomPost()" title="随机前往一个文章" href="javascript:void(0);"><i class="anzhiyufont anzhiyu-icon-dice"></i></a></div><input id="center-console" type="checkbox"/><label class="widget" for="center-console" title="中控台" onclick="anzhiyu.switchConsole();"><i class="left"></i><i class="widget center"></i><i class="widget right"></i></label><div id="console"><div class="console-card-group-reward"><ul class="reward-all console-card"><li class="reward-item"><a href="https://acallcf.oss-cn-qingdao.aliyuncs.com/images/202307192211377.png" target="_blank"><img class="post-qr-code-img" alt="wechat" src="https://acallcf.oss-cn-qingdao.aliyuncs.com/images/202307192211377.png"/></a><div class="post-qr-code-desc">wechat</div></li><li class="reward-item"><a href="https://acallcf.oss-cn-qingdao.aliyuncs.com/images/202307192207910.png" target="_blank"><img class="post-qr-code-img" alt="alipayautoh" src="https://acallcf.oss-cn-qingdao.aliyuncs.com/images/202307192207910.png"/></a><div class="post-qr-code-desc">alipayautoh</div></li></ul></div><div class="console-card-group"><div class="console-card-group-left"><div class="console-card" id="card-newest-comments" onclick="anzhiyu.hideConsole()"><div class="card-content"><div class="author-content-item-tips">互动</div><span class="author-content-item-title"> <span>最新评论</span></span></div><div class="aside-list"><span>正在加载中...</span></div></div></div><div class="console-card-group-right"><div class="console-card tags" onclick="anzhiyu.hideConsole()"><div class="card-content"><div class="author-content-item-tips">兴趣点</div><span class="author-content-item-title">寻找你感兴趣的领域</span><div class="card-tags"><div class="item-headline"></div><div class="card-tag-cloud"><a href="/tags/C/" style="font-size: 1.05rem;">C++<sup>23</sup></a><a href="/tags/%E5%90%8E%E7%AB%AF%E5%BC%80%E5%8F%91/" style="font-size: 1.05rem;">后端开发<sup>22</sup></a><a href="/tags/%E9%9D%A2%E7%BB%8F/" style="font-size: 1.05rem;">面经<sup>1</sup></a><a href="/tags/%E9%9D%A2%E8%AF%95/" style="font-size: 1.05rem;">面试<sup>3</sup></a></div></div><hr/></div></div><div class="console-card history" onclick="anzhiyu.hideConsole()"><div class="item-headline"><i class="anzhiyufont anzhiyu-icon-box-archiv"></i><span>文章</span></div><div class="card-archives"><div class="item-headline"><i class="anzhiyufont anzhiyu-icon-archive"></i><span>归档</span></div><ul class="card-archive-list"><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2023/06/"><span class="card-archive-list-date">六月 2023</span><div class="card-archive-list-count-group"><span class="card-archive-list-count">3</span><span>篇</span></div></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2023/05/"><span class="card-archive-list-date">五月 2023</span><div class="card-archive-list-count-group"><span class="card-archive-list-count">5</span><span>篇</span></div></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2023/04/"><span class="card-archive-list-date">四月 2023</span><div class="card-archive-list-count-group"><span class="card-archive-list-count">2</span><span>篇</span></div></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2023/03/"><span class="card-archive-list-date">三月 2023</span><div class="card-archive-list-count-group"><span class="card-archive-list-count">1</span><span>篇</span></div></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2023/02/"><span class="card-archive-list-date">二月 2023</span><div class="card-archive-list-count-group"><span class="card-archive-list-count">5</span><span>篇</span></div></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2023/01/"><span class="card-archive-list-date">一月 2023</span><div class="card-archive-list-count-group"><span class="card-archive-list-count">7</span><span>篇</span></div></a></li></ul></div><hr/></div></div></div><div class="button-group"><div class="console-btn-item"><a class="darkmode_switchbutton" onclick="anzhiyu.switchDarkMode()" title="显示模式切换" href="javascript:void(0);"><i class="anzhiyufont anzhiyu-icon-moon"></i></a></div><div class="console-btn-item" id="consoleHideAside" onclick="anzhiyu.hideAsideBtn()" title="边栏显示控制"><a class="asideSwitch"><i class="anzhiyufont anzhiyu-icon-arrows-left-right"></i></a></div><div class="console-btn-item on" id="consoleCommentBarrage" onclick="anzhiyu.switchCommentBarrage()" title="热评开关"><a class="commentBarrage"><i class="anzhiyufont anzhiyu-icon-message"></i></a></div><div class="console-btn-item" id="consoleMusic" onclick="anzhiyu.musicToggle()" title="音乐开关"><a class="music-switch"><i class="anzhiyufont anzhiyu-icon-music"></i></a></div><div class="console-btn-item" id="consoleKeyboard" onclick="anzhiyu.keyboardToggle()" title="快捷键开关"><a class="keyboard-switch"><i class="anzhiyufont anzhiyu-icon-keyboard"></i></a></div></div><div class="console-mask" onclick="anzhiyu.hideConsole()" href="javascript:void(0);"></div></div><div class="nav-button" id="nav-totop"><a class="totopbtn" href="javascript:void(0);"><i class="anzhiyufont anzhiyu-icon-arrow-up"></i><span id="percent" onclick="anzhiyu.scrollToDest(0,500)">0</span></a></div><div id="toggle-menu"><a class="site-page" href="javascript:void(0);"><i class="anzhiyufont anzhiyu-icon-bars"></i></a></div></div></div></nav></header><main class="layout" id="content-inner"><div id="post"><div id="post-info"><div id="post-firstinfo"><div class="meta-firstline"><a class="post-meta-original">原创</a><span class="post-meta-categories"><span class="post-meta-separator"></span><i class="anzhiyufont anzhiyu-icon-inbox post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E5%A4%A7%E5%AD%A6%E7%94%9F%E6%B6%AF/">大学生涯</a></span><span class="article-meta tags"><a class="article-meta__tags" href="/tags/C/" tabindex="-1"> <span> <i class="anzhiyufont anzhiyu-icon-hashtag"></i>C++</span></a><a class="article-meta__tags" href="/tags/%E5%90%8E%E7%AB%AF%E5%BC%80%E5%8F%91/" tabindex="-1"> <span> <i class="anzhiyufont anzhiyu-icon-hashtag"></i>后端开发</span></a><a class="article-meta__tags" href="/tags/%E9%9D%A2%E8%AF%95/" tabindex="-1"> <span> <i class="anzhiyufont anzhiyu-icon-hashtag"></i>面试</span></a></span></div></div><h1 class="post-title">2.系统知识点整理</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="anzhiyufont anzhiyu-icon-calendar-days post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2023-04-04T16:00:00.000Z" title="发表于 2023-04-05 00:00:00">2023-04-05</time><span class="post-meta-separator"></span><i class="anzhiyufont anzhiyu-icon-history post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2023-04-04T16:00:00.000Z" title="更新于 2023-04-05 00:00:00">2023-04-05</time></span></div><div class="meta-secondline"><span class="post-meta-separator"></span><span class="post-meta-wordcount"><i class="anzhiyufont anzhiyu-icon-file-word post-meta-icon" title="文章字数"></i><span class="post-meta-label" title="文章字数">字数总计:</span><span class="word-count" title="文章字数">176.9k</span><span class="post-meta-separator"></span><i class="anzhiyufont anzhiyu-icon-clock post-meta-icon" title="阅读时长"></i><span class="post-meta-label" title="阅读时长">阅读时长:</span><span>544分钟</span></span><span class="post-meta-separator"></span><span class="post-meta-pv-cv" id="" data-flag-title="2.系统知识点整理"><i class="anzhiyufont anzhiyu-icon-fw-eye post-meta-icon"></i><span class="post-meta-label" title="阅读量">阅读量:</span><span id="busuanzi_value_page_pv"><i class="anzhiyufont anzhiyu-icon-spinner anzhiyu-spin"></i></span></span><span class="post-meta-separator">       </span><span class="post-meta-position" title="作者IP属地为郑州"><i class="anzhiyufont anzhiyu-icon-location-dot"></i>郑州</span></div></div></div><article class="post-content" id="article-container"><h1 id="系列知识点总结"><a href="#系列知识点总结" class="headerlink" title="系列知识点总结"></a>系列知识点总结</h1><h2 id="操作系统"><a href="#操作系统" class="headerlink" title="操作系统"></a>操作系统</h2><h3 id="2-1-CPU-是如何执行程序的？"><a href="#2-1-CPU-是如何执行程序的？" class="headerlink" title="2.1 CPU 是如何执行程序的？"></a>2.1 CPU 是如何执行程序的？</h3><ul>
<li><p>计算机基本结构为 5 个部分，分别是<strong>运算器、控制器、存储器、输入设备、输出设备</strong>，这 5 个部分也被称为<strong>冯诺依曼模型</strong>；运算器、控制器是在中央处理器（ CPU，32 位和 64 位 CPU 最主要区别在于一次能计算多少字节数据，32-&gt;4, 64-&gt;8，这里的 32 位和 64 位，通常称为 CPU 的位宽）里的，存储器就我们常见的内存（数据存储的单位是一个<strong>二进制位（bit）</strong>，即 0 或 1。最小的存储单位是<strong>字节（byte）</strong>），输入输出设备则是计算机外接的设备</p>
</li>
<li><p>CPU 内部还有一些组件，常见的有<strong>寄存器、控制单元和逻辑运算单元</strong>等。其中，控制单元负责控制 CPU 工作，逻辑运算单元负责计算，而寄存器可以分为多种类，主要作用是存储计算时的数据，加速计算</p>
</li>
<li><p>常见的寄存器种类：<em>通用寄存器</em>，用来存放需要进行运算的数据；<em>程序计数器</em>，用来存储 CPU 要执行下一条指令「所在的内存地址」；<em>指令寄存器</em>，用来存放程序计数器指向的指令</p>
</li>
<li><p>CPU 要想操作的内存地址就需要地址总线，如果想要 CPU 操作 4G 的内存，那么就需要 32 条地址总线，因为 <code>2 ^ 32 = 4G</code>；CPU 的位宽最好不要小于线路位宽；如果计算的数额不超过 32 位数字的情况下，32 位和 64 位 CPU 之间没什么区别的，只有当计算超过 32 位数字的情况下，64 位的优势才能体现出来</p>
</li>
<li><p>一个程序执行的时候，CPU 会根据程序计数器里的内存地址，从内存里面把需要执行的指令读取到指令寄存器里面执行，然后根据指令长度自增，开始顺序读取下一条指令。CPU 从程序计数器读取指令、到执行、再到下一条指令，这个过程会不断循环，直到程序执行结束，这个不断循环的过程被称为 <strong>CPU 的指令周期</strong></p>
</li>
<li><p>a &#x3D; 1 + 2 执行具体过程：需要把整个程序翻译成<strong>汇编语言</strong>的程序，这个过程称为编译成汇编代码；程序编译过程中，编译器通过分析代码，发现 1 和 2 是数据，于是程序运行时，内存会有个专门的区域来存放这些数据，这个区域就是「数据段」；数据和指令是分开区域存放的，存放指令区域的地方称为「正文段」；编译器会把 <code>a = 1 + 2</code> 翻译成 4 条指令，存放到正文段中；编译完成后，具体执行程序的时候，程序计数器会被设置为 0x200 地址，然后依次执行这 4 条指令</p>
</li>
<li><p>指令的内容是一串二进制数字的机器码，每条指令都有对应的机器码，CPU 通过解析机器码来知道指令的内容。不同的 CPU 有不同的指令集，也就是对应着不同的汇编语言和不同的机器码；现代大多数 CPU 都使用来流水线的方式来执行指令：</p>
<ul>
<li>CPU 通过程序计数器读取对应内存地址的指令，这个部分称为 <strong>Fetch（取得指令）</strong>；</li>
<li>CPU 对指令进行解码，这个部分称为 <strong>Decode（指令译码）</strong>；</li>
<li>CPU 执行指令，这个部分称为 <strong>Execution（执行指令）</strong>；</li>
<li>CPU 将计算结果存回寄存器或者将寄存器的值存入内存，这个部分称为 <strong>Store（数据回写）</strong>；</li>
</ul>
<p>这 4 个阶段，称为<strong>指令周期（<em>Instrution Cycle</em>）</strong>，CPU 的工作就是一个周期接着一个周期，周而复始</p>
</li>
<li><p>64 位相比 32 位 CPU 的优势在哪吗？64 位 CPU 的计算性能一定比 32 位 CPU 高很多吗？</p>
<p>64 位相比 32 位 CPU 的优势主要体现在两个方面：</p>
<ul>
<li>64 位 CPU 可以一次计算超过 32 位的数字，而 32 位 CPU 如果要计算超过 32 位的数字，要分多步骤进行计算，效率就没那么高，但是大部分应用程序很少会计算那么大的数字，所以<strong>只有运算大数字的时候，64 位 CPU 的优势才能体现出来，否则和 32 位 CPU 的计算性能相差不大</strong>。</li>
<li>64 位 CPU 可以<strong>寻址更大的内存空间</strong>，32 位 CPU 最大的寻址地址是 4G，即使你加了 8G 大小的内存，也还是只能寻址到 4G，而 64 位 CPU 最大寻址地址是 <code>2^64</code>，远超于 32 位 CPU 最大寻址地址的 <code>2^32</code>。</li>
</ul>
</li>
<li><p>你知道软件的 32 位和 64 位之间的区别吗？再来 32 位的操作系统可以运行在 64 位的电脑上吗？64 位的操作系统可以运行在 32 位的电脑上吗？如果不行，原因是什么？</p>
<ul>
<li>64 位和 32 位软件，实际上代表指令是 64 位还是 32 位的：</li>
<li>如果 32 位指令在 64 位机器上执行，需要一套兼容机制，就可以做到兼容运行了。但是<strong>如果 64 位指令在 32 位机器上执行，就比较困难了，因为 32 位的寄存器存不下 64 位的指令</strong>；</li>
<li>操作系统其实也是一种程序，我们也会看到操作系统会分成 32 位操作系统、64 位操作系统，其代表意义就是操作系统中程序的指令是多少位，比如 64 位操作系统，指令也就是 64 位，因此不能装在 32 位机器上。</li>
</ul>
<p>总之，<strong>硬件的 64 位和 32 位指的是 CPU 的位宽，软件的 64 位和 32 位指的是指令的位宽</strong></p>
</li>
</ul>
<h3 id="2-3-如何写出让-CPU-跑得更快的代码？"><a href="#2-3-如何写出让-CPU-跑得更快的代码？" class="headerlink" title="2.3 如何写出让 CPU 跑得更快的代码？"></a>2.3 如何写出让 CPU 跑得更快的代码？</h3><ul>
<li>CPU 内部嵌入了 CPU Cache（高速缓存），它的存储容量很小，但是离 CPU 核心很近，所以缓存的读写速度是极快的，那么如果 CPU 运算时，直接从 CPU Cache 读取数据，而不是从内存的话，运算速度就会很快</li>
<li>CPU Cache 通常分为大小不等的三级缓存，分别是 <strong>L1 Cache、L2 Cache 和 L3 Cache</strong>。L3 Cache 比 L1 Cache 和 L2 Cache 大很多，这是因为 <strong>L1 Cache 和 L2 Cache 都是每个 CPU 核心独有的，而 L3 Cache 是多个 CPU 核心共享的</strong>。CPU 从 L1 Cache 读取数据的速度，相比从内存读取的速度，会快 <code>100</code> 多倍。</li>
<li>CPU Cache 的数据是从内存中读取过来的，它是以一小块一小块读取数据的（取决于 <code>coherency_line_size</code> 的值，一般 64 字节），称为 <strong>Cache Line（缓存块）</strong>；CPU 读取数据的时候，无论数据是否存放到 Cache 中，CPU 都是先访问 Cache，只有当 Cache 中找不到数据时，才会去访问内存，并把内存中的数据读入到 Cache 中，CPU 再从 CPU Cache 读取数据</li>
<li>对于直接映射 Cache 采用的策略，就是把内存块的地址始终「映射」在一个 CPU Line 的地址，使用「取模运算」；为了区别不同的内存块，在对应的 CPU Line 中还会存储一个<strong>组标记（Tag）</strong>、从内存加载过来的实际存放<strong>数据（Data）</strong>、和一个有效位（Valid bit）如果有效位是 0，无论 CPU Line 中是否有数据，CPU 都会直接访问内存，重新加载数据</li>
<li>CPU 在从 CPU Cache 读取数据的时候，并不是读取 CPU Line 中的整个数据块，而是读取 CPU 所需要的一个数据片段，这样的数据统称为一个<strong>字（<em>Word</em>）</strong>,需要一个<strong>偏移量（Offset）</strong>；一个内存的访问地址，包括<strong>组标记、CPU Line 索引、偏移量</strong>这三种信息，于是 CPU 就能通过这些信息，在 CPU Cache 中找到缓存的数据；对于 CPU Cache 里的数据结构，则是由<strong>索引 + 有效位 + 组标记 + 数据块</strong>组成</li>
<li>访问的数据在 CPU Cache 中的话，意味着<strong>缓存命中</strong>，缓存命中率越高的话，代码的性能就会越好，CPU 也就跑的越快；L1 Cache 通常分为「数据缓存」和「指令缓存」，这是因为 CPU 会分别处理数据和指令，要分开来看数据缓存和指令缓存的缓存命中率：<ul>
<li>遇到遍历数组的情况时，按照内存布局顺序访问，将可以有效的利用 CPU Cache 带来的好处</li>
<li>如果分支预测可以预测到接下来要执行 if 里的指令，还是 else 指令的话，就可以「提前」把这些指令放在指令缓存中，这样 CPU 可以直接从 Cache 读取到指令，于是执行速度就会很快</li>
</ul>
</li>
<li>当有多个同时执行「计算密集型」的线程，为了防止因为切换到不同的核心，而导致缓存命中率下降的问题，我们可以把<strong>线程绑定在某一个 CPU 核心上</strong>，这样性能可以得到非常可观的提升</li>
</ul>
<h3 id="2-4-CPU-缓存一致性"><a href="#2-4-CPU-缓存一致性" class="headerlink" title="2.4 CPU 缓存一致性"></a>2.4 CPU 缓存一致性</h3><ul>
<li><p>保持内存与 Cache 一致性最简单的方式是，<strong>把数据同时写入内存和 Cache 中</strong>，这种方法称为<strong>写直达（<em>Write Through</em>）</strong>；写入前会先判断数据是否已经在 CPU Cache 里面了：</p>
<ul>
<li>如果数据已经在 Cache 里面，先将数据更新到 Cache 里面，再写入到内存里面；</li>
<li>如果数据没有在 Cache 里面，就直接把数据更新到内存里面。</li>
</ul>
<p>无论数据在不在 Cache 里面，每次写操作都会写回到内存，这样写操作将会花费大量的时间，无疑性能会受到很大的影响</p>
</li>
<li><p>为了要减少数据写回内存的频率，就出现了<strong>写回（<em>Write Back</em>）的方法</strong>。在写回机制中，<strong>当发生写操作时，新的数据仅仅被写入 Cache Block 里，只有当修改过的 Cache Block被替换时才需要写到内存中</strong>，减少了数据写回内存的频率，这样便可以提高系统的性能。在把数据写入到 Cache 的时候，只有在缓存不命中，同时数据对应的 Cache 中的 Cache Block 为脏标记的情况下，才会将数据写到内存中，而在缓存命中的情况下，则在写入后 Cache 后，只需把该数据对应的 Cache Block 标记为脏即可，而不用写到内存里、</p>
</li>
<li><p>现在 CPU 都是多核的，由于 L1&#x2F;L2 Cache 是多个核心各自独有的，那么会带来多核心的<strong>缓存一致性（<em>Cache Coherence</em>）</strong> 的问题，如果不能保证缓存一致性的问题，就可能造成结果错误；需要一种机制，来同步两个不同核心里面的缓存数据。要<strong>保证做到下面这 2 点</strong>：</p>
<ul>
<li>第一点，某个 CPU 核心里的 Cache 数据更新时，必须要传播到其他核心的 Cache，这个称为<strong>写传播</strong>；</li>
<li>第二点，某个 CPU 核心里对数据的操作顺序，必须在其他核心看起来顺序是一样的，这个称为<strong>事务的串行化</strong>，要实现事务串行化，要做到 2 点：<ul>
<li>CPU 核心对于 Cache 中数据的操作，需要同步给其他 CPU 核心；</li>
<li>要引入「锁」的概念，如果两个 CPU 核心里有相同数据的 Cache，那么对于这个 Cache 数据的更新，只有拿到了「锁」，才能进行对应的数据更新</li>
</ul>
</li>
</ul>
</li>
<li><p>写传播的原则就是当某个 CPU 核心更新了 Cache 中的数据，要把该事件广播通知到其他核心。最常见实现的方式是<strong>总线嗅探</strong>；CPU 需要每时每刻监听总线上的一切活动，但是不管别的核心的 Cache 是否缓存相同的数据，都需要发出一个广播事件，这无疑会加重总线的负载；总线嗅探只是保证了某个 CPU 核心的 Cache 更新数据这个事件能被其他 CPU 核心知道，但是并不能保证事务串行化。</p>
</li>
<li><p>MESI 协议基于总线嗅探机制实现了事务串行化，也用状态机机制降低了总线带宽压力，其实是 4 个状态单词的开头字母缩写，分别是：</p>
<ul>
<li><em>Modified</em>，已修改，前面提到的脏标记，代表该 Cache Block 上的数据已经被更新过，但是还没有写到内存里</li>
<li><em>Exclusive</em>，独占，代表 Cache Block 里的数据是干净的，数据只存储在一个 CPU 核心的 Cache 里，而其他 CPU 核心的 Cache 没有该数据</li>
<li><em>Shared</em>，共享，代表 Cache Block 里的数据是干净的，在独占状态下的数据，如果有其他核心从内存读取了相同的数据到各自的 Cache ，那么这个时候，独占状态下的数据就会变成共享状态</li>
<li><em>Invalidated</em>，已失效，这个 Cache Block 里的数据已经失效了，不可以读取该状态的数据</li>
</ul>
<p>对于在「已修改」或者「独占」状态的 Cache Line，修改更新其数据不需要发送广播给其他 CPU 核心</p>
</li>
</ul>
<h3 id="2-5-CPU-是如何执行任务的？"><a href="#2-5-CPU-是如何执行任务的？" class="headerlink" title="2.5 CPU 是如何执行任务的？"></a>2.5 CPU 是如何执行任务的？</h3><ul>
<li>CPU 如何读写数据的？CPU 从内存中读取数据到 Cache 的时候，并不是一个字节一个字节读取，而是一块一块的方式来读取数据的，这一块一块的数据被称为 CPU Cache Line（缓存块），所以 <strong>CPU Cache Line 是 CPU 从内存读取数据到 Cache 的单位</strong><ul>
<li>对数组的加载， CPU 就会加载数组里面连续的多个数据到 Cache 里，因此我们应该按照物理内存地址分布的顺序去访问元素，这样访问数组元素的时候，Cache 命中率就会很高，于是就能减少从内存读取数据的频率， 从而可提高程序的性能</li>
<li>在不使用数组，而是使用单独的变量的时候，则会有 Cache 伪共享的问题：两个数据位于<strong>同一个 Cache Line 中</strong>，两个数据会被同时读入到了两个 CPU 核心中各自 Cache 中，这两个不同核心的线程分别修改不同的数据，<strong>导致Cache 并没有起到缓存的效果</strong></li>
</ul>
</li>
<li>避免伪共享的方法：在 Linux 内核中存在 <code>__cacheline_aligned_in_smp</code> 宏定义，是用于解决伪共享的问题，避免 Cache 伪共享实际上是用空间换时间的思想，浪费一部分 Cache 空间，从而换来性能的提升</li>
<li>CPU 如何选择线程的？<ul>
<li>在 Linux 内核中，进程和线程都是用 <code>task_struct</code> 结构体表示的，区别在于线程的 task_struct 结构体里部分资源是共享了进程已创建的资源，比如内存地址空间、代码段、文件描述符等，所以 Linux 中的线程也被称为轻量级进程，因为线程的 task_struct 相比进程的 task_struct 承载的 资源比较少，因此以「轻」得名；Linux 内核里的调度器，调度的对象就是 <code>task_struct</code></li>
<li>在 Linux 系统中，根据任务的优先级以及响应要求，主要分为两种，其中优先级的数值越小，优先级越高：<ul>
<li>实时任务，对系统的响应时间要求很高，也就是要尽可能快的执行实时任务，优先级在 <code>0~99</code> 范围内的就算实时任务；</li>
<li>普通任务，响应时间没有很高的要求，优先级在 <code>100~139</code> 范围内都是普通任务级别</li>
</ul>
</li>
<li>系统中需要运行的多线程数一般都会大于 CPU 核心，这样就会导致线程排队等待 CPU，这可能会产生一定的延时，如果我们的任务对延时容忍度很低，则可以通过一些人为手段干预 Linux 的默认调度策略和优先级</li>
</ul>
</li>
</ul>
<h3 id="2-6-什么是软中断？"><a href="#2-6-什么是软中断？" class="headerlink" title="2.6 什么是软中断？"></a>2.6 什么是软中断？</h3><ul>
<li><p>中断是系统用来响应硬件设备请求的一种机制，操作系统收到硬件的中断请求，会打断正在执行的进程，然后调用内核中的中断处理程序来响应请求；中断是一种异步的事件处理机制，可以提高系统的并发处理能力。操作系统收到了中断请求，会打断其他进程的运行，所以中断请求的响应程序，也就是中断处理程序，要尽可能快的执行完，这样可以减少对正常进程运行调度地影响</p>
</li>
<li><p>中断处理程序在响应中断时，可能还会「临时关闭中断」，这意味着，如果当前中断处理程序没有执行完之前，系统中其他的中断请求都无法被响应，也就说中断有可能会丢失，所以中断处理程序要短且快</p>
</li>
<li><p>Linux 系统<strong>为了解决中断处理程序执行过长和中断丢失的问题，将中断过程分成了两个阶段，分别是「上半部和下半部分」</strong>。</p>
<ul>
<li><strong>上半部直接处理硬件请求，也就是硬中断</strong>，主要是负责耗时短的工作，特点是快速执行；</li>
<li><strong>下半部是由内核触发，也就说软中断</strong>，主要是负责上半部未完成的工作，通常都是耗时比较长的事情，特点是延迟执行；</li>
</ul>
</li>
<li><p>如何定位软中断 CPU 使用率过高的问题？要想知道当前的系统的软中断情况，可以使用 <code>top</code> 命令查看，CPU 使用率最高的进程是软中断 <code>ksoftirqd</code>，可以认为此时系统的开销主要来源于软中断；如果要知道是哪种软中断类型导致的，我们可以使用 <code>watch -d cat /proc/softirqs</code> 命令查看每个软中断类型的中断次数的变化速率；一般来说都是因为网络接收软中断导致的，如果是的话，可以用 sar 命令查看是哪个网卡的有大量的网络包接收，再用 tcpdump 抓网络包，做进一步分析该网络包的源头是不是非法地址，如果是就需要考虑防火墙增加规则，如果不是，则考虑硬件升级等</p>
</li>
</ul>
<h3 id="2-7-为什么-0-1-0-2-不等于-0-3-？"><a href="#2-7-为什么-0-1-0-2-不等于-0-3-？" class="headerlink" title="2.7 为什么 0.1 + 0.2 不等于 0.3 ？"></a>2.7 为什么 0.1 + 0.2 不等于 0.3 ？</h3><ul>
<li><p>为什么负数要用补码表示？</p>
<ul>
<li>十进制数转二进制采用的是<strong>除 2 取余法</strong>，以 <code>int</code> 类型的数字作为例子，int 类型是 <code>32</code> 位的，其中<strong>最高位是作为「符号标志位」</strong>，正数的符号位是 <code>0</code>，负数的符号位是 <code>1</code>，<strong>剩余的 31 位则表示二进制数据</strong>；负数在计算机中是以「补码」表示的，<strong>所谓的补码就是把正数的二进制全部取反再加 1</strong></li>
<li>如果负数不是使用补码的方式表示，则在做基本对加减法运算的时候，<strong>还需要多一步操作来判断是否为负数，如果为负数，还得把加法反转成减法，或者把减法反转成加法</strong>，这就非常不好了，毕竟加减法运算在计算机里是很常使用的，所以为了性能考虑，应该要尽量简化这个运算过程</li>
<li><strong>用了补码的表示方式，对于负数的加减法操作，实际上是和正数加减法操作一样的</strong>。</li>
</ul>
</li>
<li><p>十进制小数与二进制的转换</p>
<ul>
<li>小数部分的转换采用的是<strong>乘 2 取整法</strong>，将十进制中的小数部分乘以 2 作为二进制的一位，然后继续取小数部分乘以 2 作为下一位，直到不存在小数为止；</li>
<li>不是所有小数都可以用二进制表示，<strong>由于计算机的资源是有限的，所以是没办法用二进制精确的表示 0.1，只能用「近似值」来表示，就是在有限的精度情况下，最大化接近 0.1 的二进制数，于是就会造成精度缺失的情况</strong></li>
<li>二进制小数转十进制时，需要注意一点，小数点后面的指数幂是<strong>负数</strong></li>
</ul>
</li>
<li><p>计算机是怎么存小数的</p>
<ul>
<li>计算机存储小数的采用的是<strong>浮点数</strong>，浮点表示小数点是可以浮动的，通常将 <code>1000.101</code> 这种二进制数，规格化表示成 <code>1.000101 x 2^3</code>，IEEE标准定义为三个部分：<ul>
<li><em>符号位</em>：表示数字是正数还是负数，为 0 表示正数，为 1 表示负数；</li>
<li><em>指数位</em>：指定了小数点在数据中的位置，指数可以是负数，也可以是正数，<strong>指数位的长度越长则数值的表达范围就越大</strong>；</li>
<li><em>尾数位</em>：小数点右侧的数字，也就是小数部分，比如二进制 1.0011 x 2^(-2)，尾数部分就是 0011，而且<strong>尾数的长度决定了这个数的精度</strong>，因此如果要表示精度更高的小数，则就要提高尾数位的长度；</li>
</ul>
</li>
<li>用 <code>32</code> 位来表示的浮点数，则称为<strong>单精度浮点数</strong>，也就是编程语言中的 <code>float</code> 变量，而用 <code>64</code> 位来表示的浮点数，称为<strong>双精度浮点数</strong>，也就是 <code>double</code> 变量<ul>
<li>double 的尾数部分是 52 位，float 的尾数部分是 23 位，由于同时都带有一个固定隐含位，所以 double 有 53 个二进制有效位，float 有 24 个二进制有效位，所以所以它们的精度在十进制中分别是 <code>log10(2^53)</code> 约等于 <code>15.95</code> 和 <code>log10(2^24)</code> 约等于 <code>7.22</code> 位，因此 double 的有效数字是 <code>15~16</code> 位，float 的有效数字是 <code>7~8</code> 位，这些有效位是包含整数部分和小数部分；</li>
<li>double 的指数部分是 11 位，而 float 的指数位是 8 位，意味着 double 相比 float 能表示更大的数值范围</li>
</ul>
</li>
<li>以 <code>10.625</code> 作为例子，看看这个数字在 float 里是如何存储的<ul>
<li>计算出 10.625 的二进制小数为 1010.101。</li>
<li>然后<strong>把小数点，移动到第一个有效数字后面</strong>，即将 1010.101 右移 <code>3</code> 位成 <code>1.010101</code>，右移 3 位就代表 +3，左移 3 位就是 -3。</li>
<li><strong>float 中的「指数位」就跟这里移动的位数有关系，把移动的位数再加上「偏移量」，float 的话偏移量是 127，相加后就是指数位的值了</strong>，即指数位这 8 位存的是 <code>10000010</code>（十进制 130），因此你可以认为「指数位」相当于指明了小数点在数据中的位置。</li>
<li><code>1.010101</code> 这个数的<strong>小数点右侧的数字就是 float 里的「尾数位」</strong>，由于尾数位是 23 位，则后面要补充 0，所以最终尾数位存储的数字是 <code>01010100000000000000000</code>。</li>
</ul>
</li>
<li>为什么要加上偏移量呢？指数可能是正数，也可能是负数，即指数是有符号的整数，而有符号整数的计算是比无符号整数麻烦的，所以为了减少不必要的麻烦，在实际存储指数的时候，需要把指数转换成<strong>无符号整数</strong>。</li>
<li>23 位尾数只存储小数部分，然后在计算时会<strong>自动把二进制浮点数的小数点左侧的 1 加上，这样就可以节约 1 位的空间，尾数就能多存一位小数，相应的精度就更高了一点</strong></li>
</ul>
</li>
<li><p><strong>在计算机中 0.1 + 0.2 并不等于完整的 0.3</strong>。这主要是<strong>因为有的小数无法可以用「完整」的二进制来表示，所以计算机里只能采用近似数的方式来保存，那两个近似数相加，得到的必然也是一个近似数</strong></p>
</li>
</ul>
<h3 id="3-1-Linux-内核-vs-Windows-内核"><a href="#3-1-Linux-内核-vs-Windows-内核" class="headerlink" title="3.1 Linux 内核 vs Windows 内核"></a>3.1 Linux 内核 vs Windows 内核</h3><ul>
<li><p>什么是内核呢？</p>
<ul>
<li>计算机是由各种外部硬件设备组成的，比如内存、cpu、硬盘等，如果每个应用都要和这些硬件设备对接通信协议，那这样太累了，所以这个中间人就由内核来负责，<strong>让内核作为应用连接硬件设备的桥梁</strong>，应用程序只需关心与内核交互，不用关心硬件的细节。</li>
</ul>
</li>
<li><p>内核有哪些能力呢？现代操作系统，内核一般会提供 4 个基本能力：</p>
<ul>
<li>管理进程、线程，决定哪个进程、线程使用 CPU，也就是进程调度的能力；</li>
<li>管理内存，决定内存的分配和回收，也就是内存管理的能力；</li>
<li>管理硬件设备，为进程与硬件设备之间提供通信能力，也就是硬件通信能力；</li>
<li>提供系统调用，如果应用程序要运行更高权限运行的服务，那么就需要有系统调用，它是用户程序与操作系统之间的接口</li>
</ul>
</li>
<li><p>内核是怎么工作的？</p>
<ul>
<li>内核具有很高的权限，可以控制 cpu、内存、硬盘等硬件，而应用程序具有的权限很小，因此大多数操作系统，把内存分成了两个区域：<ul>
<li>内核空间，这个内存空间只有内核程序可以访问；</li>
<li>用户空间，这个内存空间专门给应用程序使用；</li>
</ul>
</li>
<li>用户空间的代码只能访问一个局部的内存空间，而内核空间的代码可以访问所有内存空间。因此，当程序使用用户空间时，我们常说该程序在<strong>用户态</strong>执行，而当程序使内核空间时，程序则在<strong>内核态</strong>执行。</li>
<li>内核程序执行在内核态，用户程序执行在用户态。当应用程序使用系统调用时，会产生一个中断。发生中断后， CPU 会中断当前在执行的用户程序，转而跳转到中断处理程序，也就是开始执行内核程序。内核处理完后，主动触发中断，把 CPU 执行权限交回给用户程序，回到用户态继续工作。</li>
</ul>
</li>
<li><p>Linux 的设计</p>
<ul>
<li><em>MultiTask</em>，多任务</li>
<li><em>SMP</em>，对称多处理</li>
<li><em>ELF</em>，可执行文件链接格式</li>
<li><em>Monolithic Kernel</em>，宏内核</li>
</ul>
</li>
<li><p>Windows 的设计</p>
<ul>
<li>Windows 和 Linux 一样，同样支持 MultiTask 和 SMP，但不同的是，<strong>Window 的内核设计是混合型内核</strong>，在上图你可以看到内核中有一个 <em>MicroKernel</em> 模块，这个就是最小版本的内核，而整个内核实现是一个完整的程序，含有非常多模块。</li>
<li>Windows 的可执行文件的格式与 Linux 也不同，所以这两个系统的可执行文件是不可以在对方上运行的。</li>
<li>Windows 的可执行文件格式叫 PE，称为<strong>可移植执行文件</strong>，扩展名通常是<code>.exe</code>、<code>.dll</code>、<code>.sys</code>等。PE 与 ELF 结构有一点相似。</li>
</ul>
</li>
<li><p>对于内核的架构一般有这三种类型：</p>
<ul>
<li>宏内核，包含多个模块，整个内核像一个完整的程序；</li>
<li>微内核，有一个最小版本的内核，一些模块和服务则由用户态管理；</li>
<li>混合内核，是宏内核和微内核的结合体，内核中抽象出了微内核的概念，也就是内核中会有一个小型的内核，其他模块就在这个基础上搭建，整个内核是个完整的程序；</li>
</ul>
</li>
<li><p>Linux 的内核设计是采用了宏内核，Window 的内核设计则是采用了混合内核。这两个操作系统的可执行文件格式也不一样， Linux 可执行文件格式叫作 ELF，Windows 可执行文件格式叫作 PE。</p>
</li>
</ul>
<h3 id="4-1-为什么要有虚拟内存？"><a href="#4-1-为什么要有虚拟内存？" class="headerlink" title="4.1 为什么要有虚拟内存？"></a>4.1 为什么要有虚拟内存？</h3><ul>
<li><p>单片机是没有操作系统的，所以每次写完代码，都需要借助工具把程序烧录进去，这样程序才能跑起来；<strong>单片机的 CPU 是直接操作内存的「物理地址」</strong>，要想在内存中同时运行两个程序是不可能的；操作系统利用进程将所使用的地址「隔离」开来，为每个进程分配独立的一套「<strong>虚拟地址</strong>」，互不干涉，<strong>将不同进程的虚拟地址和不同内存的物理地址映射起来</strong>；如果程序要访问虚拟地址的时候，由操作系统转换成不同的物理地址，这样不同的进程运行的时候，写入的是不同的物理地址，这样就不会冲突了</p>
</li>
<li><p>程序所使用的内存地址叫做<strong>虚拟内存地址</strong>（<em>Virtual Memory Address</em>）；实际存在硬件里面的空间地址叫<strong>物理内存地址</strong>（<em>Physical Memory Address</em>）；操作系统引入了虚拟内存，进程持有的虚拟地址会通过 CPU 芯片中的内存管理单元（MMU）的映射关系，来转换变成物理地址，然后再通过物理地址访问内存</p>
</li>
<li><p>操作系统主要是通过<strong>内存分段和内存分页</strong>管理虚拟地址与物理地址之间的关系</p>
</li>
<li><p>内存分段：程序是由若干个逻辑分段组成的，如可由代码分段、数据分段、栈段、堆段组成。<strong>不同的段是有不同的属性的，所以就用分段（<em>Segmentation</em>）的形式把这些段分离出来</strong></p>
<ul>
<li>分段机制下的虚拟地址由两部分组成，<strong>段选择因子</strong>和<strong>段内偏移量</strong><ul>
<li><strong>段选择子</strong>就保存在段寄存器里面。段选择子里面最重要的是<strong>段号</strong>，用作段表的索引。<strong>段表</strong>里面保存的是这个<strong>段的基地址、段的界限和特权等级</strong>等。</li>
<li>虚拟地址中的<strong>段内偏移量</strong>应该位于 0 和段界限之间，如果段内偏移量是合法的，就将段基地址加上段内偏移量得到物理内存地址</li>
</ul>
</li>
<li>虚拟地址是通过<strong>段表</strong>与物理地址进行映射的，分段机制会把程序的虚拟地址分成 4 个段，每个段在段表中有一个项，在这一项找到段的基地址，再加上偏移量，于是就能找到物理内存中的地址</li>
<li>内存分段机制存在两个不足，分别是<strong>内存碎片</strong>和<strong>内存交换的效率低</strong>：<ul>
<li>内存碎片主要分为，内部内存碎片和外部内存碎片。内存分段管理可以做到段根据实际需求分配内存，所以有多少需求就分配多大的段，所以<strong>不会出现内部内存碎片</strong>。但是由于每个段的长度不固定，所以多个段未必能恰好使用所有的内存空间，会产生了多个不连续的小物理内存，导致新的程序无法被装载，所以<strong>会出现外部内存碎片</strong>的问题</li>
<li>解决「外部内存碎片」的问题就是<strong>内存交换</strong>，主要是利用内存交换空间（Linux 系统里的 Swap 空间），这块空间是从硬盘划分出来的，用于内存与硬盘的空间交换；对于多进程的系统来说，用分段的方式，外部内存碎片是很容易产生的，产生了外部内存碎片，那不得不重新 <code>Swap</code> 内存区域，这个过程会产生性能瓶颈，<strong>如果内存交换的时候，交换的是一个占内存空间很大的程序，这样整个机器都会显得卡顿</strong></li>
</ul>
</li>
</ul>
</li>
<li><p>内存分页：<strong>把整个虚拟和物理内存空间切成一段段固定尺寸的大小</strong>，也就是<strong>页</strong>（<em>Page</em>），在 Linux 下，每一页的大小为 <code>4KB</code>；虚拟地址与物理地址之间通过<strong>页表</strong>来映射，页表是存储在内存里的，<strong>内存管理单元</strong> （<em>MMU</em>）就做将虚拟内存地址转换成物理地址的工作；而当进程访问的虚拟地址在页表中查不到时，系统会产生一个<strong>缺页异常</strong>，进入系统内核空间分配物理内存、更新进程页表，最后再返回用户空间，恢复进程的运行</p>
<ul>
<li><p><strong>采用了分页，页与页之间是紧密排列的，所以不会有外部碎片</strong>；但是，因为内存分页机制分配内存的最小单位是一页，即使程序不足一页大小，最少只能分配一个页，所以页内会出现内存浪费，所以针对<strong>内存分页机制会有内部内存碎片</strong>的现象</p>
</li>
<li><p>如果内存空间不够，操作系统会把其他正在运行的进程中的「最近没被使用」的内存页面给释放掉，也就是暂时写在硬盘上，称为<strong>换出</strong>（<em>Swap Out</em>）。一旦需要的时候再加载进来，称为<strong>换入</strong>（<em>Swap In</em>）。所以，一次性写入磁盘的也只有少数的一个页或者几个页，不会花太多时间，<strong>内存交换的效率就相对比较高。</strong></p>
</li>
<li><p>分页的方式使得在加载程序的时候，不再需要一次性都把程序加载到物理内存中。只有在程序运行中，需要用到对应虚拟内存页里面的指令和数据时，再加载到物理内存</p>
</li>
<li><p>在分页机制下，虚拟地址分为两部分，<strong>页号</strong>和<strong>页内偏移</strong>。页号作为页表的索引，<strong>页表</strong>包含物理页每页所在<strong>物理内存的基地址</strong>，这个基地址与页内偏移的组合就形成了物理内存地址；对于一个内存地址转换，其实就是三个步骤：</p>
<ul>
<li>把虚拟内存地址，切分成页号和偏移量；</li>
<li>根据页号，从页表里面，查询对应的物理页号；</li>
<li>直接拿物理页号，加上前面的偏移量，就得到了物理内存地址。</li>
</ul>
</li>
<li><p>简单的分页有空间上的缺陷，因为操作系统是可以同时运行非常多的进程的，这就意味着页表会非常的庞大：32位环境下假设一个页的大小是 4KB，那么就需要大约 100 万个页，每个「页表项」需要 4 个字节大小来存储，那么整个 4GB 空间的映射就需要有 <code>4MB</code> 的内存来存储页表。而每个进程都是有自己的虚拟地址空间的，也就说都有自己的页表。<code>100</code> 个进程的话，就需要 <code>400MB</code> 内存来存储页表，这是非常大的内存了</p>
</li>
<li><p><strong>多级页表</strong>（<em>Multi-Level Page Table</em>）可以解决空间缺陷问题，将页表（一级页表）分为 <code>1024</code> 个页表（二级页表），每个表（二级页表）中包含 <code>1024</code> 个「页表项」，形成<strong>二级分页</strong>；一级页表就可以覆盖整个 4GB 虚拟地址空间，但<strong>如果某个一级页表的页表项没有被用到，也就不需要创建这个页表项对应的二级页表了，即可以在需要时才创建二级页表</strong>；页表一定要覆盖全部虚拟地址空间，不分级的页表就需要有 100 多万个页表项来映射，而二级分页则只需要 1024 个页表项</p>
</li>
<li><p>多级页表虽然解决了空间上的问题，但是虚拟地址到物理地址的转换就多了几道转换的工序，这显然就降低了这俩地址转换的速度，也就是带来了时间上的开销，程序是有局部性的，即在一段时间内，整个程序的执行仅限于程序中的某一部分。相应地，执行所访问的存储空间也局限于某个内存区域，可以利用这一特性，把最常访问的几个页表项存储到访问速度更快的硬件。CPU 芯片中加入了一个专门存放程序最常访问的页表项的 Cache，这个 Cache 就是 TLB（<em>Translation Lookaside Buffer</em>） ，通常称为页表缓存、转址旁路缓存、快表等；在 CPU 芯片里面，封装了内存管理单元（<em>Memory Management Unit</em>）芯片，它用来完成地址转换和 TLB 的访问与交互。有了 TLB 后，那么 CPU 在寻址时，会先查 TLB，如果没找到，才会继续查常规的页表。TLB 的命中率其实是很高的，因为程序最常访问的页就那么几个</p>
</li>
</ul>
</li>
<li><p>段页式内存管理：内存分段和内存分页并不是对立的，它们是可以组合起来在同一个系统中使用的，那么组合起来后，通常称为<strong>段页式内存管理</strong>：</p>
<ul>
<li>先将程序划分为多个有逻辑意义的段，也就是前面提到的分段机制；接着再把每个段划分为多个页，也就是对分段划分出来的连续空间，再划分固定大小的页；地址结构就由<strong>段号、段内页号和页内位移</strong>三部分组成。用于段页式地址变换的数据结构是每一个程序一张段表，每个段又建立一张页表，段表中的地址是页表的起始地址，而页表中的地址则为某页的物理页号</li>
<li>段页式地址变换中要得到物理地址须经过三次内存访问：<ul>
<li>第一次访问段表，得到页表起始地址；</li>
<li>第二次访问页表，得到物理页号；</li>
<li>第三次将物理页号与页内位移组合，得到物理地址。</li>
</ul>
</li>
</ul>
</li>
<li><p>Linux 内存管理</p>
<ul>
<li><p>程序所使用的地址，通常是没被段式内存管理映射的地址，称为逻辑地址；通过段式内存管理映射的地址，称为线性地址，也叫虚拟地址；逻辑地址是「段式内存管理」转换前的地址，线性地址则是「页式内存管理」转换前的地址</p>
</li>
<li><p><strong>Linux 内存主要采用的是页式内存管理，但同时也不可避免地涉及了段机制</strong>；Linux 系统中的每个段都是从 0 地址开始的整个 4GB 虚拟空间（32 位环境下）这意味着Linux 系统中的代码，包括操作系统本身的代码和应用程序代码，所面对的地址空间都是线性地址空间（虚拟地址），这种做法相当于屏蔽了处理器中的逻辑地址概念，段只被用于访问控制和内存保护</p>
</li>
<li><p>在 Linux 操作系统中，虚拟地址空间的内部又被分为<strong>内核空间和用户空间</strong>两部分，不同位数的系统，地址空间的范围也不同</p>
<ul>
<li><code>32</code> 位系统的内核空间占用 <code>1G</code>，位于最高处，剩下的 <code>3G</code> 是用户空间；</li>
<li><code>64</code> 位系统的内核空间和用户空间都是 <code>128T</code>，分别占据整个内存空间的最高和最低处，剩下的中间部分是未定义的</li>
</ul>
</li>
<li><p>进程在用户态时，只能访问用户空间内存；只有进入内核态后，才可以访问内核空间的内存；虽然每个进程都各自有独立的虚拟内存，但是<strong>每个虚拟内存中的内核地址，其实关联的都是相同的物理内存</strong></p>
</li>
<li><p>用户空间内存，从<strong>低到高</strong>分别是 6 种不同的内存段：</p>
<ul>
<li>程序文件段（.text），包括二进制可执行代码；</li>
<li>已初始化数据段（.data），包括静态常量；</li>
<li>未初始化数据段（.bss），包括未初始化的静态变量；</li>
<li>堆段，包括动态分配的内存，从低地址开始向上增长；</li>
<li>文件映射段，包括动态库、共享内存等，从低地址开始向上增长</li>
<li>栈段，包括局部变量和函数调用的上下文等。栈的大小是固定的，一般是 <code>8 MB</code>。当然系统也提供了参数，以便我们自定义大小；</li>
</ul>
<p>堆和文件映射段的内存是动态分配的。比如说，使用 C 标准库的 <code>malloc()</code> 或者 <code>mmap()</code> ，就可以分别在堆和文件映射段动态分配内存</p>
</li>
</ul>
</li>
<li><p>说下虚拟内存有什么作用？</p>
<ul>
<li>第一，虚拟内存可以使得进程对运行内存超过物理内存大小，因为程序运行符合局部性原理，CPU 访问内存会有很明显的重复访问的倾向性，对于那些没有被经常使用到的内存，我们可以把它换出到物理内存之外，比如硬盘上的 swap 区域。</li>
<li>第二，由于每个进程都有自己的页表，所以每个进程的虚拟内存空间就是相互独立的。进程也没有办法访问其他进程的页表，所以这些页表是私有的，这就解决了多进程之间地址冲突的问题。</li>
<li>第三，页表里的页表项中除了物理地址之外，还有一些标记属性的比特，比如控制一个页的读写权限，标记该页是否存在等。在内存访问方面，操作系统提供了更好的安全性</li>
</ul>
</li>
</ul>
<h3 id="4-2-malloc-是如何分配内存的？"><a href="#4-2-malloc-是如何分配内存的？" class="headerlink" title="4.2 malloc 是如何分配内存的？"></a>4.2 malloc 是如何分配内存的？</h3><ul>
<li><p>内核空间与用户空间的区别：</p>
<ul>
<li>进程在用户态时，只能访问用户空间内存；</li>
<li>只有进入内核态后，才可以访问内核空间的内存；</li>
</ul>
</li>
<li><p>虽然每个进程都各自有独立的虚拟内存，但是<strong>每个虚拟内存中的内核地址，其实关联的都是相同的物理内存</strong>。这样，进程切换到内核态后，就可以很方便地访问内核空间内存。</p>
</li>
<li><p>malloc 是如何分配内存的？</p>
<ul>
<li>如果用户分配的内存小于 128 KB，则通过 brk() 申请内存；brk() 函数将「堆顶」指针向高地址移动，获得新的内存空间</li>
<li>如果用户分配的内存大于 128 KB，则通过 mmap() 申请内存；mmap() 系统调用中「私有匿名映射」的方式，在文件映射区分配一块内存，也就是从文件映射区“偷”了一块内存</li>
</ul>
</li>
<li><p>malloc() 分配的是物理内存吗？</p>
<ul>
<li><strong>malloc() 分配的是虚拟内存</strong>。如果分配后的虚拟内存没有被访问的话，虚拟内存是不会映射到物理内存的，这样就不会占用物理内存了。</li>
<li>只有在访问已分配的虚拟地址空间的时候，操作系统通过查找页表，发现虚拟内存对应的页没有在物理内存中，就会触发缺页中断，然后操作系统会建立虚拟内存和物理内存之间的映射关系</li>
</ul>
</li>
<li><p>malloc(1) 会分配多大的虚拟内存？</p>
<ul>
<li>malloc() 在分配内存的时候，会预分配更大的空间作为内存池，<strong>malloc(1) 实际上预分配 132K 字节的内存</strong>。</li>
<li>malloc 返回给用户态的内存起始地址比进程的堆空间起始地址多了 16 字节，保存了该内存块的描述信息，比如有该内存块的大小；当执行 free() 函数时，free 会对传入进来的内存地址向左偏移 16 字节，然后从这个 16 字节的分析出当前的内存块的大小</li>
</ul>
</li>
<li><p>free 释放内存，会归还给操作系统吗？</p>
<ul>
<li>malloc 通过 <strong>brk()</strong> 方式申请的内存，free 释放内存的时候，<strong>并不会把内存归还给操作系统，而是缓存在 malloc 的内存池中，待下次使用</strong>；</li>
<li>malloc 通过 <strong>mmap()</strong> 方式申请的内存，free 释放内存的时候，<strong>会把内存归还给操作系统，内存得到真正的释放</strong></li>
</ul>
</li>
<li><p>为什么不全部使用 mmap 来分配内存？</p>
<ul>
<li>向操作系统申请内存，是要通过系统调用的，执行系统调用是要进入内核态的，然后在回到用户态，运行态的切换会耗费不少时间。申请内存的操作应该避免频繁的系统调用，如果都用 mmap 来分配内存，等于每次都要执行系统调用</li>
<li>另外，因为 mmap 分配的内存每次释放的时候，都会归还给操作系统，于是每次 mmap 分配的虚拟地址都是缺页状态的，然后在第一次访问该虚拟地址的时候，就会触发缺页中断；<strong>频繁通过 mmap 分配的内存话，不仅每次都会发生运行态的切换，还会发生缺页中断（在第一次访问虚拟地址后），这样会导致 CPU 消耗较大</strong></li>
<li>malloc 通过 brk() 系统调用在堆空间申请内存的时候，由于堆空间是连续的，所以直接预分配更大的内存来作为内存池，当内存释放的时候，就缓存在内存池中;<strong>下次在申请内存的时候，就直接从内存池取出对应的内存块就行了，而且可能这个内存块的虚拟地址与物理地址的映射关系还存在，这样不仅减少了系统调用的次数，也减少了缺页中断的次数，这将大大降低 CPU 的消耗</strong></li>
</ul>
</li>
<li><p>既然 brk 那么牛逼，为什么不全部使用 brk 来分配？</p>
<ul>
<li>随着系统频繁地 malloc 和 free ，尤其对于小块内存，堆内将产生越来越多不可用的碎片，导致“内存泄露”;所以，malloc 实现中，充分考虑了 brk 和 mmap 行为上的差异及优缺点，默认分配大块内存 (128KB) 才使用 mmap 分配内存空间</li>
</ul>
</li>
</ul>
<h3 id="4-3-内存满了，会发生什么？"><a href="#4-3-内存满了，会发生什么？" class="headerlink" title="4.3 内存满了，会发生什么？"></a>4.3 内存满了，会发生什么？</h3><ul>
<li><p>内存分配的过程是怎样的？</p>
<ul>
<li>应用程序通过 malloc 函数申请内存的时候，实际上申请的是虚拟内存，此时并不会分配物理内存。当应用程序读写了这块虚拟内存，CPU 就会去访问这个虚拟内存， 这时会发现这个虚拟内存没有映射到物理内存， CPU 就会产生<strong>缺页中断</strong>，进程会从用户态切换到内核态，并将缺页中断交给内核的 Page Fault Handler （缺页中断函数）处理</li>
<li>缺页中断处理函数会看是否有空闲的物理内存，如果有，就直接分配物理内存，并建立虚拟内存与物理内存之间的映射关系。如果没有，那么内核就会开始进行<strong>回收内存</strong>的工作，回收的方式主要是两种：直接内存回收和后台内存回收</li>
<li><strong>后台内存回收</strong>（kswapd）：在物理内存紧张的时候，会唤醒 kswapd 内核线程来回收内存，这个回收内存的过程<strong>异步</strong>的，不会阻塞进程的执行。</li>
<li><strong>直接内存回收</strong>（direct reclaim）：如果后台异步回收跟不上进程内存申请的速度，就会开始直接回收，这个回收内存的过程是<strong>同步</strong>的，会阻塞进程的执行。</li>
<li>如果直接内存回收后，空闲的物理内存仍然无法满足此次物理内存的申请，那么内核就会放最后的大招了 ——<strong>触发 OOM （Out of Memory）机制</strong>：根据算法选择一个占用物理内存较高的进程，然后将其杀死，以便释放内存资源，如果物理内存依然不足，OOM Killer 会继续杀死占用物理内存较高的进程，直到释放足够的内存位置</li>
</ul>
</li>
<li><p>哪些内存可以被回收</p>
<ul>
<li><strong>文件页</strong>（File-backed Page）：内核缓存的磁盘数据（Buffer）和内核缓存的文件数据（Cache）都叫作文件页。<strong>回收干净页的方式是直接释放内存，回收脏页的方式是先写回磁盘后再释放内存。</strong></li>
<li><strong>匿名页</strong>（Anonymous Page）：这部分内存没有实际载体，不像文件缓存有硬盘文件这样一个载体，比如堆、栈数据等。这部分内存很可能还要再次被访问，所以不能直接释放内存，它们<strong>回收的方式是通过 Linux 的 Swap 机制</strong>，Swap 会把不常访问的内存先写到磁盘中，然后释放这些内存，给其他更需要的进程使用。再次访问这些内存时，重新从磁盘读入内存就可以了</li>
<li>文件页和匿名页的回收都是基于 LRU 算法，也就是优先回收不常访问的内存。LRU 回收算法，实际上维护着 active 和 inactive 两个双向链表，其中：<ul>
<li><strong>active_list</strong> 活跃内存页链表，这里存放的是最近被访问过（活跃）的内存页；</li>
<li><strong>inactive_list</strong> 不活跃内存页链表，这里存放的是很少被访问（非活跃）的内存页</li>
</ul>
</li>
</ul>
</li>
<li><p>回收内存带来的性能影响</p>
<ul>
<li><p>回收内存的操作基本都会发生磁盘 I&#x2F;O 的，如果回收内存的操作很频繁，意味着磁盘 I&#x2F;O 次数会很多，这个过程势必会影响系统的性能，整个系统给人的感觉就是很卡</p>
</li>
<li><p>调整文件页和匿名页的回收倾向（swappiness ）：文件页的回收操作对系统的影响相比匿名页的回收操作会少一点，因为文件页对于干净页回收是不会发生磁盘 I&#x2F;O 的，而匿名页的 Swap 换入换出这两个操作都会发生磁盘 I&#x2F;O。</p>
</li>
<li><p>尽早触发 kswapd 内核线程异步回收内存（min_free_kbytes）：内核定义了三个内存阈值（watermark，也称为水位），用来衡量当前剩余内存（pages_free）是否充裕或者紧张，分别是：</p>
</li>
<li><p>页最小阈值（pages_min）；</p>
</li>
<li><p>页低阈值（pages_low）；</p>
</li>
<li><p>页高阈值（pages_high）；</p>
</li>
</ul>
<p>  当剩余内存页（pages_free）小于页低阈值（pages_low），就会触发 kswapd 进行后台回收，然后 kswapd 会一直回收到剩余内存页（pages_free）大于页高阈值（pages_high）</p>
</li>
<li><p>如何保护一个进程不被 OOM 杀掉呢？</p>
<ul>
<li>Linux 内核里有一个 <code>oom_badness()</code> 函数，它会把系统中可以被杀掉的进程扫描一遍，并对每个进程打分，得分最高的进程就会被首先杀掉，<strong>用「系统总的可用页面数」乘以 「OOM 校准值 oom_score_adj」再除以 1000，最后再加上进程已经使用的物理页面数，计算出来的值越大，那么这个进程被 OOM Kill 的几率也就越大</strong>。</li>
</ul>
</li>
</ul>
<h3 id="4-4-在-4GB-物理内存的机器上，申请-8G-内存会怎么样？"><a href="#4-4-在-4GB-物理内存的机器上，申请-8G-内存会怎么样？" class="headerlink" title="4.4 在 4GB 物理内存的机器上，申请 8G 内存会怎么样？"></a>4.4 在 4GB 物理内存的机器上，申请 8G 内存会怎么样？</h3><ul>
<li>回答这个问题需要考虑三个前置条件，操作系统是 32 位的，还是 64 位的？申请完 8G 内存后会不会被使用？操作系统有没有使用 Swap 机制？</li>
<li>32 位操作系统和 64 位操作系统的虚拟地址空间大小是不同的，在 Linux 操作系统中，虚拟地址空间的内部又被分为<strong>内核空间和用户空间</strong>两部分，32位具有4G虚拟内存，64位内核空间和用户空间都是 <code>128T</code>，分别占据整个内存空间的最高和最低处，剩下的中间部分是未定义的</li>
<li>32 位操作系统，进程最多只能申请 3 GB 大小的虚拟内存空间，所以进程申请 8GB 内存的话，在申请虚拟内存阶段就会失败；64 位操作系统，进程可以使用 128 TB 大小的虚拟内存空间，所以进程申请 8GB 内存是没问题的，因为进程申请内存是申请虚拟内存，只要不读写这个虚拟内存，操作系统就不会分配物理内存</li>
<li>当系统的物理内存不够用的时候（内存闲置或者内存不足触发了内存回收行为），就需要将物理内存中的一部分空间释放出来，以供当前运行的程序使用。将内存数据换出磁盘，又从磁盘中恢复数据到内存的过程，就是 Swap 机制（换入换出）负责的。使用 Swap 机制优点是，应用程序实际可以使用的内存空间将远远超过系统的物理内存。Swap 换入换出的是像进程的堆、栈数据等这些没有实际载体的匿名页内存</li>
<li>对于没有开启SWAP机制的操作系统来说，当内存不足时会直接出发OOM，该进程会被操作系统 OOM killer 机制杀掉；但是有了 Swap 分区，也不意味着进程可以使用的内存是无上限的，当系统多次尝试回收内存，还是无法满足所需使用的内存大小，进程就会被系统 kill 掉了，意味着发生了 OOM</li>
</ul>
<h3 id="4-5-如何避免预读失效和缓存污染的问题？"><a href="#4-5-如何避免预读失效和缓存污染的问题？" class="headerlink" title="4.5 如何避免预读失效和缓存污染的问题？"></a>4.5 如何避免预读失效和缓存污染的问题？</h3><ul>
<li>传统的 LRU 算法存在这两个问题：<strong>「预读失效」导致缓存命中率下降</strong>；<strong>「缓存污染」导致缓存命中率下降</strong></li>
<li>Redis 的缓存淘汰算法则是通过<strong>实现 LFU 算法</strong>来避免「缓存污染」而导致缓存命中率下降的问题（Redis 没有预读机制）。MySQL 和 Linux 操作系统是通过<strong>改进 LRU 算法</strong>来避免「预读失效和缓存污染」而导致缓存命中率下降的问题</li>
<li>MySQL 和 Linux 操作系统利用了类似的思想解决预读失效的问题，都是将数据分为了冷数据和热数据，然后分别进行 LRU 算法；Linux 操作系统实现两个了 LRU 链表：<strong>活跃 LRU 链表（active_list）和非活跃 LRU 链表（inactive_list）</strong>。MySQL 的 Innodb 存储引擎是在一个 LRU 链表上划分来 2 个区域，<strong>young 区域 和 old 区域</strong>，划分这两个区域后，预读的页就只需要加入到 old 区域的头部，当页被真正访问的时候，才将页插入 young 区域的头部</li>
<li>批量读取数据的时候，由于数据被访问了一次，这些大量数据都会被加入到「活跃 LRU 链表」里，然后之前缓存在活跃 LRU 链表（或者 young 区域）里的热点数据全部都被淘汰了，<strong>如果这些大量的数据在很长一段时间都不会被访问的话，那么整个活跃 LRU 链表（或者 young 区域）就被污染了</strong></li>
<li>针对缓存污染的问题，提高进入到活跃 LRU 链表（或者 young 区域）的门槛，就能有效地保证活跃 LRU 链表（或者 young 区域）里的热点数据不会被轻易替换掉，比如MySQL Innodb在内存页被访问第二次的时候，并不会马上将该页从 old 区域升级到 young 区域，因为还要进行停留在 old 区域的时间判断</li>
</ul>
<h3 id="5-1-进程、线程基础知识"><a href="#5-1-进程、线程基础知识" class="headerlink" title="5.1 进程、线程基础知识"></a>5.1 进程、线程基础知识</h3><h4 id="进程"><a href="#进程" class="headerlink" title="进程"></a>进程</h4><ul>
<li><p>编写的代码只是一个存储在硬盘的静态文件，通过编译后就会生成二进制可执行文件，当我们运行这个可执行文件后，它会被装载到内存中，接着 CPU 会执行程序中的每一条指令，那么这个<strong>运行中的程序，就被称为「进程」（Process）</strong></p>
</li>
<li><p>当进程要从硬盘读取数据时，CPU 不需要阻塞等待数据的返回，而是去执行另外的进程。当硬盘数据返回时，CPU 会收到个<strong>中断</strong>，于是 CPU 再继续运行这个进程；<strong>多个程序、交替执行</strong>；对于一个支持多进程的系统，CPU 会从一个进程快速切换至另一个进程，其间每个进程各运行几十或几百个毫秒，产生<strong>并行的错觉</strong>，实际上这是<strong>并发</strong></p>
</li>
<li><p>进程的状态：一个进程并不是自始至终连续不停地运行的，它与并发执行中的其他进程的执行是相互制约的，<strong>在一个进程的活动期间至少具备三种基本状态，即运行状态、就绪状态、阻塞状态。</strong>进程还有另外两个基本状态：</p>
<ul>
<li>创建状态（<em>new</em>）：进程正在被创建时的状态；</li>
<li>结束状态（<em>Exit</em>）：进程正在从系统中消失时的状态；</li>
</ul>
<p>如果有大量处于阻塞状态的进程，进程可能会占用着物理内存空间，在虚拟内存管理的操作系统中，通常会把阻塞状态的进程的物理内存空间换出到硬盘，等需要再次运行的时候，再从硬盘换入到物理内存；就需要一个新的状态，来<strong>描述进程没有占用实际的物理内存空间的情况，这个状态就是挂起状态</strong>。挂起状态可以分为两种：</p>
<ul>
<li>阻塞挂起状态：进程在外存（硬盘）并等待某个事件的出现；</li>
<li>就绪挂起状态：进程在外存（硬盘），但只要进入内存，即刻立刻运行；</li>
</ul>
<p>导致进程挂起的原因不只是因为进程所使用的内存空间不在物理内存，还包括如下情况：</p>
<ul>
<li>通过 sleep 让进程间歇性挂起，其工作原理是设置一个定时器，到期后唤醒进程。</li>
<li>用户希望挂起一个程序的执行，比如在 Linux 中用 <code>Ctrl+Z</code> 挂起进程</li>
</ul>
</li>
<li><p>进程的控制结构：在操作系统中，是用<strong>进程控制块</strong>（<em>process control block，PCB</em>）数据结构来描述进程的。<strong>PCB 是进程存在的唯一标识</strong>，这意味着一个进程的存在，必然会有一个 PCB，如果进程消失了，那么 PCB 也会随之消失。</p>
<ul>
<li><p>PCB 具体包含什么信息呢？</p>
<p><strong>进程描述信息：</strong></p>
<ul>
<li>进程标识符：标识各个进程，每个进程都有一个并且唯一的标识符；</li>
<li>用户标识符：进程归属的用户，用户标识符主要为共享和保护服务；</li>
</ul>
<p><strong>进程控制和管理信息：</strong></p>
<ul>
<li>进程当前状态，如 new、ready、running、waiting 或 blocked 等；</li>
<li>进程优先级：进程抢占 CPU 时的优先级；</li>
</ul>
<p><strong>资源分配清单：</strong></p>
<ul>
<li>有关内存地址空间或虚拟地址空间的信息，所打开文件的列表和所使用的 I&#x2F;O 设备信息。</li>
</ul>
<p><strong>CPU 相关信息：</strong></p>
<ul>
<li>CPU 中各个寄存器的值，当进程被切换时，CPU 的状态信息都会被保存在相应的 PCB 中，以便进程重新执行时，能从断点处继续执行。</li>
</ul>
</li>
<li><p>每个 PCB 是如何组织的呢？</p>
<p>通常是通过<strong>链表</strong>的方式进行组织，把具有<strong>相同状态的进程链在一起，组成各种队列</strong>。比如：</p>
<ul>
<li>将所有处于就绪状态的进程链在一起，称为<strong>就绪队列</strong>；</li>
<li>把所有因等待某事件而处于等待状态的进程链在一起就组成各种<strong>阻塞队列</strong>；</li>
<li>另外，对于运行队列在单核 CPU 系统中则只有一个运行指针了，因为单核 CPU 在某个时间，只能运行一个程序。</li>
</ul>
</li>
</ul>
</li>
<li><p>进程的控制：进程的<strong>创建、终止、阻塞、唤醒</strong>的过程</p>
<ul>
<li><strong>创建进程</strong>：操作系统允许一个进程创建另一个进程，而且允许子进程继承父进程所拥有的资源。<ul>
<li>申请一个空白的 PCB，并向 PCB 中填写一些控制和管理进程的信息，比如进程的唯一标识等；</li>
<li>为该进程分配运行时所必需的资源，比如内存资源；</li>
<li>将 PCB 插入到就绪队列，等待被调度运行；</li>
</ul>
</li>
<li><strong>终止进程</strong>：进程可以有 3 种终止方式：正常结束、异常结束以及外界干预（信号 <code>kill</code> 掉）。<ul>
<li>查找需要终止的进程的 PCB；</li>
<li>如果处于执行状态，则立即终止该进程的执行，然后将 CPU 资源分配给其他进程；</li>
<li>如果其还有子进程，则应将该进程的子进程交给 1 号进程接管；</li>
<li>将该进程所拥有的全部资源都归还给操作系统；</li>
<li>将其从 PCB 所在队列中删除；</li>
</ul>
</li>
<li><strong>阻塞进程</strong>：当进程需要等待某一事件完成时，它可以调用阻塞语句把自己阻塞等待。而一旦被阻塞等待，它只能由另一个进程唤醒。<ul>
<li>找到将要被阻塞进程标识号对应的 PCB；</li>
<li>如果该进程为运行状态，则保护其现场，将其状态转为阻塞状态，停止运行；</li>
<li>将该 PCB 插入到阻塞队列中去；</li>
</ul>
</li>
<li><strong>唤醒进程</strong>：进程由「运行」转变为「阻塞」状态是由于进程必须等待某一事件的完成，处于阻塞状态的进程是绝对不可能叫醒自己的。<ul>
<li>在该事件的阻塞队列中找到相应进程的 PCB；</li>
<li>将其从阻塞队列中移出，并置其状态为就绪状态；</li>
<li>把该 PCB 插入到就绪队列中，等待调度程序调度；</li>
</ul>
</li>
</ul>
</li>
<li><p>进程的上下文切换：各个进程之间是共享 CPU 资源的，在不同的时候进程之间需要切换，让不同的进程可以在 CPU 执行，那么这个<strong>一个进程切换到另一个进程运行，称为进程的上下文切换</strong>。</p>
<ul>
<li><p>CPU 上下文切换：</p>
</li>
<li><p>CPU 寄存器是 CPU 内部一个容量小，但是速度极快的内存（缓存）。</p>
</li>
<li><p>程序计数器则是用来存储 CPU 正在执行的指令位置、或者即将执行的下一条指令位置。</p>
</li>
</ul>
<p>  CPU 寄存器和程序计数是 CPU 在运行任何任务前，所必须依赖的环境，这些环境就叫做 <strong>CPU 上下文</strong></p>
<ul>
<li><p>CPU 上下文切换就是先把前一个任务的 CPU 上下文（CPU 寄存器和程序计数器）保存起来，然后加载新任务的上下文到这些寄存器和程序计数器，最后再跳转到程序计数器所指的新位置，运行新任务;「任务」主要包含进程、线程和中断。</p>
</li>
<li><p>进程是由内核管理和调度的，所以进程的切换只能发生在内核态。<strong>进程的上下文切换不仅包含了虚拟内存、栈、全局变量等用户空间的资源，还包括了内核堆栈、寄存器等内核空间的资源。</strong>通常，会把交换的信息保存在进程的 PCB，当要运行另外一个进程的时候，我们需要从这个进程的 PCB 取出上下文，然后恢复到 CPU 中，这使得这个进程可以继续执行</p>
</li>
<li><p>发生进程上下文切换有哪些场景？</p>
<ul>
<li>为了保证所有进程可以得到公平调度，CPU 时间被划分为一段段的时间片，这些时间片再被轮流分配给各个进程。</li>
<li>进程在系统资源不足（比如内存不足）时，要等到资源满足后才可以运行，这个时候进程也会被挂起，并由系统调度其他进程运行；</li>
<li>当进程通过睡眠函数 sleep 这样的方法将自己主动挂起时，自然也会重新调度；</li>
<li>当有优先级更高的进程运行时，为了保证高优先级进程的运行，当前进程会被挂起，由高优先级进程来运行；</li>
<li>发生硬件中断时，CPU 上的进程会被中断挂起，转而执行内核中的中断服务程序；</li>
</ul>
</li>
</ul>
</li>
</ul>
<h4 id="线程"><a href="#线程" class="headerlink" title="线程"></a>线程</h4><ul>
<li><p>多进程的这种方式，依然会存在问题：</p>
<ul>
<li>进程之间如何通信，共享数据？</li>
<li>维护进程的系统开销较大，如创建进程时，分配资源、建立 PCB；终止进程时，回收资源、撤销 PCB；进程切换时，保存当前进程的状态信息；</li>
</ul>
<p>需要有一种新的实体，满足以下特性：</p>
<ul>
<li>实体之间可以并发运行；</li>
<li>实体之间共享相同的地址空间；</li>
</ul>
<p>这个新的实体，就是**线程( <em>Thread</em> )**，线程之间可以并发运行且共享相同的地址空间</p>
</li>
<li><p>什么是线程？<strong>线程是进程当中的一条执行流程。</strong>同一个进程内多个线程之间可以共享代码段、数据段、打开的文件等资源，但每个线程各自都有一套独立的寄存器和栈，这样可以确保线程的控制流是相对独立的。</p>
</li>
<li><p>线程的优缺点？</p>
<p>线程的优点：</p>
<ul>
<li>一个进程中可以同时存在多个线程；</li>
<li>各个线程之间可以并发执行；</li>
<li>各个线程之间可以共享地址空间和文件等资源；</li>
</ul>
<p>线程的缺点：</p>
<ul>
<li>当进程中的一个线程崩溃时，会导致其所属进程的所有线程崩溃（这里是针对 C&#x2F;C++ 语言，Java语言中的线程奔溃不会造成进程崩溃</li>
</ul>
</li>
<li><p>线程与进程的比较如下：</p>
<ul>
<li>进程是资源（包括内存、打开的文件等）分配的单位，线程是 CPU 调度的单位；</li>
<li>进程拥有一个完整的资源平台，而线程只独享必不可少的资源，如寄存器和栈；</li>
<li>线程同样具有就绪、阻塞、执行三种基本状态，同样具有状态之间的转换关系；</li>
<li>线程能减少并发执行的时间和空间开销；</li>
</ul>
<p>对于，线程相比进程能减少开销，体现在：</p>
<ul>
<li>线程的创建时间比进程快，因为进程在创建的过程中，还需要资源管理信息，比如内存管理信息、文件管理信息，而线程在创建的过程中，不会涉及这些资源管理信息，而是共享它们；</li>
<li>线程的终止时间比进程快，因为线程释放的资源相比进程少很多；</li>
<li>同一个进程内的线程切换比进程切换快，因为线程具有相同的地址空间（虚拟内存共享），这意味着同一个进程的线程都具有同一个页表，那么在切换的时候不需要切换页表。而对于进程之间的切换，切换的时候要把页表给切换掉，而页表的切换过程开销是比较大的；</li>
<li>由于同一进程的各线程间共享内存和文件资源，那么在线程之间数据传递的时候，就不需要经过内核了，这就使得线程之间的数据交互效率更高了；</li>
</ul>
</li>
<li><p>操作系统的任务调度，实际上的调度对象是线程，而进程只是给线程提供了虚拟内存、全局变量等资源。</p>
<ul>
<li>当进程只有一个线程时，可以认为进程就等于线程；</li>
<li>当进程拥有多个线程时，这些线程会共享相同的虚拟内存和全局变量等资源，这些资源在上下文切换时是不需要修改的；</li>
</ul>
</li>
<li><p>线程上下文切换的是什么？</p>
<ul>
<li>当两个线程不是属于同一个进程，则切换的过程就跟进程上下文切换一样；</li>
<li><strong>当两个线程是属于同一个进程，因为虚拟内存是共享的，所以在切换时，虚拟内存这些资源就保持不动，只需要切换线程的私有数据、寄存器等不共享的数据</strong>；</li>
</ul>
</li>
<li><p>主要有三种线程的实现方式：</p>
<ul>
<li><strong>用户线程</strong>：在用户空间实现的线程，不是由内核管理的线程，是由用户态的线程库来完成线程的管理；<ul>
<li>每个进程都需要有它私有的线程控制块（TCB）列表，用来跟踪记录它各个线程状态信息，TCB 由用户级线程库函数来维护，可用于不支持线程技术的操作系统；</li>
<li>用户线程的切换也是由线程库函数来完成的，无需用户态与内核态的切换，所以速度特别快；</li>
<li>由于操作系统不参与线程的调度，如果一个线程发起了系统调用而阻塞，那进程所包含的用户线程都不能执行了。</li>
<li>当一个线程开始运行后，除非它主动地交出 CPU 的使用权，否则它所在的进程当中的其他线程无法运行，因为用户态的线程没法打断当前运行中的线程，它没有这个特权，只有操作系统才有，但是用户线程不是由操作系统管理的。</li>
<li>由于时间片分配给进程，故与其他进程比，在多线程执行时，每个线程得到的时间片较少，执行会比较慢；</li>
</ul>
</li>
<li><strong>内核线程</strong>：<strong>由操作系统管理的，线程对应的 TCB 自然是放在操作系统里的，这样线程的创建、终止和管理都是由操作系统负责</strong><ul>
<li>在一个进程当中，如果某个内核线程发起系统调用而被阻塞，并不会影响其他内核线程的运行；</li>
<li>分配给线程，多线程的进程获得更多的 CPU 运行时间；</li>
<li>在支持内核线程的操作系统中，由内核来维护进程和线程的上下文信息，如 PCB 和 TCB；</li>
<li>线程的创建、终止和切换都是通过系统调用的方式来进行，因此对于系统来说，系统开销比较大；</li>
</ul>
</li>
<li><strong>轻量级进程</strong>：在内核中来支持用户线程；<strong>一个进程可有一个或多个 LWP，每个 LWP 是跟内核线程一对一映射的，也就是 LWP 都是由一个内核线程支持，而且 LWP 是由内核管理并像普通进程一样被调度</strong></li>
</ul>
</li>
</ul>
<h4 id="调度"><a href="#调度" class="headerlink" title="调度"></a>调度</h4><ul>
<li><p>如果硬件时钟提供某个频率的周期性中断，那么可以根据如何处理时钟中断 ，把调度算法分为两类：</p>
<ul>
<li><strong>非抢占式调度算法</strong>挑选一个进程，然后让该进程运行直到被阻塞，或者直到该进程退出，才会调用另外一个进程，也就是说不会理时钟中断这个事情。</li>
<li><strong>抢占式调度算法</strong>挑选一个进程，然后让该进程只运行某段时间，如果在该时段结束时，该进程仍然在运行时，则会把它挂起，接着调度程序从就绪队列挑选另外一个进程。这种抢占式调度处理，需要在时间间隔的末端发生<strong>时钟中断</strong>，以便把 CPU 控制返回给调度程序进行调度，也就是常说的<strong>时间片机制</strong>。</li>
</ul>
</li>
<li><p>调度原则</p>
<ul>
<li><strong>CPU 利用率</strong>：调度程序应确保 CPU 是始终匆忙的状态，这可提高 CPU 的利用率；</li>
<li><strong>系统吞吐量</strong>：吞吐量表示的是单位时间内 CPU 完成进程的数量，长作业的进程会占用较长的 CPU 资源，因此会降低吞吐量，相反，短作业的进程会提升系统吞吐量；</li>
<li><strong>周转时间</strong>：周转时间是进程运行+阻塞时间+等待时间的总和，一个进程的周转时间越小越好；</li>
<li><strong>等待时间</strong>：这个等待时间不是阻塞状态的时间，而是进程处于就绪队列的时间，等待的时间越长，用户越不满意；</li>
<li><strong>响应时间</strong>：用户提交请求到系统第一次产生响应所花费的时间，在交互式系统中，响应时间是衡量调度算法好坏的主要标准。</li>
</ul>
</li>
<li><p>调度算法</p>
<ul>
<li><p>先来先服务调度算法：先来后到，<strong>每次从就绪队列选择最先进入队列的进程，然后一直运行，直到进程退出或被阻塞，才会继续从队列中选择第一个进程接着运行。</strong></p>
</li>
<li><p>最短作业优先调度算法：<strong>优先选择运行时间最短的进程来运行</strong>，这有助于提高系统的吞吐量。</p>
</li>
<li><p>高响应比优先调度算法：<strong>每次进行进程调度时，先计算「响应比优先级」，然后把「响应比优先级」最高的进程投入运行；</strong>高响应比优先调度算法是「理想型」的调度算法，现实中是实现不了的</p>
</li>
<li><p>时间片轮转调度算法：<strong>每个进程被分配一个时间段，称为时间片，即允许该进程在该时间段中运行</strong></p>
</li>
<li><p>最高优先级调度算法：<strong>从就绪队列中选择最高优先级的进程进行运行</strong></p>
<p>多级反馈队列调度算法：时间片轮转算法和最高优先级算法的综合和发展。</p>
</li>
</ul>
</li>
</ul>
<h3 id="5-2-进程间有哪些通信方式？"><a href="#5-2-进程间有哪些通信方式？" class="headerlink" title="5.2 进程间有哪些通信方式？"></a>5.2 进程间有哪些通信方式？</h3><ul>
<li><p>管道</p>
<ul>
<li><p>命令行里的「<code>|</code>」竖线就是一个<strong>管道</strong>，它的功能是将前一个命令的输出，作为后一个命令的输入，从这功能描述，可以看出<strong>管道传输数据是单向的</strong>，如果想相互通信，我们需要创建两个管道才行；「<code>|</code>」表示的管道称为<strong>匿名管道</strong>，用完了就销毁</p>
</li>
<li><p><strong>命名管道</strong>，也被叫做 <code>FIFO</code>，因为数据是先进先出的传输方式。在使用命名管道前，先需要通过 <code>mkfifo</code> 命令来创建，并且指定管道名字；</p>
</li>
<li><p><strong>管道这种通信方式效率低，不适合进程间频繁地交换数据</strong>。当然，它的好处，自然就是简单，同时也我们很容易得知管道里的数据已经被另一个进程读取了</p>
</li>
<li><p><strong>所谓的管道，就是内核里面的一串缓存</strong>。从管道的一段写入的数据，实际上是缓存在内核中的，另一端读取，也就是从内核中读取这段数据。另外，管道传输的数据是无格式的流且大小受限。</p>
</li>
<li><p><strong>对于匿名管道，它的通信范围是存在父子关系的进程</strong>。因为管道没有实体，也就是没有管道文件，只能通过 fork 来复制父进程 fd 文件描述符，来达到通信的目的。<strong>对于命名管道，它可以在不相关的进程间也能相互通信</strong>。因为命令管道，提前创建了一个类型为管道的设备文件，在进程里只要使用这个设备文件，就可以相互通信。</p>
</li>
<li><p>不管是匿名管道还是命名管道，进程写入的数据都是缓存在内核中，另一个进程读取数据时候自然也是从内核中获取，同时通信数据都遵循<strong>先进先出</strong>原则，不支持 lseek 之类的文件定位操作</p>
</li>
</ul>
</li>
<li><p>消息队列</p>
<ul>
<li>管道的通信方式是效率低的，因此管道不适合进程间频繁地交换数据。对于这个问题，<strong>消息队列</strong>的通信模式就可以解决</li>
<li><strong>消息队列是保存在内核中的消息链表</strong>，在发送数据时，会分成一个一个独立的数据单元，也就是消息体（数据块），消息体是用户自定义的数据类型，消息的发送方和接收方要约定好消息体的数据类型，所以每个消息体都是固定大小的存储块，不像管道是无格式的字节流数据。如果进程从消息队列中读取了消息体，内核就会把这个消息体删除。</li>
<li>消息队列生命周期随内核，如果没有释放消息队列或者没有关闭操作系统，消息队列会一直存在，而前面提到的匿名管道的生命周期，是随进程的创建而建立，随进程的结束而销毁</li>
<li><strong>消息队列不适合比较大数据的传输</strong>，因为在内核中每个消息体都有一个最大长度的限制，同时所有队列所包含的全部消息体的总长度也是有上限</li>
<li><strong>消息队列通信过程中，存在用户态与内核态之间的数据拷贝开销</strong>，因为进程写入数据到内核中的消息队列时，会发生从用户态拷贝数据到内核态的过程，同理另一进程读取内核中的消息数据时，会发生从内核态拷贝数据到用户态的过程</li>
</ul>
</li>
<li><p>共享内存</p>
<ul>
<li>消息队列的读取和写入的过程，都会有发生用户态与内核态之间的消息拷贝过程。那<strong>共享内存</strong>的方式，就很好的解决了这一问题。</li>
<li><strong>共享内存的机制，就是拿出一块虚拟地址空间来，映射到相同的物理内存中</strong>。这样这个进程写入的东西，另外一个进程马上就能看到了，都不需要拷贝来拷贝去，传来传去，大大提高了进程间通信的速度</li>
</ul>
</li>
<li><p>信号量</p>
<ul>
<li><p>用了共享内存通信方式，带来新的问题，那就是如果多个进程同时修改同一个共享内存，很有可能就冲突了。例如两个进程都同时写一个地址，那先写的那个进程会发现内容被别人覆盖了。为了防止多进程竞争共享资源，而造成的数据错乱，所以需要保护机制，使得共享的资源，在任意时刻只能被一个进程访问。正好，<strong>信号量</strong>就实现了这一保护机制。</p>
</li>
<li><p><strong>信号量其实是一个整型的计数器，主要用于实现进程间的互斥与同步，而不是用于缓存进程间通信的数据</strong>。信号量表示资源的数量，控制信号量的方式有两种原子操作：</p>
<ul>
<li>一个是 <strong>P 操作</strong>，这个操作会把信号量减去 1，相减后如果信号量 &lt; 0，则表明资源已被占用，进程需阻塞等待；相减后如果信号量 &gt;&#x3D; 0，则表明还有资源可使用，进程可正常继续执行。</li>
<li>另一个是 <strong>V 操作</strong>，这个操作会把信号量加上 1，相加后如果信号量 &lt;&#x3D; 0，则表明当前有阻塞中的进程，于是会将该进程唤醒运行；相加后如果信号量 &gt; 0，则表明当前没有阻塞中的进程；</li>
</ul>
<p>P 操作是用在进入共享资源之前，V 操作是用在离开共享资源之后，这两个操作是必须成对出现的。</p>
</li>
</ul>
</li>
<li><p>信号</p>
<ul>
<li><p>上面说的进程间通信，都是常规状态下的工作模式。<strong>对于异常情况下的工作模式，就需要用「信号」的方式来通知进程。</strong>在 Linux 操作系统中， 为了响应各种各样的事件，提供了几十种信号，分别代表不同的意义。</p>
</li>
<li><p>运行在 shell 终端的进程，我们可以通过键盘输入某些组合键的时候，给进程发送信号。例如</p>
<ul>
<li>Ctrl+C 产生 <code>SIGINT</code> 信号，表示终止该进程；</li>
<li>Ctrl+Z 产生 <code>SIGTSTP</code> 信号，表示停止该进程，但还未结束；</li>
</ul>
</li>
<li><p>信号是进程间通信机制中<strong>唯一的异步通信机制</strong>，因为可以在任何时候发送信号给某一进程，一旦有信号产生，我们就有下面这几种，用户进程对信号的处理方式。</p>
<p><strong>1.执行默认操作</strong>。</p>
<p><strong>2.捕捉信号</strong>。我们可以为信号定义一个信号处理函数。</p>
<p><strong>3.忽略信号</strong>。有两个信号是应用进程无法捕捉和忽略的，即 <code>SIGKILL</code> 和 <code>SEGSTOP</code>，它们用于在任何时候中断或结束某一进程。</p>
</li>
</ul>
</li>
<li><p>Socket</p>
<ul>
<li>前面提到的管道、消息队列、共享内存、信号量和信号都是在同一台主机上进行进程间通信，那要想<strong>跨网络与不同主机上的进程之间通信，就需要 Socket 通信了。</strong></li>
<li>Socket 实际上不仅用于不同的主机进程间通信，还可以用于本地主机进程间通信，可根据创建 Socket 的类型不同，分为三种常见的通信方式，一个是基于 TCP 协议的通信方式，一个是基于 UDP 协议的通信方式，一个是本地进程间通信方式</li>
</ul>
</li>
<li><p>线程通信间的方式呢？</p>
<ul>
<li>同个进程下的线程之间都是共享进程的资源，只要是共享变量都可以做到线程间通信，比如全局变量，所以对于线程间关注的不是通信方式，而是关注多线程竞争共享资源的问题，信号量也同样可以在线程间实现互斥与同步：<ul>
<li>互斥的方式，可保证任意时刻只有一个线程访问共享资源；</li>
<li>同步的方式，可保证线程 A 应在线程 B 之前执行</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="5-3-多线程冲突了怎么办？"><a href="#5-3-多线程冲突了怎么办？" class="headerlink" title="5.3 多线程冲突了怎么办？"></a>5.3 多线程冲突了怎么办？</h3><ul>
<li><p>在单核 CPU 系统里，为了实现多个程序同时运行的假象，操作系统通常以时间片调度的方式，让每个进程执行每次执行一个时间片，时间片用完了，就切换下一个进程运行，由于这个时间片的时间很短，于是就造成了「并发」的现象。另外，操作系统也为每个进程创建巨大、私有的虚拟内存的假象，这种地址空间的抽象让每个程序好像拥有自己的内存，而实际上操作系统在背后秘密地让多个地址空间「复用」物理内存或者磁盘</p>
</li>
<li><p>如果一个程序只有一个执行流程，也代表它是单线程的。当然一个程序可以有多个执行流程，也就是所谓的多线程程序，线程是调度的基本单位，进程则是资源分配的基本单位。所以，线程之间是可以共享进程的资源，比如代码段、堆空间、数据段、打开的文件等资源，但每个线程都有自己独立的栈空间。</p>
</li>
<li><p>只是单纯给 <code>i</code> 加上数字 1，在 CPU 运行的时候，实际上要执行 <code>3</code> 条指令：从内存取出值后放入寄存器，对寄存器中的值+1，讲寄存器的值放回内存；若中间发生了时间中断则可能导致不可控的调度，当多线程相互竞争操作共享变量时，由于运气不好，即在执行过程中发生了上下文切换，我们得到了错误的结果，事实上，每次运行都可能得到不同的结果，因此输出的结果存在<strong>不确定性</strong>。</p>
<ul>
<li>由于多线程执行操作共享变量的这段代码可能会导致竞争状态，因此我们将此段代码称为<strong>临界区，它是访问共享资源的代码片段，一定不能给多线程同时执行。</strong>希望这段代码是<strong>互斥的，也就说保证一个线程在临界区执行时，其他线程应该被阻止进入临界区</strong>，说白了，就是这段代码执行过程中，最多只能出现一个线程</li>
<li>互斥解决了并发进程&#x2F;线程对临界区的使用问题。这种基于临界区控制的交互作用是比较简单的，只要一个进程&#x2F;线程进入了临界区，其他试图想进入临界区的进程&#x2F;线程都会被阻塞着，直到第一个进程&#x2F;线程离开了临界区。</li>
</ul>
</li>
<li><p>在多线程里，每个线程并不一定是顺序执行的，它们基本是以各自独立的、不可预知的速度向前推进，但有时候我们又希望多个线程能密切合作，以实现一个共同的任务；<strong>所谓同步，就是并发进程&#x2F;线程在一些关键点上可能需要互相等待与互通消息，这种相互制约的等待与互通信息称为进程&#x2F;线程同步</strong>。</p>
</li>
<li><p>为了实现进程&#x2F;线程间正确的协作，操作系统必须提供实现进程协作的措施和方法，主要的方法有两种：<em>锁</em>：加锁、解锁操作；<em>信号量</em>：P、V 操作；这两个都可以方便地实现进程&#x2F;线程互斥，而信号量比锁的功能更强一些，它还可以方便地实现进程&#x2F;线程同步</p>
<ul>
<li><p>使用加锁操作和解锁操作可以解决并发线程&#x2F;进程的互斥问题。任何想进入临界区的线程，必须先执行加锁操作。若加锁操作顺利通过，则线程可进入临界区；在完成对临界资源的访问后再执行解锁操作，以释放该临界资源。根据锁的实现不同，可以分为「忙等待锁」和「无忙等待锁」。</p>
<ul>
<li>现代 CPU 体系结构提供的特殊<strong>原子操作指令 —— 测试和置位（Test-and-Set）指令</strong>。<strong>原子操作就是要么全部执行，要么都不执行，不能出现执行到一半的中间状态</strong></li>
<li>当获取不到锁时，线程就会一直 while 循环，不做任何事情，所以就被称为「忙等待锁」，也被称为自旋锁</li>
<li>无等待锁顾明思议就是获取不到锁的时候，不用自旋。既然不想自旋，那当没获取到锁的时候，就把当前线程放入到锁的等待队列，然后执行调度程序，把 CPU 让给其他线程执行。</li>
</ul>
</li>
<li><p>通常<strong>信号量表示资源的数量</strong>，对应的变量是一个整型（<code>sem</code>）变量。另外，还有<strong>两个原子操作的系统调用函数来控制信号量的</strong>，分别是：</p>
<ul>
<li><em>P 操作</em>：将 <code>sem</code> 减 <code>1</code>，相减后，如果 <code>sem &lt; 0</code>，则进程&#x2F;线程进入阻塞等待，否则继续，表明 P 操作可能会阻塞；</li>
<li><em>V 操作</em>：将 <code>sem</code> 加 <code>1</code>，相加后，如果 <code>sem &lt;= 0</code>，唤醒一个等待中的进程&#x2F;线程，表明 V 操作不会阻塞；</li>
</ul>
<p>P 操作是用在进入临界区之前，V 操作是用在离开临界区之后，这两个操作是必须成对出现的。PV 操作的函数是由操作系统管理和实现的，所以操作系统已经使得执行 PV 函数时是具有原子性的。</p>
</li>
</ul>
</li>
<li><p>生产者-消费者问题描述：<strong>生产者</strong>在生成数据后，放在一个缓冲区中；<strong>消费者</strong>从缓冲区取出数据处理；任何时刻，<strong>只能有一个</strong>生产者或消费者可以访问缓冲区；</p>
<ul>
<li>任何时刻只能有一个线程操作缓冲区，说明操作缓冲区是临界代码，<strong>需要互斥</strong>；</li>
<li>缓冲区空时，消费者必须等待生产者生成数据；缓冲区满时，生产者必须等待消费者取出数据。说明生产者和消费者<strong>需要同步</strong>。</li>
<li>需要三个信号量，分别是：<ul>
<li>互斥信号量 <code>mutex</code>：用于互斥访问缓冲区，初始化值为 1；</li>
<li>资源信号量 <code>fullBuffers</code>：用于消费者询问缓冲区是否有数据，有数据则读取数据，初始化值为 0（表明缓冲区一开始为空）；</li>
<li>资源信号量 <code>emptyBuffers</code>：用于生产者询问缓冲区是否有空位，有空位则生成数据，初始化值为 n （缓冲区大小）；</li>
</ul>
</li>
</ul>
</li>
<li><p>哲学家就餐的问题描述：</p>
<ul>
<li><code>5</code> 个老大哥哲学家，闲着没事做，围绕着一张圆桌吃面；</li>
<li>巧就巧在，这个桌子只有 <code>5</code> 支叉子，每两个哲学家之间放一支叉子；</li>
<li>哲学家围在一起先思考，思考中途饿了就会想进餐；</li>
<li><strong>这些哲学家要两支叉子才愿意吃面，也就是需要拿到左右两边的叉子才进餐</strong>；</li>
<li><strong>吃完后，会把两支叉子放回原处，继续思考</strong>；</li>
</ul>
<p>那么问题来了，如何保证哲 学家们的动作有序进行，而不会出现有人永远拿不到叉子呢？</p>
<ul>
<li><strong>假设五位哲学家同时拿起左边的叉子，桌面上就没有叉子了， 这样就没有人能够拿到他们右边的叉子，也就说每一位哲学家都会在 <code>P(fork[(i + 1) % N ])</code> 这条语句阻塞了，很明显这发生了死锁的现象</strong>。</li>
<li>在拿叉子前，加个互斥信号量，互斥信号量的作用就在于，<strong>只要有一个哲学家进入了「临界区」，也就是准备要拿叉子时，其他哲学家都不能动，只有这位哲学家用完叉子了，才能轮到下一个哲学家进餐</strong>；每次进餐只能有一位哲学家，从效率角度上，这不是最好的解决方案。</li>
<li>采用分支结构，根据哲学家的编号的不同，而采取不同的动作。<strong>即让偶数编号的哲学家「先拿左边的叉子后拿右边的叉子」，奇数编号的哲学家「先拿右边的叉子后拿左边的叉子」。</strong></li>
<li><strong>用一个数组 state 来记录每一位哲学家的三个状态，分别是在进餐状态、思考状态、饥饿状态（正在试图拿叉子）。</strong>那么，<strong>一个哲学家只有在两个邻居都没有进餐时，才可以进入进餐状态。</strong></li>
</ul>
</li>
<li><p>读者-写者的问题描述：「读-读」允许：同一时刻，允许多个读者同时读；「读-写」互斥：没有写者时读者才能读，没有读者时写者才能写；「写-写」互斥：没有其他写者时，写者才能写</p>
<ul>
<li><p>使用信号量的方式来尝试解决：</p>
<ul>
<li>信号量 <code>wMutex</code>：控制写操作的互斥信号量，初始值为 1 </li>
<li>读者计数 <code>rCount</code>：正在进行读操作的读者个数，初始化为 0；</li>
<li>信号量 <code>rCountMutex</code>：控制对 rCount 读者计数器的互斥修改，初始值为 1；</li>
</ul>
<p>读者优先的策略，因为只要有读者正在读的状态，后来的读者都可以直接进入，如果读者持续不断进入，则写者会处于饥饿状态</p>
</li>
<li><p>写者优先策略：</p>
<ul>
<li>只要有写者准备要写入，写者应尽快执行写操作，后来的读者就必须阻塞；</li>
<li>如果有写者持续不断写入，则读者就处于饥饿；</li>
</ul>
<p>在方案一的基础上新增如下变量：</p>
<ul>
<li>信号量 <code>rMutex</code>：控制读者进入的互斥信号量，初始值为 1；</li>
<li>信号量 <code>wDataMutex</code>：控制写者写操作的互斥信号量，初始值为 1；</li>
<li>写者计数 <code>wCount</code>：记录写者数量，初始值为 0；</li>
<li>信号量 <code>wCountMutex</code>：控制 wCount 互斥修改，初始值为 1；</li>
</ul>
</li>
<li><p>公平策略：</p>
<ul>
<li>优先级相同；</li>
<li>写者、读者互斥访问；</li>
<li>只能一个写者访问临界区；</li>
<li>可以有多个读者同时访问临界资源；</li>
</ul>
<p>加了一个信号量 <code>flag</code>实现了公平竞争，阻止特殊权限</p>
</li>
</ul>
</li>
</ul>
<h3 id="5-4-怎么避免死锁？"><a href="#5-4-怎么避免死锁？" class="headerlink" title="5.4 怎么避免死锁？"></a>5.4 怎么避免死锁？</h3><ul>
<li><p>在多线程编程中，我们为了防止多线程竞争共享资源而导致数据错乱，都会在操作共享资源之前加上互斥锁，只有成功获得到锁的线程，才能操作共享资源，获取不到锁的线程就只能等待，直到锁被释放；当两个线程为了保护两个不同的共享资源而使用了两个互斥锁，那么这两个互斥锁应用不当的时候，可能会造成<strong>两个线程都在等待对方释放锁</strong>，在没有外力的作用下，这些线程会一直相互等待，就没办法继续运行，这种情况就是发生了<strong>死锁</strong>。</p>
</li>
<li><p>死锁只有<strong>同时满足</strong>以下四个条件才会发生：</p>
<ul>
<li>互斥条件；<strong>多个线程不能同时使用同一个资源</strong>。</li>
<li>持有并等待条件；<strong>线程 A 在等待资源 2 的同时并不会释放自己已经持有的资源 1</strong></li>
<li>不可剥夺条件；<strong>在自己使用完之前不能被其他线程获取</strong>，</li>
<li>环路等待条件；<strong>两个线程获取资源的顺序构成了环形链</strong></li>
</ul>
</li>
<li><p>利用工具排查死锁问题</p>
<ul>
<li>在 Linux 下，我们可以使用 <code>pstack</code> + <code>gdb</code> 工具来定位死锁问题。pstack 命令可以显示每个线程的栈跟踪信息（函数调用过程），它的使用方式也很简单，只需要 <code>pstack &lt;pid&gt;</code> 就可以了。在定位死锁问题时，我们可以多次执行 pstack 命令查看线程的函数调用过程，多次对比结果，确认哪几个线程一直没有变化，且是因为在等待锁，那么大概率是由于死锁问题导致的。不能够确认这两个线程是在互相等待对方的锁的释放，因为看不到它们是等在哪个锁对象，于是可以使用 gdb 工具进一步确认。</li>
</ul>
</li>
<li><p>避免死锁问题就只需要破环其中一个条件就可以，最常见的并且可行的就是<strong>使用资源有序分配法，来破环环路等待条件</strong>。</p>
</li>
</ul>
<h3 id="5-5-什么是悲观锁、乐观锁？"><a href="#5-5-什么是悲观锁、乐观锁？" class="headerlink" title="5.5 什么是悲观锁、乐观锁？"></a>5.5 什么是悲观锁、乐观锁？</h3><ul>
<li><p>加锁的目的就是保证共享资源在任意时间里，只有一个线程访问，这样就可以避免多线程导致共享数据错乱的问题。当已经有一个线程加锁后，其他线程加锁则就会失败，互斥锁和自旋锁对于加锁失败后的处理方式是不一样的：</p>
<ul>
<li><strong>互斥锁</strong>加锁失败后，线程会<strong>释放 CPU</strong> ，给其他线程；</li>
<li><strong>自旋锁</strong>加锁失败后，线程会<strong>忙等待</strong>，直到它拿到锁；</li>
</ul>
</li>
<li><p>互斥锁是一种「独占锁」，比如当线程 A 加锁成功后，此时互斥锁已经被线程 A 独占了，只要线程 A 没有释放手中的锁，线程 B 加锁就会失败，于是就会释放 CPU 让给其他线程，<strong>既然线程 B 释放掉了 CPU，自然线程 B 加锁的代码就会被阻塞</strong>。</p>
<ul>
<li><strong>对于互斥锁加锁失败而阻塞的现象，是由操作系统内核实现的</strong>。当加锁失败时，内核会将线程置为「睡眠」状态，等到锁被释放后，内核会在合适的时机唤醒线程，当这个线程成功获取到锁后，于是就可以继续执行。</li>
<li>互斥锁加锁失败时，会从用户态陷入到内核态，让内核帮我们切换线程，虽然简化了使用锁的难度，但是存在一定的性能开销成本。会有<strong>两次线程上下文切换的成本</strong>：<ul>
<li>当线程加锁失败时，内核会把线程的状态从「运行」状态设置为「睡眠」状态，然后把 CPU 切换给其他线程运行；</li>
<li>接着，当锁被释放时，之前「睡眠」状态的线程会变为「就绪」状态，然后内核会在合适的时间，把 CPU 切换给该线程运行。</li>
</ul>
</li>
<li>当两个线程是属于同一个进程，<strong>因为虚拟内存是共享的，所以在切换时，虚拟内存这些资源就保持不动，只需要切换线程的私有数据、寄存器等不共享的数据。</strong> <strong>如果你能确定被锁住的代码执行时间很短，就不应该用互斥锁，而应该选用自旋锁，否则使用互斥锁</strong></li>
</ul>
</li>
<li><p>自旋锁是通过 CPU 提供的 <code>CAS</code> 函数（<em>Compare And Swap</em>），在「用户态」完成加锁和解锁操作，不会主动产生线程上下文切换，所以相比互斥锁来说，会快一些，开销也小一些。一般加锁的过程，包含两个步骤：</p>
<ul>
<li>第一步，查看锁的状态，如果锁是空闲的，则执行第二步；</li>
<li>第二步，将锁设置为当前线程持有；</li>
</ul>
<p>CAS 函数就把这两个步骤合并成一条硬件级指令，形成<strong>原子指令</strong>，这样就保证了这两个步骤是不可分割的，要么一次性执行完两个步骤，要么两个步骤都不执行。</p>
<ul>
<li>使用自旋锁的时候，当发生多线程竞争锁的情况，加锁失败的线程会「忙等待」，直到它拿到锁。这里的「忙等待」可以用 <code>while</code> 循环等待实现，不过最好是使用 CPU 提供的 <code>PAUSE</code> 指令来实现「忙等待」，因为可以减少循环等待时的耗电量。</li>
<li>自旋锁是最比较简单的一种锁，一直自旋，利用 CPU 周期，直到锁可用。<strong>需要注意，在单核 CPU 上，需要抢占式的调度器（即不断通过时钟中断一个线程，运行其他线程）。否则，自旋锁在单 CPU 上无法使用，因为一个自旋的线程永远不会放弃 CPU。</strong></li>
<li>自旋锁开销少，在多核系统下一般不会主动产生线程切换，适合异步、协程等在用户态切换请求的编程方式，但如果被锁住的代码执行时间过长，自旋的线程会长时间占用 CPU 资源，所以自旋的时间和被锁住的代码执行的时间是成「正比」的关系，我们需要清楚的知道这一点。</li>
<li>自旋锁与互斥锁使用层面比较相似，但实现层面上完全不同：<strong>当加锁失败时，互斥锁用「线程切换」来应对，自旋锁则用「忙等待」来应对</strong>。</li>
</ul>
</li>
<li><p><strong>读写锁适用于能明确区分读操作和写操作的场景</strong>。读写锁的工作原理是：</p>
<ul>
<li>当「写锁」没有被线程持有时，多个线程能够并发地持有读锁，这大大提高了共享资源的访问效率，因为「读锁」是用于读取共享资源的场景，所以多个线程同时持有读锁也不会破坏共享资源的数据。</li>
<li>但是，一旦「写锁」被线程持有后，读线程的获取读锁的操作会被阻塞，而且其他写线程的获取写锁的操作也会被阻塞。</li>
</ul>
<p>写锁是独占锁，因为任何时刻只能有一个线程持有写锁，类似互斥锁和自旋锁，而读锁是共享锁，因为读锁可以被多个线程同时持有</p>
</li>
<li><p><strong>读写锁在读多写少的场景，能发挥出优势</strong>。根据实现的不同，读写锁可以分为「读优先锁」和「写优先锁」。</p>
<ul>
<li>读优先锁期望的是，读锁能被更多的线程持有，以便提高读线程的并发性，它的工作方式是：当读线程 A 先持有了读锁，写线程 B 在获取写锁的时候，会被阻塞，并且在阻塞过程中，后续来的读线程 C 仍然可以成功获取读锁，最后直到读线程 A 和 C 释放读锁后，写线程 B 才可以成功获取写锁。</li>
<li>写优先锁是优先服务写线程，其工作方式是：当读线程 A 先持有了读锁，写线程 B 在获取写锁的时候，会被阻塞，并且在阻塞过程中，后续来的读线程 C 获取读锁时会失败，于是读线程 C 将被阻塞在获取读锁的操作，这样只要读线程 A 释放读锁后，写线程 B 就可以成功获取写锁。</li>
<li><strong>公平读写锁比较简单的一种方式是：用队列把获取锁的线程排队，不管是写线程还是读线程都按照先进先出的原则加锁即可，这样读线程仍然可以并发，也不会出现「饥饿」的现象。</strong></li>
</ul>
</li>
<li><p>互斥锁、自旋锁、读写锁，都是属于悲观锁。悲观锁做事比较悲观，它认为<strong>多线程同时修改共享资源的概率比较高，于是很容易出现冲突，所以访问共享资源前，先要上锁</strong>。那相反的，如果多线程同时修改共享资源的概率比较低，就可以采用乐观锁。</p>
</li>
<li><p>乐观锁做事比较乐观，它假定冲突的概率很低，它的工作方式是：<strong>先修改完共享资源，再验证这段时间内有没有发生冲突，如果没有其他线程在修改资源，那么操作完成，如果发现有其他线程已经修改过这个资源，就放弃本次操作</strong>。放弃后如何重试，这跟业务场景息息相关，虽然重试的成本很高，但是冲突的概率足够低的话，还是可以接受的。<strong>乐观锁全程并没有加锁，所以它也叫无锁编程</strong>。服务端要怎么验证是否冲突了呢？通常方案如下：</p>
<ul>
<li>由于发生冲突的概率比较低，所以先让用户编辑文档，但是浏览器在下载文档时会记录下服务端返回的文档版本号；</li>
<li>当用户提交修改时，发给服务端的请求会带上原始文档版本号，服务器收到后将它与当前版本号进行比较，如果版本号不一致则提交失败，如果版本号一致则修改成功，然后服务端版本号更新到最新的版本号。</li>
</ul>
<p>乐观锁虽然去除了加锁解锁的操作，但是一旦发生冲突，重试的成本非常高，所以<strong>只有在冲突概率非常低，且加锁成本非常高的场景时，才考虑使用乐观锁</strong></p>
</li>
</ul>
<h3 id="5-6-一个进程最多可以创建多少个线程？"><a href="#5-6-一个进程最多可以创建多少个线程？" class="headerlink" title="5.6 一个进程最多可以创建多少个线程？"></a>5.6 一个进程最多可以创建多少个线程？</h3><ul>
<li><p>这个问题跟两个东西有关系：</p>
<ul>
<li><p><strong>进程的虚拟内存空间上限</strong>，因为创建一个线程，操作系统需要为其分配一个栈空间，如果线程数量越多，所需的栈空间就要越大，那么虚拟内存就会占用的越多。</p>
</li>
<li><p><strong>系统参数限制</strong>，虽然 Linux 并没有内核参数来控制单个进程创建的最大线程个数，但是有系统级别的参数来控制整个系统的最大线程个数。</p>
</li>
</ul>
</li>
<li><p>可以执行 ulimit -a 这条命令，查看进程创建线程时默认分配的栈空间大小</p>
</li>
<li><p>在 32 位 Linux 系统里，一个进程的虚拟空间是 4G，内核分走了1G，<strong>留给用户用的只有 3G</strong>。那么假设创建一个线程需要占用 10M 虚拟内存，总共有 3G 虚拟内存可以使用。于是最多可以创建差不多 300 个（3G&#x2F;10M）左右的线程。如果想使得进程创建上千个线程，那么可以调整创建线程时分配的栈空间大小，比如调整为 512k</p>
</li>
<li><p>64 位系统意味着用户空间的虚拟内存最大值是 128T，这个数值是很大的，如果按创建一个线程需占用 10M 栈空间的情况来算，那么理论上可以创建 128T&#x2F;10M 个线程，也就是 1000多万个线程，所以按 64 位系统的虚拟内存大小，理论上可以创建无数个线程。事实上，肯定创建不了那么多线程，除了虚拟内存的限制，还有系统的限制。比如下面这三个内核参数的大小，都会影响创建线程的上限：</p>
<ul>
<li><em><strong>&#x2F;proc&#x2F;sys&#x2F;kernel&#x2F;threads-max</strong></em>，表示系统支持的最大线程数，默认值是 <code>14553</code>；</li>
<li><em><strong>&#x2F;proc&#x2F;sys&#x2F;kernel&#x2F;pid_max</strong></em>，表示系统全局的 PID 号数值的限制，每一个进程或线程都有 ID，ID 的值超过这个数，进程或线程就会创建失败，默认值是 <code>32768</code>；</li>
<li><em><strong>&#x2F;proc&#x2F;sys&#x2F;vm&#x2F;max_map_count</strong></em>，表示限制一个进程可以拥有的VMA(虚拟内存区域)的数量，默认值是 <code>65530</code>。</li>
</ul>
</li>
<li><p>为什么物理内存只有 2G，进程的虚拟内存却可以使用 25T 呢？因为虚拟内存并不是全部都映射到物理内存的，程序是有局部性的特性，也就是某一个时间只会执行部分代码，所以只需要映射这部分程序就好。</p>
</li>
</ul>
<h3 id="5-7-线程崩溃了，进程也会崩溃吗？"><a href="#5-7-线程崩溃了，进程也会崩溃吗？" class="headerlink" title="5.7 线程崩溃了，进程也会崩溃吗？"></a>5.7 线程崩溃了，进程也会崩溃吗？</h3><ul>
<li>C&#x2F;C++ 语言里，线程崩溃后，进程也会崩溃，而 Java 语言里却不会，这是由于 JVM 自己定义了信号处理函数，这样当发送 kill pid 命令（默认会传 15 也就是 SIGTERM）后，JVM 就可以在信号处理函数中执行一些资源清理之后再调用 exit 退出</li>
<li>一般来说如果线程是因为非法访问内存引起的崩溃，那么进程肯定会崩溃，这主要是因为在进程中各个线程的地址空间是共享的，那么某个线程对地址的非法访问就会导致内存的不确定性，进而可能会影响到其他线程</li>
<li>线程共享代码段，数据段，地址空间，文件非法访问内存有以下几种情况：针对只读内存写入数据、访问了进程没有权限访问的地址空间（比如内核空间）、访问了不存在的内存</li>
<li>线程崩溃后，进程是通过信号实现崩溃的，其背后的机制如下：<ol>
<li>CPU 执行正常的进程指令</li>
<li>调用 kill 系统调用向进程发送信号</li>
<li>进程收到操作系统发的信号，CPU 暂停当前程序运行，并将控制权转交给操作系统</li>
<li>调用 kill 系统调用向进程发送信号（假设为 11，即 SIGSEGV，一般非法访问内存报的都是这个错误）</li>
<li><strong>操作系统根据情况执行相应的信号处理程序（函数），一般执行完信号处理程序逻辑后会让进程退出</strong></li>
</ol>
</li>
<li>如果进程没有注册自己的信号处理函数，那么操作系统会执行默认的信号处理程序，但如果注册了，则会执行自己的信号处理函数；另外当进程接收信号之后也可以不定义自己的信号处理函数，而是选择忽略信号</li>
<li>虚拟机针对 stackoverflow 它采用了一种栈回溯的方法保证线程可以一直执行下去，而捕获空指针错误主要是这个错误实在太普遍了。为了这一个很常见的错误而让 JVM 崩溃那线上的 JVM 要宕机多少次，所以出于工程健壮性的考虑，与其直接让 JVM 崩溃倒不如让线程起死回生，并且将这两个错误&#x2F;异常抛给用户来处理</li>
</ul>
<h3 id="6-1-进程调度-x2F-页面置换-x2F-磁盘调度算法"><a href="#6-1-进程调度-x2F-页面置换-x2F-磁盘调度算法" class="headerlink" title="6.1 进程调度&#x2F;页面置换&#x2F;磁盘调度算法"></a>6.1 进程调度&#x2F;页面置换&#x2F;磁盘调度算法</h3><h4 id="进程调度算法"><a href="#进程调度算法" class="headerlink" title="进程调度算法"></a>进程调度算法</h4><ul>
<li><p>进程调度算法也称 CPU 调度算法，毕竟进程是由 CPU 调度的。当 CPU 空闲时，操作系统就选择内存中的某个「就绪状态」的进程，并给其分配 CPU。</p>
</li>
<li><p>什么时候会发生 CPU 调度呢？通常有以下情况：</p>
<ol>
<li>当进程从运行状态转到等待状态；</li>
<li>当进程从运行状态转到就绪状态；</li>
<li>当进程从等待状态转到就绪状态；</li>
<li>当进程从运行状态转到终止状态；</li>
</ol>
<p>其中发生在 1 和 4 两种情况下的调度称为「非抢占式调度」，2 和 3 两种情况下发生的调度称为「抢占式调度」。</p>
<ul>
<li>非抢占式的意思就是，当进程正在运行时，它就会一直运行，直到该进程完成或发生某个事件而被阻塞时，才会把 CPU 让给其他进程。</li>
<li>而抢占式调度，顾名思义就是进程正在运行的时，可以被打断，使其把 CPU 让给其他进程。那抢占的原则一般有三种，分别是时间片原则、优先权原则、短作业优先原则。</li>
</ul>
</li>
<li><p>调度算法影响的是等待时间（进程在就绪队列中等待调度的时间总和），而不能影响进程真在使用 CPU 的时间和 I&#x2F;O 时间。常见的调度算法：</p>
<ul>
<li>先来先服务调度算法，先来后到，<strong>每次从就绪队列选择最先进入队列的进程，然后一直运行，直到进程退出或被阻塞，才会继续从队列中选择第一个进程接着运行。</strong></li>
<li>最短作业优先调度算法：<strong>优先选择运行时间最短的进程来运行</strong>，这有助于提高系统的吞吐量。</li>
<li>高响应比优先调度算法：权衡了短作业和长作业。<strong>每次进行进程调度时，先计算「响应比优先级」，然后把「响应比优先级」最高的进程投入运行</strong>，「响应比优先级」的计算公式：等待时间 + 要求的服务时间 &#x2F; 要求的服务时间</li>
<li>时间片轮转调度算法：<strong>每个进程被分配一个时间段，称为时间片，即允许该进程在该时间段中运行</strong></li>
<li>最高优先级调度算法：<strong>从就绪队列中选择最高优先级的进程进行运行</strong></li>
<li>多级反馈队列调度算法：时间片轮转算法和最高优先级算法的综合和发展，设置了多个队列，赋予每个队列不同的优先级，每个<strong>队列优先级从高到低</strong>，同时<strong>优先级越高时间片越短</strong>；</li>
</ul>
</li>
</ul>
<h4 id="内存页面置换算法"><a href="#内存页面置换算法" class="headerlink" title="内存页面置换算法"></a>内存页面置换算法</h4><ul>
<li>当 CPU 访问的页面不在物理内存时，便会产生一个缺页中断，请求操作系统将所缺页调入到物理内存。那它与一般中断的主要区别在于：<ul>
<li>缺页中断在指令执行「期间」产生和处理中断信号，而一般中断在一条指令执行「完成」后检查和处理中断信号。</li>
<li>缺页中断返回到该指令的开始重新执行「该指令」，而一般中断返回回到该指令的「下一个指令」执行。</li>
</ul>
</li>
<li>找不到空闲页的话，就说明此时内存已满了，这时候，就需要「页面置换算法」选择一个物理页，如果该物理页有被修改过（脏页），则把它换出到磁盘，然后把该被置换出去的页表项的状态改成「无效的」，最后把正在访问的页面装入到这个物理页中。</li>
<li>页表项通常有如下图的字段：<ul>
<li><em>状态位</em>：用于表示该页是否有效，也就是说是否在物理内存中，供程序访问时参考。</li>
<li><em>访问字段</em>：用于记录该页在一段时间被访问的次数，供页面置换算法选择出页面时参考。</li>
<li><em>修改位</em>：表示该页在调入内存后是否有被修改过，由于内存中的每一页都在磁盘上保留一份副本，因此，如果没有修改，在置换该页时就不需要将该页写回到磁盘上，以减少系统的开销；如果已经被修改，则将该页重写到磁盘上，以保证磁盘中所保留的始终是最新的副本。</li>
<li><em>硬盘地址</em>：用于指出该页在硬盘上的地址，通常是物理块号，供调入该页时使用。</li>
</ul>
</li>
<li>页面置换算法的功能是，<strong>当出现缺页异常，需调入新页面而内存已满时，选择被置换的物理页面</strong>，也就是说选择一个物理页面换出到磁盘，然后把需要访问的页面换入到物理页。其算法目标则是，尽可能减少页面的换入换出的次数，常见的页面置换算法有如下几种：<ul>
<li>最佳页面置换算法（<em>OPT</em>）：<strong>置换在「未来」最长时间不访问的页面</strong>。主要是为了衡量算法的效率</li>
<li>先进先出置换算法（<em>FIFO</em>）：<strong>选择在内存驻留时间很长的页面进行中置换</strong></li>
<li>最近最久未使用的置换算法（<em>LRU</em>）：<strong>选择最长时间没有被访问的页面进行置换</strong></li>
<li>时钟页面置换算法（<em>Lock</em>）：跟 LRU 近似，又是对 FIFO 的一种改进，当发生缺页中断时，算法首先检查表针指向的页面：<ul>
<li>如果它的访问位位是 0 就淘汰该页面，并把新的页面插入这个位置，然后把表针前移一个位置；</li>
<li>如果访问位是 1 就清除访问位，并把表针前移一个位置，重复这个过程直到找到了一个访问位为 0 的页面为止；</li>
</ul>
</li>
<li>最不常用置换算法（<em>LFU</em>）：<strong>当发生缺页中断时，选择「访问次数」最少的那个页面，并将其淘汰</strong></li>
</ul>
</li>
</ul>
<h4 id="磁盘调度算法"><a href="#磁盘调度算法" class="headerlink" title="磁盘调度算法"></a>磁盘调度算法</h4><ul>
<li>磁盘调度算法的目的很简单，就是为了提高磁盘的访问性能，一般是通过优化磁盘的访问请求顺序来做到的。寻道的时间是磁盘访问最耗时的部分，如果请求顺序优化的得当，必然可以节省一些不必要的寻道时间，从而提高磁盘的访问性能。</li>
<li>常见的磁盘调度算法有：<ul>
<li>先来先服务算法，先到来的请求，先被服务</li>
<li>最短寻道时间优先算法，优先选择从当前磁头位置所需寻道时间最短的请求<ul>
<li>但这个算法可能存在某些请求的<strong>饥饿</strong>，<strong>磁头在一小块区域来回移动</strong></li>
</ul>
</li>
<li>扫描算法：磁头在一个方向上移动，访问所有未完成的请求，直到磁头到达该方向上的最后的磁道，才调换方向<ul>
<li>中间部分的磁道会比较占便宜，中间部分相比其他部分响应的频率会比较多，也就是说每个磁道的响应频率存在差异</li>
</ul>
</li>
<li>循环扫描算法：只有磁头朝某个特定方向移动时，才处理磁道访问请求，而返回时直接快速移动至最靠边缘的磁道，也就是复位磁头，这个过程是很快的，并且<strong>返回中途不处理任何请求</strong>，该算法的特点，就是<strong>磁道只响应一个方向上的请求</strong>。</li>
<li>LOOK 与 C-LOOK 算法<ul>
<li>针对 SCAN 算法的优化则叫 LOOK 算法，它的工作方式，磁头在每个方向上仅仅移动到最远的请求位置，然后立即反向移动，而不需要移动到磁盘的最始端或最末端，<strong>反向移动的途中会响应请求</strong>。</li>
<li>针 C-SCAN 算法的优化则叫 C-LOOK，它的工作方式，磁头在每个方向上仅仅移动到最远的请求位置，然后立即反向移动，而不需要移动到磁盘的最始端或最末端，<strong>反向移动的途中不会响应请求</strong>。</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="7-1-文件系统全家桶"><a href="#7-1-文件系统全家桶" class="headerlink" title="7.1 文件系统全家桶"></a>7.1 文件系统全家桶</h3><ul>
<li><p>文件系统的基本组成</p>
<ul>
<li>Linux 最经典的一句话是：「<strong>一切皆文件</strong>」，不仅普通的文件和目录，就连块设备、管道、socket 等，也都是统一交给文件系统管理的</li>
<li>Linux 文件系统会为每个文件分配两个数据结构：<strong>索引节点和目录项</strong>，它们主要用来记录文件的元信息和目录层次结构<ul>
<li>索引节点，也就是 <em>inode</em>，用来记录文件的元信息，比如 inode 编号、文件大小、访问权限、创建时间、修改时间、<strong>数据在磁盘的位置</strong>等等。索引节点是文件的<strong>唯一</strong>标识，它们之间一一对应，也同样都会被存储在硬盘中，所以<strong>索引节点同样占用磁盘空间</strong>。</li>
<li>目录项，也就是 <em>dentry</em>，用来记录文件的名字、<strong>索引节点指针</strong>以及与其他目录项的层级关联关系。多个目录项关联起来，就会形成目录结构，但它与索引节点不同的是，<strong>目录项是由内核维护的一个数据结构，不存放于磁盘，而是缓存在内存</strong>。</li>
</ul>
</li>
<li>由于索引节点唯一标识一个文件，而目录项记录着文件的名字，所以目录项和索引节点的关系是多对一，也就是说，一个文件可以有多个别名。比如，硬链接的实现就是多个目录项中的索引节点指向同一个文件。</li>
<li>目录也是文件，也是用索引节点唯一标识，和普通文件不同的是，普通文件在磁盘里面保存的是文件数据，而目录文件在磁盘里面保存子目录或文件。<ul>
<li>目录项是内核一个数据结构，缓存在内存。如果查询目录频繁从磁盘读，效率会很低，所以内核会把已经读过的目录用目录项这个数据结构缓存在内存，下次再次读到相同的目录时，只需从内存读就可以，大大提高了文件系统的效率。</li>
<li>注意，目录项这个数据结构不只是表示目录，也是可以表示文件的</li>
</ul>
</li>
</ul>
</li>
<li><p>那文件数据是如何存储在磁盘的呢？</p>
<ul>
<li>文件系统把多个扇区组成了一个<strong>逻辑块</strong>，每次读写的最小单位就是逻辑块（数据块），Linux 中的逻辑块大小为 <code>4KB</code>，也就是一次性读写 8 个扇区，这将大大提高了磁盘的读写的效率</li>
<li>磁盘进行格式化的时候，会被分成三个存储区域，分别是超级块、索引节点区和数据块区。<ul>
<li><em>超级块</em>，用来存储文件系统的详细信息，比如块个数、块大小、空闲块等等。</li>
<li><em>索引节点区</em>，用来存储索引节点；</li>
<li><em>数据块区</em>，用来存储文件或目录数据；</li>
</ul>
</li>
<li>不可能把超级块和索引节点区全部加载到内存，这样内存肯定撑不住，所以只有当需要使用的时候，才将其加载进内存，它们加载进内存的时机是不同的：<ul>
<li>超级块：当文件系统挂载时进入内存；</li>
<li>索引节点区：当文件被访问时进入内存</li>
</ul>
</li>
</ul>
</li>
<li><p>文件系统的种类众多，而操作系统希望<strong>对用户提供一个统一的接口</strong>，于是在用户层与文件系统层引入了中间层，这个中间层就称为<strong>虚拟文件系统（<em>Virtual File System，VFS</em>）</strong></p>
<ul>
<li>Linux 支持的文件系统也不少，根据存储位置的不同，可以把文件系统分为三类：<ul>
<li><em>磁盘的文件系统</em>，它是直接把数据存储在磁盘中，比如 Ext 2&#x2F;3&#x2F;4、XFS 等都是这类文件系统。</li>
<li><em>内存的文件系统</em>，这类文件系统的数据不是存储在硬盘的，而是占用内存空间，我们经常用到的 <code>/proc</code> 和 <code>/sys</code> 文件系统都属于这一类，读写这类文件，实际上是读写内核中相关的数据。</li>
<li><em>网络的文件系统</em>，用来访问其他计算机主机数据的文件系统，比如 NFS、SMB 等等。</li>
</ul>
</li>
<li>文件系统首先要先挂载到某个目录才可以正常使用，比如 Linux 系统在启动时，会把文件系统挂载到根目录</li>
</ul>
</li>
<li><p>文件的使用</p>
<ul>
<li><p>操作系统为每个进程维护一个打开文件表，文件表里的每一项代表「<strong>文件描述符</strong>」，文件描述符是打开文件的标识，操作系统在打开文件表中维护着打开文件的状态和信息：</p>
<ul>
<li>文件指针：系统跟踪上次读写位置作为当前文件位置指针，这种指针对打开文件的某个进程来说是唯一的；</li>
<li>文件打开计数器：文件关闭时，操作系统必须重用其打开文件表条目，否则表内空间不够用。该计数器跟踪打开和关闭的数量，当该计数为 0 时，系统关闭文件，删除该条目；</li>
<li>文件磁盘位置：绝大多数文件操作都要求系统修改文件数据，该信息保存在内存中，以免每个操作都从磁盘中读取；</li>
<li>访问权限：每个进程打开文件都需要有一个访问模式（创建、只读、读写、添加等），该信息保存在进程的打开文件表中，以便操作系统能允许或拒绝之后的 I&#x2F;O 请求；</li>
</ul>
</li>
<li><p>在用户视角里，文件就是一个持久化的数据结构，但操作系统并不会关心你想存在磁盘上的任何的数据结构，操作系统的视角是如何把文件数据和磁盘块对应起来；用户习惯以字节的方式读写文件，而操作系统则是以数据块来读写文件，那屏蔽掉这种差异的工作就是文件系统</p>
</li>
<li><p>读文件和写文件的过程：</p>
<ul>
<li>当用户进程从文件读取 1 个字节大小的数据时，文件系统则需要获取字节所在的数据块，再返回数据块对应的用户进程所需的数据部分。</li>
<li>当用户进程把 1 个字节大小的数据写进文件时，文件系统则找到需要写入数据的数据块的位置，然后修改数据块中对应的部分，最后再把数据块写回磁盘。</li>
</ul>
<p>所以说，<strong>文件系统的基本操作单位是数据块</strong></p>
</li>
</ul>
</li>
<li><p>文件的数据是要存储在硬盘上面的，数据在磁盘上的存放方式，就像程序在内存中存放的方式那样，有以下两种：</p>
<ul>
<li><p>连续空间存放方式：<strong>文件存放在磁盘连续的物理空间中</strong>。文件的数据都是紧密相连，<strong>读写效率很高</strong>，因为一次磁盘寻道就可以读出整个文件</p>
<ul>
<li>使用连续存放的方式有一个前提，必须先知道一个文件的大小，这样文件系统才会根据文件的大小在磁盘上找到一块连续的空间分配给文件。所以，<strong>文件头里需要指定「起始块的位置」和「长度」</strong></li>
<li>连续空间存放的方式虽然读写效率高，<strong>但是有「磁盘空间碎片」和「文件长度不易扩展」的缺陷</strong></li>
</ul>
</li>
<li><p>非连续空间存放方式：分为「链表方式」和「索引方式」</p>
<ul>
<li>链表的方式存放是<strong>离散的，不用连续的</strong>，于是就可以<strong>消除磁盘碎片</strong>，可大大提高磁盘空间的利用率，同时<strong>文件的长度可以动态扩展</strong>。根据实现的方式的不同，链表可分为「<strong>隐式链表</strong>」和「<strong>显式链接</strong>」两种形式<ul>
<li><strong>隐式链表</strong>实现的方式是文件头要包含第一块和最后一块的位置，并且每个数据块里面留出一个指针空间，用来存放下一个数据块的位置；<strong>无法直接访问数据块，只能通过指针顺序访问文件，以及数据块指针消耗了一定的存储空间</strong></li>
<li><strong>显式链接</strong>指<strong>把用于链接文件各数据块的指针，显式地存放在内存的</strong>文件分配表（<em>File Allocation Table，FAT</em>）<strong>，该表在整个磁盘仅设置一张，</strong>每个表项中存放链接指针，指向下一个数据块号；显著地<strong>提高了检索速度</strong>，而且<strong>大大减少了访问磁盘的次数</strong>。但也正是整个表都存放在内存中的关系，它的主要的缺点是<strong>不适用于大磁盘</strong></li>
</ul>
</li>
<li>索引的实现是为每个文件创建一个「<strong>索引数据块</strong>」，里面存放的是<strong>指向文件数据块的指针列表</strong>；<strong>文件头需要包含指向「索引数据块」的指针</strong>，这样就可以通过文件头知道索引数据块的位置，再通过索引数据块里的索引信息找到对应的数据块</li>
<li>链表 + 索引的组合，这种组合称为「<strong>链式索引块</strong>」，它的实现方式是<strong>在索引数据块留出一个存放下一个索引数据块的指针</strong>，于是当一个索引数据块的索引信息用完了，就可以通过指针的方式，找到下一个索引数据块的信息</li>
<li>索引 + 索引的方式，这种组合称为「<strong>多级索引块</strong>」，实现方式是<strong>通过一个索引块来存放多个索引数据块</strong>，一层套一层索引</li>
</ul>
</li>
<li><p>Unix 文件的实现方式：根据文件的大小，存放的方式会有所变化：</p>
<ul>
<li>如果存放文件所需的数据块小于 10 块，则采用直接查找的方式；</li>
<li>如果存放文件所需的数据块超过 10 块，则采用一级间接索引方式；</li>
<li>如果前面两种方式都不够存放大文件，则采用二级间接索引方式；</li>
<li>如果二级间接索引也不够存放大文件，这采用三级间接索引方式；</li>
</ul>
<p>那么，文件头（<em>Inode</em>）就需要包含 13 个指针：</p>
<ul>
<li>10 个指向数据块的指针；</li>
<li>第 11 个指向索引块的指针；</li>
<li>第 12 个指向二级索引块的指针；</li>
<li>第 13 个指向三级索引块的指针；</li>
</ul>
</li>
</ul>
</li>
<li><p>针对磁盘的空闲空间也是要引入管理的机制</p>
<ul>
<li>空闲表法：为所有空闲空间建立一张表，表内容包括空闲区的第一个块号和该空闲区的块个数，这个方式是连续分配的</li>
<li>空闲链表法：使用「链表」的方式来管理空闲空间，每一个空闲块里有一个指针指向下一个空闲块，这样也能很方便的找到空闲块并管理起来；空闲表法和空闲链表法都不适合用于大型文件系统，因为这会使空闲表或空闲链表太大</li>
<li>位图法：利用二进制的一位来表示磁盘中一个盘块的使用情况，磁盘上所有的盘块都有一个二进制位与之对应；在 Linux 文件系统就采用了位图的方式来管理空闲空间，不仅用于数据空闲块的管理，还用于 inode 空闲块的管理</li>
</ul>
</li>
<li><p>数据块的位图是放在磁盘块里的，假设是放在一个块里，一个块 4K，每位表示一个数据块，共可以表示 <code>4 * 1024 * 8 = 2^15</code> 个空闲块，由于 1 个数据块是 4K 大小，那么最大可以表示的空间为 <code>2^15 * 4 * 1024 = 2^27</code> 个 byte，也就是 128M。如果采用「一个块的位图 + 一系列的块」，外加「一个块的 inode 的位图 + 一系列的 inode 的结构」能表示的最大空间也就 128M，这太少了，现在很多文件都比这个大。在 Linux 文件系统，把这个结构称为一个<strong>块组</strong>，那么有 N 多的块组，就能够表示 N 大的文件</p>
</li>
<li><p>目录文件和普通文件不同的是，<strong>普通文件的块里面保存的是文件数据，而目录文件的块里面保存的是目录里面一项一项的文件信息。</strong>在目录文件的块中，最简单的保存格式就是<strong>列表</strong>，就是一项一项地将目录下的文件信息（如文件名、文件 inode、文件类型等）列在表里。列表中每一项就代表该目录下的文件的文件名和对应的 inode，通过这个 inode，就可以找到真正的文件。</p>
<ul>
<li>如果一个目录有超级多的文件，要想在这个目录下找文件，按照列表一项一项的找，效率就不高了。于是，保存目录的格式改成<strong>哈希表</strong>，对文件名进行哈希计算，把哈希值保存起来，如果我们要查找一个目录下面的文件名，可以通过名称取哈希。如果哈希能够匹配上，就说明这个文件的信息在相应的块里面。</li>
<li>为了减少 I&#x2F;O 操作，把当前使用的文件目录缓存在内存，以后要使用该文件时只要在内存中操作，从而降低了磁盘操作次数，提高了文件系统的访问速度</li>
</ul>
</li>
<li><p>软链接和硬链接：给某个文件取个别名，在 Linux 中可以通过<strong>硬链接</strong> 和软链接的方式来实现，它们都是比较特殊的文件，但是实现方式也是不相同的</p>
<ul>
<li>硬链接是<strong>多个目录项中的「索引节点」指向一个文件</strong>，也就是指向同一个 inode，但是 inode 是不可能跨越文件系统的，每个文件系统都有各自的 inode 数据结构和列表，所以<strong>硬链接是不可用于跨文件系统的</strong>。由于多个目录项都是指向一个 inode，那么<strong>只有删除文件的所有硬链接以及源文件时，系统才会彻底删除该文件。</strong></li>
<li>软链接相当于重新创建一个文件，这个文件有<strong>独立的 inode</strong>，但是这个<strong>文件的内容是另外一个文件的路径</strong>，所以访问软链接的时候，实际上相当于访问到了另外一个文件，所以<strong>软链接是可以跨文件系统的</strong>，甚至<strong>目标文件被删除了，链接文件还是在的，只不过指向的文件找不到了而已。</strong></li>
</ul>
</li>
<li><p>文件的 I&#x2F;O 分类</p>
<ul>
<li>缓冲与非缓冲 I&#x2F;O，<strong>根据「是否利用标准库缓冲」</strong><ul>
<li>比方说，很多程序遇到换行时才真正输出，而换行前的内容，其实就是被标准库暂时缓存了起来，这样做的目的是，减少系统调用的次数，毕竟系统调用是有 CPU 上下文切换的开销的</li>
</ul>
</li>
<li>直接与非直接 I&#x2F;O，<strong>根据是「否利用操作系统的缓存」</strong><ul>
<li>Linux 内核为了减少磁盘 I&#x2F;O 次数，在系统调用后，会把用户数据拷贝到内核中缓存起来，这个内核缓存空间也就是「页缓存」，只有当缓存满足某些条件的时候，才发起磁盘 I&#x2F;O 的请求</li>
<li>以下几种场景会触发内核缓存的数据写入磁盘：<ul>
<li>在调用 <code>write</code> 的最后，当发现内核缓存的数据太多的时候，内核会把数据写到磁盘上；</li>
<li>用户主动调用 <code>sync</code>，内核缓存会刷到磁盘上；</li>
<li>当内存十分紧张，无法再分配页面时，也会把内核缓存的数据刷到磁盘上；</li>
<li>内核缓存的数据的缓存时间超过某个时间时，也会把数据刷到磁盘上；</li>
</ul>
</li>
</ul>
</li>
<li>阻塞与非阻塞 I&#x2F;O VS 同步与异步 I&#x2F;O<ul>
<li><strong>阻塞等待的是「内核数据准备好」和「数据从内核态拷贝到用户态」这两个过程</strong></li>
<li>非阻塞的 read 请求在数据未准备好的情况下立即返回，可以继续往下执行，此时应用程序不断轮询内核，直到数据准备好，内核将数据拷贝到应用程序缓冲区；<strong>最后一次 read 调用，获取数据的过程，是一个同步的过程，是需要等待的过程。这里的同步指的是内核态的数据拷贝到用户程序的缓存区这个过程。</strong><ul>
<li>为了解决轮询方式，于是 <strong>I&#x2F;O 多路复用</strong>技术就出来了，如 select、poll，它是通过 I&#x2F;O 事件分发，当内核数据准备好时，再以事件通知应用程序进行操作，<strong>用户可以在一个线程内同时处理多个 socket 的 IO 请求</strong>，但是<code>read</code> 获取数据的过程（数据从内核态拷贝到用户态的过程），也是一个<strong>同步的过程</strong>，需要等待</li>
</ul>
</li>
<li>无论是阻塞 I&#x2F;O、非阻塞 I&#x2F;O，还是基于非阻塞 I&#x2F;O 的多路复用<strong>都是同步调用。因为它们在 read 调用时，内核将数据从内核空间拷贝到应用程序空间，过程都是需要等待的，也就是说这个过程是同步的，如果内核实现的拷贝效率不高，read 调用就会在这个同步过程中等待比较长的时间</strong></li>
<li>真正的<strong>异步 I&#x2F;O</strong> 是「内核数据准备好」和「数据从内核态拷贝到用户态」这两个过程都不用等待；发起 <code>aio_read</code> 之后，就立即返回，内核自动将数据从内核空间拷贝到应用程序空间，这个拷贝过程同样是异步的，内核自动完成的，和前面的同步操作不一样，应用程序并不需要主动发起拷贝动作</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="7-2-进程写文件时，进程发生了崩溃，已写入的数据会丢失吗？"><a href="#7-2-进程写文件时，进程发生了崩溃，已写入的数据会丢失吗？" class="headerlink" title="7.2 进程写文件时，进程发生了崩溃，已写入的数据会丢失吗？"></a>7.2 进程写文件时，进程发生了崩溃，已写入的数据会丢失吗？</h3><ul>
<li><p>进程在执行 write （使用缓冲 IO）系统调用的时候，实际上是将文件数据写到了内核的 page cache，它是文件系统中用于缓存文件数据的缓冲，所以即使进程崩溃了，文件数据还是保留在内核的 page cache，我们读数据的时候，也是从内核的 page cache 读取，因此还是依然读的进程崩溃前写入的数据。内核会找个合适的时机，将 page cache 中的数据持久化到磁盘。但是如果 page cache 里的文件数据，在持久化到磁盘化到磁盘之前，系统发生了崩溃，那这部分数据就会丢失了。也可以在程序里调用 fsync 函数，在写文文件的时候，立刻将文件数据持久化到磁盘，这样就可以解决系统崩溃导致的文件数据丢失的问题。</p>
</li>
<li><p>Page Cache 是什么？</p>
<ul>
<li><p>Page Cache 的本质是由 Linux 内核管理的内存区域。我们通过 mmap 以及 buffered I&#x2F;O 将文件读取到内存空间实际上都是读取到 Page Cache 中</p>
</li>
<li><p>通过读取 <code>/proc/meminfo</code> 文件，能够实时获取系统内存情况</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">Page Cache = Buffers + Cached + SwapCached = Active(file) + Inactive(file) + Shmem + SwapCached</span><br></pre></td></tr></table></figure></li>
</ul>
</li>
<li><p>page 是内存管理分配的基本单位， Page Cache 由多个 page 构成。page 在操作系统中通常为 4KB 大小（32bits&#x2F;64bits），而 Page Cache 的大小则为 4KB 的整数倍。</p>
<ul>
<li><strong>并不是所有 page 都被组织为 Page Cache</strong>。Linux 系统上供用户可访问的内存分为两个类型，即：<ul>
<li>File-backed pages：文件备份页也就是 Page Cache 中的 page，对应于磁盘上的若干数据块；对于这些页最大的问题是脏页回盘；</li>
<li>Anonymous pages：匿名页不对应磁盘上的任何磁盘数据块，它们是进程的运行是内存空间（例如方法栈、局部变量表等属性）；</li>
</ul>
</li>
<li>内存是一种珍惜资源，当内存不够用时，内存管理单元（Memory Mangament Unit）需要提供调度算法来回收相关内存空间。内存空间回收的方式通常就是 swap，即交换到持久化存储设备上。</li>
<li>File-backed pages（Page Cache）的内存回收代价较低。Page Cache 通常对应于一个文件上的若干顺序块，因此可以通过顺序 I&#x2F;O 的方式落盘。另一方面，如果 Page Cache 上没有进行写操作（所谓的没有脏页），甚至不会将 Page Cache 回盘，因为数据的内容完全可以通过再次读取磁盘文件得到。Page Cache 的主要难点在于脏页回盘</li>
<li>Anonymous pages 的内存回收代价较高。这是因为 Anonymous pages 通常随机地写入持久化交换设备。另一方面，无论是否有写操作，为了确保数据不丢失，Anonymous pages 在 swap 时必须持久化到磁盘</li>
</ul>
</li>
<li><p>Swap 机制指的是当物理内存不够用，内存管理单元（Memory Mangament Unit，MMU）需要提供调度算法来回收相关内存空间，然后将清理出来的内存空间给当前内存申请方。</p>
<ul>
<li>操作系统以 page 为单位管理内存，当进程发现需要访问的数据不在内存时，操作系统可能会将数据以页的方式加载到内存中。上述过程被称为<strong>缺页中断</strong>，当操作系统发生缺页中断时，就会通过系统调用将 page 再次读到内存中</li>
<li>对于有发生内存泄漏几率的应用程序（进程），Swap 交换分区更是重要，这可以确保内存泄露不至于导致物理内存不够用，最终导致系统崩溃。但内存泄露会引起频繁的 swap，此时非常影响操作系统的性能</li>
<li><strong>为什么 SwapCached 也是 Page Cache 的一部分？</strong>这是因为当匿名页（Inactive(anon) 以及 Active(anon)）先被交换（swap out）到磁盘上后，然后再加载回（swap in）内存中，由于读入到内存后原来的 Swap File 还在，所以 SwapCached 也可以认为是 File-backed page，即属于 Page Cache</li>
</ul>
</li>
<li><p><strong>Page Cache 用于缓存文件的页数据，buffer cache 用于缓存块设备（如磁盘）的块数据。</strong></p>
<ul>
<li>页是逻辑上的概念，因此 Page Cache 是与文件系统同级的；块是物理上的概念，因此 buffer cache 是与块设备驱动程序同级的。</li>
<li>Page Cache 与 buffer cache 的<strong>共同目的都是加速数据 I&#x2F;O</strong><ul>
<li>写数据时首先写到缓存，将写入的页标记为 dirty，然后向外部存储 flush，也就是缓存写机制中的 write-back</li>
<li>读数据时首先读取缓存，如果未命中，再去外部存储读取，并且将读取来的数据也加入缓存。操作系统总是积极地将所有空闲内存都用作 Page Cache 和 buffer cache，当内存不够用时也会用 LRU 等算法淘汰缓存页</li>
</ul>
</li>
<li><strong>在 2.4 版本内核之后，两块缓存近似融合在了一起：如果一个文件的页加载到了 Page Cache，那么同时 buffer cache 只需要维护块指向页的指针就可以了</strong>，<strong>现在提起 Page Cache，基本上都同时指 Page Cache 和 buffer cache 两者</strong></li>
</ul>
</li>
<li><p>操作系统为基于 Page Cache 的读缓存机制提供<strong>预读机制</strong></p>
<ul>
<li>用户线程仅仅请求读取磁盘上文件 A 的 offset 为 0-3KB 范围内的数据，由于磁盘的基本读写单位为 block（4KB），于是操作系统至少会读 0-4KB 的内容，这恰好可以在一个 page 中装下。</li>
<li>但是操作系统出于局部性原理会选择将磁盘块 offset [4KB,8KB)、[8KB,12KB) 以及 [12KB,16KB) 都加载到内存，于是额外在内存中申请了 3 个 page</li>
</ul>
</li>
<li><p>任何系统引入缓存，就会引发一致性问题：内存中的数据与磁盘中的数据不一致；<strong>文件 &#x3D; 数据 + 元数据</strong>。元数据用来描述文件的各种属性，也必须存储在磁盘上。因此，保证文件一致性其实包含了两个方面：数据一致+元数据一致</p>
<ul>
<li>Linux 下以两种方式实现文件一致性：</li>
</ul>
<ol>
<li><strong>Write Through（写穿）</strong>：向用户层提供特定接口，应用程序可主动调用接口来保证文件一致性；</li>
<li><strong>Write back（写回）</strong>：系统中存在定期任务（表现形式为内核线程），周期性地同步文件系统中文件脏数据块，这是默认的 Linux 一致性方案；</li>
</ol>
<ul>
<li>Write Through 与 Write back 在持久化的可靠性上有所不同：<ul>
<li>Write Through 以牺牲系统 I&#x2F;O 吞吐量作为代价，向上层应用确保一旦写入，数据就已经落盘，不会丢失；</li>
<li>Write back 在系统发生宕机的情况下无法确保数据已经落盘，因此存在数据丢失的问题。不过，在程序挂了，例如被 kill -9，Page Cache 中的数据操作系统还是会确保落盘</li>
</ul>
</li>
</ul>
</li>
<li><p>Page Cache 的优势</p>
<ul>
<li>加快数据访问：如果数据能够在内存中进行缓存，那么下一次访问就不需要通过磁盘 I&#x2F;O 了，直接命中内存缓存即可。由于内存访问比磁盘访问快很多，因此加快数据访问是 Page Cache 的一大优势。</li>
<li>减少 I&#x2F;O 次数，提高系统磁盘 I&#x2F;O 吞吐量：得益于 Page Cache 的缓存以及预读能力，而程序又往往符合局部性原理，因此通过一次 I&#x2F;O 将多个 page 装入 Page Cache 能够减少磁盘 I&#x2F;O 次数， 进而提高系统磁盘 I&#x2F;O 吞吐量。</li>
</ul>
</li>
<li><p>Page Cache 的劣势</p>
<ul>
<li>需要占用额外物理内存空间，物理内存在比较紧俏的时候可能会导致频繁的 swap 操作，最终导致系统的磁盘 I&#x2F;O 负载的上升</li>
<li>对应用层并没有提供很好的管理 API，几乎是透明管理。应用层即使想优化 Page Cache 的使用策略也很难进行。因此一些应用选择在用户空间实现自己的 page 管理，而不使用 page cache，例如 MySQL InnoDB 存储引擎以 16KB 的页进行管理。</li>
<li>在某些应用场景下比 Direct I&#x2F;O 多一次磁盘读 I&#x2F;O 以及磁盘写 I&#x2F;O。</li>
<li>Direct I&#x2F;O 即直接 I&#x2F;O。其名字中的”直接”二字用于区分使用 page cache 机制的缓存 I&#x2F;O。“直接”在这里还有另一层语义：其他所有技术中，数据至少需要在内核空间存储一份，但是在 Direct I&#x2F;O 技术中，数据直接存储在用户空间中，绕过了内核。</li>
<li><strong>Direct I&#x2F;O 的读写非常有特点</strong>：<ul>
<li>Write 操作：由于其不使用 page cache，所以其进行写文件，如果返回成功，数据就真的落盘了（不考虑磁盘自带的缓存）；</li>
<li>Read 操作：由于其不使用 page cache，每次读操作是真的从磁盘中读取，不会从文件系统的缓存中读取。</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="8-1-键盘敲入-A-字母时，操作系统期间发生了什么？"><a href="#8-1-键盘敲入-A-字母时，操作系统期间发生了什么？" class="headerlink" title="8.1 键盘敲入 A 字母时，操作系统期间发生了什么？"></a>8.1 键盘敲入 A 字母时，操作系统期间发生了什么？</h3><ul>
<li><p>为了屏蔽设备之间的差异，每个设备都有一个叫<strong>设备控制器（Device Control）</strong> 的组件，比如硬盘有硬盘控制器、显示器有视频控制器等；设备控制器里有芯片，它可执行自己的逻辑，也有自己的寄存器，用来与 CPU 进行通信</p>
<ul>
<li>通过写入这些寄存器，操作系统可以命令设备发送数据、接收数据、开启或关闭，或者执行某些其他操作。</li>
<li>通过读取这些寄存器，操作系统可以了解设备的状态，是否准备好接收一个新的命令等</li>
<li>控制器是有三类寄存器，它们分别是**状态寄存器、 **命令寄存器以及数据寄存器；</li>
</ul>
</li>
<li><p>CPU 通过读写设备控制器中的寄存器控制设备，这比 CPU 直接控制输入输出设备要方便和标准很多；另外， 输入输出设备可分为两大类 ：块设备和字符设备</p>
<ul>
<li><em>块设备</em>，把数据存储在固定大小的块中，每个块有自己的地址，硬盘、USB 是常见的块设备<ul>
<li>块设备通常传输的数据量会非常大，于是控制器设立了一个可读写的<strong>数据缓冲区</strong></li>
</ul>
</li>
<li><em>字符设备</em>，以字符为单位发送或接收一个字符流，字符设备是不可寻址的，也没有任何寻道操作，鼠标是常见的字符设备</li>
</ul>
</li>
<li><p>CPU 是如何与设备的控制寄存器和数据缓冲区进行通信的？存在两个方法：</p>
<ul>
<li><em>端口 I&#x2F;O</em>，每个控制寄存器被分配一个 I&#x2F;O 端口，可以通过特殊的汇编指令操作这些寄存器，比如 <code>in/out</code> 类似的指令</li>
<li><em>内存映射 I&#x2F;O</em>，将所有控制寄存器映射到内存空间中，这样就可以像读写内存一样读写数据缓冲区</li>
</ul>
</li>
<li><p>当 CPU 给设备发送了一个指令，让设备控制器去读设备的数据，它读完的时候，要怎么通知 CPU 呢？</p>
<ul>
<li>控制器的寄存器一般会有状态标记位，用来标识输入或输出操作是否完成。于是，我们想到第一种<strong>轮询等待</strong>的方法，让 CPU 一直查寄存器的状态，直到状态标记为完成</li>
<li><strong>中断</strong>，通知操作系统数据已经准备好；一般会有一个硬件的<strong>中断控制器</strong>，当设备完成任务后触发中断到中断控制器，中断控制器就通知 CPU，一个中断产生了，CPU 需要停下当前手里的事情来处理中断<ul>
<li>中断有两种，一种<strong>软中断</strong>，例如代码调用 <code>INT</code> 指令触发，一种是<strong>硬件中断</strong>，就是硬件通过中断控制器触发的</li>
<li>但中断的方式对于频繁读写数据的磁盘，并不友好，这样 CPU 容易经常被打断，会占用 CPU 大量的时间</li>
</ul>
</li>
<li>对于这一类设备的问题的解决方法是使用 <strong>DMA</strong> 功能，它可以使得设备在 CPU 不参与的情况下，能够自行完成把设备 I&#x2F;O 数据放入到内存。那要实现 DMA 功能要有 「DMA 控制器」硬件的支持</li>
</ul>
</li>
<li><p>DMA 的工作方式如下：</p>
<ul>
<li>CPU 需对 DMA 控制器下发指令，告诉它想读取多少数据，读完的数据放在内存的某个地方就可以了；</li>
<li>接下来，DMA 控制器会向磁盘控制器发出指令，通知它从磁盘读数据到其内部的缓冲区中，接着磁盘控制器将缓冲区的数据传输到内存；</li>
<li>当磁盘控制器把数据传输到内存的操作完成后，磁盘控制器在总线上发出一个确认成功的信号到 DMA 控制器；</li>
<li>DMA 控制器收到信号后，DMA 控制器发中断通知 CPU 指令完成，CPU 就可以直接用内存里面现成的数据了；</li>
</ul>
</li>
<li><p>设备控制器屏蔽了设备的众多细节，但每种设备的控制器的寄存器、缓冲区等使用模式都是不同的，所以为了屏蔽「设备控制器」的差异，引入了<strong>设备驱动程序</strong></p>
<ul>
<li>不同的设备控制器虽然功能不同，但是<strong>设备驱动程序会提供统一的接口给操作系统</strong>，这样不同的设备驱动程序，就可以以相同的方式接入操作系统</li>
</ul>
</li>
<li><p>中断处理程序的处理流程：</p>
<ol>
<li>在 I&#x2F;O 时，设备控制器如果已经准备好数据，则会通过中断控制器向 CPU 发送中断请求；</li>
<li>保护被中断进程的 CPU 上下文；</li>
<li>转入相应的设备中断处理函数；</li>
<li>进行中断处理；</li>
<li>恢复被中断进程的上下文</li>
</ol>
</li>
<li><p>Linux 存储系统的 I&#x2F;O 软件分层由上到下可以分为三个层次，分别是文件系统层、通用块层、设备层；这三个层次的作用是：</p>
<ul>
<li>文件系统层，包括虚拟文件系统和其他文件系统的具体实现，它向上为应用程序统一提供了标准的文件访问接口，向下会通过通用块层来存储和管理磁盘数据。</li>
<li>通用块层，包括块设备的 I&#x2F;O 队列和 I&#x2F;O 调度器，它会对文件系统的 I&#x2F;O 请求进行排队，再通过 I&#x2F;O 调度器，选择一个 I&#x2F;O 发给下一层的设备层。</li>
<li>设备层，包括硬件设备、设备控制器和驱动程序，负责最终物理设备的 I&#x2F;O 操作。</li>
</ul>
</li>
<li><p>键盘敲入字母时，期间发生了什么？</p>
<ul>
<li>那当用户输入了键盘字符，<strong>键盘控制器</strong>就会产生扫描码数据，并将其缓冲在键盘控制器的寄存器中，紧接着键盘控制器通过总线给 CPU 发送<strong>中断请求</strong>。</li>
<li>CPU 收到中断请求后，操作系统会<strong>保存被中断进程的 CPU 上下文</strong>，然后调用键盘的<strong>中断处理程序</strong>。</li>
<li>键盘的中断处理程序是在<strong>键盘驱动程序</strong>初始化时注册的，那键盘<strong>中断处理函数</strong>的功能就是从键盘控制器的寄存器的缓冲区读取扫描码，再根据扫描码找到用户在键盘输入的字符，如果输入的字符是显示字符，那就会把扫描码翻译成对应显示字符的 ASCII 码，比如用户在键盘输入的是字母 A，是显示字符，于是就会把扫描码翻译成 A 字符的 ASCII 码。</li>
<li>得到了显示字符的 ASCII 码后，就会把 ASCII 码放到「读缓冲区队列」，接下来就是要把显示字符显示屏幕了，显示设备的驱动程序会定时从「读缓冲区队列」读取数据放到「写缓冲区队列」，最后把「写缓冲区队列」的数据一个一个写入到显示设备的控制器的寄存器中的数据缓冲区，最后将这些数据显示在屏幕里。</li>
<li>显示出结果后，<strong>恢复被中断进程的上下文</strong>。</li>
</ul>
</li>
</ul>
<h3 id="9-1-什么是零拷贝"><a href="#9-1-什么是零拷贝" class="headerlink" title="9.1 什么是零拷贝"></a>9.1 什么是零拷贝</h3><ul>
<li>针对优化磁盘的技术非常的多，比如零拷贝、直接 I&#x2F;O、异步 I&#x2F;O 等等，这些优化的目的就是<strong>为了提高系统的吞吐量</strong>，另外操作系统内核中的磁盘高速缓存区，可以有效的减少磁盘的访问次数</li>
<li>没有 DMA （<em>Direct Memory Access</em>，直接内存访问）技术前，CPU 亲自参与搬运数据的过程而且该过程是阻塞的，没有办法做其他事情，而DMA技术的引入就是在进行 I&#x2F;O 设备和内存的数据传输的时候，<strong>数据搬运的工作全部交给 DMA 控制器</strong>，而 CPU 不再参与任何与数据搬运相关的事情，这样 CPU 就可以去处理别的事务；但是 CPU 在这个过程中也是必不可少的，因为传输什么数据，从哪里传输到哪里，都需要 CPU 来告诉 DMA 控制器</li>
<li>DMA的工作过程：<ul>
<li>首先是用户进程调用 read 方法，向操作系统发出 I&#x2F;O 请求，请求读取数据到自己的内存缓冲区中，进程进入阻塞状态；</li>
<li>操作系统收到请求后，进一步将 I&#x2F;O 请求发送 DMA，然后让 CPU 执行其他任务；</li>
<li>DMA 进一步将 I&#x2F;O 请求发送给磁盘；</li>
<li>磁盘收到 DMA 的 I&#x2F;O 请求，把数据从磁盘读取到磁盘控制器的缓冲区中，当磁盘控制器的缓冲区被读满后，向 DMA 发起中断信号，告知自己缓冲区已满；</li>
<li><strong>DMA 收到磁盘的信号，将磁盘控制器缓冲区中的数据拷贝到内核缓冲区中，此时不占用 CPU，CPU 可以执行其他任务</strong>；</li>
<li>当 DMA 读取了足够多的数据，就会发送中断信号给 CPU；</li>
<li>CPU 收到 DMA 的信号，知道数据已经准备好，于是将数据从内核拷贝到用户空间，系统调用返回；</li>
</ul>
</li>
<li>传统的文件传输是通过write和read实现，这样子就需要两个系统调用，伴随着<strong>4 次用户态与内核态的上下文切换</strong> （高并发的场景下，上下文切换的时间容易被累积和放大，从而影响系统的性能），其次还<strong>发生了 4 次数据拷贝</strong>，其中两次是 DMA 的拷贝，另外两次则是通过 CPU 拷贝的；<strong>要想提高文件传输的性能，就需要减少「用户态与内核态的上下文切换」和「内存拷贝」的次数</strong></li>
<li><strong>要想减少上下文切换到次数，就要减少系统调用的次数</strong>，从内核的读缓冲区拷贝到用户的缓冲区里，再从用户的缓冲区里拷贝到 socket 的缓冲区里这个过程是没有必要的，因为文件传输的应用场景中，在用户空间不会对数据再加工，所以数据实际上可以不用搬运到用户空间，因此<strong>用户的缓冲区是没有必要存在的</strong></li>
<li>零拷贝技术实现的方式通常有 2 种：<ul>
<li>mmap + write：<code>mmap()</code> 系统调用函数会直接把内核缓冲区里的数据「<strong>映射</strong>」到用户空间，这样，操作系统内核与用户空间就不需要再进行任何的数据拷贝操作，使用 <code>mmap()</code> 来代替 <code>read()</code>， 可以减少一次数据拷贝的过程。具体过程如下：<ul>
<li>应用进程调用了 <code>mmap()</code> 后，DMA 会把磁盘的数据拷贝到内核的缓冲区里。接着，应用进程跟操作系统内核「共享」这个缓冲区；</li>
<li>应用进程再调用 <code>write()</code>，操作系统直接将内核缓冲区的数据拷贝到 socket 缓冲区中，这一切都发生在内核态，由 CPU 来搬运数据；</li>
<li>最后，把内核的 socket 缓冲区里的数据，拷贝到网卡的缓冲区里，这个过程是由 DMA 搬运的</li>
</ul>
</li>
<li>sendfile：可以替代 <code>read()</code> 和 <code>write()</code> 这两个系统调用，这样就可以减少一次系统调用，也就减少了 2 次上下文切换的开销，其次该系统调用可以直接把内核缓冲区里的数据拷贝到 socket 缓冲区里，不再拷贝到用户态，这样就只有 2 次上下文切换，和 3 次数据拷贝<ul>
<li>如果网卡支持 SG-DMA（<em>The Scatter-Gather Direct Memory Access</em>）技术，缓冲区描述符和数据长度会传到 socket 缓冲区，这样网卡的 SG-DMA 控制器就可以直接将内核缓存中的数据拷贝到网卡的缓冲区里，此过程不需要将数据从操作系统内核缓冲区拷贝到 socket 缓冲区中，这样就减少了一次数据拷贝</li>
<li>这就是所谓的<strong>零拷贝（<em>Zero-copy</em>）技术，因为没有在内存层面去拷贝数据，也就是说全程没有通过 CPU 来搬运数据，所有的数据都是通过 DMA 来进行传输的</strong></li>
</ul>
</li>
</ul>
</li>
<li>零拷贝技术的文件传输方式相比传统文件传输的方式，减少了 2 次上下文切换和数据拷贝次数，<strong>只需要 2 次上下文切换和数据拷贝次数，就可以完成文件的传输，而且 2 次的数据拷贝过程，都不需要通过 CPU，2 次都是由 DMA 来搬运</strong>，总体来看，<strong>零拷贝技术可以把文件传输的性能提高至少一倍以上</strong><ul>
<li>Kafka 这个开源项目，就利用了「零拷贝」技术，从而大幅提升了 I&#x2F;O 的吞吐率，这也是 Kafka 在处理海量数据为什么这么快的原因之一</li>
</ul>
</li>
<li>文件传输过程，其中第一步都是先需要先把磁盘文件数据拷贝「内核缓冲区」里，这个内核缓冲区实际上是<strong>磁盘高速缓存（<em>PageCache</em>）</strong>。由于零拷贝使用了 PageCache 技术，可以使得零拷贝进一步提升了性能<ul>
<li>内存空间远比磁盘要小，内存注定只能拷贝磁盘里的一小部分数据。程序运行的时候具有局部性，所以通常刚被访问的数据在短时间内再次被访问的概率很高，于是可以用 <strong>PageCache 来缓存最近被访问的数据</strong>，当空间不足时淘汰最久未被访问的缓存；读磁盘数据的时候，优先在 PageCache 找，如果数据存在则可以直接返回；如果没有，则从磁盘中读取，然后缓存 PageCache 中</li>
<li>读取磁盘数据的时候，需要找到数据所在的位置，但是对于机械磁盘来说，就是通过磁头旋转到数据所在的扇区，再开始顺序读取数据，但是旋转磁头这个物理动作是非常耗时的，为了降低它的影响，<strong>PageCache 使用了「预读功能」</strong></li>
<li><strong>但是，在传输大文件（GB 级别的文件）的时候，PageCache 会不起作用，那就白白浪费 DMA 多做的一次数据拷贝，造成性能的降低，即使使用了 PageCache 的零拷贝也会损失性能</strong>；针对大文件的传输，不应该使用 PageCache，也就是说不应该使用零拷贝技术，因为可能由于 PageCache 被大文件占据，而导致「热点」小文件无法利用到 PageCache，这样在高并发的环境下，会带来严重的性能问题</li>
</ul>
</li>
<li>绕开 PageCache 的 I&#x2F;O 叫直接 I&#x2F;O，使用 PageCache 的 I&#x2F;O 则叫缓存 I&#x2F;O。通常，对于磁盘，异步 I&#x2F;O 只支持直接 I&#x2F;O。<strong>在高并发的场景下，针对大文件的传输的方式，应该使用「异步 I&#x2F;O + 直接 I&#x2F;O」来替代零拷贝技术</strong></li>
</ul>
<h3 id="9-2-I-x2F-O-多路复用：select-x2F-poll-x2F-epoll"><a href="#9-2-I-x2F-O-多路复用：select-x2F-poll-x2F-epoll" class="headerlink" title="9.2 I&#x2F;O 多路复用：select&#x2F;poll&#x2F;epoll"></a>9.2 I&#x2F;O 多路复用：select&#x2F;poll&#x2F;epoll</h3><ul>
<li><p>最基本的 Socket 模型</p>
<ul>
<li>双方要进行网络通信前，各自得创建一个 Socket，这相当于客户端和服务器都开了一个“口子”，双方读取和发送数据的时候，都通过这个“口子”。很像弄了一根网线，一头插在客户端，一头插在服务端，然后进行通信。</li>
<li>服务端首先调用 <code>socket()</code> 函数，创建网络协议为 IPv4，以及传输协议为 TCP 的 Socket ，接着调用 <code>bind()</code> 函数，给这个 Socket 绑定一个 <strong>IP 地址和端口</strong><ul>
<li>绑定端口的目的：当内核收到 TCP 报文，通过 TCP 头里面的端口号，来找到我们的应用程序，然后把数据传递给我们。</li>
<li>绑定 IP 地址的目的：一台机器是可以有多个网卡的，每个网卡都有对应的 IP 地址，当绑定一个网卡时，内核在收到该网卡上的包，才会发给我们；</li>
</ul>
</li>
<li>绑定完 IP 地址和端口后，就可以调用 <code>listen()</code> 函数进行监听，此时对应 TCP 状态图中的 <code>listen</code>，如果我们要判定服务器中一个网络程序有没有启动，可以通过 <code>netstat</code> 命令查看对应的端口号是否有被监听。</li>
<li>服务端进入了监听状态后，通过调用 <code>accept()</code> 函数，来从内核获取客户端的连接，如果没有客户端连接，则会阻塞等待客户端连接的到来。</li>
<li>客户端在创建好 Socket 后，调用 <code>connect()</code> 函数发起连接，该函数的参数要指明服务端的 IP 地址和端口号，然后就开始TCP 三次握手了。</li>
<li>在 TCP 连接的过程中，服务器的内核实际上为每个 Socket 维护了两个队列：<ul>
<li>一个是「还没完全建立」连接的队列，称为 <strong>TCP 半连接队列</strong>，这个队列都是没有完成三次握手的连接，此时服务端处于 <code>syn_rcvd</code> 的状态；</li>
<li>一个是「已经建立」连接的队列，称为 <strong>TCP 全连接队列</strong>，这个队列都是完成了三次握手的连接，此时服务端处于 <code>established</code> 状态；</li>
</ul>
</li>
<li>当 TCP 全连接队列不为空后，服务端的 <code>accept()</code> 函数，就会从内核中的 TCP 全连接队列里拿出一个已经完成连接的 Socket 返回应用程序，后续数据传输都用这个 Socket。注意，监听的 Socket 和真正用来传数据的 Socket 是两个：<ul>
<li>一个叫作<strong>监听 Socket</strong>；</li>
<li>一个叫作<strong>已连接 Socket</strong>；</li>
</ul>
</li>
</ul>
</li>
<li><p>内核里的数据结构</p>
<ul>
<li>每一个进程都有一个数据结构 <code>task_struct</code>，该结构体里有一个指向「文件描述符数组」的成员指针。该数组里列出这个进程打开的所有文件的文件描述符。数组的下标是文件描述符，是一个整数，而数组的内容是一个指针，指向内核中所有打开的文件的列表，也就是说内核可以通过文件描述符找到对应打开的文件。</li>
<li>每个文件都有一个 inode，Socket 文件的 inode 指向了内核中的 Socket 结构，在这个结构体里有两个队列，分别是<strong>发送队列</strong>和<strong>接收队列</strong>，这个两个队列里面保存的是一个个 <code>struct sk_buff</code>，用链表的组织形式串起来。</li>
<li>sk_buff 可以表示各个层的数据包，在应用层数据包叫 data，在 TCP 层我们称为 segment，在 IP 层我们叫 packet，在数据链路层称为 frame。过调整 sk_buff 中 <code>data</code> 的指针实现协议的转换</li>
</ul>
</li>
<li><p>如果服务器只能服务一个客户，那就太浪费资源了，于是要改进这个网络 I&#x2F;O 模型，以支持更多的客户端。服务器单机理论最大能连接多少个客户端？ </p>
<ul>
<li>TCP 连接是由四元组唯一确认的，这个四元组就是：<strong>本机IP, 本机端口, 对端IP, 对端端口</strong>。</li>
<li>服务器作为服务方，通常会在本地固定监听一个端口，等待客户端的连接。因此服务器的本地 IP 和端口是固定的，于是对于服务端 TCP 连接的四元组只有对端 IP 和端口是会变化的，所以<strong>最大 TCP 连接数 &#x3D; 客户端 IP 数×客户端端口数</strong>。</li>
<li>对于 IPv4，客户端的 IP 数最多为 2 的 32 次方，客户端的端口数最多为 2 的 16 次方，也就是<strong>服务端单机最大 TCP 连接数约为 2 的 48 次方</strong>。这个理论值相当“丰满”，但是服务器肯定承载不了那么大的连接数，主要会受<strong>文件描述符</strong>和<strong>系统内存</strong>的限制</li>
<li>从硬件资源角度看，对于 2GB 内存千兆网卡的服务器，如果每个请求处理占用不到 200KB 的内存和 100Kbit 的网络带宽就可以满足并发 1 万个请求</li>
</ul>
</li>
<li><p>基于最原始的阻塞网络 I&#x2F;O， 如果服务器要支持多个客户端，其中比较传统的方式，就是使用<strong>多进程模型</strong>，也就是为每个客户端分配一个进程来处理请求。</p>
<ul>
<li>服务器的主进程负责监听客户的连接，一旦与客户端连接完成，accept() 函数就会返回一个「已连接 Socket」，这时就通过 <code>fork()</code> 函数创建一个子进程，实际上就把父进程所有相关的东西都<strong>复制</strong>一份，包括文件描述符、内存地址空间、程序计数器、执行的代码等。</li>
<li>这两个进程刚复制完的时候，几乎一模一样。不过，会根据<strong>返回值</strong>来区分是父进程还是子进程，如果返回值是 0，则是子进程；如果返回值是其他的整数，就是父进程。</li>
<li>正因为子进程会<strong>复制父进程的文件描述符</strong>，于是就可以直接使用「已连接 Socket 」和客户端通信了，子进程不需要关心「监听 Socket」，只需要关心「已连接 Socket」；父进程则相反，将客户服务交给子进程来处理，因此父进程不需要关心「已连接 Socket」，只需要关心「监听 Socket」</li>
<li>当「子进程」退出时，实际上内核里还会保留该进程的一些信息，也是会占用内存的，如果不做好“回收”工作，就会变成<strong>僵尸进程</strong>，随着僵尸进程越多，会慢慢耗尽我们的系统资源。因此，父进程要“善后”好自己的孩子，有两种方式可以在子进程退出后回收资源，分别是调用 <code>wait()</code> 和 <code>waitpid()</code> 函数。</li>
<li>用多个进程来应付多个客户端的方式，在应对 100 个客户端还是可行的，但是当客户端数量高达一万时，肯定扛不住的，因为每产生一个进程，必会占据一定的系统资源，而且进程间上下文切换的“包袱”是很重的，性能会大打折扣</li>
</ul>
</li>
<li><p>比较轻量级的模型来应对多用户的请求 —— <strong>多线程模型</strong>。</p>
<ul>
<li>线程是运行在进程中的一个“逻辑流”，单进程中可以运行多个线程，同进程里的线程可以共享进程的部分资源，比如文件描述符列表、进程空间、代码、全局数据、堆、共享库等，这些共享些资源在上下文切换时不需要切换，而只需要切换线程的私有数据、寄存器等不共享的数据，因此同一个进程下的线程上下文切换的开销要比进程小得多</li>
<li>当服务器与客户端 TCP 完成连接后，通过 <code>pthread_create()</code> 函数创建线程，然后将「已连接 Socket」的文件描述符传递给线程函数，接着在线程里和客户端进行通信，从而达到并发处理的目的。</li>
<li>如果每来一个连接就创建一个线程，线程运行完后，还得操作系统还得销毁线程，虽说线程切换的上写文开销不大，但是如果频繁创建和销毁线程，系统开销也是不小的</li>
<li>可以使用<strong>线程池</strong>的方式来避免线程的频繁创建和销毁，所谓的线程池，就是提前创建若干个线程，这样当由新连接建立时，将这个已连接的 Socket 放入到一个队列里，然后线程池里的线程负责从队列中取出「已连接 Socket 」进行处理。这个队列是全局的，每个线程都会操作，为了避免多线程竞争，线程在操作这个队列前要加锁。</li>
<li>如果要达到 C10K，意味着要一台机器维护 1 万个连接，相当于要维护 1 万个进程&#x2F;线程，操作系统就算死扛也是扛不住的</li>
</ul>
</li>
<li><p>一个进程虽然任一时刻只能处理一个请求，但是处理每个请求的事件时，耗时控制在 1 毫秒以内，这样 1 秒内就可以处理上千个请求，把时间拉长来看，多个请求复用了一个进程，这就是多路复用，这种思想很类似一个 CPU 并发多个进程，所以也叫做时分多路复用。 select&#x2F;poll&#x2F;epoll 内核提供给用户态的多路复用系统调用，<strong>进程可以通过一个系统调用函数从内核中获取多个事件</strong>。</p>
<ul>
<li><p>select 实现多路复用的方式是，将已连接的 Socket 都放到一个<strong>文件描述符集合</strong>，然后调用 select 函数将文件描述符集合<strong>拷贝</strong>到内核里，让内核来检查是否有网络事件产生，检查的方式很粗暴，就是通过<strong>遍历</strong>文件描述符集合的方式，当检查到有事件产生后，将此 Socket 标记为可读或可写， 接着再把整个文件描述符集合<strong>拷贝</strong>回用户态里，然后用户态还需要再通过<strong>遍历</strong>的方法找到可读或可写的 Socket，然后再对其处理。</p>
<ul>
<li>对于 select 这种方式，需要进行 <strong>2 次「遍历」文件描述符集合</strong>，一次是在内核态里，一个次是在用户态里 ，而且还会发生 <strong>2 次「拷贝」文件描述符集合</strong>，先从用户空间传入内核空间，由内核修改后，再传出到用户空间中。</li>
<li>select 使用固定长度的 BitsMap，表示文件描述符集合，而且所支持的文件描述符的个数是有限制的，在 Linux 系统中，由内核中的 FD_SETSIZE 限制， 默认最大值为 <code>1024</code>，只能监听 0~1023 的文件描述符。</li>
</ul>
</li>
<li><p>poll 不再用 BitsMap 来存储所关注的文件描述符，取而代之用动态数组，以链表形式来组织，突破了 select 的文件描述符个数限制，当然还会受到系统文件描述符限制。</p>
<ul>
<li>但是 poll 和 select 并没有太大的本质区别，<strong>都是使用「线性结构」存储进程关注的 Socket 集合，因此都需要遍历文件描述符集合来找到可读或可写的 Socket，时间复杂度为 O(n)，而且也需要在用户态与内核态之间拷贝文件描述符集合</strong>，这种方式随着并发数上来，性能的损耗会呈指数级增长</li>
</ul>
</li>
<li><p>epoll 的用法：先用epoll_create 创建一个 epoll对象 epfd，再通过 epoll_ctl 将需要监视的 socket 添加到epfd中，最后调用 epoll_wait 等待数据。</p>
<ul>
<li>epoll 在内核里使用<strong>红黑树来跟踪进程所有待检测的文件描述字</strong>，把需要监控的 socket 通过 <code>epoll_ctl()</code> 函数加入内核中的红黑树里，红黑树是个高效的数据结构，增删改一般时间复杂度是 <code>O(logn)</code>。而 select&#x2F;poll 内核里没有类似 epoll 红黑树这种保存所有待检测的 socket 的数据结构，所以 select&#x2F;poll 每次操作时都传入整个 socket 集合给内核，而 epoll 因为在内核维护了红黑树，可以保存所有待检测的 socket ，所以只需要传入一个待检测的 socket，减少了内核和用户空间大量的数据拷贝和内存分配。</li>
<li>epoll 使用<strong>事件驱动</strong>的机制，内核里<strong>维护了一个链表来记录就绪事件</strong>，当某个 socket 有事件发生时，通过<strong>回调函数</strong>内核会将其加入到这个就绪事件列表中，当用户调用 <code>epoll_wait()</code> 函数时，只会返回有事件发生的文件描述符的个数，不需要像 select&#x2F;poll 那样轮询扫描整个 socket 集合，大大提高了检测的效率。</li>
</ul>
</li>
<li><p>epoll 的方式即使监听的 Socket 数量越多的时候，效率不会大幅度降低，能够同时监听的 Socket 的数目也非常的多了，上限就为系统定义的进程打开的最大文件描述符个数。因而，<strong>epoll 被称为解决 C10K 问题的利器</strong>。</p>
</li>
<li><p>epoll 支持两种事件触发模式，分别是<strong>边缘触发和水平触发</strong></p>
<ul>
<li>使用边缘触发模式时，当被监控的 Socket 描述符上有可读事件发生时，<strong>服务器端只会从 epoll_wait 中苏醒一次</strong>，即使进程没有调用 read 函数从内核读取数据，也依然只苏醒一次，因此我们程序要保证一次性将内核缓冲区的数据读取完；<strong>边缘触发模式一般和非阻塞 I&#x2F;O 搭配使用</strong>，程序会一直执行 I&#x2F;O 操作，直到系统调用（如 <code>read</code> 和 <code>write</code>）返回错误，错误类型为 <code>EAGAIN</code> 或 <code>EWOULDBLOCK</code>。</li>
<li>使用水平触发模式时，当被监控的 Socket 上有可读事件发生时，<strong>服务器端不断地从 epoll_wait 中苏醒，直到内核缓冲区数据被 read 函数读完才结束</strong>，目的是告诉我们有数据需要读取；</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="9-3-高性能网络模式：Reactor-和-Proactor"><a href="#9-3-高性能网络模式：Reactor-和-Proactor" class="headerlink" title="9.3 高性能网络模式：Reactor 和 Proactor"></a>9.3 高性能网络模式：Reactor 和 Proactor</h3><ul>
<li><p>如果要让服务器服务多个客户端，那么最直接的方式就是为每一条连接创建线程。处理完业务逻辑后，随着连接关闭后线程也同样要销毁了，但是这样不停地创建和销毁线程，不仅会带来性能开销，也会造成浪费资源，而且如果要连接几万条连接，创建几万个线程去应对也是不现实的。</p>
<ul>
<li>要这么解决这个问题可以使用「资源复用」的方式。创建一个「线程池」，将连接分配给线程，然后一个线程可以处理多个连接的业务。线程在处理某个连接的 <code>read</code> 操作时，如果遇到没有数据可读，就会发生阻塞，那么线程就没办法继续处理其他连接的业务。</li>
<li>要解决这一个问题，最简单的方式就是将 socket 改成非阻塞，然后线程不断地轮询调用 <code>read</code> 操作来判断是否有数据，这种方式虽然该能够解决阻塞的问题，但是解决的方式比较粗暴，因为轮询是要消耗 CPU 的，而且随着一个 线程处理的连接越多，轮询的效率就会越低。其问题在于线程并不知道当前连接是否有数据可读，从而需要每次通过 <code>read</code> 去试探。</li>
<li>I&#x2F;O 多路复用技术会用一个系统调用函数来监听有关心的连接，也就说可以在一个监控线程里面监控很多的连接。select&#x2F;poll&#x2F;epoll 就是内核提供给用户态的多路复用系统调用，线程可以通过一个系统调用函数从内核中获取多个事件。</li>
</ul>
</li>
<li><p>select&#x2F;poll&#x2F;epoll 是如何获取网络事件的呢？在获取事件时，先把要关心的连接传给内核，再由内核检测：</p>
<ul>
<li>如果没有事件发生，线程只需阻塞在这个系统调用，而无需像前面的线程池方案那样轮训调用 read 操作来判断是否有数据。</li>
<li>如果有事件发生，内核会返回产生了事件的连接，线程就会从阻塞状态返回，然后在用户态中再处理这些连接对应的业务即可。</li>
</ul>
</li>
<li><p>当下开源软件能做到网络高性能的原因基本是基于 I&#x2F;O 多路复用，但是使用I&#x2F;O 多路复用接口写网络程序是面向过程的方式写代码的，开发的效率不高。于是，大佬们基于面向对象的思想，对 I&#x2F;O 多路复用作了一层封装，让使用者不用考虑底层网络 API 的细节，只需要关注应用代码的编写：<strong>Reactor 模式</strong>。也叫 <code>Dispatcher</code> 模式，即 <strong>I&#x2F;O 多路复用监听事件，收到事件后，根据事件类型分配（Dispatch）给某个进程 &#x2F; 线程</strong>。Reactor 模式主要由 Reactor 和处理资源池这两个核心部分组成，它俩负责的事情如下：</p>
<ul>
<li>Reactor 负责监听和分发事件，事件类型包含连接事件、读写事件；</li>
<li>处理资源池负责处理事件，如 read -&gt; 业务逻辑 -&gt; send；</li>
</ul>
<p>Reactor 模式是灵活多变的，可以应对不同的业务场景，灵活在于：</p>
<ul>
<li>Reactor 的数量可以只有一个，也可以有多个；</li>
<li>处理资源池可以是单个进程 &#x2F; 线程，也可以是多个进程 &#x2F;线程；</li>
</ul>
<p>方案具体使用进程还是线程，要看使用的编程语言以及平台有关：</p>
<ul>
<li>Java 语言一般使用线程，比如 Netty;</li>
<li>C 语言使用进程和线程都可以，例如 Nginx 使用的是进程，Memcache 使用的是线程。</li>
</ul>
</li>
<li><p>单 Reactor 单进程 &#x2F; 线程</p>
<ul>
<li><p>一般来说，C 语言实现的是「<strong>单 Reactor <em>单进程</em></strong>」的方案，因为 C 语编写完的程序，运行后就是一个独立的进程，不需要在进程中再创建线程。</p>
</li>
<li><p>而 Java 语言实现的是「<strong>单 Reactor <em>单线程</em></strong>」的方案，因为 Java 程序是跑在 Java 虚拟机这个进程上面的，虚拟机中有很多线程，写的 Java 程序只是其中的一个线程而已</p>
</li>
<li><p>进程里有 <strong>Reactor、Acceptor、Handler</strong> 这三个对象：</p>
<ul>
<li>Reactor 对象的作用是监听和分发事件；</li>
<li>Acceptor 对象的作用是获取连接；</li>
<li>Handler 对象的作用是处理业务；</li>
</ul>
</li>
<li><p>单 Reactor 单进程这个方案：</p>
<ul>
<li>Reactor 对象通过 select （IO 多路复用接口） 监听事件，收到事件后通过 dispatch 进行分发，具体分发给 Acceptor 对象还是 Handler 对象，还要看收到的事件类型；</li>
<li>如果是连接建立的事件，则交由 Acceptor 对象进行处理，Acceptor 对象会通过 accept 方法 获取连接，并创建一个 Handler 对象来处理后续的响应事件；</li>
<li>如果不是连接建立事件， 则交由当前连接对应的 Handler 对象来进行响应；</li>
<li>Handler 对象通过 read -&gt; 业务处理 -&gt; send 的流程来完成完整的业务流程。</li>
</ul>
</li>
<li><p>单 Reactor 单进程的方案因为全部工作都在同一个进程内完成，所以实现起来比较简单，不需要考虑进程间通信，也不用担心多进程竞争。</p>
</li>
<li><p>这种方案存在 2 个缺点：</p>
<ul>
<li>第一个缺点，因为只有一个进程，<strong>无法充分利用 多核 CPU 的性能</strong>；</li>
<li>第二个缺点，Handler 对象在业务处理时，整个进程是无法处理其他连接的事件的，<strong>如果业务处理耗时比较长，那么就造成响应的延迟</strong>；</li>
</ul>
<p>所以，单 Reactor 单进程的方案<strong>不适用计算机密集型的场景，只适用于业务处理非常快速的场景</strong>。</p>
</li>
<li><p>Redis 是由 C 语言实现的，在 Redis 6.0 版本之前采用的正是「单 Reactor 单进程」的方案，因为 Redis 业务处理主要是在内存中完成，操作的速度是很快的，性能瓶颈不在 CPU 上，所以 Redis 对于命令的处理是单进程的方案</p>
</li>
</ul>
</li>
<li><p>单 Reactor 多线程 &#x2F; 多进程</p>
<ul>
<li>Reactor 对象通过 select （IO 多路复用接口） 监听事件，收到事件后通过 dispatch 进行分发，具体分发给 Acceptor 对象还是 Handler 对象，还要看收到的事件类型；</li>
<li>如果是连接建立的事件，则交由 Acceptor 对象进行处理，Acceptor 对象会通过 accept 方法 获取连接，并创建一个 Handler 对象来处理后续的响应事件；</li>
<li>如果不是连接建立事件， 则交由当前连接对应的 Handler 对象来进行响应；</li>
</ul>
<p>上面的三个步骤和单 Reactor 单线程方案是一样的，接下来的步骤就开始不一样了：</p>
<ul>
<li>Handler 对象不再负责业务处理，只负责数据的接收和发送，Handler 对象通过 read 读取到数据后，会将数据发给子线程里的 Processor 对象进行业务处理；</li>
<li>子线程里的 Processor 对象就进行业务处理，处理完后，将结果发给主线程中的 Handler 对象，接着由 Handler 通过 send 方法将响应结果发送给 client；</li>
</ul>
<p>单 Reator 多线程的方案优势在于<strong>能够充分利用多核 CPU 的能力</strong>，那既然引入多线程，那么自然就带来了多线程竞争资源的问题。</p>
<ul>
<li>例如，子线程完成业务处理后，要把结果传递给主线程的 Handler 进行发送，这里涉及共享数据的竞争。</li>
<li>要避免多线程由于竞争共享资源而导致数据错乱的问题，就需要在操作共享资源前加上互斥锁，以保证任意时间里只有一个线程在操作共享资源，待该线程操作完释放互斥锁后，其他线程才有机会操作共享数据。</li>
<li>单 Reactor 多进程相比单 Reactor 多线程实现起来很麻烦，主要因为要考虑子进程 &lt;-&gt; 父进程的双向通信，并且父进程还得知道子进程要将数据发送给哪个客户端。而多线程间可以共享数据，虽然要额外考虑并发问题，但是这远比进程间通信的复杂度低得多，因此实际应用中也看不到单 Reactor 多进程的模式。</li>
<li>另外，「单 Reactor」的模式还有个问题，<strong>因为一个 Reactor 对象承担所有事件的监听和响应，而且只在主线程中运行，在面对瞬间高并发的场景时，容易成为性能的瓶颈的地方</strong>。</li>
</ul>
</li>
<li><p>多 Reactor 多进程 &#x2F; 线程</p>
<ul>
<li>主线程中的 MainReactor 对象通过 select 监控连接建立事件，收到事件后通过 Acceptor 对象中的 accept 获取连接，将新的连接分配给某个子线程；</li>
<li>子线程中的 SubReactor 对象将 MainReactor 对象分配的连接加入 select 继续进行监听，并创建一个 Handler 用于处理连接的响应事件。</li>
<li>如果有新的事件发生时，SubReactor 对象会调用当前连接对应的 Handler 对象来进行响应。</li>
<li>Handler 对象通过 read -&gt; 业务处理 -&gt; send 的流程来完成完整的业务流程。</li>
</ul>
<p>多 Reactor 多线程的方案虽然看起来复杂的，但是实际实现时比单 Reactor 多线程的方案要简单的多，原因如下：</p>
<ul>
<li>主线程和子线程分工明确，主线程只负责接收新连接，子线程负责完成后续的业务处理。</li>
<li>主线程和子线程的交互很简单，主线程只需要把新连接传给子线程，子线程无须返回数据，直接就可以在子线程将处理结果发送给客户端。</li>
</ul>
<p>大名鼎鼎的两个开源软件 Netty 和 Memcache 都采用了「多 Reactor 多线程」的方案。采用了「多 Reactor 多进程」方案的开源软件是 Nginx，不过方案与标准的多 Reactor 多进程有些差异。具体差异表现在主进程中仅仅用来初始化 socket，并没有创建 mainReactor 来 accept 连接，而是由子进程的 Reactor 来 accept 连接，通过锁来控制一次只有一个子进程进行 accept（防止出现惊群现象），子进程 accept 新连接后就放到自己的 Reactor 进行处理，不会再分配给其他子进程。</p>
</li>
<li><p>阻塞、非阻塞、同步、异步 I&#x2F;O 的概念</p>
<ul>
<li><strong>阻塞 I&#x2F;O</strong>，当用户程序执行 <code>read</code> ，线程会被阻塞，一直等到内核数据准备好，并把数据从内核缓冲区拷贝到应用程序的缓冲区中，当拷贝过程完成，<code>read</code> 才会返回。注意，<strong>阻塞等待的是「内核数据准备好」和「数据从内核态拷贝到用户态」这两个过程</strong></li>
<li><strong>非阻塞 I&#x2F;O</strong>，非阻塞的 read 请求在数据未准备好的情况下立即返回，可以继续往下执行，此时应用程序不断轮询内核，直到数据准备好，内核将数据拷贝到应用程序缓冲区，<code>read</code> 调用才可以获取到结果；<strong>最后一次 read 调用，获取数据的过程，是一个同步的过程，是需要等待的过程。这里的同步指的是内核态的数据拷贝到用户程序的缓存区这个过程。</strong></li>
<li>无论 read 和 send 是阻塞 I&#x2F;O，还是非阻塞 I&#x2F;O 都是同步调用。因为在 read 调用时，内核将数据从内核空间拷贝到用户空间的过程都是需要等待的，也就是说这个过程是同步的，如果内核实现的拷贝效率不高，read 调用就会在这个同步过程中等待比较长的时间。</li>
<li>真正的<strong>异步 I&#x2F;O</strong> 是「内核数据准备好」和「数据从内核态拷贝到用户态」这<strong>两个过程都不用等待</strong>；发起 <code>aio_read</code> （异步 I&#x2F;O） 之后，就立即返回，内核自动将数据从内核空间拷贝到用户空间，这个拷贝过程同样是异步的，内核自动完成的，和前面的同步操作不一样，<strong>应用程序并不需要主动发起拷贝动作</strong></li>
</ul>
</li>
<li><p>Reactor 是非阻塞同步网络模式，而 <strong>Proactor 是异步网络模式</strong>。Reactor 和 Proactor 的区别：</p>
<ul>
<li><strong>Reactor 是非阻塞同步网络模式，感知的是就绪可读写事件</strong>。在每次感知到有事件发生（比如可读就绪事件）后，就需要应用进程主动调用 read 方法来完成数据的读取，也就是要应用进程主动将 socket 接收缓存中的数据读到应用进程内存中，这个过程是同步的，读取完数据后应用进程才能处理数据。</li>
<li><strong>Proactor 是异步网络模式， 感知的是已完成的读写事件</strong>。在发起异步读写请求时，需要传入数据缓冲区的地址（用来存放结果数据）等信息，这样系统内核才可以自动帮我们把数据的读写工作完成，这里的读写工作全程由操作系统来做，并不需要像 Reactor 那样还需要应用进程主动发起 read&#x2F;write 来读写数据，操作系统完成读写工作后，就会通知应用进程直接处理数据。</li>
</ul>
<p><strong>Reactor 可以理解为「来了事件操作系统通知应用进程，让应用进程来处理」</strong>，而 <strong>Proactor 可以理解为「来了事件操作系统来处理，处理完再通知应用进程」</strong>。这里的「事件」就是有新连接、有数据可读、有数据可写的这些 I&#x2F;O 事件这里的「处理」包含从驱动读取到内核以及从内核读取到用户空间。</p>
<p>无论是 Reactor，还是 Proactor，都是一种基于「事件分发」的网络编程模式，区别在于 <strong>Reactor 模式是基于「待完成」的 I&#x2F;O 事件，而 Proactor 模式则是基于「已完成」的 I&#x2F;O 事件</strong></p>
</li>
<li><p>Proactor 模式的工作流程：</p>
<ul>
<li>Proactor Initiator 负责创建 Proactor 和 Handler 对象，并将 Proactor 和 Handler 都通过 Asynchronous Operation Processor 注册到内核；</li>
<li>Asynchronous Operation Processor 负责处理注册请求，并处理 I&#x2F;O 操作；</li>
<li>Asynchronous Operation Processor 完成 I&#x2F;O 操作后通知 Proactor；</li>
<li>Proactor 根据不同的事件类型回调不同的 Handler 进行业务处理；</li>
<li>Handler 完成业务处理；</li>
</ul>
</li>
</ul>
<h3 id="9-4-什么是一致性哈希？"><a href="#9-4-什么是一致性哈希？" class="headerlink" title="9.4 什么是一致性哈希？"></a>9.4 什么是一致性哈希？</h3><ul>
<li><p>大多数网站背后肯定不是只有一台服务器提供服务，因为单机的并发量和数据量都是有限的，所以都会用多台服务器构成集群来对外提供服务。要如何分配客户端的请求呢？</p>
<ul>
<li>最简单的方式，引入一个中间的负载均衡层，让它将外界的请求「轮流」的转发给内部的集群。考虑到每个节点的硬件配置有所区别，我们可以引入权重值，将硬件配置更好的节点的权重值设高，然后根据各个节点的权重值，按照一定比重分配在不同的节点上，让硬件配置更好的节点承担更多的请求，这种算法叫做加权轮询</li>
<li>加权轮询算法是无法应对分布式系统（数据分片的系统）的，因为分布式系统中，每个节点存储的数据是不同的；想提高系统的容量，就会将数据水平切分到不同的节点来存储，也就是将数据分布到了不同的节点。比如<strong>一个分布式 KV（key-valu） 缓存系统，某个 key 应该到哪个或者哪些节点上获得，应该是确定的</strong>，不是说任意访问一个节点都可以得到缓存结果的。</li>
<li>要想一个能应对分布式系统的负载均衡算法：<strong>哈希算法</strong>。因为对同一个关键字进行哈希计算，每次计算都是相同的值，这样就可以将某个 key 确定到一个节点了，可以满足分布式系统的负载均衡需求</li>
</ul>
</li>
<li><p>使用哈希算法有什么问题？</p>
<ul>
<li><strong>如果节点数量发生了变化，也就是在对系统做扩容或者缩容时，必须迁移改变了映射关系的数据</strong>，否则会出现查询不到数据的问题。</li>
<li>假设总数据条数为 M，哈希算法在面对节点数量变化时，**最坏情况下所有数据都需要迁移，所以它的数据迁移规模是 O(M)**，这样数据的迁移成本太高了。</li>
</ul>
</li>
<li><p>一致性哈希算法就很好地解决了分布式系统在扩容或者缩容时，发生过多的数据迁移的问题。</p>
<ul>
<li>一致哈希算法也用了取模运算，但与哈希算法不同的是，哈希算法是对节点的数量进行取模运算，而<strong>一致哈希算法是对 2^32 进行取模运算，是一个固定的值</strong>。</li>
<li>一致性哈希要进行两步哈希：<ul>
<li>第一步：对存储节点进行哈希计算，也就是对存储节点做哈希映射，比如根据节点的 IP 地址进行哈希；</li>
<li>第二步：当对数据进行存储或访问时，对数据进行哈希映射；</li>
</ul>
</li>
<li><strong>一致性哈希是指将「存储节点」和「数据」都映射到一个首尾相连的哈希环上</strong>。对「数据」进行哈希映射得到一个结果往<strong>顺时针的方向的找到第一个节点</strong>，就是存储该数据的节点<ul>
<li>因此，<strong>在一致哈希算法中，如果增加或者移除一个节点，仅影响该节点在哈希环上顺时针相邻的后继节点，其它数据也不会受到影响</strong>。</li>
</ul>
</li>
<li>但是<strong>一致性哈希算法并不保证节点能够在哈希环上分布均匀</strong>，这样就会带来一个问题，会有大量的请求集中在一个节点上。在这种节点分布不均匀的情况下，进行容灾与扩容时，哈希环上的相邻节点容易受到过大影响，容易发生雪崩式的连锁反应。</li>
</ul>
</li>
<li><p>要想解决节点能在哈希环上分配不均匀的问题，就是要有大量的节点，节点数越多，哈希环上的节点分布的就越均匀。</p>
<ul>
<li><strong>不再将真实节点映射到哈希环上，而是将虚拟节点映射到哈希环上，并将虚拟节点映射到实际节点，所以这里有「两层」映射关系。</strong></li>
<li><strong>节虚拟节点除了会提高节点的均衡度，还会提高系统的稳定性。</strong>当节点变化时，会有不同的节点共同分担系统的变化，因此稳定性更高。</li>
<li>有了虚拟节点后，还可以为硬件配置更好的节点增加权重，比如对权重更高的节点增加更多的虚拟机节点即可。因此，<strong>带虚拟节点的一致性哈希方法不仅适合硬件配置不同的节点的场景，而且适合节点规模会发生变化的场景</strong></li>
</ul>
</li>
</ul>
<h3 id="10-1-如何查看网络的性能指标？"><a href="#10-1-如何查看网络的性能指标？" class="headerlink" title="10.1 如何查看网络的性能指标？"></a>10.1 如何查看网络的性能指标？</h3><ul>
<li><p>通常是以 4 个指标来衡量网络的性能，分别是带宽、延时、吞吐率、PPS（Packet Per Second），它们表示的意义如下：</p>
<ul>
<li><em>带宽</em>，表示链路的最大传输速率，单位是 b&#x2F;s （比特 &#x2F; 秒），带宽越大，其传输能力就越强。</li>
<li><em>延时</em>，表示请求数据包发送后，收到对端响应，所需要的时间延迟。不同的场景有着不同的含义，比如可以表示建立 TCP 连接所需的时间延迟，或一个数据包往返所需的时间延迟。</li>
<li><em>吞吐率</em>，表示单位时间内成功传输的数据量，单位是 b&#x2F;s（比特 &#x2F; 秒）或者 B&#x2F;s（字节 &#x2F; 秒），吞吐受带宽限制，带宽越大，吞吐率的上限才可能越高。</li>
<li><em>PPS</em>，全称是 Packet Per Second（包 &#x2F; 秒），表示以网络包为单位的传输速率，一般用来评估系统对于网络的转发能力。</li>
</ul>
<p>当然，除了以上这四种基本的指标，还有一些其他常用的性能指标，比如：</p>
<ul>
<li><em>网络的可用性</em>，表示网络能否正常通信；</li>
<li><em>并发连接数</em>，表示 TCP 连接数量；</li>
<li><em>丢包率</em>，表示所丢失数据包数量占所发送数据组的比率；</li>
<li><em>重传率</em>，表示重传网络包的比例；</li>
</ul>
</li>
<li><p>要想知道网络的配置和状态，可以使用 <code>ifconfig</code> 或者 <code>ip</code> 命令来查看。虽然这两个命令输出的格式不尽相同，但是输出的内容基本相同，比如都包含了 IP 地址、子网掩码、MAC 地址、网关地址、MTU 大小、网口的状态以及网络包收发的统计信息</p>
</li>
<li><p>可以使用 <code>netstat</code> 或者 <code>ss</code>，这两个命令查看 socket、网络协议栈、网口以及路由表的信息。</p>
<ul>
<li>虽然 <code>netstat</code> 与 <code>ss</code> 命令查看的信息都差不多，但是如果在生产环境中要查看这类信息的时候，尽量不要使用 <code>netstat</code> 命令，因为它的性能不好，在系统比较繁忙的情况下，如果频繁使用 <code>netstat</code> 命令则会对性能的开销雪上加霜，所以更推荐你使用性能更好的 <code>ss</code> 命令。</li>
<li>输出的内容都差不多， 比如都包含了 socket 的状态（<em>State</em>）、接收队列（<em>Recv-Q</em>）、发送队列（<em>Send-Q</em>）、本地地址（<em>Local Address</em>）、远端地址（<em>Foreign Address</em>）、进程 PID 和进程名称（<em>PID&#x2F;Program name</em>）等。</li>
<li><code>ss</code> 命令输出的统计信息相比 <code>netsat</code> 比较少，<code>ss</code> 只显示已经连接（<em>estab</em>）、关闭（<em>closed</em>）、孤儿（<em>orphaned</em>） socket 等简要统计。</li>
<li>而 <code>netstat</code> 则有更详细的网络协议栈信息，比如上面显示了 TCP 协议的主动连接（<em>active connections openings</em>）、被动连接（<em>passive connection openings</em>）、失败重试（<em>failed connection attempts</em>）、发送（<em>segments send out</em>）和接收（<em>segments received</em>）的分段数量等各种信息</li>
</ul>
</li>
<li><p>可以使用 <code>sar</code> 命令当前网络的吞吐率和 PPS，用法是给 <code>sar</code> 增加 <code>-n</code> 参数就可以查看网络的统计信息，比如</p>
<ul>
<li>sar -n DEV，显示网口的统计数据；</li>
<li>sar -n EDEV，显示关于网络错误的统计数据；</li>
<li>sar -n TCP，显示 TCP 的统计数据</li>
<li><code>rxpck/s</code> 和 <code>txpck/s</code> 分别是接收和发送的 PPS，单位为包 &#x2F; 秒。</li>
<li><code>rxkB/s</code> 和 <code>txkB/s</code> 分别是接收和发送的吞吐率，单位是 KB&#x2F; 秒。</li>
<li><code>rxcmp/s</code> 和 <code>txcmp/s</code> 分别是接收和发送的压缩数据包数，单位是包 &#x2F; 秒</li>
</ul>
</li>
<li><p>对于带宽，我们可以使用 <code>ethtool</code> 命令来查询，它的单位通常是 <code>Gb/s</code> 或者 <code>Mb/s</code>，不过注意这里小写字母 <code>b</code> ，表示比特而不是字节。我们通常提到的千兆网卡、万兆网卡等，单位也都是比特（<em>bit</em>）。</p>
</li>
<li><p>要测试本机与远程主机的连通性和延时，通常是使用 <code>ping</code> 命令，它是基于 ICMP 协议的，工作在网络层。</p>
<ul>
<li>显示的内容主要包含 <code>icmp_seq</code>（ICMP 序列号）、<code>TTL</code>（生存时间，或者跳数）以及 <code>time</code> （往返延时），而且最后会汇总本次测试的情况，如果网络没有丢包，<code>packet loss</code> 的百分比就是 0。</li>
<li>不过，需要注意的是，<code>ping</code> 不通服务器并不代表 HTTP 请求也不通，因为有的服务器的防火墙是会禁用 ICMP 协议的</li>
</ul>
</li>
</ul>
<h3 id="10-2-如何从日志分析-PV、UV？"><a href="#10-2-如何从日志分析-PV、UV？" class="headerlink" title="10.2 如何从日志分析 PV、UV？"></a>10.2 如何从日志分析 PV、UV？</h3><ul>
<li>分析日志的时候，先用 <code>ls -lh</code> 命令查看日志文件的大小，如果日志文件大小非常大，最好不要在线上环境做。<ul>
<li>如果日志文件数据量太大，直接一个 <code>cat</code> 命令一执行，是会影响线上环境，加重服务器的负载，严重的话，可能导致服务器无响应。</li>
<li>当发现日志很大的时候，可以使用 <code>scp</code> 命令将文件传输到闲置的服务器再分析</li>
</ul>
</li>
<li>PV 的全称叫 <em>Page View</em>，用户访问一个页面就是一次 PV，比如大多数博客平台，点击一次页面，阅读量就加 1，所以说 PV 的数量并不代表真实的用户数量，只是个点击量。直接使用 <code>wc -l</code> 命令，就可以查看整体的 PV 了</li>
<li>UV 的全称是 <em>Uniq Visitor</em>，它代表访问人数，比如公众号的阅读量就是以 UV 统计的，不管单个用户点击了多少次，最终只算 1 次阅读量。</li>
</ul>
<h2 id="计算机网络"><a href="#计算机网络" class="headerlink" title="计算机网络"></a>计算机网络</h2><h3 id="2-2-键入网址到网页显示，期间发生了什么？"><a href="#2-2-键入网址到网页显示，期间发生了什么？" class="headerlink" title="2.2 键入网址到网页显示，期间发生了什么？"></a>2.2 键入网址到网页显示，期间发生了什么？</h3><ul>
<li>浏览器做的第一步工作是解析 URL，浏览器确定了 Web 服务器和文件名，接下来就是根据这些信息来生成 HTTP 请求消息，然后委托操作系统将消息发送给 <code>Web</code> 服务器</li>
<li>下一步是通过<code>DNS</code> 服务器<strong>查询服务器域名对应的 IP 地址</strong>，整个过程就和日常生活中找人问路的过程类似，<strong>只指路不带路</strong>；浏览器缓存 -&gt; 系统本地缓存 -&gt; host文件 -&gt; 本地DNS -&gt; 根DNS -&gt; 顶级域名服务器(.com) -&gt; 权威域名服务器</li>
<li>然后应用程序（浏览器）通过调用 Socket 库，来委托协议栈工作。协议栈的上半部分有两块，分别是负责收发数据的 TCP 和 UDP 协议，这两个传输协议会接受应用层的委托执行收发数据的操作<ul>
<li>TCP 的连接状态查看，在 Linux 可以通过 <code>netstat -napt</code> 命令查看</li>
</ul>
</li>
<li>协议栈的下面一半是用 IP 协议控制网络包收发操作，在互联网上传数据时，数据会被切分成一块块的网络包，而将网络包发送给对方的操作就是由 IP 负责的<ul>
<li>根据<strong>路由表</strong>规则，来判断哪一个网卡作为源地址 IP，在 Linux 操作系统，可以使用 <code>route -n</code> 命令查看当前系统的路由表</li>
</ul>
</li>
<li>生成了 IP 头部之后，接下来网络包还需要在 IP 头部的前面加上 <strong>MAC 头部</strong>。MAC 头部是以太网使用的头部，它包含了接收方和发送方的 MAC 地址等信息，在 MAC 包头里需要<strong>发送方 MAC 地址</strong>和<strong>接收方目标 MAC 地址</strong>，用于<strong>两点之间的传输</strong><ul>
<li><strong>接收方</strong>的 MAC 地址需要 <code>ARP</code> 协议帮我们找到路由器的 MAC 地址，ARP 协议会在以太网中以<strong>广播</strong>的形式，对以太网所有的设备进行查找MAC地址操作；在后续操作系统会把本次查询结果放到一块叫做 <strong>ARP 缓存</strong>的内存空间留着以后用，不过缓存的时间就几分钟</li>
</ul>
</li>
<li>网络包只是存放在内存中的一串二进制数字信息，没有办法直接发送给对方。因此，我们需要将<strong>数字信息转换为电信号</strong>，才能在网线上传输，也就是说，这才是真正的数据发送过程；负责执行这一操作的是<strong>网卡</strong>，要控制网卡还需要靠<strong>网卡驱动程序</strong>。<ul>
<li>网卡驱动获取网络包之后，会将其<strong>复制</strong>到网卡内的缓存区中，接着会在其<strong>开头加上报头和起始帧分界符，在末尾加上用于检测错误的帧校验序列</strong></li>
</ul>
</li>
<li>交换机的设计是将网络包<strong>原样</strong>转发到目的地。交换机工作在 MAC 层，也称为<strong>二层网络设备</strong>，<strong>交换机根据 MAC 地址表查找 MAC 地址，然后将信号发送到相应的端口</strong><ul>
<li>地址表中找不到指定的 MAC 地址只能将包转发到除了源端口之外的所有端口上，<strong>只有相应的接收者才接收包，而其他设备则会忽略这个包</strong></li>
</ul>
</li>
<li>网络包经过交换机之后，现在到达了<strong>路由器</strong>，并在此被转发到下一个路由器或目标设备。这一步转发的工作原理和交换机类似，也是通过查表判断包转发的目标<ul>
<li><strong>路由器</strong>是基于 IP 设计的，俗称<strong>三层</strong>网络设备，路由器的各个端口都具有 MAC 地址和 IP 地址；检查 MAC 头部中的<strong>接收方 MAC 地址</strong>，看看是不是发给自己的包，如果是就放到接收缓冲区中，否则就丢弃这个包</li>
<li>完成包接收操作之后，路由器就会<strong>去掉</strong>包开头的 MAC 头部。<strong>MAC 头部的作用就是将包送达路由器</strong>，其中的接收方 MAC 地址就是路由器端口的 MAC 地址。因此，当包到达路由器之后，MAC 头部的任务就完成了，于是 MAC 头部就会<strong>被丢弃</strong>。接下来，路由器会根据 MAC 头部后方的 <code>IP</code> 头部中的内容进行包的转发操作<ul>
<li>首先是查询<strong>路由表</strong>判断转发目标</li>
<li>根据<strong>路由表的网关列</strong>判断对方的地址进入包的<strong>发送操作</strong></li>
</ul>
</li>
<li><strong>源 IP 和目标 IP 始终是不会变的，一直变化的是 MAC 地址</strong>，因为需要 MAC 地址在以太网内进行<strong>两个设备</strong>之间的包传输</li>
</ul>
</li>
<li>数据包抵达服务器后，服务器会先扒开数据包的 MAC 头部，查看是否和服务器自己的 MAC 地址符合，符合就将包收起来。接着继续扒开数据包的 IP 头，发现 IP 地址符合，根据 IP 头中协议项，知道自己上层是 TCP 协议。于是，扒开 TCP 的头，里面有序列号，需要看一看这个序列包是不是我想要的，如果是就放入缓存中然后返回一个 ACK，如果不是就丢弃。TCP头部里面还有端口号， HTTP 的服务器正在监听这个端口号。于是，服务器自然就知道是 HTTP 进程想要这个包，于是就将包发给 HTTP 进程。服务器的 HTTP 进程看到，原来这个请求是要访问一个页面，于是就把这个网页封装在 HTTP 响应报文里。HTTP 响应报文也需要穿上 TCP、IP、MAC 头部，不过这次是源地址是服务器 IP 地址，目的地址是客户端 IP 地址</li>
</ul>
<h3 id="2-3-Linux-系统是如何收发网络包的？"><a href="#2-3-Linux-系统是如何收发网络包的？" class="headerlink" title="2.3 Linux 系统是如何收发网络包的？"></a>2.3 Linux 系统是如何收发网络包的？</h3><ul>
<li><p>Linux 网络协议栈：</p>
<ul>
<li>应用程序需要通过系统调用，来跟 Socket 层进行数据交互；</li>
<li>Socket 层的下面就是传输层、网络层和网络接口层；</li>
<li>最下面的一层，则是网卡驱动程序和硬件网卡设备</li>
</ul>
</li>
<li><p>Linux 接收网络包的流程</p>
<ul>
<li><p>网卡是计算机里的一个硬件，专门负责接收和发送网络包，当网卡接收到一个网络包后，会通过 DMA 技术，将网络包写入到指定的内存地址，也就是写入到 Ring Buffer ，这个是一个环形缓冲区，接着就会告诉操作系统这个网络包已经到达</p>
</li>
<li><p>怎么告诉操作系统这个网络包已经到达了呢？</p>
<ul>
<li>最简单的一种方式就是触发中断，也就是每当网卡收到一个网络包，就触发一个中断告诉操作系统（频繁地触发中断，则会导致 CPU 一直没完没了的处理中断，而导致其他任务可能无法继续前进，从而影响系统的整体效率）</li>
<li>Linux 内核在 2.6 版本中引入了 <strong>NAPI 机制</strong>，它是混合「中断和轮询」的方式来接收网络包，它的核心概念就是<strong>不采用中断的方式读取数据</strong>，而是首先采用中断唤醒数据接收的服务程序，然后 <code>poll</code> 的方法来轮询数据</li>
</ul>
</li>
<li><p>当 CPU 收到硬件中断请求后，根据中断表，调用已经注册的中断处理函数；内核中的 ksoftirqd 线程专门负责软中断的处理，当 ksoftirqd 内核线程收到软中断后，就会来轮询处理数据；ksoftirqd 线程会从 Ring Buffer 中获取一个数据帧，用 sk_buff 表示，从而可以作为一个网络包交给网络协议栈进行逐层处理</p>
</li>
<li><p>网络协议栈：</p>
<ul>
<li><p>首先，会先进入到网络接口层，在这一层会检查报文的合法性，如果不合法则丢弃，合法则会找出该网络包的上层协议的类型，比如是 IPv4，还是 IPv6，接着再去掉帧头和帧尾，然后交给网络层。</p>
</li>
<li><p>到了网络层，则取出 IP 包，判断网络包下一步的走向，比如是交给上层处理还是转发出去。当确认这个网络包要发送给本机后，就会从 IP 头里看看上一层协议的类型是 TCP 还是 UDP，接着去掉 IP 头，然后交给传输层。</p>
</li>
<li><p>传输层取出 TCP 头或 UDP 头，根据四元组「源 IP、源端口、目的 IP、目的端口」 作为标识，找出对应的 Socket，并把数据放到 Socket 的接收缓冲区。</p>
<p>最后，应用层程序调用 Socket 接口，将内核的 Socket 接收缓冲区的数据「拷贝」到应用层的缓冲区，然后唤醒用户进程。</p>
</li>
</ul>
</li>
</ul>
</li>
<li><p>Linux 发送网络包的流程</p>
<ul>
<li>首先，应用程序会调用 Socket 发送数据包的接口，由于这个是系统调用，所以会从用户态陷入到内核态中的 Socket 层，内核会申请一个内核态的 sk_buff 内存，<strong>将用户待发送的数据拷贝到 sk_buff 内存，并将其加入到发送缓冲区</strong></li>
<li>接下来，网络协议栈从 Socket 发送缓冲区中取出 sk_buff，并按照 TCP&#x2F;IP 协议栈从上到下逐层处理。</li>
<li>如果使用的是 TCP 传输协议发送数据，那么<strong>先拷贝一个新的 sk_buff 副本</strong> ，这是因为 sk_buff 后续在调用网络层，最后到达网卡发送完成的时候，这个 sk_buff 会被释放掉。而 TCP 协议是支持丢失重传的，在收到对方的 ACK 之前，这个 sk_buff 不能被删除。所以内核的做法就是每次调用网卡发送的时候，实际上传递出去的是 sk_buff 的一个拷贝，等收到 ACK 再真正删除。<ul>
<li>为了在层级之间传递数据时，不发生拷贝，只用 sk_buff 一个结构体来描述所有的网络包，通过调整 sk_buff 中 <code>data</code> 的指针</li>
</ul>
</li>
<li>然后交给网络层，在网络层里会做这些工作：选取路由（确认下一跳的 IP）、填充 IP 头、netfilter 过滤、对超过 MTU 大小的数据包进行分片。处理完这些工作后会交给网络接口层处理</li>
<li>网络接口层会通过 ARP 协议获得下一跳的 MAC 地址，然后对 sk_buff 填充帧头和帧尾，接着将 sk_buff 放到网卡的发送队列中。</li>
<li>这一些工作准备好后，会触发「软中断」告诉网卡驱动程序，这里有新的网络包需要发送，驱动程序会从发送队列中读取 sk_buff，将这个 sk_buff 挂到 RingBuffer 中，接着将 sk_buff 数据映射到网卡可访问的内存 DMA 区域，最后触发真实的发送</li>
</ul>
</li>
<li><p>发送网络数据的时候，涉及几次内存拷贝操作？</p>
<ul>
<li>第一次，调用发送数据的系统调用的时候，内核会申请一个内核态的 sk_buff 内存，将用户待发送的数据拷贝到 sk_buff 内存，并将其加入到发送缓冲区。</li>
<li>第二次，在使用 TCP 传输协议的情况下，从传输层进入网络层的时候，每一个 sk_buff 都会被克隆一个新的副本出来。副本 sk_buff 会被送往网络层，等它发送完的时候就会释放掉，然后原始的 sk_buff 还保留在传输层，目的是为了实现 TCP 的可靠传输，等收到这个数据包的 ACK 时，才会释放原始的 sk_buff 。</li>
<li>第三次，当 IP 层发现 sk_buff 大于 MTU 时才需要进行。会再申请额外的 sk_buff，并将原来的 sk_buff 拷贝为多个小的 sk_buff。</li>
</ul>
</li>
</ul>
<h3 id="3-1-HTTP-常见面试题"><a href="#3-1-HTTP-常见面试题" class="headerlink" title="3.1 HTTP 常见面试题"></a>3.1 HTTP 常见面试题</h3><h4 id="1-HTTP-基本概念"><a href="#1-HTTP-基本概念" class="headerlink" title="1.HTTP 基本概念"></a>1.HTTP 基本概念</h4><ul>
<li>HTTP 是超文本传输协议，也就是<strong>H</strong>yperText <strong>T</strong>ransfer <strong>P</strong>rotocol，<strong>是一个在计算机世界里专门在「两点」之间「传输」文字、图片、音频、视频等「超文本」数据的「约定和规范」。</strong><ul>
<li>HTTP 是一个用在计算机世界里的<strong>协议</strong>。它使用计算机能够理解的语言确立了一种计算机之间交流通信的规范（<strong>两个以上的参与者</strong>），以及相关的各种控制和错误处理方式（<strong>行为约定和规范</strong>）</li>
<li>HTTP 协议是一个<strong>双向协议</strong>。数据虽然是在 A 和 B 之间传输，但允许中间有<strong>中转或接力</strong>。在 HTTP 里，需要中间人遵从 HTTP 协议，只要不打扰基本的数据传输，就可以添加任意额外的东西。HTTP 是一个在计算机世界里专门用来在<strong>两点之间传输数据</strong>的约定和规范</li>
<li>HTTP 传输的内容是「超文本」，其是文字、图片、视频等的混合体，最关键有超链接，能从一个超文本跳转到另外一个超文本</li>
</ul>
</li>
<li>HTTP 常见的状态码：<ul>
<li><code>2xx</code> 类状态码表示服务器<strong>成功</strong>处理了客户端的请求（200 OK，204 No Content，206 Partial Content）</li>
<li><code>3xx</code> 类状态码表示客户端请求的资源发生了变动，需要客户端用新的 URL 重新发送请求获取资源，也就是<strong>重定向</strong>（<strong>301 Moved Permanently</strong>，<strong>302 Found</strong>，<strong>304 Not Modified</strong>）</li>
<li><code>4xx</code> 类状态码表示客户端发送的<strong>报文有误</strong>，服务器无法处理，也就是错误码的含义（<strong>400 Bad Request</strong>，<strong>403 Forbidden</strong>，<strong>404 Not Found</strong>）</li>
<li><code>5xx</code> 类状态码表示客户端请求报文正确，但是<strong>服务器处理时内部发生了错误</strong>，属于服务器端的错误码（<strong>500 Internal Server Error</strong>，<strong>501 Not Implemented</strong>，<strong>502 Bad Gateway</strong>，<strong>503 Service Unavailable</strong>）</li>
</ul>
</li>
<li>HTTP 常见字段有哪些：<ul>
<li><em>Host</em> 字段：客户端发送请求时，用来指定服务器的域名</li>
<li><em>Content-Length 字段</em>：服务器在返回数据时，会有 <code>Content-Length</code> 字段，表明本次回应的数据长度</li>
<li><em>Connection 字段</em>：最常用于客户端要求服务器使用 TCP 持久连接，以便其他请求复用;HTTP&#x2F;1.1 版本的默认连接都是持久连接，但为了兼容老版本的 HTTP，需要指定 <code>Connection</code> 首部字段的值为 <code>Keep-Alive</code></li>
<li><em>Content-Type 字段</em>：用于服务器回应时，告诉客户端，本次数据是什么格式</li>
<li><em>Content-Encoding 字段</em>：表示服务器返回的数据使用了什么压缩格式</li>
</ul>
</li>
</ul>
<h4 id="2-GET-与-POST"><a href="#2-GET-与-POST" class="headerlink" title="2. GET 与 POST"></a>2. GET 与 POST</h4><ul>
<li>GET 和 POST 有什么区别？<ul>
<li><strong>GET 的语义是从服务器获取指定的资源</strong>，这个资源可以是静态的文本、页面、图片视频等。GET 请求的参数位置一般是写在 URL 中，URL 规定只能支持 ASCII，所以 GET 请求的参数只允许 ASCII 字符 ，而且浏览器会对 URL 的长度有限制</li>
<li><strong>POST 的语义是根据请求负荷（报文body）对指定的资源做出处理</strong>，具体的处理方式视资源类型而不同。POST 请求携带数据的位置一般是写在报文 body 中， body 中的数据可以是任意格式的数据，只要客户端与服务端协商好即可，而且浏览器不会对 body 大小做限制</li>
</ul>
</li>
<li>GET 和 POST 方法都是安全和幂等的吗？<ul>
<li>安全和幂等的概念：所谓的「安全」是指请求方法不会「破坏」服务器上的资源。所谓的「幂等」，意思是多次执行相同的操作，结果都是「相同」的</li>
<li>从 RFC 规范定义的语义来看:<strong>GET 方法就是安全且幂等的</strong>，因为它是「只读」操作，无论操作多少次，服务器上的数据都是安全的，且每次的结果都是相同的。<strong>POST</strong> 因为是「新增或提交数据」的操作，会修改服务器上的资源，所以是<strong>不安全</strong>的，且多次提交数据就会创建多个资源，所以<strong>不是幂等</strong>的。所以，<strong>浏览器一般不会缓存 POST 请求，也不能把 POST 请求保存为书签</strong>。</li>
<li>但是实际过程中，开发者不一定会按照 RFC 规范定义的语义来实现 GET 和 POST 方法。如果「安全」放入概念是指信息是否会被泄漏的话，虽然 POST 用 body 传输数据，而 GET 用 URL 传输，这样数据会在浏览器地址拦容易看到，但是并不能说 GET 不如 POST 安全的；因为 HTTP 传输的内容都是明文的，虽然在浏览器地址拦看不到 POST 提交的 body 数据，但是只要抓个包就都能看到了</li>
</ul>
</li>
<li>GET 请求可以带 body 吗？<ul>
<li>理论上，任何请求都可以带 body 的。只是因为 RFC 规范定义的 GET 请求是获取资源，所以根据这个语义不需要用到 body。另外，URL 中的查询参数也不是 GET 所独有的，POST 请求的 URL 中也可以有参数的</li>
</ul>
</li>
</ul>
<h4 id="3-HTTP-缓存技术"><a href="#3-HTTP-缓存技术" class="headerlink" title="3.HTTP 缓存技术"></a>3.HTTP 缓存技术</h4><ul>
<li>HTTP 缓存有哪些实现方式？<ul>
<li>对于一些具有重复性的 HTTP 请求，比如每次请求得到的数据都一样的，可以把这对「请求-响应」的数据都<strong>缓存在本地</strong>，那么下次就直接读取本地的数据，不必在通过网络获取服务器的响应</li>
<li>HTTP 缓存有两种实现方式，分别是<strong>强制缓存和协商缓存</strong><ul>
<li>强缓存指的是只要浏览器判断缓存没有过期，则直接使用浏览器的本地缓存，决定是否使用缓存的主动性在于浏览器这边，利用Cache-Control和 Expires HTTP 响应头部（Response Header）字段实现的。<strong>Cache-Control的优先级高于 Expires</strong> </li>
<li><strong>协商缓存就是与服务端协商之后，通过协商结果来判断是否使用本地缓存</strong>。可以通过请求头部中的 <code>If-Modified-Since</code> 字段与响应头部中的 <code>Last-Modified</code> 字段实现（基于时间）；也可以通过请求头部中的 <code>If-None-Match</code> 字段与响应头部中的 <code>ETag</code> 字段实现（基于一个唯一标识） ；<strong>Etag 的优先级更高</strong></li>
<li>协商缓存这两个字段都需要配合强制缓存中 Cache-control 字段来使用，只有在未能命中强制缓存的时候，才能发起带有协商缓存字段的请求</li>
</ul>
</li>
</ul>
</li>
</ul>
<h4 id="4-HTTP-特性"><a href="#4-HTTP-特性" class="headerlink" title="4.HTTP 特性"></a>4.HTTP 特性</h4><ul>
<li>HTTP（1.1） 的优点有哪些<ul>
<li><em>简单</em>：HTTP 基本的报文格式就是 <code>header + body</code>，头部信息也是 <code>key-value</code> 简单文本的形式，<strong>易于理解</strong>，降低了学习和使用的门槛</li>
<li><em>灵活和易于扩展</em>：HTTP协议里的各类请求方法、URI&#x2F;URL、状态码、头字段等每个组成要求都没有被固定死，都允许开发人员<strong>自定义和扩充</strong>；工作在应用层（ <code>OSI</code> 第七层），则它<strong>下层可以随意变化</strong>（HTTPS 也就是在 HTTP 与 TCP 层之间增加了 SSL&#x2F;TLS 安全传输层，HTTP&#x2F;3 甚至把 TCP 层换成了基于 UDP 的 QUIC）</li>
<li><em>应用广泛和跨平台</em>：HTTP 的应用遍地开花，同时天然具有<strong>跨平台</strong>的优越性</li>
</ul>
</li>
<li>HTTP（1.1） 的缺点有哪些？<ul>
<li><em>无状态双刃剑</em>：<ul>
<li>无状态的<strong>好处</strong>，因为服务器不会去记忆 HTTP 的状态，所以不需要额外的资源来记录状态信息，这能减轻服务器的负担，能够把更多的 CPU 和内存用来对外提供服务</li>
<li>无状态的<strong>坏处</strong>，既然服务器没有记忆能力，它在完成有关联性的操作时会非常麻烦；解法方案有很多种，其中比较简单的方式用 <strong>Cookie</strong> 技术</li>
</ul>
</li>
<li><em>明文传输双刃剑</em>：明文意味着在传输过程中的信息，是可方便阅读的，但是这正是这样，HTTP 的所有信息都暴露在了光天化日下，相当于<strong>信息裸奔</strong>；</li>
<li><em>不安全</em>：<ul>
<li>通信使用明文（不加密），内容可能会被窃听。比如，<strong>账号信息容易泄漏</strong></li>
<li>不验证通信方的身份，因此有可能遭遇伪装。比如，<strong>访问假的淘宝、拼多多</strong></li>
<li>无法证明报文的完整性，所以有可能已遭篡改。比如，<strong>网页上植入垃圾广告</strong></li>
</ul>
</li>
</ul>
</li>
<li>HTTP&#x2F;1.1 的性能如何？<ul>
<li>HTTP 协议是基于 <strong>TCP&#x2F;IP</strong>，并且使用了「<strong>请求 - 应答</strong>」的通信模式，所以性能的关键就在这<strong>两点</strong>里</li>
<li>HTTP&#x2F;1.1 提出了<strong>长连接</strong>的通信方式，也叫持久连接。这种方式的好处在于减少了 TCP 连接的重复建立和断开所造成的额外开销，减轻了服务器端的负载</li>
<li><em>管道网络传输</em>：可在同一个 TCP 连接里面，客户端可以发起多个请求，只要第一个请求发出去了，不必等其回来，就可以发第二个请求出去，可以<strong>减少整体的响应时间</strong>。但是<strong>服务器必须按照接收请求的顺序发送对这些管道化请求的响应</strong>。</li>
<li><em>队头阻塞</em>：「请求 - 应答」的模式加剧了 HTTP 的性能问题，当顺序发送的请求序列中的一个请求因为某种原因被阻塞时，在后面排队的所有请求也一同被阻塞了，会招致客户端一直请求不到数据，这也就是「<strong>队头阻塞</strong>」</li>
</ul>
</li>
</ul>
<h4 id="5-HTTP-与-HTTPS"><a href="#5-HTTP-与-HTTPS" class="headerlink" title="5. HTTP 与 HTTPS"></a>5. HTTP 与 HTTPS</h4><ul>
<li><p>HTTP 与 HTTPS 有哪些区别？</p>
<ol>
<li>HTTP 是超文本传输协议，信息是明文传输，存在安全风险的问题。HTTPS 则解决 HTTP 不安全的缺陷，在 TCP 和 HTTP 网络层之间加入了 SSL&#x2F;TLS 安全协议，使得报文能够加密传输。</li>
<li>HTTP 连接建立相对简单， TCP 三次握手之后便可进行 HTTP 的报文传输。而 HTTPS 在 TCP 三次握手之后，还需进行 SSL&#x2F;TLS 的握手过程，才可进入加密报文传输。</li>
<li>HTTP 的端口号是 80，HTTPS 的端口号是 443。</li>
<li>HTTPS 协议需要向 CA（证书权威机构）申请数字证书，来保证服务器的身份是可信的</li>
</ol>
</li>
<li><p>HTTPS 解决了 HTTP 的哪些问题？</p>
<ul>
<li><strong>HTTPS</strong> 在 HTTP 与 TCP 层之间加入了 <code>SSL/TLS</code> 协议，可以很好的HTTP的<strong>窃听风险</strong>、<strong>篡改风险</strong>、<strong>冒充风险</strong>：<ul>
<li><strong>混合加密</strong>的方式实现信息的<strong>机密性</strong>，解决了窃听的风险。</li>
<li><strong>摘要算法</strong>的方式来实现<strong>完整性</strong>，它能够为数据生成独一无二的「指纹」，指纹用于校验数据的完整性，解决了篡改的风险。</li>
<li>将服务器公钥放入到<strong>数字证书</strong>(「个人信息 + 公钥 + 数字签名」打包而成)中，解决了冒充的风险</li>
</ul>
</li>
<li>HTTPS 采用的是<strong>对称加密</strong>和<strong>非对称加密</strong>结合的「混合加密」方式：<ul>
<li>在通信建立前采用<strong>非对称加密</strong>(使用两个密钥：公钥和私钥，公钥可以任意分发而私钥保密，解决了密钥交换问题但速度慢)的方式交换「会话秘钥」，后续就不再使用非对称加密。</li>
<li>在通信过程中全部使用<strong>对称加密</strong>（只使用一个密钥，运算速度快）的「会话秘钥」的方式加密明文数据。</li>
<li><strong>公钥加密，私钥解密</strong>。这个目的是为了<strong>保证内容传输的安全</strong>，因为被公钥加密的内容，其他人是无法解密的，只有持有私钥的人，才能解密出实际的内容；</li>
<li><strong>私钥加密，公钥解密</strong>。这个目的是为了<strong>保证消息不会被冒充</strong>，因为私钥是不可泄露的，如果公钥能正常解密出私钥加密的内容，就能证明这个消息是来源于持有私钥身份的人发送的。</li>
</ul>
</li>
</ul>
</li>
<li><p>HTTPS 是如何建立连接的？其间交互了什么？</p>
<ul>
<li><p>SSL&#x2F;TLS 协议基本流程：</p>
<ul>
<li>客户端向服务器索要并验证服务器的公钥。</li>
<li>双方协商生产「会话秘钥」。</li>
<li>双方采用「会话秘钥」进行加密通信。</li>
</ul>
</li>
<li><p>前两步也就是 SSL&#x2F;TLS 的建立过程，也就是 TLS 握手阶段。SSL&#x2F;TLS 的「握手阶段」涉及<strong>四次</strong>通信：</p>
<ul>
<li>首先，由客户端向服务器发起加密通信请求，也就是 <code>ClientHello</code> 请求。客户端主要向服务器发送以下信息：客户端支持的 SSL&#x2F;TLS 协议版本；客户端生产的随机数（<code>Client Random</code>），后面用于生成「会话秘钥」条件之一；客户端支持的密码套件列表</li>
<li>服务器收到客户端请求后，向客户端发出响应，也就是 <code>SeverHello</code>。服务器回应的内容有如下内容：确认 SSL&#x2F; TLS 协议版本；服务器生产的随机数（<code>Server Random</code>），也是后面用于生产「会话秘钥」条件之一；确认的密码套件列表；服务器的数字证书</li>
<li>客户端收到服务器的回应之后，首先通过浏览器或者操作系统中的 CA 公钥，确认服务器的数字证书的真实性。如果证书没有问题，客户端会<strong>从数字证书中取出服务器的公钥</strong>，然后使用它加密报文，向服务器发送如下信息：一个随机数（<code>pre-master key</code>，会被服务器公钥加密）；加密通信算法改变通知，表示随后的信息都将用「会话秘钥」加密通信；客户端握手结束通知，表示客户端的握手阶段已经结束（这一项同时把之前所有内容的发生的数据做个摘要，用来供服务端校验）</li>
<li><strong>服务器和客户端有了这三个随机数（Client Random、Server Random、pre-master key），接着就用双方协商的加密算法，各自生成本次通信的「会话秘钥」</strong>。然后，向客户端发送最后的信息：加密通信算法改变通知，表示随后的信息都将用「会话秘钥」加密通信；服务器握手结束通知，表示服务器的握手阶段已经结束。这一项同时把之前所有内容的发生的数据做个摘要，用来供客户端校验。</li>
</ul>
<p>接下来，客户端与服务器进入加密通信，就完全是使用普通的 HTTP 协议，只不过用「会话秘钥」加密内容</p>
</li>
</ul>
</li>
<li><p>客户端校验数字证书的流程是怎样的？</p>
<ul>
<li><p>CA 签发证书的过程：</p>
<ul>
<li>首先 CA 会把持有者的公钥、用途、颁发者、有效时间等信息打成一个包，然后对这些信息进行 Hash 计算，得到一个 Hash 值；</li>
<li>然后 CA 会使用自己的私钥将该 Hash 值加密，生成 Certificate Signature，也就是 CA 对证书做了签名；</li>
<li>最后将 Certificate Signature 添加在文件证书上，形成数字证书；</li>
</ul>
</li>
<li><p>客户端校验服务端的数字证书的过程：</p>
<ul>
<li>首先客户端会使用同样的 Hash 算法获取该证书的 Hash 值 H1；</li>
<li>通常浏览器和操作系统中集成了 CA 的公钥信息，浏览器收到证书后可以使用 CA 的公钥解密 Certificate Signature 内容，得到一个 Hash 值 H2 ；</li>
<li>最后比较 H1 和 H2，如果值相同，则为可信赖的证书，否则则认为证书不可信。</li>
</ul>
<p>但事实上，证书的验证过程中<strong>还存在一个证书信任链的问题</strong>，因为我们向 CA 申请的证书一般不是根证书签发的，而是由中间证书签发的。<strong>这是为了确保根证书的绝对安全性，将根证书隔离地越严格越好，不然根证书如果失守了，那么整个信任链都会有问题。</strong></p>
</li>
</ul>
</li>
<li><p>HTTPS 的应用数据是如何保证完整性的？</p>
<ul>
<li><p>TLS 在实现上分为<strong>握手协议</strong>和<strong>记录协议</strong>两层：</p>
<ul>
<li>TLS 握手协议就是我们前面说的 TLS 四次握手的过程，负责协商加密算法和生成对称密钥，后续用此密钥来保护应用程序数据（即 HTTP 数据）；</li>
<li>TLS 记录协议负责保护应用程序数据并验证其完整性和来源，所以对 HTTP 数据加密是使用记录协议；</li>
</ul>
</li>
<li><p>TLS 记录协议主要负责消息（HTTP 数据）的压缩，加密及数据的认证，具体过程如下：</p>
<ul>
<li>首先，消息被分割成多个较短的片段,然后分别对每个片段进行压缩。</li>
<li>接下来，经过压缩的片段会被<strong>加上消息认证码（MAC 值，这个是通过哈希算法生成的），这是为了保证完整性，并进行数据的认证</strong>。通过附加消息认证码的 MAC 值，可以识别出篡改。与此同时，为了防止重放攻击，在计算消息认证码时，还加上了片段的编码。</li>
<li>再接下来，经过压缩的片段再加上消息认证码会一起通过对称密码进行加密。</li>
<li>最后，上述经过加密的数据再加上由数据类型、版本号、压缩后的长度组成的报头就是最终的报文数据。</li>
</ul>
<p>记录协议完成后，最终的报文数据将传递到传输控制协议 (TCP) 层进行传输。</p>
</li>
</ul>
</li>
<li><p>HTTPS 一定安全可靠吗？</p>
<ul>
<li>客户端通过浏览器向服务端发起 HTTPS 请求时，被「假基站」转发到了一个「中间人服务器」，于是客户端是和「中间人服务器」完成了 TLS 握手，然后这个「中间人服务器」再与真正的服务端完成 TLS 握手；具体过程如下：<ul>
<li>客户端向服务端发起 HTTPS 建立连接请求时，然后被「假基站」转发到了一个「中间人服务器」，接着中间人向服务端发起 HTTPS 建立连接请求，此时客户端与中间人进行 TLS 握手，中间人与服务端进行 TLS 握手；</li>
<li>在客户端与中间人进行 TLS 握手过程中，中间人会发送自己的公钥证书给客户端，<strong>客户端验证证书的真伪</strong>，然后从证书拿到公钥，并生成一个随机数，用公钥加密随机数发送给中间人，中间人使用私钥解密，得到随机数，此时双方都有随机数，然后通过算法生成对称加密密钥（A），后续客户端与中间人通信就用这个对称加密密钥来加密数据了。</li>
<li>在中间人与服务端进行 TLS 握手过程中，服务端会发送从 CA 机构签发的公钥证书给中间人，从证书拿到公钥，并生成一个随机数，用公钥加密随机数发送给服务端，服务端使用私钥解密，得到随机数，此时双方都有随机数，然后通过算法生成对称加密密钥（B），后续中间人与服务端通信就用这个对称加密密钥来加密数据了。</li>
<li>后续的通信过程中，中间人用对称加密密钥（A）解密客户端的 HTTPS 请求的数据，然后用对称加密密钥（B）加密 HTTPS 请求后，转发给服务端，接着服务端发送 HTTPS 响应数据给中间人，中间人用对称加密密钥（B）解密 HTTPS 响应数据，然后再用对称加密密钥（A）加密后，转发给客户端。</li>
</ul>
</li>
<li>从客户端的角度看，其实并不知道网络中存在中间人服务器这个角色。那么中间人就可以解开浏览器发起的 HTTPS 请求里的数据，也可以解开服务端响应给浏览器的 HTTPS 响应数据。相当于，中间人能够 “偷看” 浏览器与服务端之间的 HTTPS 请求和响应的数据。</li>
<li>但是要发生这种场景是有前提的，前提是用户点击接受了中间人服务器的证书。中间人服务器与客户端在 TLS 握手过程中，实际上发送了自己伪造的证书给浏览器，而这个伪造的证书是能被浏览器（客户端）识别出是非法的，于是就会提醒用户该证书存在问题</li>
<li><strong>HTTPS 协议本身到目前为止还是没有任何漏洞的，即使你成功进行中间人攻击，本质上是利用了客户端的漏洞（用户点击继续访问或者被恶意导入伪造的根证书），并不是 HTTPS 不够安全</strong></li>
</ul>
</li>
<li><p>为什么抓包工具能截取 HTTPS 数据？</p>
<ul>
<li>很多抓包工具 之所以可以明文看到 HTTPS 数据，工作原理与中间人一致的。对于 HTTPS 连接来说，中间人要满足以下两点，才能实现真正的明文代理:<ol>
<li>中间人，作为客户端与真实服务端建立连接这一步不会有问题，因为服务端不会校验客户端的身份；</li>
<li>中间人，作为服务端与真实客户端建立连接，这里会有客户端信任服务端的问题，也就是服务端必须有对应域名的私钥；</li>
</ol>
</li>
<li>中间人要拿到私钥只能通过如下方式：去网站服务端拿到私钥；去CA处拿域名签发私钥；自己签发证书，切要被浏览器信任；抓包工具只能使用第三种方式取得中间人的身份。</li>
<li>使用抓包工具进行 HTTPS 抓包的时候，需要在客户端安装 Fiddler 的根证书，这里实际上起认证中心（CA）的作用。</li>
<li>抓包工具能够抓包的关键是客户端会往系统受信任的根证书列表中导入抓包工具生成的证书，而这个证书会被浏览器信任，也就是抓包工具给自己创建了一个认证中心 CA，客户端拿着中间人签发的证书去中间人自己的 CA 去认证，当然认为这个证书是有效的。</li>
</ul>
</li>
<li><p>如何避免被中间人抓取数据？</p>
<ul>
<li>可以通过 <strong>HTTPS 双向认证</strong>来避免这种问题</li>
<li>如果用了双向认证方式，不仅客户端会验证服务端的身份，而且服务端也会验证客户端的身份。服务端一旦验证到请求自己的客户端为不可信任的，服务端就拒绝继续通信，客户端如果发现服务端为不可信任的，那么也中止通信</li>
</ul>
</li>
</ul>
<h4 id="6-HTTP-x2F-1-1、HTTP-x2F-2、HTTP-x2F-3-演变"><a href="#6-HTTP-x2F-1-1、HTTP-x2F-2、HTTP-x2F-3-演变" class="headerlink" title="6. HTTP&#x2F;1.1、HTTP&#x2F;2、HTTP&#x2F;3 演变"></a>6. HTTP&#x2F;1.1、HTTP&#x2F;2、HTTP&#x2F;3 演变</h4><ul>
<li><p>HTTP&#x2F;1.1 相比 HTTP&#x2F;1.0 提高了什么性能？</p>
<ul>
<li>使用长连接的方式改善了 HTTP&#x2F;1.0 短连接造成的性能开销。</li>
<li>支持管道（pipeline）网络传输，只要第一个请求发出去了，不必等其回来，就可以发第二个请求出去，可以减少整体的响应时间。</li>
</ul>
<p>但 HTTP&#x2F;1.1 还是有性能瓶颈：</p>
<ul>
<li>请求 &#x2F; 响应头部（Header）未经压缩就发送，首部信息越多延迟越大。只能压缩 <code>Body</code> 的部分；</li>
<li>发送冗长的首部。每次互相发送相同的首部造成的浪费较多；</li>
<li>服务器是按请求的顺序响应的，如果服务器响应慢，会招致客户端一直请求不到数据，也就是队头阻塞；</li>
<li>没有请求优先级控制；</li>
<li>请求只能从客户端开始，服务器只能被动响应</li>
</ul>
</li>
<li><p>HTTP&#x2F;2 做了什么优化？</p>
<ul>
<li><em>头部压缩</em>：HTTP&#x2F;2 会<strong>压缩头</strong>（Header）如果你同时发出多个请求，他们的头是一样的或是相似的，那么，协议会帮你<strong>消除重复的部分</strong>。这就是所谓的 <code>HPACK</code> 算法：在客户端和服务器同时维护一张头信息表，所有字段都会存入这个表，生成一个索引号，以后就不发送同样字段了，只发送索引号，这样就<strong>提高速度</strong>了</li>
<li><em>二进制格式</em>：HTTP&#x2F;2 不再像 HTTP&#x2F;1.1 里的纯文本形式的报文，而是全面采用了<strong>二进制格式</strong>，头信息和数据体都是二进制，并且统称为帧（frame）：<strong>头信息帧（Headers Frame）和数据帧（Data Frame）</strong>。计算机收到报文后，无需再将明文的报文转成二进制，而是直接解析二进制报文，这<strong>增加了数据传输的效率</strong></li>
<li><em>并发传输</em>： HTTP&#x2F;2 引出了 Stream 概念，多个 Stream 复用在一条 TCP 连接，Stream 里可以包含 1 个或多个 Message，Message 对应 HTTP&#x2F;1 中的请求或响应，由 HTTP 头部和包体构成。Message 里包含一条或者多个 Frame，Frame 是 HTTP&#x2F;2 最小单位，以二进制压缩格式存放 HTTP&#x2F;1 中的内容（头部和包体）<ul>
<li><strong>针对不同的 HTTP 请求用独一无二的 Stream ID 来区分，接收端可以通过 Stream ID 有序组装成 HTTP 消息，不同 Stream 的帧是可以乱序发送的，因此可以并发不同的 Stream ，也就是 HTTP&#x2F;2 可以并行交错地发送请求和响应</strong></li>
</ul>
</li>
<li><em>服务器推送</em>：HTTP&#x2F;2 还在一定程度上改善了传统的「请求 - 应答」工作模式，服务端不再是被动地响应，可以<strong>主动</strong>向客户端发送消息。客户端和服务器<strong>双方都可以建立 Stream</strong>， Stream ID 也是有区别的，客户端建立的 Stream 必须是奇数号，而服务器建立的 Stream 必须是偶数号。</li>
</ul>
</li>
<li><p>HTTP&#x2F;2 有什么缺陷？</p>
<ul>
<li>HTTP&#x2F;2 通过 Stream 的并发能力，解决了 HTTP&#x2F;1 队头阻塞的问题，看似很完美了，但是 HTTP&#x2F;2 还是存在“队头阻塞”的问题，只不过问题不是在 HTTP 这一层面，而是在 TCP 这一层</li>
<li><strong>HTTP&#x2F;2 是基于 TCP 协议来传输数据的，TCP 是字节流协议，TCP 层必须保证收到的字节数据是完整且连续的，这样内核才会将缓冲区里的数据返回给 HTTP 应用，那么当「前 1 个字节数据」没有到达时，后收到的字节数据只能存放在内核缓冲区里，只有等到这 1 个字节数据到达时，HTTP&#x2F;2 应用层才能从内核中拿到数据，这就是 HTTP&#x2F;2 队头阻塞问题</strong>。一旦发生了丢包现象，就会触发 TCP 的重传机制，这样在一个 TCP 连接中的<strong>所有的 HTTP 请求都必须等待这个丢了的包被重传回来</strong></li>
</ul>
</li>
<li><p>HTTP&#x2F;3 做了哪些优化？</p>
<ul>
<li><p>HTTP&#x2F;1.1 中的管道（ pipeline）虽然解决了请求的队头阻塞，但是<strong>没有解决响应的队头阻塞</strong>，因为服务端需要按顺序响应收到的请求，如果服务端处理某个请求消耗的时间比较长，那么只能等响应完这个请求后， 才能处理下一个请求，这属于 HTTP 层队头阻塞。</p>
</li>
<li><p>HTTP&#x2F;2 虽然通过多个请求复用一个 TCP 连接解决了 HTTP 的队头阻塞 ，但是<strong>一旦发生丢包，就会阻塞住所有的 HTTP 请求</strong>，这属于 TCP 层队头阻塞。</p>
</li>
<li><p>HTTP&#x2F;2 队头阻塞的问题是因为 TCP，所以 <strong>HTTP&#x2F;3 把 HTTP 下层的 TCP 协议改成了 UDP</strong>，基于 UDP 的 <strong>QUIC 协议</strong> 可以实现类似 TCP 的可靠性传输</p>
<ul>
<li><p><em>无队头阻塞</em>：</p>
<p>QUIC 协议也有类似 HTTP&#x2F;2 Stream 与多路复用的概念，也是可以在同一条连接上并发传输多个 Stream，Stream 可以认为就是一条 HTTP 请求。</p>
<p>QUIC 有自己的一套机制可以保证传输的可靠性的。<strong>当某个流发生丢包时，只会阻塞这个流，其他流不会受到影响，因此不存在队头阻塞问题</strong>。这与 HTTP&#x2F;2 不同，HTTP&#x2F;2 只要某个流中的数据包丢失了，其他流也会因此受影响。</p>
<p>所以，QUIC 连接上的多个 Stream 之间并没有依赖，都是独立的，某个流发生丢包了，只会影响该流，其他流不受影响。</p>
</li>
<li><p><em>更快的连接建立</em>：</p>
<p>对于 HTTP&#x2F;1 和 HTTP&#x2F;2 协议，TCP 和 TLS 是分层的，分别属于内核实现的传输层、openssl 库实现的表示层，因此它们难以合并在一起，需要分批次来握手，先 TCP 握手，再 TLS 握手。</p>
<p>HTTP&#x2F;3 在传输数据前虽然需要 QUIC 协议握手，这个握手过程只需要 1 RTT，握手的目的是为确认双方的「连接 ID」，连接迁移就是基于连接 ID 实现的。</p>
<p>但是 HTTP&#x2F;3 的 QUIC 协议并不是与 TLS 分层，而是QUIC 内部包含了 TLS，它在自己的帧会携带 TLS 里的“记录”，再加上 QUIC 使用的是 TLS&#x2F;1.3，因此仅需 1 个 RTT 就可以「同时」完成建立连接与密钥协商。甚至，在第二次连接的时候，应用数据包可以和 QUIC 握手信息（连接信息 + TLS 信息）一起发送，达到 0-RTT 的效果。</p>
</li>
<li><p><em>连接迁移</em></p>
<p>基于 TCP 传输协议的 HTTP 协议，由于是通过四元组（源 IP、源端口、目的 IP、目的端口）确定一条 TCP 连接。</p>
<p>那么<strong>当移动设备的网络从 4G 切换到 WIFI 时，意味着 IP 地址变化了，那么就必须要断开连接，然后重新建立连接</strong>。而建立连接的过程包含 TCP 三次握手和 TLS 四次握手的时延，以及 TCP 慢启动的减速过程，给用户的感觉就是网络突然卡顿了一下，因此连接的迁移成本是很高的。</p>
<p>而 QUIC 协议没有用四元组的方式来“绑定”连接，而是通过<strong>连接 ID</strong>来标记通信的两个端点，客户端和服务器可以各自选择一组 ID 来标记自己，因此即使移动设备的网络变化后，导致 IP 地址变化了，只要仍保有上下文信息（比如连接 ID、TLS 密钥等），就可以“无缝”地复用原连接，消除重连的成本，没有丝毫卡顿感，达到了<strong>连接迁移</strong>的功能。</p>
</li>
</ul>
</li>
<li><p>QUIC 是一个在 UDP 之上的<strong>伪</strong> TCP + TLS + HTTP&#x2F;2 的多路复用的协议。</p>
</li>
</ul>
</li>
</ul>
<h3 id="3-2-HTTP-x2F-1-1如何优化？"><a href="#3-2-HTTP-x2F-1-1如何优化？" class="headerlink" title="3.2 HTTP&#x2F;1.1如何优化？"></a>3.2 HTTP&#x2F;1.1如何优化？</h3><ul>
<li><em>尽量避免发送 HTTP 请求</em>；<ul>
<li><strong>缓存技术</strong>：对于一些具有重复性的 HTTP 请求，把这对请求-响应的数据都<strong>缓存在本地</strong>，下次就直接读取本地的数据</li>
<li>服务器在发送 HTTP 响应时，会估算一个过期的时间，并把这个信息放到<strong>响应头部</strong>中，这样客户端在查看响应头部的信息时，一旦发现缓存的响应是过期的，则就会重新发送网络请求</li>
<li>如果客户端发现过期了，重新向服务端发送请求而服务端的数据没有变化，此时就可以通过Etag头部中第一次请求响应头部中的摘要作为唯一标识响应的资源，服务端通过摘要的比较判断是否需要重新发送资源，不需要则<strong>返回不含有包体的 <code>304 Not Modified</code> 响应</strong></li>
</ul>
</li>
<li><em>在需要发送 HTTP 请求时，考虑如何减少请求次数</em>；<ul>
<li><em>减少重定向请求次数</em>；<ul>
<li>重定向请求越多，那么客户端就要多次发起 HTTP 请求，每一次的 HTTP 请求都得经过网络，这无疑会越降低网络性能；如果<strong>重定向的工作交由代理服务器完成，就能减少 HTTP 请求次数</strong></li>
<li><code>301</code> 和 <code>308</code> 响应码是告诉客户端可以将重定向响应缓存到本地磁盘，之后客户端就自动用 url2 替代 url1 访问服务器的资源</li>
</ul>
</li>
<li><em>合并请求</em>；<ul>
<li>把多个访问小文件的请求合并成一个大的请求，虽然传输的总资源还是一样，但是减少请求，也就意味着<strong>减少了重复发送的 HTTP 头部</strong></li>
<li>如果合并了请求，也就会<strong>减少 TCP 连接的数量，因而省去了 TCP 握手和慢启动过程耗费的时间</strong></li>
<li><code>CSS Image Sprites</code> 技术就是<strong>通过将多个小图片合并成一个大图片来减少 HTTP 请求的次数，以减少 HTTP 请求的次数，从而减少网络的开销</strong>；</li>
<li>但是<strong>当大资源中的某一个小资源发生变化后，客户端必须重新下载整个完整的大资源文件</strong>，这显然带来了额外的网络消耗</li>
</ul>
</li>
<li><em>延迟发送请求</em>，一般 HTML 里会含有很多 HTTP 的 URL，当前不需要的资源没必要也获取过来，于是可以通过「<strong>按需获取</strong>」的方式，来减少第一时间的 HTTP 请求次数</li>
</ul>
</li>
<li><em>减少服务器的 HTTP 响应的数据大小</em>；<ul>
<li>对响应的资源进行<strong>压缩</strong>，这样就可以减少响应的数据大小，从而提高网络传输的效率</li>
<li>无损压缩是指资源经过压缩后，信息不被破坏，还能完全恢复到压缩前的原样，适合用在文本文件、程序可执行文件、程序源代码；gzip 就是比较常见的无损压缩。客户端支持的压缩算法，会在 HTTP 请求中通过头部中的 <code>Accept-Encoding</code> 字段告诉服务器；服务器收到后会从中选择一个服务器支持的或者合适的压缩算法，通过响应头部中的 <code>content-encoding</code> 字段告诉客户端该资源使用的压缩算法</li>
<li>与无损压缩相对的就是有损压缩，经过此方法压缩，解压的数据会与原始数据不同但是非常接近。可以通过 HTTP 请求头部中的 <code>Accept</code> 字段里的「 q 质量因子」，告诉服务器期望的资源质量；关于音视频的压缩，音视频主要是动态的，每个帧都有时序的关系，通常时间连续的帧之间的变化是很小的，用<strong>增量数据</strong>来表达后续的帧，这样便减少了很多数据</li>
</ul>
</li>
</ul>
<h3 id="3-3-HTTPS-RSA-握手解析"><a href="#3-3-HTTPS-RSA-握手解析" class="headerlink" title="3.3 HTTPS RSA 握手解析"></a>3.3 HTTPS RSA 握手解析</h3><ul>
<li><p>TLS 协议是如何解决 HTTP 的风险的呢？</p>
<ul>
<li><em>信息加密</em>： HTTP 交互信息是被加密的，第三方就无法被窃取；</li>
<li><em>校验机制</em>：校验信息传输过程中是否有被第三方篡改过，如果被篡改过，则会有警告提示；</li>
<li><em>身份证书</em>：证明淘宝是真的淘宝网；</li>
</ul>
</li>
<li><p>RSA 握手过程：</p>
<ul>
<li>TLS 第一次握手：客户端首先会发一个「<strong>Client Hello</strong>」消息；消息里面有客户端使用的 TLS 版本号、支持的密码套件列表，以及生成的<strong>随机数（<em>Client Random</em>）</strong>，这个随机数会被服务端保留，它是生成对称加密密钥的材料之一</li>
<li>TLS 第二次握手：当服务端收到客户端的「Client Hello」消息后，会确认 TLS 版本号是否支持，和从密码套件列表中选择一个密码套件，以及生成<strong>随机数（<em>Server Random</em>）</strong>。接着，返回「<strong>Server Hello</strong>」消息，消息里面有服务器确认的 TLS 版本号，也给出了随机数（Server Random），然后从客户端的密码套件列表选择了一个合适的密码套件；然后，服务端为了证明自己的身份，会发送「<strong>Server Certificate</strong>」给客户端，这个消息里含有数字证书；随后，服务端发了「<strong>Server Hello Done</strong>」消息</li>
<li>TLS 第三次握手：客户端验证完证书后，认为可信则继续往下走。接着，客户端就会生成一个新的<strong>随机数 (<em>pre-master</em>)<strong>，用服务器的 RSA 公钥加密该随机数，通过「</strong>Client Key Exchange</strong>」消息传给服务端；服务端收到后，用 RSA 私钥解密，得到客户端发来的随机数 (pre-master)。至此，<strong>客户端和服务端双方都共享了三个随机数，分别是 Client Random、Server Random、pre-master</strong>。于是，双方根据已经得到的三个随机数，生成<strong>会话密钥（Master Secret）</strong>，它是对称密钥，用于对后续的 HTTP 请求&#x2F;响应的数据加解密。生成完「会话密钥」后，然后客户端发一个「<strong>Change Cipher Spec</strong>」，告诉服务端开始使用加密方式发送消息。然后，客户端再发一个「<strong>Encrypted Handshake Message（Finishd）</strong>」消息，把之前所有发送的数据做个<strong>摘要</strong>，再用会话密钥（master secret）加密一下，让服务器做个验证，验证加密通信「是否可用」和「之前握手信息是否有被中途篡改过」</li>
<li>TLS 第四次握手：服务器也是同样的操作，发「<strong>Change Cipher Spec</strong>」和「<strong>Encrypted Handshake Message</strong>」消息，如果双方都验证加密和解密没问题，那么握手正式完成。最后，就用「会话密钥」加解密 HTTP 请求和响应了</li>
</ul>
</li>
<li><p>客户端验证证书</p>
<ul>
<li>数字证书的作用，是用来认证公钥持有者的身份，以防止第三方进行冒充。说简单些，证书就是用来告诉客户端，该服务端是否是合法的，因为只有证书合法，才代表服务端身份是可信的</li>
<li>为了让服务端的公钥被大家信任，服务端的证书都是由 CA （<em>Certificate Authority</em>，证书认证机构）签名的</li>
<li>数字证书签发流程：<ul>
<li>首先CA 会把持有者的公钥、用途、颁发者、有效时间等信息打成一个包，然后对这些信息进行 Hash 计算，得到一个 Hash 值</li>
<li>然后 CA 会使用自己的私钥将该 Hash 值加密，生成 Certificate Signature，也就是 CA 对证书做了签名；</li>
<li>最后将 Certificate Signature 添加在文件证书上，形成数字证书；</li>
</ul>
</li>
<li>数字证书验证流程：<ul>
<li>首先客户端会使用同样的 Hash 算法获取该证书的 Hash 值 H1；</li>
<li>通常浏览器和操作系统中集成了 CA 的公钥信息，浏览器收到证书后可以使用 CA 的公钥解密 Certificate Signature 内容，得到一个 Hash 值 H2 ；</li>
<li>最后比较 H1 和 H2，如果值相同，则为可信赖的证书，否则则认为证书不可信。</li>
</ul>
</li>
</ul>
</li>
<li><p>RSA 算法的缺陷：</p>
<ul>
<li><strong>使用 RSA 密钥协商算法的最大问题是不支持前向保密</strong>。</li>
<li>因为客户端传递随机数（用于生成对称加密密钥的条件之一）给服务端时使用的是公钥加密的，服务端收到后，会用私钥解密得到随机数。所以一旦服务端的私钥泄漏了，过去被第三方截获的所有 TLS 通讯密文都会被破解。</li>
<li>为了解决这个问题，后面就出现了 ECDHE 密钥协商算法</li>
</ul>
</li>
</ul>
<h3 id="3-4-HTTPS-ECDHE-握手解析"><a href="#3-4-HTTPS-ECDHE-握手解析" class="headerlink" title="3.4 HTTPS ECDHE 握手解析"></a>3.4 HTTPS ECDHE 握手解析</h3><ul>
<li><p>DH 算法：核心数学思想是<strong>离散对数</strong>，离散对数是在对数运算的基础上加了模运算</p>
<p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost4@main/%E7%BD%91%E7%BB%9C/https/%E7%A6%BB%E6%95%A3%E5%AF%B9%E6%95%B0.png" alt="img"></p>
<p>底数 a 和模数 p 是离散对数的公共参数，b 是真数，i 是对数。知道了对数，就可以计算出真数。但反过来，知道真数却很难推算出对数。<strong>当模数 p 是一个很大的质数，即使知道底数 a 和真数 b ，在现有的计算机的计算水平是几乎无法算出离散对数</strong></p>
</li>
<li><p>DH 算法是如何密钥交换的：</p>
<ul>
<li>需要先确定模数和底数作为算法的参数，这两个参数是公开的，用 P 和 G 来代称</li>
<li>然后各自生成一个随机整数作为<strong>私钥</strong>，双方的私钥要各自严格保管，不能泄漏，小红的私钥用 a 代称，小明的私钥用 b 代称</li>
<li>于是就可以计算出<strong>公钥</strong>：<ul>
<li>小红的公钥记作 A，A &#x3D; G ^ a ( mod P )；</li>
<li>小明的公钥记作 B，B &#x3D; G ^ b ( mod P )；</li>
<li>从真数（A 和 B）反向计算对数 a 和 b 是非常困难的，至少在现有计算机的计算能力是无法破解的</li>
</ul>
</li>
<li>双方交换各自 DH 公钥后，小红手上共有 5 个数：P、G、a、A、B，小明手上也同样共有 5 个数：P、G、b、B、A。然后小红执行运算： B ^ a ( mod P )，其结果为 K，因为离散对数的幂运算有交换律，所以小明执行运算： A ^ b ( mod P )，得到的结果也是 K。这个 K 就是小红和小明之间用的<strong>对称加密密钥</strong>，可以作为会话密钥使用。</li>
</ul>
</li>
<li><p>DHE 算法：</p>
</li>
<li><p><strong>static DH 算法不具备前向安全性</strong>，static DH 算法里有一方的私钥是静态的，密钥协商的过程有些数据是公开的，黑客就可以依据这些数据暴力破解出服务器的私钥，然后就可以计算出会话密钥了，于是之前截获的加密数据会被破解</p>
</li>
<li><p>既然固定一方的私钥有被破解的风险，那么干脆就让双方的私钥在每次密钥交换通信时，都是随机生成的、临时的，这个方式也就是 DHE 算法，E 全称是 ephemeral（临时性的）</p>
</li>
<li><p>即使有个牛逼的黑客破解了某一次通信过程的私钥，其他通信过程的私钥仍然是安全的，因为<strong>每个通信过程的私钥都是没有任何关系的，都是独立的，这样就保证了「前向安全」</strong></p>
</li>
<li><p>DHE 算法由于计算性能不佳，因为需要做大量的乘法，为了提升 DHE 算法的性能，所以就出现了现在广泛用于密钥交换算法 —— <strong>ECDHE 算法</strong></p>
</li>
<li><p>使用 ECDHE 密钥交换算法的过程：</p>
<ul>
<li>双方事先确定好使用哪种椭圆曲线，和曲线上的基点 G，这两个参数都是公开的；</li>
<li>双方各自随机生成一个随机数作为<strong>私钥d</strong>，并与基点 G相乘得到<strong>公钥Q</strong>（Q &#x3D; dG），此时小红的公私钥为 Q1 和 d1，小明的公私钥为 Q2 和 d2；</li>
<li>双方交换各自的公钥，最后小红计算点（x1，y1） &#x3D; d1Q2，小明计算点（x2，y2） &#x3D; d2Q1，由于椭圆曲线上是可以满足乘法交换和结合律，所以 d1Q2 &#x3D; d1d2G &#x3D; d2d1G &#x3D; d2Q1 ，因此<strong>双方的 x 坐标是一样的，所以它是共享密钥，也就是会话密钥</strong>。</li>
</ul>
<p>这个过程中，双方的私钥都是随机、临时生成的，都是不公开的，即使根据公开的信息（椭圆曲线、公钥、基点 G）也是很难计算出椭圆曲线上的离散对数（私钥）</p>
</li>
<li><p><strong>最终的会话密钥，就是用「客户端随机数 + 服务端随机数 + x（ECDHE 算法算出的共享密钥） 」三个材料生成的</strong></p>
</li>
<li><p>RSA 和 ECDHE 握手过程的区别：</p>
<ul>
<li><p>RSA 密钥协商算法「不支持」前向保密，ECDHE 密钥协商算法「支持」前向保密；</p>
</li>
<li><p>使用了 RSA 密钥协商算法，TLS 完成四次握手后，才能进行应用数据传输，而对于 ECDHE 算法，客户端可以不用等服务端的最后一次 TLS 握手，就可以提前发出加密的 HTTP 数据，节省了一个消息的往返时间；</p>
</li>
<li><p>使用 ECDHE， <strong>在 TLS 第 2 次握手中，会出现服务器端发出的「Server Key Exchange」消息，而 RSA 握手过程没有该消息</strong>；</p>
</li>
</ul>
</li>
</ul>
<h3 id="3-5-HTTPS-如何优化？"><a href="#3-5-HTTPS-如何优化？" class="headerlink" title="3.5 HTTPS 如何优化？"></a>3.5 HTTPS 如何优化？</h3><ul>
<li><p>由裸数据传输的 HTTP 协议转成加密数据传输的 HTTPS 协议，给应用数据套了个「保护伞」，提高安全性的同时也带来了性能消耗。因为 HTTPS 相比 HTTP 协议多一个 TLS 协议握手过程，<strong>目的是为了通过非对称加密握手协商或者交换出对称加密密钥</strong>，这个过程最长可以花费掉 2 RTT，接着后续传输的应用数据都得使用对称加密密钥来加密&#x2F;解密。</p>
</li>
<li><p>产生性能消耗的两个环节：</p>
<ul>
<li>第一个环节， TLS 协议握手过程；不仅增加了网络延时（最长可以花费掉 2 RTT），而且握手过程中的一些步骤也会产生性能损耗，比如：ECDHE 密钥协商算法，客户端验证证书，双方计算 Pre-Master</li>
<li>第二个环节，握手后的对称加密报文传输。</li>
</ul>
</li>
<li><p><strong>HTTPS 协议是计算密集型，而不是 I&#x2F;O 密集型</strong>，一个好的 CPU，可以提高计算性能，因为 HTTPS 连接过程中就有大量需要计算密钥的过程，所以这样可以加速 TLS 握手过程</p>
</li>
<li><p><strong>RSA 密钥交换算法的 TLS 握手过程，不仅慢，而且安全性也不高</strong>。因此如果可以，尽量<strong>选用 ECDHE 密钥交换</strong>算法替换 RSA 算法，因为该算法由于支持「False Start」，客户端可以在 TLS 协议的第 3 次握手后，第 4 次握手前，发送加密的应用数据，以此将 <strong>TLS 握手的消息往返由 2 RTT 减少到 1 RTT，而且安全性也高，具备前向安全性</strong></p>
</li>
<li><p>对于证书优化的方向：</p>
<ul>
<li>服务器应该选用 <strong>ECDSA 证书</strong>，而非 RSA 证书，因为在相同安全级别下，ECC 的密钥长度比 RSA 短很多，这样可以提高证书传输的效率；</li>
<li>服务器应该开启 <strong>OCSP Stapling</strong> 功能，由服务器预先获得 OCSP 的响应，并把响应结果缓存起来，这样 TLS 握手的时候就不用再访问 CA 服务器，减少了网络通信的开销，提高了证书验证的效率；</li>
</ul>
</li>
<li><p>把 TLS 1.2 升级成 TLS 1.3，TLS 1.3 大幅度简化了握手的步骤，<strong>完成 TLS 握手只要 1 RTT</strong>，而且安全性更高；</p>
<ul>
<li>在 TLS 1.2 的握手中，一般是需要 4 次握手，先要通过 Client Hello （第 1 次握手）和 Server Hello（第 2 次握手） 消息协商出后续使用的加密算法，再互相交换公钥（第 3 和 第 4 次握手），然后计算出最终的会话密钥</li>
<li><strong>TLS 1.3 把 Hello 和公钥交换这两个消息合并成了一个消息，于是这样就减少到只需 1 RTT 就能完成 TLS 握手</strong></li>
</ul>
</li>
<li><p>TLS 握手的目的就是为了协商出会话密钥，也就是对称加密密钥，那如果把首次 TLS 握手协商的对称加密密钥缓存起来，待下次需要建立 HTTPS 连接时，直接复用这个密钥就减少 TLS 握手的性能损耗了，这种方式就是<strong>会话复用</strong>（<em>TLS session resumption</em>），会话复用分两种：</p>
<ul>
<li>第一种叫 Session ID；<strong>客户端和服务器首次 TLS 握手连接后，双方会在内存缓存会话密钥，并用唯一的 Session ID 来标识</strong>，Session ID 和会话密钥相当于 key-value 的关系；它有两个缺点：<ul>
<li>服务器必须保持每一个客户端的会话密钥，随着客户端的增多，<strong>服务器的内存压力也会越大</strong></li>
<li>现在网站服务一般是由多台服务器通过负载均衡提供服务的，<strong>客户端再次连接不一定会命中上次访问过的服务器</strong>，于是还要走完整的 TLS 握手过程；</li>
</ul>
</li>
<li>第二种叫 Session Ticket，<strong>服务器不再缓存每个客户端的会话密钥，而是把缓存的工作交给了客户端</strong>，类似于 HTTP 的 Cookie；对于集群服务器的话，<strong>要确保每台服务器加密 「会话密钥」的密钥是一致的</strong>，这样客户端携带 Ticket 访问任意一台服务器时，都能恢复会话。</li>
<li>Session ID 和 Session Ticket <strong>都不具备前向安全性</strong>，因为一旦加密「会话密钥」的密钥被破解或者服务器泄漏「会话密钥」，前面劫持的通信密文都会被破解。同时应对<strong>重放攻击</strong>也很困难，避免重放攻击的方式就是需要<strong>对会话密钥设定一个合理的过期时间</strong></li>
</ul>
</li>
<li><p>TLS1.3 对于重连 TLS1.3 只需要 <strong>0 RTT</strong>，原理和 Ticket 类似，只不过在重连时，客户端会把 Ticket 和 HTTP 请求一同发送给服务端，这种方式叫 <strong>Pre-shared Ke</strong>；同样的，Pre-shared Key 也有重放攻击的危险</p>
</li>
</ul>
<h3 id="3-6-HTTP-x2F-2-牛逼在哪？"><a href="#3-6-HTTP-x2F-2-牛逼在哪？" class="headerlink" title="3.6 HTTP&#x2F;2 牛逼在哪？"></a>3.6 HTTP&#x2F;2 牛逼在哪？</h3><ul>
<li><p>HTTP&#x2F;1.1 协议存在的性能问题:</p>
</li>
<li><p><strong><em>延迟难以下降</em>，</strong>虽然现在网络的「带宽」相比以前变多了，但是延迟降到一定幅度后，就很难再下降了，说白了就是到达了延迟的下限；</p>
</li>
<li><p><strong><em>并发连接有限</em>，</strong>谷歌浏览器最大并发连接数是 6 个，而且每一个连接都要经过 TCP 和 TLS 握手耗时，以及 TCP 慢启动过程给流量带来的影响；</p>
</li>
<li><p><em><strong>队头阻塞问题</strong></em>，同一连接只能在完成一个 HTTP 事务（请求和响应）后，才能处理下一个事务</p>
</li>
<li><p><em><strong>HTTP 头部巨大且重复</strong></em>，由于 HTTP 协议是无状态的，每一个请求都得携带 HTTP 头部，特别是对于有携带 cookie 的头部，而 cookie 的大小通常很大；</p>
</li>
<li><p><em><strong>不支持服务器推送消息</strong></em>，因此当客户端需要获取通知时，只能通过定时器不断地拉取消息，这无疑浪费大量了带宽和服务器资源。</p>
</li>
<li><p>HTTP&#x2F;2 没有在 URI 里引入新的协议名，仍然用「http:&#x2F;&#x2F;」表示明文协议，用「https:&#x2F;&#x2F;」表示加密协议，于是只需要浏览器和服务器在背后自动升级协议，这样可以让用户意识不到协议的升级，很好的实现了协议的平滑升级；只在应用层做了改变，还是基于 TCP 协议传输，应用层方面为了保持功能上的兼容，HTTP&#x2F;2 把 HTTP 分解成了「语义」和「语法」两个部分，「语义」层不做改动，与 HTTP&#x2F;1.1 完全一致，比如请求方法、状态码、头字段等规则保留不变。但是，HTTP&#x2F;2 在「语法」层面做了很多改造，基本改变了 HTTP 报文的传输格式</p>
</li>
<li><p>HTTP&#x2F;2 没使用常见的 gzip 压缩方式来压缩头部，而是开发了 <strong>HPACK</strong> 算法，HPACK 算法主要包含三个组成部分：静态字典；动态字典；Huffman 编码（压缩算法）；</p>
<ul>
<li>客户端和服务器两端都会建立和维护「<strong>字典</strong>」，用长度较小的索引号表示重复的字符串，再用 Huffman 编码压缩数据，<strong>可达到 50%~90% 的高压缩率</strong>；</li>
<li>HTTP&#x2F;2 头部由于基于<strong>二进制编码</strong>，就不需要冒号空格和末尾的\r\n作为分隔符，于是改用表示字符串长度（Value Length）来分割 Index 和 Value</li>
</ul>
</li>
<li><p>HTTP&#x2F;2 将 HTTP&#x2F;1 的文本格式改成二进制格式传输数据，极大提高了 HTTP 传输效率，而且二进制数据使用位运算能高效解析</p>
<ul>
<li>帧头（Frame Header）很小，只有 9 个字节，帧开头的前 3 个字节表示帧数据（Frame Playload）的<strong>长度</strong></li>
<li>帧长度后面的一个字节是表示<strong>帧的类型</strong>，HTTP&#x2F;2 总共定义了 10 种类型的帧，一般分为<strong>数据帧</strong>和<strong>控制帧</strong>两类</li>
<li><strong>帧数据</strong>存放的是通过 <strong>HPACK 算法</strong>压缩过的 HTTP 头部和包体</li>
</ul>
</li>
<li><p>通过 Stream 这个设计，<strong>多个 Stream 复用一条 TCP 连接，达到并发的效果</strong>，解决了 HTTP&#x2F;1.1 队头阻塞的问题，提高了 HTTP 传输的吞吐量</p>
<ul>
<li>1 个 TCP 连接包含一个或者多个 Stream，Stream 是 HTTP&#x2F;2 并发的关键技术；</li>
<li>Stream 里可以包含 1 个或多个 Message，Message 对应 HTTP&#x2F;1 中的请求或响应，由 HTTP 头部和包体构成；</li>
<li>Message 里包含一条或者多个 Frame，Frame 是 HTTP&#x2F;2 最小单位，以二进制压缩格式存放 HTTP&#x2F;1 中的内容（头部和包体）；</li>
</ul>
<p>多个 Stream 跑在一条 TCP 连接，同一个 HTTP 请求与响应是跑在同一个 Stream 中，HTTP 消息可以由多个 Frame 构成， 一个 Frame 可以由多个 TCP 报文构成</p>
<ul>
<li>在 HTTP&#x2F;2 连接上，<strong>不同 Stream 的帧是可以乱序发送的（因此可以并发不同的 Stream ）</strong>，因为每个帧的头部会携带 Stream ID 信息，所以接收端可以通过 Stream ID 有序组装成 HTTP 消息，而<strong>同一 Stream 内部的帧必须是严格有序的</strong></li>
<li>客户端和服务器<strong>双方都可以建立 Stream</strong>，因为服务端可以主动推送资源给客户端， 客户端建立的 Stream 必须是奇数号，而服务器建立的 Stream 必须是偶数号</li>
<li><strong>当 HTTP&#x2F;2 实现 100 个并发 Stream 时，只需要建立一次 TCP 连接，而 HTTP&#x2F;1.1 需要建立 100 个 TCP 连接，每个 TCP 连接都要经过TCP 握手、慢启动以及 TLS 握手过程，这些都是很耗时的</strong></li>
</ul>
</li>
<li><p>在 HTTP&#x2F;2 中，客户端在访问 HTML 时，服务器可以直接主动推送 CSS 文件，减少了消息传递的次数，服务器在推送资源时，会通过 <code>PUSH_PROMISE</code> 帧传输 HTTP 头部，并通过帧中的 <code>Promised Stream ID</code> 字段告知客户端，接下来会在哪个偶数号 Stream 中发送包体</p>
</li>
<li><p><strong>HTTP&#x2F;2 是基于 TCP 协议来传输数据的，TCP 是字节流协议，TCP 层必须保证收到的字节数据是完整且连续的，这样内核才会将缓冲区里的数据返回给 HTTP 应用，那么当「前 1 个字节数据」没有到达时，后收到的字节数据只能存放在内核缓冲区里，只有等到这 1 个字节数据到达时，HTTP&#x2F;2 应用层才能从内核中拿到数据，这就是 HTTP&#x2F;2 队头阻塞问题</strong></p>
</li>
</ul>
<h3 id="3-7-HTTP-x2F-3-强势来袭"><a href="#3-7-HTTP-x2F-3-强势来袭" class="headerlink" title="3.7 HTTP&#x2F;3 强势来袭"></a>3.7 HTTP&#x2F;3 强势来袭</h3><ul>
<li><p>HTTP&#x2F;2 通过头部压缩、二进制编码、多路复用、服务器推送等新特性大幅度提升了 HTTP&#x2F;1.1 的性能，而美中不足的是 HTTP&#x2F;2 协议是基于 TCP 实现的，于是存在的缺陷有三个。</p>
<ul>
<li>队头阻塞；当 TCP 丢包时，整个 TCP 都要等待重传，那么就会阻塞该 TCP 连接中的所有请求</li>
<li>TCP 与 TLS 的握手时延迟；发起 HTTP 请求时，需要经过 TCP 三次握手和 TLS 四次握手（TLS 1.2）的过程，因此共需要 3 个 RTT 的时延才能发出请求数据</li>
<li>网络迁移需要重新连接；一个 TCP 连接是由四元组（源 IP 地址，源端口，目标 IP 地址，目标端口）确定的，这意味着如果 IP 地址或者端口变动了，就会导致需要 TCP 与 TLS 重新握手，这不利于移动设备切换网络的场景，比如 4G 网络环境切换成 WIFI</li>
</ul>
<p>这些问题都是 TCP 协议固有的问题，无论应用层的 HTTP&#x2F;2 在怎么设计都无法逃脱。要解决这个问题，就必须把<strong>传输层协议替换成 UDP</strong></p>
</li>
<li><p>HTTP&#x2F;3 不仅仅只是简单将传输协议替换成了 UDP，还基于 UDP 协议在「应用层」实现了 <strong>QUIC 协议</strong>，它具有类似 TCP 的连接管理、拥塞窗口、流量控制的网络特性，相当于将不可靠传输的 UDP 协议变成“可靠”的了，所以不用担心数据包丢失的问题</p>
</li>
<li><p><strong>无队头阻塞</strong>：QUIC 协议也有类似 HTTP&#x2F;2 Stream 与多路复用的概念，也是可以在同一条连接上并发传输多个 Stream，Stream 可以认为就是一条 HTTP 请求。由于 QUIC 使用的传输协议是 UDP，UDP 不关心数据包的顺序，如果数据包丢失，UDP 也不关心</p>
<ul>
<li>不过 QUIC 协议会保证数据包的可靠性，每个数据包都有一个序号唯一标识。当某个流中的一个数据包丢失了，即使该流的其他数据包到达了，数据也无法被 HTTP&#x2F;3 读取，直到 QUIC 重传丢失的报文，数据才会交给 HTTP&#x2F;3</li>
<li>而其他流的数据报文只要被完整接收，HTTP&#x2F;3 就可以读取到数据。这与 HTTP&#x2F;2 不同，HTTP&#x2F;2 只要某个流中的数据包丢失了，其他流也会因此受影响。所以，QUIC 连接上的多个 Stream 之间并没有依赖，都是独立的，某个流发生丢包了，只会影响该流，其他流不受影响</li>
</ul>
</li>
<li><p><strong>更快的连接建立</strong>：对于 HTTP&#x2F;1 和 HTTP&#x2F;2 协议，TCP 和 TLS 是分层的，分别属于内核实现的传输层、openssl 库实现的表示层，因此它们难以合并在一起，需要分批次来握手，先 TCP 握手，再 TLS 握手。HTTP&#x2F;3 在传输数据前虽然需要 QUIC 协议握手，这个握手过程只需要 1 RTT，握手的目的是为确认双方的「连接 ID」，连接迁移就是基于连接 ID 实现的</p>
<ul>
<li>HTTP&#x2F;3 的 QUIC 协议并不是与 TLS 分层，而是<strong>QUIC 内部包含了 TLS，它在自己的帧会携带 TLS 里的“记录”，再加上 QUIC 使用的是 TLS1.3，因此仅需 1 个 RTT 就可以「同时」完成建立连接与密钥协商，甚至在第二次连接的时候，应用数据包可以和 QUIC 握手信息（连接信息 + TLS 信息）一起发送，达到 0-RTT 的效果</strong></li>
</ul>
</li>
<li><p><strong>连接迁移</strong>： QUIC 协议没有用四元组的方式来“绑定”连接，而是通过<strong>连接 ID</strong>来标记通信的两个端点，客户端和服务器可以各自选择一组 ID 来标记自己，因此即使移动设备的网络变化后，导致 IP 地址变化了，只要仍保有上下文信息（比如连接 ID、TLS 密钥等），就可以“无缝”地复用原连接，消除重连的成本，没有丝毫卡顿感，达到了<strong>连接迁移</strong>的功能</p>
</li>
<li><p>HTTP&#x2F;3 同 HTTP&#x2F;2 一样采用二进制帧的结构，不同的地方在于 HTTP&#x2F;2 的二进制帧里需要定义 Stream，而 HTTP&#x2F;3 自身不需要再定义 Stream，直接使用 QUIC 里的 Stream，于是 HTTP&#x2F;3 的帧的结构也变简单了</p>
</li>
<li><p>HTTP&#x2F;3 在头部压缩算法这一方面也做了升级，升级成了 <strong>QPACK</strong>。与 HTTP&#x2F;2 中的 HPACK 编码方式相似，HTTP&#x2F;3 中的 QPACK 也采用了静态表、动态表及 Huffman 编码。</p>
<ul>
<li><p>动态表是具有时序性的，如果首次出现的请求发生了丢包，后续的收到请求，对方就无法解码出 HPACK 头部，因为对方还没建立好动态表，因此后续的请求解码会阻塞到首次请求中丢失的数据包重传过来</p>
</li>
<li><p>QUIC 会有两个特殊的单向流，所谓的单向流只有一端可以发送消息，双向则指两端都可以发送消息，传输 HTTP 消息时用的是双向流，这两个单向流的用法：</p>
<ul>
<li>一个叫 QPACK Encoder Stream， 用于将一个字典（key-value）传递给对方，比如面对不属于静态表的 HTTP 请求头部，客户端可以通过这个 Stream 发送字典；</li>
<li>一个叫 QPACK Decoder Stream，用于响应对方，告诉它刚发的字典已经更新到自己的本地动态表了，后续就可以使用这个字典来编码了。</li>
</ul>
<p>这两个特殊的单向流是用来<strong>同步双方的动态表</strong>，编码方收到解码方更新确认的通知后，才使用动态表编码 HTTP 头部</p>
</li>
</ul>
</li>
</ul>
<h3 id="4-1-TCP-三次握手与四次挥手面试题"><a href="#4-1-TCP-三次握手与四次挥手面试题" class="headerlink" title="4.1 TCP 三次握手与四次挥手面试题"></a>4.1 TCP 三次握手与四次挥手面试题</h3><h4 id="1-TCP-基本认识"><a href="#1-TCP-基本认识" class="headerlink" title="1. TCP 基本认识"></a>1. TCP 基本认识</h4><ul>
<li><p>TCP 头格式有哪些？</p>
<ul>
<li><strong>序列号</strong>：在建立连接时由计算机生成的随机数作为其初始值，通过 SYN 包传给接收端主机，每发送一次数据，就「累加」一次该「<strong>数据字节数</strong>」的大小。<strong>用来解决网络包乱序问题。</strong></li>
<li><strong>确认应答号</strong>：指下一次「期望」收到的数据的序列号，发送端收到这个确认应答以后可以认为在这个序号以前的数据都已经被正常接收。<strong>用来解决丢包的问题。</strong></li>
<li><strong>控制位：</strong><ul>
<li><em>ACK</em>：该位为 <code>1</code> 时，「确认应答」的字段变为有效，TCP 规定除了最初建立连接时的 <code>SYN</code> 包之外该位必须设置为 <code>1</code> 。</li>
<li><em>RST</em>：该位为 <code>1</code> 时，表示 TCP 连接中出现异常必须强制断开连接。</li>
<li><em>SYN</em>：该位为 <code>1</code> 时，表示希望建立连接，并在其「序列号」的字段进行序列号初始值的设定。</li>
<li><em>FIN</em>：该位为 <code>1</code> 时，表示今后不会再有数据发送，希望断开连接。当通信结束希望断开连接时，通信双方的主机之间就可以相互交换 <code>FIN</code> 位为 1 的 TCP 段</li>
</ul>
</li>
</ul>
</li>
<li><p>为什么需要 TCP 协议？ TCP 工作在哪一层？</p>
<ul>
<li><code>IP</code> 层是「不可靠」的，它不保证网络包的交付、不保证网络包的按序交付、也不保证网络包中的数据的完整性。如果需要保障网络数据包的可靠性，那么就需要由上层（传输层）的 <code>TCP</code> 协议来负责。</li>
<li>TCP 是一个工作在<strong>传输层</strong>的<strong>可靠</strong>数据传输的服务，它能确保接收端接收的网络包是<strong>无损坏、无间隔、非冗余和按序的</strong></li>
</ul>
</li>
<li><p>什么是 TCP ？</p>
<ul>
<li>TCP 是<strong>面向连接的、可靠的、基于字节流</strong>的传输层通信协议。</li>
<li><strong>面向连接</strong>：一定是「一对一」才能连接，不能像 UDP 协议可以一个主机同时向多个主机发送消息，也就是一对多是无法做到的；</li>
<li><strong>可靠的</strong>：无论的网络链路中出现了怎样的链路变化，TCP 都可以保证一个报文一定能够到达接收端；</li>
<li><strong>字节流</strong>：用户消息通过 TCP 协议传输时，消息可能会被操作系统「分组」成多个的 TCP 报文，如果接收方的程序如果不知道「消息的边界」，是无法读出一个有效的用户消息的。并且 TCP 报文是「有序的」，当「前一个」TCP 报文没有收到的时候，即使它先收到了后面的 TCP 报文，那么也不能扔给应用层去处理，同时对「重复」的 TCP 报文会自动丢弃</li>
</ul>
</li>
<li><p>什么是 TCP 连接？</p>
<ul>
<li>简单来说就是，<strong>用于保证可靠性和流量控制维护的某些状态信息，这些信息的组合，包括Socket、序列号和窗口大小称为连接</strong>，建立一个 TCP 连接是需要客户端与服务器端达成上述三个信息的共识<ul>
<li><strong>Socket</strong>：由 IP 地址和端口号组成</li>
<li><strong>序列号</strong>：用来解决乱序问题等</li>
<li><strong>窗口大小</strong>：用来做流量控制</li>
</ul>
</li>
</ul>
</li>
<li><p>如何唯一确定一个 TCP 连接呢？</p>
<ul>
<li>TCP 四元组可以唯一的确定一个连接，四元组包括如下：源地址、源端口、目的地址、目的端口</li>
<li>源地址和目的地址的字段（32位）是在 IP 头部中，作用是通过 IP 协议发送报文给对方主机。源端口和目的端口的字段（16位）是在 TCP 头部中，作用是告诉 TCP 协议应该把报文发给哪个进程</li>
</ul>
</li>
<li><p>有一个 IP 的服务器监听了一个端口，它的 TCP 的最大连接数是多少？</p>
<ul>
<li>服务器通常固定在某个本地端口上监听，等待客户端的连接请求。因此，客户端 IP 和 端口是可变的</li>
<li>对 IPv4，客户端的 IP 数最多为 <code>2</code> 的 <code>32</code> 次方，客户端的端口数最多为 <code>2</code> 的 <code>16</code> 次方，也就是服务端单机最大 TCP 连接数，约为 <code>2</code> 的 <code>48</code> 次方。</li>
<li>当然，服务端最大并发 TCP 连接数远不能达到理论上限，会受以下因素影响：<ul>
<li>文件描述符限制，每个 TCP 连接都是一个文件，如果文件描述符被占满了，会发生 too many open files。Linux 对可打开的文件描述符的数量分别作了三个方面的限制：<strong>系统级</strong>，当前系统可打开的最大数量；<strong>用户级</strong>，指定用户可打开的最大数量；<strong>进程级</strong>，单个进程可打开的最大数量</li>
<li><strong>内存限制</strong>，每个 TCP 连接都要占用一定内存，操作系统的内存是有限的，如果内存资源被占满后，会发生 OOM。</li>
</ul>
</li>
</ul>
</li>
<li><p>UDP 和 TCP 有什么区别呢？分别的应用场景是？</p>
<ul>
<li>UDP 不提供复杂的控制机制，利用 IP 提供面向「无连接」的通信服务。UDP 协议头部只有 <code>8</code> 个字节（ 64 位），包含如下信息：<ul>
<li>目标和源端口：主要是告诉 UDP 协议应该把报文发给哪个进程。</li>
<li>包长度：该字段保存了 UDP 首部的长度跟数据的长度之和。</li>
<li>校验和：校验和是为了提供可靠的 UDP 首部和数据而设计，防止收到在网络传输中受损的 UDP包。</li>
</ul>
</li>
<li><strong>TCP 和 UDP 区别：</strong><ul>
<li><em>连接</em>：TCP 是面向连接的传输层协议，传输数据前先要建立连接；UDP 是不需要连接，即刻传输数据。</li>
<li><em>服务对象</em>：TCP 是一对一的两点服务，即一条连接只有两个端点；UDP 支持一对一、一对多、多对多的交互通信</li>
<li><em>可靠性</em>：TCP 是可靠交付数据的，数据可以无差错、不丢失、不重复、按序到达；UDP 是尽最大努力交付，不保证可靠交付数据</li>
<li><em>拥塞控制、流量控制</em>：TCP 有拥塞控制和流量控制机制，保证数据传输的安全性；UDP 则没有，即使网络非常拥堵了，也不会影响 UDP 的发送速率</li>
<li><em>首部开销</em>：TCP 首部长度较长，会有一定的开销，首部在没有使用「选项」字段时是 <code>20</code> 个字节，如果使用了「选项」字段则会变长的；UDP 首部只有 8 个字节，并且是固定不变的，开销较小</li>
<li><em>传输方式</em>：TCP 是流式传输，没有边界，但保证顺序和可靠。UDP 是一个包一个包的发送，是有边界的，但可能会丢包和乱序</li>
<li><em>分片不同</em>：TCP 的数据大小如果大于 MSS 大小，则会在传输层进行分片，目标主机收到后，也同样在传输层组装 TCP 数据包，如果中途丢失了一个分片，只需要传输丢失的这个分片。UDP 的数据大小如果大于 MTU 大小，则会在 IP 层进行分片，目标主机收到后，在 IP 层组装完数据，接着再传给传输层。</li>
</ul>
</li>
<li><strong>TCP 和 UDP 应用场景：</strong><ul>
<li>由于 TCP 是面向连接，能保证数据的可靠性交付，因此经常用于：<code>FTP</code> 文件传输；HTTP &#x2F; HTTPS；</li>
<li>由于 UDP 面向无连接，它可以随时发送数据，再加上UDP本身的处理既简单又高效，因此经常用于：包总量较少的通信，如 <code>DNS</code> 、<code>SNMP</code> 等；视频、音频等多媒体通信；广播通信；</li>
</ul>
</li>
</ul>
</li>
<li><p>为什么 UDP 头部没有「首部长度」字段，而 TCP 头部有「首部长度」字段呢？</p>
<ul>
<li>原因是 TCP 有<strong>可变长</strong>的「选项」字段，而 UDP 头部长度则是<strong>不会变化</strong>的，无需多一个字段去记录 UDP 的首部长度。</li>
</ul>
</li>
<li><p>为什么 UDP 头部有「包长度」字段，而 TCP 头部则没有「包长度」字段呢？</p>
<ul>
<li>TCP 是如何计算负载数据长度：TCP数据总长度 &#x3D; IP 总长度 - IP 首部长度 -TCP 首部长度 ；其中 IP 总长度 和 IP 首部长度，在 IP 首部格式是已知的。TCP 首部长度，则是在 TCP 首部格式已知的，所以就可以求得 TCP 数据的长度。</li>
<li>UDP 也是基于 IP 层的呀，那 UDP 的数据长度也可以通过这个公式计算；这么一问，确实感觉 UDP 「包长度」是冗余的。估计是<strong>因为为了网络设备硬件设计和处理方便，首部长度需要是 <code>4</code>字节的整数倍</strong></li>
</ul>
</li>
</ul>
<h4 id="2-TCP-连接建立"><a href="#2-TCP-连接建立" class="headerlink" title="2. TCP 连接建立"></a>2. TCP 连接建立</h4><ul>
<li><p>TCP 三次握手过程是怎样的？</p>
<ul>
<li>一开始，客户端和服务端都处于 <code>CLOSE</code> 状态。先是服务端主动监听某个端口，处于 <code>LISTEN</code> 状态。客户端会随机初始化序号（<code>client_isn</code>），将此序号置于 TCP 首部的「序号」字段中，同时把 <code>SYN</code> 标志位置为 <code>1</code> ，表示 <code>SYN</code> 报文。接着把第一个 SYN 报文发送给服务端，表示向服务端发起连接，该报文不包含应用层数据，之后客户端处于 <code>SYN-SENT</code> 状态。</li>
<li>服务端收到客户端的 <code>SYN</code> 报文后，首先服务端也随机初始化自己的序号（<code>server_isn</code>），将此序号填入 TCP 首部的「序号」字段中，其次把 TCP 首部的「确认应答号」字段填入 <code>client_isn + 1</code>, 接着把 <code>SYN</code> 和 <code>ACK</code> 标志位置为 <code>1</code>。最后把该报文发给客户端，该报文也不包含应用层数据，之后服务端处于 <code>SYN-RCVD</code> 状态。</li>
<li>客户端收到服务端报文后，还要向服务端回应最后一个应答报文，首先该应答报文 TCP 首部 <code>ACK</code> 标志位置为 <code>1</code> ，其次「确认应答号」字段填入 <code>server_isn + 1</code> ，最后把报文发送给服务端，这次报文可以携带客户到服务器的数据，之后客户端处于 <code>ESTABLISHED</code> 状态。服务器收到客户端的应答报文后，也进入 <code>ESTABLISHED</code> 状态</li>
</ul>
<p><strong>第三次握手是可以携带数据的，前两次握手是不可以携带数据的</strong>，一旦完成三次握手，双方都处于 <code>ESTABLISHED</code> 状态，此时连接就已建立完成，<strong>客户端和服务端就可以相互发送数据了</strong></p>
</li>
<li><p>如何在 Linux 系统中查看 TCP 状态？</p>
<ul>
<li>TCP 的连接状态查看，在 Linux 可以通过 <code>netstat -napt</code> 命令查看。</li>
</ul>
</li>
<li><p>为什么是三次握手？不是两次、四次？(为什么三次握手才可以初始化Socket、序列号和窗口大小并建立 TCP 连接)</p>
<ul>
<li>三次握手才可以阻止重复历史连接的初始化（主要原因）：<strong>在两次握手的情况下，「被动发起方」没有中间状态给「主动发起方」来阻止历史连接，导致「被动发起方」可能建立一个历史连接，造成资源浪费</strong>。要解决这种现象，最好就是在「被动发起方」发送数据前，也就是建立连接之前，要阻止掉历史连接，这样就不会造成资源浪费，而要实现这个功能，就需要三次握手</li>
<li>三次握手才可以同步双方的初始序列号：<ul>
<li>TCP 协议的通信双方， 都必须维护一个「序列号」， 序列号是可靠传输的一个关键因素，它的作用：接收方可以去除重复的数据；接收方可以根据数据包的序列号按序接收；可以标识发送出去的数据包中， 哪些是已经被对方收到的（通过 ACK 报文中的序列号知道）</li>
<li><strong>一来一回，才能确保双方的初始序列号能被可靠的同步</strong>，两次握手只保证了一方的初始序列号能被对方成功接收，没办法保证双方的初始序列号都能被确认接收</li>
</ul>
</li>
<li>三次握手才可以避免资源浪费：两次握手是假设「由于没有第三次握手，服务器不清楚客户端是否收到了自己发送的建立连接的 <code>ACK</code> 确认报文，所以每收到一个 <code>SYN</code> 就只能先主动建立一个连接」。这个场景如果客户端的 <code>SYN</code> 阻塞了，重复发送多次 <code>SYN</code> 报文，那么服务器在收到请求后就会<strong>建立多个冗余的无效链接，造成不必要的资源浪费</strong></li>
</ul>
<p>总结：TCP 建立连接时，通过三次握手<strong>能防止历史连接的建立，能减少双方不必要的资源开销，能帮助双方同步初始化序列号</strong>。序列号能够保证数据包不重复、不丢弃和按序传输。不使用「两次握手」和「四次握手」的原因：</p>
<ul>
<li>「两次握手」：无法防止历史连接的建立，会造成双方资源的浪费，也无法可靠的同步双方序列号；</li>
<li>「四次握手」：三次握手就已经理论上最少可靠连接建立，所以不需要使用更多的通信次数</li>
</ul>
</li>
<li><p>为什么每次建立 TCP 连接时，初始化的序列号都要求不一样呢？</p>
<ul>
<li>为了防止历史报文被下一个相同四元组的连接接收（主要方面）：如果每次建立连接客户端和服务端的初始化序列号都「不一样」，就有大概率因为历史报文的序列号「不在」对方接收窗口，从而很大程度上避免了历史报文</li>
<li>为了安全性，防止黑客伪造的相同序列号的 TCP 报文被对方接收；</li>
</ul>
</li>
<li><p>初始序列号 ISN 是如何随机产生的？</p>
<ul>
<li>起始 <code>ISN</code> 是基于时钟的，每 4 微秒 + 1，转一圈要 4.55 个小时</li>
<li>ISN 随机生成算法：ISN &#x3D; M + F(localhost, localport, remotehost, remoteport)。<ul>
<li><code>M</code> 是一个计时器，这个计时器每隔 4 微秒加 1。</li>
<li><code>F</code> 是一个 Hash 算法，根据源 IP、目的 IP、源端口、目的端口生成一个随机数值</li>
</ul>
</li>
</ul>
</li>
<li><p>既然 IP 层会分片，为什么 TCP 层还需要 MSS 呢？</p>
<ul>
<li><p><code>MTU</code>：一个网络包的最大长度，以太网中一般为 <code>1500</code> 字节；</p>
</li>
<li><p><code>MSS</code>：除去 IP 和 TCP 头部之后，一个网络包所能容纳的 TCP 数据的最大长度；</p>
</li>
<li><p>如果在 TCP 的整个报文（头部 + 数据）交给 IP 层进行分片，当 IP 层有一个超过 <code>MTU</code> 大小的数据（TCP 头部 + TCP 数据）要发送，那么 IP 层就要进行分片，把数据分片成若干片，保证每一个分片都小于 MTU。把一份 IP 数据报进行分片以后，由目标主机的 IP 层来进行重新组装后，再交给上一层 TCP 传输层。这看起来井然有序，但这存在隐患的，<strong>那么当如果一个 IP 分片丢失，整个 IP 报文的所有分片都得重传</strong>。因为 IP 层本身没有超时重传机制，它由传输层的 TCP 来负责超时和重传。当接收方发现 TCP 报文（头部 + 数据）的某一片丢失后，则不会响应 ACK 给对方，那么发送方的 TCP 在超时后，就会重发「整个 TCP 报文（头部 + 数据）」。因此，可以得知由 IP 层进行分片传输，是非常没有效率的</p>
</li>
<li><p>为了达到最佳的传输效能 TCP 协议在<strong>建立连接的时候通常要协商双方的 MSS 值</strong>，当 TCP 层发现数据超过 MSS 时，则就先会进行分片，当然由它形成的 IP 包的长度也就不会大于 MTU ，自然也就不用 IP 分片了；经过 TCP 层分片后，如果一个 TCP 分片丢失后，<strong>进行重发时也是以 MSS 为单位</strong>，而不用重传所有的分片，大大增加了重传的效率</p>
</li>
</ul>
</li>
<li><p>第一次握手丢失了，会发生什么？</p>
<ul>
<li>如果客户端迟迟收不到服务端的 SYN-ACK 报文（第二次握手），就会触发「超时重传」机制，重传 SYN 报文，而且<strong>重传的 SYN 报文的序列号都是一样的</strong></li>
<li>客户端的 SYN 报文最大重传次数由 <code>tcp_syn_retries</code>内核参数控制，这个参数是可以自定义的，默认值一般是 5；<strong>每次超时的时间是上一次的 2 倍</strong>，如果还是没能收到服务端的第二次握手，那么客户端就会断开连接</li>
</ul>
</li>
<li><p>第二次握手丢失了，会发生什么？</p>
<ul>
<li>第二次握手的 <code>SYN-ACK</code> 报文其实有两个目的 ：<ul>
<li>第二次握手里的 ACK， 是对第一次握手的确认报文；</li>
<li>第二次握手里的 SYN，是服务端发起建立 TCP 连接的报文；</li>
</ul>
</li>
<li>第二次握手报文里是包含对客户端的第一次握手的 ACK 确认报文，所以，如果客户端迟迟没有收到第二次握手，那么客户端就觉得可能自己的 SYN 报文（第一次握手）丢失了，于是<strong>客户端就会触发超时重传机制，重传 SYN 报文</strong></li>
<li>第二次握手中包含服务端的 SYN 报文，所以当客户端收到后，需要给服务端发送 ACK 确认报文（第三次握手），服务端才会认为该 SYN 报文被客户端收到了。如果第二次握手丢失了，服务端就收不到第三次握手，于是<strong>服务端这边会触发超时重传机制，重传 SYN-ACK 报文</strong>。</li>
</ul>
</li>
<li><p>第三次握手丢失了，会发生什么？</p>
<ul>
<li>第三次握手的 ACK 是对第二次握手的 SYN 的确认报文，所以当第三次握手丢失了，如果服务端那一方迟迟收不到这个确认报文，就会触发超时重传机制，重传 SYN-ACK 报文，直到收到第三次握手，或者达到最大重传次数</li>
<li><strong>ACK 报文是不会有重传的，当 ACK 丢失了，就由对方重传对应的报文</strong></li>
</ul>
</li>
<li><p>什么是 SYN 攻击？如何避免 SYN 攻击？</p>
<ul>
<li>TCP 连接建立是需要三次握手，假设攻击者短时间伪造不同 IP 地址的 <code>SYN</code> 报文，服务端每接收到一个 <code>SYN</code> 报文，就进入<code>SYN_RCVD</code> 状态，但服务端发送出去的 <code>ACK + SYN</code> 报文，无法得到未知 IP 主机的 <code>ACK</code> 应答，久而久之就会<strong>占满服务端的半连接队列</strong>，使得服务器不能为正常用户服务</li>
<li>避免 SYN 攻击方式，可以有以下四种方法：<ul>
<li>调大 netdev_max_backlog：当网卡接收数据包的速度大于内核处理的速度时，会有一个队列保存这些数据包</li>
<li>增大 TCP 半连接队列：需要同时增大下面这三个参数：<ul>
<li>增大 net.ipv4.tcp_max_syn_backlog</li>
<li>增大 listen() 函数中的 backlog</li>
<li>增大 net.core.somaxconn</li>
</ul>
</li>
<li>开启 tcp_syncookies：开启 syncookies 功能就可以在不使用 SYN 半连接队列的情况下成功建立连接，相当于绕过了 SYN 半连接来建立连接：<ul>
<li>当 「 SYN 队列」满之后，后续服务器收到 SYN 包，不会丢弃，而是根据算法，计算出一个 <code>cookie</code> 值；</li>
<li>将 cookie 值放到第二次握手报文的「序列号」里，然后服务端回第二次握手给客户端；</li>
<li>服务端接收到客户端的应答报文时，服务器会检查这个 ACK 包的合法性。如果合法，将该连接对象放入到「 Accept 队列」</li>
</ul>
</li>
<li>减少 SYN+ACK 重传次数，以加快处于 SYN_REVC 状态的 TCP 连接断开。</li>
</ul>
</li>
</ul>
</li>
</ul>
<h4 id="3-TCP-连接断开"><a href="#3-TCP-连接断开" class="headerlink" title="3. TCP 连接断开"></a>3. TCP 连接断开</h4><ul>
<li><p>TCP 四次挥手过程是怎样的？</p>
<ul>
<li>客户端打算关闭连接，此时会发送一个 TCP 首部 <code>FIN</code> 标志位被置为 <code>1</code> 的报文，也即 <code>FIN</code> 报文，之后客户端进入 <code>FIN_WAIT_1</code> 状态。</li>
<li>服务端收到该报文后，就向客户端发送 <code>ACK</code> 应答报文，接着服务端进入 <code>CLOSE_WAIT</code> 状态。客户端收到服务端的 <code>ACK</code> 应答报文后，之后进入 <code>FIN_WAIT_2</code> 状态。</li>
<li>等待服务端处理完数据后，也向客户端发送 <code>FIN</code> 报文，之后服务端进入 <code>LAST_ACK</code> 状态。</li>
<li>客户端收到服务端的 <code>FIN</code> 报文后，回一个 <code>ACK</code> 应答报文，之后进入 <code>TIME_WAIT</code> 状态服务器收到了 <code>ACK</code> 应答报文后，就进入了 <code>CLOSE</code> 状态，至此服务端已经完成连接的关闭。客户端在经过 <code>2MSL</code> 一段时间后，自动进入 <code>CLOSE</code> 状态，至此客户端也完成连接的关闭。</li>
</ul>
<p>每个方向都需要<strong>一个 FIN 和一个 ACK</strong>，因此通常被称为<strong>四次挥手</strong>。这里一点需要注意是：<strong>主动关闭连接的，才有 TIME_WAIT 状态</strong></p>
</li>
<li><p>为什么挥手需要四次？</p>
<ul>
<li>关闭连接时，客户端向服务端发送 <code>FIN</code> 时，仅仅表示客户端不再发送数据了但是还能接收数据。</li>
<li>服务器收到客户端的 <code>FIN</code> 报文时，先回一个 <code>ACK</code> 应答报文，而服务端可能还有数据需要处理和发送，等服务端不再发送数据时，才发送 <code>FIN</code> 报文给客户端来表示同意现在关闭连接。</li>
<li>服务端通常需要等待完成数据的发送和处理，所以服务端的 <code>ACK</code> 和 <code>FIN</code> 一般都会分开发送，因此是需要四次挥手。但是<strong>在特定情况下，四次挥手是可以变成三次挥手的</strong>：当被动关闭方在 TCP 挥手过程中，如果「没有数据要发送」，同时「没有开启 TCP_QUICKACK（默认情况就是没有开启，没有开启 TCP_QUICKACK，等于就是在使用 TCP 延迟确认机制）」，那么第二和第三次挥手就会合并传输，这样就出现了三次挥手。出现三次挥手现象是因为 TCP 延迟确认机制导致的</li>
</ul>
</li>
<li><p>第一次挥手丢失了，会发生什么？</p>
<ul>
<li>正常情况下，如果能及时收到服务端（被动关闭方）的 ACK，则会很快变为 <code>FIN_WAIT2</code>状态。如果第一次挥手丢失了，那么客户端迟迟收不到被动方的 ACK 的话，也就会触发超时重传机制，重传 FIN 报文，重发次数由 <code>tcp_orphan_retries</code> 参数控制。</li>
<li>当客户端重传 FIN 报文的次数超过 <code>tcp_orphan_retries</code> 后，就不再发送 FIN 报文，则会在等待一段时间（时间为上一次超时时间的 2 倍），如果还是没能收到第二次挥手，那么直接进入到 <code>close</code> 状态</li>
</ul>
</li>
<li><p>第二次挥手丢失了，会发生什么？</p>
<ul>
<li>ACK 报文是不会重传的，所以如果服务端的第二次挥手丢失了，客户端就会触发超时重传机制，重传 FIN 报文，直到收到服务端的第二次挥手，或者达到最大的重传次数</li>
<li>当客户端收到第二次挥手，也就是收到服务端发送的 ACK 报文后，客户端就会处于 <code>FIN_WAIT2</code> 状态，在这个状态需要等服务端发送第三次挥手，也就是服务端的 FIN 报文。</li>
<li>对于 close 函数关闭的连接，由于无法再发送和接收数据，所以<code>FIN_WAIT2</code> 状态不可以持续太久，而 <code>tcp_fin_timeout</code> 控制了这个状态下连接的持续时长，默认值是 60 秒。这意味着对于调用 close 关闭的连接，如果在 60 秒后还没有收到 FIN 报文，客户端（主动关闭方）的连接就会直接关闭</li>
<li>如果主动关闭方使用 shutdown 函数关闭连接，指定了只关闭发送方向，而接收方向并没有关闭，那么意味着主动关闭方还是可以接收数据的。此时，如果主动关闭方一直没收到第三次挥手，那么主动关闭方的连接将会一直处于 <code>FIN_WAIT2</code> 状态（<code>tcp_fin_timeout</code> 无法控制 shutdown 关闭的连接）</li>
</ul>
</li>
<li><p>第三次挥手丢失了，会发生什么？</p>
<ul>
<li>当服务端（被动关闭方）收到客户端（主动关闭方）的 FIN 报文后，内核会自动回复 ACK，同时连接处于 <code>CLOSE_WAIT</code> 状态，顾名思义，它表示等待应用进程调用 close 函数关闭连接。此时，内核是没有权利替代进程关闭连接，必须由进程主动调用 close 函数来触发服务端发送 FIN 报文。</li>
<li>服务端处于 CLOSE_WAIT 状态时，调用了 close 函数，内核就会发出 FIN 报文，同时连接进入 LAST_ACK 状态，等待客户端返回 ACK 来确认连接关闭。如果迟迟收不到这个 ACK，服务端就会重发 FIN 报文，重发次数仍然由 <code>tcp_orphan_retrie</code>s 参数控制，这与客户端重发 FIN 报文的重传次数控制方式是一样的</li>
</ul>
</li>
<li><p>第四次挥手丢失了，会发生什么？</p>
<ul>
<li>当客户端收到服务端的第三次挥手的 FIN 报文后，就会回 ACK 报文，也就是第四次挥手，此时客户端连接进入 <code>TIME_WAIT</code> 状态。在 Linux 系统，TIME_WAIT 状态会持续 2MSL 后才会进入关闭状态。</li>
<li>然后，服务端（被动关闭方）没有收到 ACK 报文前，还是处于 LAST_ACK 状态。如果第四次挥手的 ACK 报文没有到达服务端，服务端就会重发 FIN 报文，重发次数仍然由前面介绍过的 <code>tcp_orphan_retries</code> 参数控制。</li>
</ul>
</li>
<li><p>为什么 TIME_WAIT 等待的时间是 2MSL？</p>
<ul>
<li><code>MSL</code> 是 Maximum Segment Lifetime，<strong>报文最大生存时间</strong>，它是任何报文在网络上存在的最长时间，超过这个时间报文将被丢弃。因为 TCP 报文基于是 IP 协议的，而 IP 头中有一个 <code>TTL</code> 字段，是 IP 数据报可以经过的最大路由数，每经过一个处理他的路由器此值就减 1，当此值为 0 则数据报将被丢弃，同时发送 ICMP 报文通知源主机</li>
<li>MSL 与 TTL 的区别： MSL 的单位是时间，而 TTL 是经过路由跳数。所以 <strong>MSL 应该要大于等于 TTL 消耗为 0 的时间</strong>，以确保报文已被自然消亡。<strong>TTL 的值一般是 64，Linux 将 MSL 设置为 30 秒，意味着 Linux 认为数据报文经过 64 个路由器的时间不会超过 30 秒，如果超过了，就认为报文已经消失在网络中了</strong></li>
<li>TIME_WAIT 等待 2 倍的 MSL，比较合理的解释是： 网络中可能存在来自发送方的数据包，当这些发送方的数据包被接收方处理后又会向对方发送响应，所以<strong>一来一回需要等待 2 倍的时间</strong></li>
<li><strong>2MSL时长</strong> 这其实是相当于<strong>至少允许报文丢失一次</strong>。比如，若 ACK 在一个 MSL 内丢失，这样被动方重发的 FIN 会在第 2 个 MSL 内到达，TIME_WAIT 状态的连接可以应对；为什么不是 4 或者 8 MSL 的时长呢？一个丢包率达到百分之一的糟糕网络，连续两次丢包的概率只有万分之一，这个概率实在是太小了，忽略它比解决它更具性价比</li>
<li><code>2MSL</code> 的时间是从<strong>客户端接收到 FIN 后发送 ACK 开始计时的</strong>。如果在 TIME-WAIT 时间内，因为客户端的 ACK 没有传输到服务端，客户端又接收到了服务端重发的 FIN 报文，那么 <strong>2MSL 时间将重新计时</strong></li>
</ul>
</li>
<li><p>为什么需要 TIME_WAIT 状态？</p>
<ul>
<li>防止历史连接中的数据，被后面相同四元组的连接错误的接收；<ul>
<li><strong>序列号是一个 32 位的无符号数，因此在到达 4G 之后再循环回到 0</strong>；初始化序列号可被视为一个 32 位的计数器，该计数器的数值每 4 微秒加 1，循环一次需要 4.55 小时；</li>
<li><strong>序列号和初始化序列号并不是无限递增的，会发生回绕为初始值的情况，这意味着无法根据序列号来判断新老数据</strong></li>
<li>为了防止历史连接中的数据，被后面相同四元组的连接错误的接收，因此 TCP 设计了 TIME_WAIT 状态，状态会持续 <code>2MSL</code> 时长，这个时间<strong>足以让两个方向上的数据包都被丢弃，使得原来连接的数据包在网络中都自然消失，再出现的数据包一定都是新建立连接所产生的</strong></li>
</ul>
</li>
<li>保证「被动关闭连接」的一方，能被正确的关闭、<ul>
<li>TIME-WAIT 作用是<strong>等待足够的时间以确保最后的 ACK 能让被动关闭方接收，从而帮助其正常关闭</strong></li>
<li>假设客户端没有 TIME_WAIT 状态，而是在发完最后一次回 ACK 报文就直接进入 CLOSE 状态，如果该 ACK 报文丢失了，服务端则重传的 FIN 报文，而这时客户端已经进入到关闭状态了，在收到服务端重传的 FIN 报文后，就会回 RST 报文</li>
</ul>
</li>
</ul>
</li>
<li><p>TIME_WAIT 过多有什么危害？</p>
<ul>
<li>第一是占用系统资源，比如文件描述符、内存资源、CPU 资源、线程资源等；</li>
<li>第二是占用端口资源，端口资源也是有限的，一般可以开启的端口为 <code>32768～61000</code>，也可以通过 <code>net.ipv4.ip_local_port_range</code>参数指定范围。<ul>
<li><strong>如果客户端（发起连接方）的 TIME_WAIT 状态过多</strong>，占满了所有端口资源，那么就无法对「目的 IP+ 目的 PORT」都一样的服务器发起连接了，但是被使用的端口，还是可以继续对另外一个服务器发起连接的</li>
<li><strong>如果服务端（发起连接方）的 TIME_WAIT 状态过多</strong>，并不会导致端口资源受限，因为服务端只监听一个端口，而且由于一个四元组唯一确定一个 TCP 连接，因此理论上服务端可以建立很多连接</li>
</ul>
</li>
</ul>
</li>
<li><p>如何优化 TIME_WAIT？</p>
<ul>
<li>打开 net.ipv4.tcp_tw_reuse 和 net.ipv4.tcp_timestamps 选项；<ul>
<li>可以<strong>复用处于 TIME_WAIT 的 socket 为新的连接所用</strong>。有一点需要注意的是，<strong>tcp_tw_reuse 功能只能用客户端（连接发起方），因为开启了该功能，在调用 connect() 函数时，内核会随机找一个 time_wait 状态超过 1 秒的连接给新的连接复用</strong></li>
<li>由于引入了时间戳，在前面提到的 <code>2MSL</code> 问题就不复存在了，因为重复的数据包会因为时间戳过期被自然丢弃</li>
</ul>
</li>
<li>net.ipv4.tcp_max_tw_buckets<ul>
<li>这个值默认为 18000，<strong>当系统中处于 TIME_WAIT 的连接一旦超过这个值时，系统就会将后面的 TIME_WAIT 连接状态重置</strong>，这个方法比较暴力</li>
</ul>
</li>
<li>程序中使用 SO_LINGER ，应用强制使用 RST 关闭<ul>
<li>通过设置 socket 选项，来设置调用 close 关闭连接行为。如果<code>l_onoff</code>为非 0， 且<code>l_linger</code>值为 0，那么调用<code>close</code>后，会立该发送一个<code>RST</code>标志给对端，该 TCP 连接将跳过四次挥手，也就跳过了<code>TIME_WAIT</code>状态，直接关闭。</li>
<li>但这为跨越<code>TIME_WAIT</code>状态提供了一个可能，不过是一个非常危险的行为，不值得提倡</li>
</ul>
</li>
<li><strong>如果服务端要避免过多的 TIME_WAIT 状态的连接，就永远不要主动断开连接，让客户端去断开，由分布在各处的客户端去承受 TIME_WAIT</strong></li>
</ul>
</li>
<li><p>如果已经建立了连接，但是客户端突然出现故障了怎么办？</p>
<ul>
<li>TCP 有一个机制是<strong>保活机制</strong>：定义一个时间段，在这个时间段内，如果没有任何连接相关的活动，TCP 保活机制会开始作用，每隔一个时间间隔，发送一个探测报文，该探测报文包含的数据非常少，如果连续几个探测报文都没有得到响应，则认为当前的 TCP 连接已经死亡，系统内核将错误信息通知给上层应用程序</li>
<li>应用程序若想使用 TCP 保活机制需要通过 socket 接口设置 <code>SO_KEEPALIVE</code> 选项才能够生效，如果没有设置，那么就无法使用 TCP 保活机制</li>
<li>如果开启了 TCP 保活，需要考虑以下几种情况：<ul>
<li>第一种，对端程序是正常工作的。当 TCP 保活的探测报文发送给对端, 对端会正常响应，这样 <strong>TCP 保活时间会被重置</strong>，等待下一个 TCP 保活时间的到来。</li>
<li>第二种，对端程序崩溃并重启。当 TCP 保活的探测报文发送给对端后，对端是可以响应的，但由于没有该连接的有效信息，<strong>会产生一个 RST 报文</strong>，这样很快就会发现 TCP 连接已经被重置。</li>
<li>第三种，是对端程序崩溃，或对端由于其他原因导致报文不可达。当 TCP 保活的探测报文发送给对端后，石沉大海，没有响应，连续几次，达到保活探测次数后，<strong>TCP 会报告该 TCP 连接已经死亡</strong></li>
</ul>
</li>
<li>可以自己在应用层实现一个心跳机制：比如，web 服务软件一般都会提供 <code>keepalive_timeout</code> 参数，用来指定 HTTP 长连接的超时时间。如果设置了 HTTP 长连接的超时时间是 60 秒，web 服务软件就会<strong>启动一个定时器</strong>，如果客户端在完成一个 HTTP 请求后，在 60 秒内都没有再发起新的请求，<strong>定时器的时间一到，就会触发回调函数来释放该连接。</strong></li>
</ul>
</li>
<li><p>如果已经建立了连接，但是服务端的进程崩溃会发生什么？</p>
<ul>
<li>TCP 的连接信息是由内核维护的，所以当服务端的进程崩溃后，内核需要回收该进程的所有 TCP 连接资源，于是内核会发送第一次挥手 FIN 报文，后续的挥手过程也都是在内核完成，并不需要进程的参与，所以即使服务端的进程退出了，还是能与客户端完成 TCP四次挥手的过程</li>
</ul>
</li>
</ul>
<h4 id="4-Socket-编程"><a href="#4-Socket-编程" class="headerlink" title="4. Socket 编程"></a>4. Socket 编程</h4><ul>
<li><p>针对 TCP 应该如何 Socket 编程？</p>
<ul>
<li>服务端和客户端初始化 <code>socket</code>，得到文件描述符；</li>
<li>服务端调用 <code>bind</code>，将 socket 绑定在指定的 IP 地址和端口;</li>
<li>服务端调用 <code>listen</code>，进行监听；</li>
<li>服务端调用 <code>accept</code>，等待客户端连接；</li>
<li>客户端调用 <code>connect</code>，向服务器端的地址和端口发起连接请求；</li>
<li>服务端 <code>accept</code> 返回用于传输的 <code>socket</code> 的文件描述符；</li>
<li>客户端调用 <code>write</code> 写入数据；服务端调用 <code>read</code> 读取数据；</li>
<li>客户端断开连接时，会调用 <code>close</code>，那么服务端 <code>read</code> 读取数据的时候，就会读取到了 <code>EOF</code>，待处理完数据后，服务端调用 <code>close</code>，表示连接关闭。</li>
</ul>
<p>这里需要注意的是，服务端调用 <code>accept</code> 时，连接成功了会返回一个已完成连接的 socket，后续用来传输数据。所以，监听的 socket 和真正用来传送数据的 socket，是「两个」 socket，一个叫作<strong>监听 socket</strong>，一个叫作<strong>已完成连接 socket</strong>。成功连接建立之后，双方开始通过 read 和 write 函数来读写数据，就像往一个文件流里面写东西一样</p>
</li>
<li><p>listen 时候参数 backlog 的意义？</p>
<ul>
<li><p>Linux内核中会维护两个队列：</p>
<ul>
<li>半连接队列（SYN 队列）：接收到一个 SYN 建立连接请求，处于 SYN_RCVD 状态；</li>
<li>全连接队列（Accpet 队列）：已完成 TCP 三次握手过程，处于 ESTABLISHED 状态</li>
</ul>
</li>
<li><pre><code class="c">int listen (int socketfd, int backlog)
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">    - 参数一 socketfd 为 socketfd 文件描述符</span><br><span class="line">    - 参数二 backlog，这参数在历史版本有一定的变化</span><br><span class="line"></span><br><span class="line">  - 在 Linux 内核 2.2 之后，backlog 变成 accept 队列，也就是已完成连接建立的队列长度，**所以现在通常认为 backlog 是 accept 队列。**但是上限值是内核参数 somaxconn 的大小，也就说 accpet 队列长度 = min(backlog, somaxconn)。</span><br><span class="line"></span><br><span class="line">- accept 发生在三次握手的哪一步？</span><br><span class="line"></span><br><span class="line">  - 客户端协议栈收到 ACK 之后，使得应用程序从 `connect` 调用返回，表示客户端到服务器端的单向连接建立成功，客户端的状态为 ESTABLISHED，同时客户端协议栈也会对服务器端的 SYN 包进行应答，应答数据为 server_isn+1；</span><br><span class="line">  - ACK 应答包到达服务器端后，服务器端的 TCP 连接进入 ESTABLISHED 状态，同时服务器端协议栈使得 `accept` 阻塞调用返回，这个时候服务器端到客户端的单向连接也建立成功。至此，客户端与服务端两个方向的连接都建立成功。</span><br><span class="line"></span><br><span class="line">  从上面的描述过程，可以得知**客户端 connect 成功返回是在第二次握手，服务端 accept 成功返回是在三次握手成功之后**</span><br><span class="line"></span><br><span class="line">- 客户端调用 close 了，连接是断开的流程是什么？</span><br><span class="line"></span><br><span class="line">  - 客户端调用 `close`，表明客户端没有数据需要发送了，则此时会向服务端发送 FIN 报文，进入 FIN_WAIT_1 状态；</span><br><span class="line">  - 服务端接收到了 FIN 报文，TCP 协议栈会为 FIN 包插入一个文件结束符 `EOF` 到接收缓冲区中，应用程序可以通过 `read` 调用来感知这个 FIN 包。这个 `EOF` 会被**放在已排队等候的其他已接收的数据之后**，这就意味着服务端需要处理这种异常情况，因为 EOF 表示在该连接上再无额外数据到达。此时，服务端进入 CLOSE_WAIT 状态；</span><br><span class="line">  - 接着，当处理完数据后，自然就会读到 `EOF`，于是也调用 `close` 关闭它的套接字，这会使得服务端发出一个 FIN 包，之后处于 LAST_ACK 状态；</span><br><span class="line">  - 客户端接收到服务端的 FIN 包，并发送 ACK 确认包给服务端，此时客户端将进入 TIME_WAIT 状态；</span><br><span class="line">  - 服务端收到 ACK 确认包后，就进入了最后的 CLOSE 状态；</span><br><span class="line">  - 客户端经过 `2MSL` 时间之后，也进入 CLOSE 状态</span><br><span class="line"></span><br><span class="line">### 4.2 TCP 重传、滑动窗口、流量控制、拥塞控制</span><br><span class="line"></span><br><span class="line">#### 重传机制</span><br><span class="line"></span><br><span class="line">- TCP 实现可靠传输的方式之一，是通过序列号与确认应答。在 TCP 中，当发送端的数据到达接收主机时，接收端主机会返回一个确认应答消息，表示已收到消息。TCP 针对数据包丢失的情况，会用**重传机制**解决。</span><br><span class="line">- 超时重传：在发送数据时，设定一个定时器，当超过指定的时间后，没有收到对方的 `ACK` 确认应答报文，就会重发该数据；</span><br><span class="line">  - TCP 会在以下两种情况发生超时重传：数据包丢失；确认应答丢失</span><br><span class="line">  - `RTT` 指的是**数据发送时刻到接收到确认的时刻的差值**，也就是包的往返时间。超时重传时间是以 `RTO` （Retransmission Timeout 超时重传时间）表示。**超时重传时间 RTO 的值应该略大于报文往返 RTT 的值**。实际上RTT 的值是经常变化的，因为网络也是时常变化的，所以RTO 的值应该是一个**动态变化的值**。</span><br><span class="line">  - 如果超时重发的数据，再次超时的时候，又需要重传的时候，TCP 的策略是**超时间隔加倍。**也就是**每当遇到一次超时重传的时候，都会将下一次超时时间间隔设为先前值的两倍。两次超时，就说明网络环境差，不宜频繁反复发送。**</span><br><span class="line">- 快速重传：**不以时间为驱动，而是以数据驱动重传**，当收到三个相同的 ACK 报文时，会在定时器过期之前，重传丢失的报文段</span><br><span class="line">  - 依然面临着另外一个问题。就是**重传的时候，是重传一个，还是重传所有的问题。**不管是重传一个报文，还是重传已发送的报文，都存在问题。</span><br><span class="line">- SACK（ Selective Acknowledgment）， **选择性确认**</span><br><span class="line">  - 需要在 TCP 头部「选项」字段里加一个 `SACK` 的东西，它**可以将已收到的数据的信息发送给「发送方」**，这样发送方就可以知道哪些数据收到了，哪些数据没收到，知道了这些信息，就可以**只重传丢失的数据**</span><br><span class="line">- D-SACK（Duplicate SACK），主要**使用了 SACK 来告诉「发送方」有哪些数据被重复接收了**</span><br><span class="line">  - 可以让「发送方」知道，是发出去的包丢了，还是接收方回应的 ACK 包丢了;</span><br><span class="line">  - 可以知道是不是「发送方」的数据包被网络延迟了;</span><br><span class="line">  - 可以知道网络中是不是把「发送方」的数据包给复制了;</span><br><span class="line"></span><br><span class="line">#### 滑动窗口</span><br><span class="line"></span><br><span class="line">- 窗口大小就是指**无需等待确认应答，而可以继续发送数据的最大值**。窗口的实现实际上是操作系统开辟的一个缓存空间，发送方主机在等到确认应答返回之前，必须在缓冲区中保留已发送的数据。如果按期收到确认应答，此时数据就可以从缓存区清除。</span><br><span class="line">- 窗口大小由哪一方决定？TCP 头里有一个字段叫 `Window`，也就是窗口大小。**这个字段是接收端告诉发送端自己还有多少缓冲区可以接收数据。于是发送端就可以根据这个接收端的处理能力来发送数据，而不会导致接收端处理不过来。**通常窗口的大小是由接收方的窗口大小来决定的。发送方发送的数据大小不能超过接收方的窗口大小，否则接收方就无法正常接收到数据。</span><br><span class="line">- TCP 滑动窗口方案使用三个指针来跟踪在四个传输类别中的每一个类别中的字节。其中两个指针是绝对指针（指特定的序列号），一个是相对指针（需要做偏移）</span><br><span class="line">- 接收窗口和发送窗口的大小是相等的吗？并不是完全相等，接收窗口的大小是**约等于**发送窗口的大小的。因为滑动窗口并不是一成不变的。比如，当接收方的应用进程读取数据的速度非常快的话，这样的话接收窗口可以很快的就空缺出来。那么新的接收窗口大小，是通过 TCP 报文中的 Windows 字段来告诉发送方。那么这个传输过程是存在时延的，所以接收窗口和发送窗口是约等于的关系</span><br><span class="line"></span><br><span class="line">#### 流量控制</span><br><span class="line"></span><br><span class="line">- 如果一直无脑的发数据给对方，但对方处理不过来，那么就会导致触发重发机制，从而导致网络流量的无端的浪费。为了解决这种现象发生，**TCP 提供一种机制可以让「发送方」根据「接收方」的实际接收能力控制发送的数据量，这就是所谓的流量控制。**</span><br><span class="line">- **TCP 规定是不允许同时减少缓存又收缩窗口的，而是采用先收缩窗口，过段时间再减少缓存，这样就可以避免了丢包情况**</span><br><span class="line">- **如果窗口大小为 0 时，就会阻止发送方给接收方传递数据，直到窗口变为非 0 为止，这就是窗口关闭。**接收方向发送方通告窗口大小时，是通过 `ACK` 报文来通告的。那么，当发生窗口关闭时，接收方处理完数据后，会向发送方通告一个窗口非 0 的 ACK 报文，如果这个通告窗口的 ACK 报文在网络中丢失了，这会导致发送方一直等待接收方的非 0 窗口通知，接收方也一直等待发送方的数据，如不采取措施，这种相互等待的过程，会造成了死锁的现象</span><br><span class="line">  - 为了解决这个问题，TCP 为每个连接设有一个持续定时器，**只要 TCP 连接一方收到对方的零窗口通知，就启动持续计时器。**如果持续计时器超时，就会发送**窗口探测 ( Window probe ) 报文**，而对方在确认这个探测报文时，给出自己现在的接收窗口大小。</span><br><span class="line">- 如果接收方太忙了，来不及取走接收窗口里的数据，那么就会导致发送方的发送窗口越来越小。到最后，**如果接收方腾出几个字节并告诉发送方现在有几个字节的窗口，而发送方会义无反顾地发送这几个字节，这就是糊涂窗口综合症**。</span><br><span class="line">  - 糊涂窗口综合症的现象是可以发生在发送方和接收方：接收方可以通告一个小的窗口；而发送方可以发送小数据。于是，要解决糊涂窗口综合症，就要同时解决上面两个问题就可以了</span><br><span class="line">  - 让接收方不通告小窗口给发送方：当「窗口大小」小于 min( MSS，缓存空间/2 ) ，也就是小于 MSS 与 1/2 缓存大小中的最小值时，就会向发送方通告窗口为 `0`，也就阻止了发送方再发数据过来。等到接收方处理了一些数据后，窗口大小 &gt;= MSS，或者接收方缓存空间有一半可以使用，就可以把窗口打开让发送方发送数据过来。</span><br><span class="line">  - 让发送方避免发送小数据：使用 Nagle 算法，该算法的思路是延时处理，只有满足下面两个条件中的任意一个条件，才可以发送数据：条件一：要等到窗口大小 &gt;= `MSS` 并且 数据大小 &gt;= `MSS`；条件二：收到之前发送数据的 `ack` 回包；只要上面两个条件都不满足，发送方一直在囤积数据，直到满足上面的发送条件</span><br><span class="line">  - **接收方得满足「不通告小窗口给发送方」+ 发送方开启 Nagle 算法，才能避免糊涂窗口综合症**</span><br><span class="line"></span><br><span class="line">#### 拥塞控制</span><br><span class="line"></span><br><span class="line">- 流量控制是避免「发送方」的数据填满「接收方」的缓存，但是并不知道网络的中发生了什么。一般来说，计算机网络都处在一个共享的环境。因此也有可能会因为其他主机之间的通信使得网络拥堵。**在网络出现拥堵时，如果继续发送大量数据包，可能会导致数据包时延、丢失等，这时 TCP 就会重传数据，但是一重传就会导致网络的负担更重，于是会导致更大的延迟以及更多的丢包，这个情况就会进入恶性循环被不断地放大**</span><br><span class="line">- **拥塞控制**，控制的目的就是**避免「发送方」的数据填满整个网络**；为了在「发送方」调节所要发送数据的量，定义了一个叫做「**拥塞窗口**」的概念；**拥塞窗口 cwnd**是发送方维护的一个的状态变量，它会根据**网络的拥塞程度动态变化的**。</span><br><span class="line">  - 发送窗口 `swnd` 和接收窗口 `rwnd` 是约等于的关系，那么由于加入了拥塞窗口的概念后，此时发送窗口的值是swnd = min(cwnd, rwnd)，也就是拥塞窗口和接收窗口中的最小值；拥塞窗口 `cwnd` 变化的规则：</span><br><span class="line">    - 只要网络中没有出现拥塞，`cwnd` 就会增大；</span><br><span class="line">    - 但网络中出现了拥塞，`cwnd` 就减少；</span><br><span class="line">- 只要「发送方」没有在规定时间内接收到 ACK 应答报文，也就是**发生了超时重传，就会认为网络出现了拥塞。**</span><br><span class="line">- 拥塞控制主要是四个算法：</span><br><span class="line">  - 慢启动，**当发送方每收到一个 ACK，拥塞窗口 cwnd 的大小就会加 1。**发包的个数是**指数性的增长**</span><br><span class="line">  - 拥塞避免，当拥塞窗口 `cwnd` 「超过」慢启动门限 `ssthresh` 就会进入拥塞避免算法，**每当收到一个 ACK 时，cwnd 增加 1/cwnd，**变成了**线性增长。**</span><br><span class="line">  - 拥塞发生</span><br><span class="line">    - 当发生了「超时重传」，则就会使用拥塞发生算法。这个时候，ssthresh 和 cwnd 的值会发生变化：`ssthresh` 设为 `cwnd/2`，`cwnd` 重置为 `1` （是恢复为 cwnd 初始化值，我这里假定 cwnd 初始化值 1）</span><br><span class="line">    - 当接收方发现丢了一个中间包的时候，发送三次前一个包的 ACK，于是发送端就会快速地重传，不必等待超时再重传。TCP 认为这种情况不严重，因为大部分没丢，只丢了一小部分，则 `ssthresh` 和 `cwnd` 变化如下：`cwnd = cwnd/2` ，也就是设置为原来的一半;`ssthresh = cwnd`;进入快速恢复算法</span><br><span class="line">  - 快速恢复：</span><br><span class="line">    - 拥塞窗口 `cwnd = ssthresh + 3` （ 3 的意思是确认有 3 个数据包被收到了）；</span><br><span class="line">    - 重传丢失的数据包；</span><br><span class="line">    - 如果再收到重复的 ACK，那么 cwnd 增加 1；</span><br><span class="line">    - 如果收到新数据的 ACK 后，把 cwnd 设置为第一步中的 ssthresh 的值，原因是该 ACK 确认了新的数据，说明从 duplicated ACK 时的数据都已收到，该恢复过程已经结束，可以回到恢复之前的状态了，也即再次进入拥塞避免状态；</span><br><span class="line">  - 快速恢复</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">### 4.3 TCP 实战抓包分析</span><br><span class="line"></span><br><span class="line">- tcpdump 和 Wireshark 有什么区别？</span><br><span class="line">  - tcpdump 和 Wireshark 就是最常用的网络抓包和分析工具，更是分析网络性能必不可少的利器。</span><br><span class="line">  - tcpdump 仅支持命令行格式使用，常用在 Linux 服务器中抓取和分析网络包。tcpdump 虽然功能强大，但是输出的格式并不直观。在工作中 tcpdump 只是用来抓取数据包，不用来分析数据包，而是把 tcpdump 抓取的数据包保存成 pcap 后缀的文件，接着用 Wireshark 工具进行数据包分析</span><br><span class="line">  - Wireshark 除了可以抓包外，还提供了可视化分析网络包的图形页面。同时，还内置了一系列的汇总分析工具。</span><br><span class="line"></span><br><span class="line">- 为什么抓到的 TCP 挥手是三次，而不是书上说的四次？</span><br><span class="line"></span><br><span class="line">  - 当被动关闭方在 TCP 挥手过程中，「**没有数据要发送」并且「开启了 TCP 延迟确认机制」，那么第二和第三次挥手就会合并传输，这样就出现了三次挥手。**</span><br><span class="line">  - 而通常情况下，服务器端收到客户端的 `FIN` 后，很可能还没发送完数据，所以就会先回复客户端一个 `ACK` 包，稍等一会儿，完成所有数据包的发送后，才会发送 `FIN` 包，这也就是四次挥手了。</span><br><span class="line"></span><br><span class="line">- 模拟客户端收不到服务端第二次握手 SYN、ACK 包：在客户端加上防火墙限制（iptables），直接粗暴的把来自服务端的数据都丢弃；客户端设置了防火墙，屏蔽了服务端的网络包，为什么 tcpdump 还能抓到服务端的网络包？</span><br><span class="line"></span><br><span class="line">  - 添加 iptables 限制后， tcpdump 是否能抓到包 ，这要看添加的 iptables 限制条件：</span><br><span class="line">    - 如果添加的是 `INPUT` 规则，则可以抓得到包</span><br><span class="line">    - 如果添加的是 `OUTPUT` 规则，则抓不到包</span><br><span class="line">  - 网络包进入主机后的顺序如下：</span><br><span class="line">    - 进来的顺序 Wire -&gt; NIC -&gt; **tcpdump -&gt; netfilter/iptables**</span><br><span class="line">    - 出去的顺序 **iptables -&gt; tcpdump** -&gt; NIC -&gt; Wire</span><br><span class="line"></span><br><span class="line">- tcp_syn_retries 是限制 SYN 重传次数，那第二次握手 SYN、ACK 限制最大重传次数是多少？</span><br><span class="line"></span><br><span class="line">  - 当 TCP 第二次握手 SYN、ACK 包丢了后，客户端 SYN 包会发生超时重传，服务端 SYN、ACK 也会发生超时重传。</span><br><span class="line">  - 客户端 SYN 包超时重传的最大次数，是由 tcp_syn_retries 决定的，默认值是 5 次；服务端 SYN、ACK 包时重传的最大次数，是由 tcp_synack_retries 决定的，默认值是 5 次</span><br><span class="line"></span><br><span class="line">- 模拟 TCP 第三次握手 ACK 包丢，我的实验方法是在服务端配置防火墙，屏蔽客户端 TCP 报文中标志位是 ACK 的包，也就是当服务端收到客户端的 TCP ACK 的报文时就会丢弃</span><br><span class="line"></span><br><span class="line">  - 为什么服务端原本处于 `SYN_RECV` 状态的连接，过 1 分钟后就消失了？</span><br><span class="line">    - 服务端超时重传了 SYN、ACK 包，重传了 5 次后，也就是**超过 tcp_synack_retries 的值（默认值是 5），然后就没有继续重传了，此时服务端的 TCP 连接主动中止了，所以刚才处于 SYN_RECV 状态的 TCP 连接断开了**，而客户端依然处于`ESTABLISHED` 状态</span><br><span class="line">  - 为什么客户端 telnet 输入 123456 字符后，过了好长一段时间，telnet 才断开连接？</span><br><span class="line">    - 由于服务端已经断开连接，**客户端发送的数据报文，一直在超时重传，每一次重传，RTO 的值是指数增长的，所以持续了好长一段时间，客户端的 telnet 才报错退出了，此时共重传了 15 次。**</span><br><span class="line">  - TCP 建立连接后的数据包最大超时重传次数是由什么参数指定呢？</span><br><span class="line">    - TCP 建立连接后的数据包传输，最大超时重传次数是由 `tcp_retries2` 指定，默认值是 15 次</span><br><span class="line">  - 那如果客户端不发送数据，什么时候才会断开处于 ESTABLISHED 状态的连接？</span><br><span class="line">    -  TCP 的 **保活机制**：定义一个时间段，在这个时间段内，如果没有任何连接相关的活动，TCP 保活机制会开始作用，每隔一个时间间隔，发送一个「探测报文」，该探测报文包含的数据非常少，如果连续几个探测报文都没有得到响应，则认为当前的 TCP 连接已经死亡，系统内核将错误信息通知给上层应用程序。</span><br><span class="line"></span><br><span class="line">-  TCP Fast Open 功能减少 TCP 连接建立的时延</span><br><span class="line"></span><br><span class="line">  - 在第一次建立连接的时候，服务端在第二次握手产生一个 `Cookie` （已加密）并通过 SYN、ACK 包一起发给客户端，于是客户端就会缓存这个 `Cookie`，所以第一次发起 HTTP Get 请求的时候，还是需要 2 个 RTT 的时延；</span><br><span class="line">  - 在下次请求的时候，客户端在 SYN 包带上 `Cookie` 发给服务端，就提前可以跳过三次握手的过程，因为 `Cookie` 中维护了一些信息，服务端可以从 `Cookie` 获取 TCP 相关的信息，这时发起的 HTTP GET 请求就只需要 1 个 RTT 的时延；</span><br><span class="line"></span><br><span class="line">- 在 Wireshark 看到的 Windows size 也就是 &quot; win = &quot;，这个值表示发送窗口吗？</span><br><span class="line"></span><br><span class="line">  - 抓包文件里有「Window size scaling factor」，它其实是算出实际窗口大小的乘法因子，「Window size value」实际上并不是真实的窗口大小，真实窗口大小的计算公式如下：</span><br><span class="line">  - 「Window size value」 * 「Window size scaling factor」 = 「Caculated window size 」</span><br><span class="line"></span><br><span class="line">- 如何在包里看出发送窗口的大小？</span><br><span class="line"></span><br><span class="line">  - 没有简单的办法，发送窗口虽然是由接收窗口决定，但是它又可以被网络因素影响，也就是拥塞窗口，实际上发送窗口是值是 min(拥塞窗口，接收窗口)。</span><br><span class="line"></span><br><span class="line">- 发送窗口和 MSS 有什么关系？</span><br><span class="line"></span><br><span class="line">  - 发送窗口决定了一口气能发多少字节，而 MSS 决定了这些字节要分多少包才能发完。</span><br><span class="line">  - 举个例子，如果发送窗口为 16000 字节的情况下，如果 MSS 是 1000 字节，那就需要发送 1600/1000 = 16 个包。</span><br><span class="line"></span><br><span class="line">- 发送方在一个窗口发出 n 个包，是不是需要 n 个 ACK 确认报文？</span><br><span class="line"></span><br><span class="line">  - 不一定，因为 TCP 有累计确认机制，所以当收到多个数据包时，只需要应答最后一个数据包的 ACK 报文就可以了。</span><br><span class="line"></span><br><span class="line">- Nagle 算法是如何避免大量 TCP 小数据报文的传输？</span><br><span class="line"></span><br><span class="line">  - Nagle 算法做了一些策略来避免过多的小数据报文发送，这可提高传输效率</span><br><span class="line"></span><br><span class="line">  - 使用 Nagle 算法，该算法的思路是延时处理，只有满足下面两个条件中的任意一个条件，才能可以发送数据：</span><br><span class="line"></span><br><span class="line">    - 条件一：要等到窗口大小 &gt;= `MSS` 并且 数据大小 &gt;= `MSS`；</span><br><span class="line">    - 条件二：收到之前发送数据的 `ack` 回包；</span><br><span class="line"></span><br><span class="line">    只要上面两个条件都不满足，发送方一直在囤积数据，直到满足上面的发送条件。</span><br><span class="line"></span><br><span class="line">  - **Nagle 算法一定会有一个小报文，也就是在最开始的时候。**</span><br><span class="line"></span><br><span class="line">  - 可以在 Socket 设置 `TCP_NODELAY` 选项来关闭这个算法（关闭 Nagle 算法没有全局参数，需要根据每个应用自己的特点来关闭）</span><br><span class="line"></span><br><span class="line">- TCP 延迟确认的策略：</span><br><span class="line"></span><br><span class="line">  - 当有响应数据要发送时，ACK 会随着响应数据一起立刻发送给对方</span><br><span class="line">  - 当没有响应数据要发送时，ACK 将会延迟一段时间，以等待是否有响应数据可以一起发送</span><br><span class="line">  - 如果在延迟等待发送 ACK 期间，对方的第二个数据报文又到达了，这时就会立刻发送 ACK</span><br><span class="line"></span><br><span class="line">- 延迟确认 和 Nagle 算法混合使用时，会产生新的问题</span><br><span class="line"></span><br><span class="line">  - 当 TCP 延迟确认 和 Nagle 算法混合使用时，会导致时耗增长</span><br><span class="line"></span><br><span class="line">  - 发送方使用了 Nagle 算法，接收方使用了 TCP 延迟确认会发生如下的过程：</span><br><span class="line"></span><br><span class="line">    - 发送方先发出一个小报文，接收方收到后，由于延迟确认机制，自己又没有要发送的数据，只能干等着发送方的下一个报文到达；</span><br><span class="line">    - 而发送方由于 Nagle 算法机制，在未收到第一个报文的确认前，是不会发送后续的数据；</span><br><span class="line">    - 所以接收方只能等待最大时间 200 ms 后，才回 ACK 报文，发送方收到第一个报文的确认报文后，也才可以发送后续的数据。</span><br><span class="line"></span><br><span class="line">    很明显，这两个同时使用会造成额外的时延，这就会使得网络&quot;很慢&quot;的感觉。</span><br><span class="line"></span><br><span class="line">### 4.4 TCP 半连接队列和全连接队列</span><br><span class="line"></span><br><span class="line">- 在 TCP 三次握手的时候，Linux 内核会维护两个队列，分别是：</span><br><span class="line">  - 半连接队列，也称 SYN 队列；</span><br><span class="line">  - 全连接队列，也称 accept 队列；</span><br><span class="line">- 服务端收到客户端发起的 SYN 请求后，**内核会把该连接存储到半连接队列**，并向客户端响应 SYN+ACK，接着客户端会返回 ACK，服务端收到第三次握手的 ACK 后，**内核会把连接从半连接队列移除，然后创建新的完全的连接，并将其添加到 accept 队列，等待进程调用 accept 函数时把连接取出来。**不管是半连接队列还是全连接队列，都有最大长度限制，超过限制时，内核会直接丢弃，或返回 RST 包。</span><br><span class="line">- 如何知道应用程序的 TCP 全连接队列大小？</span><br><span class="line">  - 在服务端可以使用 `ss` 命令，来查看 TCP 全连接队列的情况;`ss` 命令获取的 `Recv-Q/Send-Q` 在「LISTEN 状态」和「非 LISTEN 状态」所表达的含义是不同的</span><br><span class="line">  - 在「LISTEN 状态」时，`Recv-Q/Send-Q` 表示的含义如下：</span><br><span class="line">    - Recv-Q：当前全连接队列的大小，也就是当前已完成三次握手并等待服务端 `accept()` 的 TCP 连接；</span><br><span class="line">    - Send-Q：当前全连接最大队列长度，上面的输出结果说明监听 8088 端口的 TCP 服务，最大全连接长度为 128；</span><br><span class="line">  - 在「非 LISTEN 状态」时，`Recv-Q/Send-Q` 表示的含义如下：</span><br><span class="line">    - Recv-Q：已收到但未被应用进程读取的字节数；</span><br><span class="line">    - Send-Q：已发送但未收到确认的字节数；</span><br><span class="line">- 如何模拟 TCP 全连接队列溢出的场景？</span><br><span class="line">  - 使用 `wrk` 工具来压力测试服务端，发起大量的请求；其是一款简单的 HTTP 压测工具，它能够在单机多核 CPU 的条件下，使用系统自带的高性能 I/O 机制，通过多线程和事件模式，对目标机器产生大量的负载</span><br><span class="line">- **当服务端并发处理大量请求时，如果 TCP 全连接队列过小，就容易溢出。发生 TCP 全连接队溢出的时候，后续的请求就会被丢弃，这样就会出现服务端请求数量上不去的现象。**丢掉的 TCP 连接的个数会被统计起来，可以使用 netstat -s 命令来查看</span><br><span class="line">  - 丢弃连接只是 Linux 的默认行为，我们还可以选择向客户端发送 RST 复位报文，告诉客户端连接已经建立失败，tcp_abort_on_overflow 共有两个值分别是 0 和 1，其分别表示：</span><br><span class="line">    - 0 ：如果全连接队列满了，那么 server 扔掉 client 发过来的 ack ；</span><br><span class="line">    - 1 ：如果全连接队列满了，server 发送一个 `reset` 包给 client，表示废掉这个握手过程和这个连接；</span><br><span class="line">  - 通常情况下，应当把 tcp_abort_on_overflow 设置为 0，因为这样更有利于应对突发流量。当 TCP 全连接队列满导致服务器丢掉了 ACK，与此同时，客户端的连接状态却是 ESTABLISHED，进程就在建立好的连接上发送请求。只要服务器没有为请求回复 ACK，请求就会被多次**重发**。如果服务器上的进程只是**短暂的繁忙造成 accept 队列满，那么当 TCP 全连接队列有空位时，再次接收到的请求报文由于含有 ACK，仍然会触发服务器端成功建立连接。**</span><br><span class="line">- 如何增大 TCP 全连接队列呢？</span><br><span class="line">  - **TCP 全连接队列的最大值取决于 somaxconn 和 backlog 之间的最小值，也就是 min(somaxconn, backlog)**</span><br><span class="line">  - `somaxconn` 是 Linux 内核的参数，默认值是 128，可以通过 `/proc/sys/net/core/somaxconn` 来设置其值；</span><br><span class="line">  - `backlog` 是 `listen(int sockfd, int backlog)` 函数中的 backlog 大小，Nginx 默认值是 511，可以通过修改配置文件设置其长度；</span><br><span class="line">- 如何查看 TCP 半连接队列长度？</span><br><span class="line">  - 可以抓住 TCP 半连接的特点，就是服务端处于 `SYN_RECV` 状态的 TCP 连接，就是 TCP 半连接队列。netstat -natp | grep STN_RECV |wc -l</span><br><span class="line">  - 通过 netstat -s 观察半连接队列溢出的情况；上面输出的数值是**累计值**，表示共有多少个 TCP 连接因为半连接队列溢出而被丢弃。**隔几秒执行几次，如果有上升的趋势，说明当前存在半连接队列溢出的现象**</span><br><span class="line">- 如何模拟 TCP 半连接队列溢出场景？</span><br><span class="line">  - 实际上就是对服务端一直发送 TCP SYN 包，但是不回第三次握手 ACK，这样就会使得服务端有大量的处于 `SYN_RECV` 状态的 TCP 连接。这其实也就是所谓的 SYN 洪泛、SYN 攻击、DDos 攻击。</span><br><span class="line">  - 使用 `hping3` 工具模拟 SYN 攻击,当服务端受到 SYN 攻击后，连接服务端 ssh 就会断开了，无法再连上。只能在服务端主机上执行查看当前 TCP 半连接队列大小</span><br><span class="line">-  TCP 半连接队列的最大值是如何决定的</span><br><span class="line">  - **如果半连接队列满了，并且没有开启 tcp_syncookies，则会丢弃；**</span><br><span class="line">  - **若全连接队列满了，且没有重传 SYN+ACK 包的连接请求多于 1 个，则会丢弃；**</span><br><span class="line">  - **如果没有开启 tcp_syncookies，并且 max_syn_backlog 减去 当前半连接队列长度小于 (max_syn_backlog &gt;&gt; 2)，则会丢弃；**</span><br><span class="line">  - **全**连接队列的最大值是 `sk_max_ack_backlog` 变量，sk_max_ack_backlog 实际上是在 listen() 源码里指定的，也就是 **min(somaxconn, backlog)**；</span><br><span class="line">  - **半**连接队列的最大值是 `max_qlen_log` 变量</span><br><span class="line">    - 当 max_syn_backlog &gt; min(somaxconn, backlog) 时， 半连接队列最大值 max_qlen_log = min(somaxconn, backlog) * 2;</span><br><span class="line">    - 当 max_syn_backlog &lt; min(somaxconn, backlog) 时， 半连接队列最大值 max_qlen_log = max_syn_backlog * 2;</span><br><span class="line">  - 服务端处于 SYN_RECV 状态的最大个数分为如下两种情况：</span><br><span class="line">    - 如果「当前半连接队列」**没超过**「理论半连接队列最大值」，但是**超过** max_syn_backlog - (max_syn_backlog &gt;&gt; 2)，那么处于 SYN_RECV 状态的最大个数就是 max_syn_backlog - (max_syn_backlog &gt;&gt; 2)；</span><br><span class="line">    - 如果「当前半连接队列」**超过**「理论半连接队列最大值」，那么处于 SYN_RECV 状态的最大个数就是「理论半连接队列最大值」；</span><br><span class="line"></span><br><span class="line">### 4.5 如何优化 TCP?</span><br><span class="line"></span><br><span class="line">#### TCP 三次握手的性能提升</span><br><span class="line"></span><br><span class="line">- 三次握手的过程在一个 HTTP 请求的平均时间占比 10% 以上，在网络状态不佳、高并发或者遭遇 SYN 攻击等场景中，如果不能有效正确的调节三次握手中的参数，就会对性能产生很多的影响；当出现问题时，先用 `netstat` 命令查看是哪个握手阶段出现了问题，再来对症下药</span><br><span class="line"></span><br><span class="line">- 客户端优化：客户端作为主动发起连接方，首先它将发送 SYN 包，于是客户端的连接就会处于 `SYN_SENT` 状态。客户端在等待服务端回复的 ACK 报文，正常情况下，服务器会在几毫秒内返回 SYN+ACK ，但如果客户端长时间没有收到 SYN+ACK 报文，则会重发 SYN 包，**重发的次数由 tcp_syn_retries 参数控制；可以根据网络的稳定性和目标服务器的繁忙程度修改 SYN 的重传次数，调整客户端的三次握手时间上限**</span><br><span class="line"></span><br><span class="line">- 服务端优化：</span><br><span class="line"></span><br><span class="line">  - 当服务端收到 SYN 包后，服务端会立马回复 SYN+ACK 包，表明确认收到了客户端的序列号，同时也把自己的序列号发给对方。此时，服务端出现了新连接，状态是 `SYN_RCV`。在这个状态下，Linux 内核就会建立一个「半连接队列」来维护「未完成」的握手信息，当半连接队列溢出后，服务端就无法再建立新的连接。可以通过该 `netstat -s` 命令给出的统计结果中， 可以得到由于半连接队列已满，引发的失败次数</span><br><span class="line">    - 要想增大半连接队列，**不能只单纯增大 tcp_max_syn_backlog 的值，还需一同增大 somaxconn 和 backlog，也就是增大 accept 队列**</span><br><span class="line">    - **开启 syncookies 功能就可以在不使用 SYN 半连接队列的情况下成功建立连接**</span><br><span class="line">  - 当客户端接收到服务器发来的 SYN+ACK 报文后，就会回复 ACK 给服务器，同时客户端连接状态从 SYN_SENT 转换为 ESTABLISHED，表示连接建立成功；当网络繁忙、不稳定时，报文丢失就会变严重，此时应该调大重发次数。反之则可以调小重发次数。**修改重发次数的方法是，调整 tcp_synack_retries 参数**</span><br><span class="line">  - 服务器收到 ACK 后连接建立成功，此时，内核会把连接从半连接队列移除，然后创建新的完全的连接，并将其添加到 accept 队列，等待进程调用 accept 函数时把连接取出来。如果进程不能及时地调用 accept 函数，就会造成 accept 队列（也称全连接队列）溢出，最终导致建立好的 TCP 连接被丢弃。</span><br><span class="line">    - 丢弃连接只是 Linux 的默认行为，我们还可以选择向客户端发送 RST 复位报文，告诉客户端连接已经建立失败。打开这一功能需要将 tcp_abort_on_overflow 参数设置为 1</span><br><span class="line">    - 通常情况下，应当把 tcp_abort_on_overflow 设置为 0，因为这样更有利于应对突发流量。只要服务器没有为请求回复 ACK，客户端的请求就会被多次「重发」。**如果服务器上的进程只是短暂的繁忙造成 accept 队列满，那么当 accept 队列有空位时，再次接收到的请求报文由于含有 ACK，仍然会触发服务器端成功建立连接**</span><br><span class="line">    - accept 队列的长度取决于 somaxconn 和 backlog 之间的最小值，也就是 min(somaxconn, backlog);可以通过 `ss -ltn` 命令查看 accept 队列的长度；使用 netstat -s 命令来查看丢掉的 TCP 连接的个数</span><br><span class="line"></span><br><span class="line">- 如何绕过三次握手？</span><br><span class="line"></span><br><span class="line">  - TCP Fast Open 功能的工作方式：</span><br><span class="line"></span><br><span class="line">    首次建立连接时的过程：</span><br><span class="line"></span><br><span class="line">    1. 客户端发送 SYN 报文，该报文包含 Fast Open 选项，且该选项的 Cookie 为空，这表明客户端请求 Fast Open Cookie；</span><br><span class="line">    2. 支持 TCP Fast Open 的服务器生成 Cookie，并将其置于 SYN-ACK 数据包中的 Fast Open 选项以发回客户端；</span><br><span class="line">    3. 客户端收到 SYN-ACK 后，本地缓存 Fast Open 选项中的 Cookie。</span><br><span class="line"></span><br><span class="line">    再次向服务器建立连接时的过程：</span><br><span class="line"></span><br><span class="line">    1. 客户端发送 SYN 报文，该报文包含「数据」（对于非 TFO 的普通 TCP 握手过程，SYN 报文中不包含「数据」）以及此前记录的 Cookie；</span><br><span class="line">    2. 支持 TCP Fast Open 的服务器会对收到 Cookie 进行校验：如果 Cookie 有效，服务器将在 SYN-ACK 报文中对 SYN 和「数据」进行确认，服务器随后将「数据」递送至相应的应用程序；如果 Cookie 无效，服务器将丢弃 SYN 报文中包含的「数据」，且其随后发出的 SYN-ACK 报文将只确认 SYN 的对应序列号；</span><br><span class="line">    3. 如果服务器接受了 SYN 报文中的「数据」，服务器可在握手完成之前发送「数据」，**这就减少了握手带来的 1 个 RTT 的时间消耗**；</span><br><span class="line">    4. 客户端将发送 ACK 确认服务器发回的 SYN 以及「数据」，但如果客户端在初始的 SYN 报文中发送的「数据」没有被确认，则客户端将重新发送「数据」；</span><br><span class="line">    5. 此后的 TCP 连接的数据传输过程和非 TFO 的正常情况一致</span><br><span class="line"></span><br><span class="line">  - TFO 功能，cookie 的值是存放到 TCP option 字段里的；可以通过**设置 tcp_fastopn 内核参数，来打开 Fast Open 功能，**TCP Fast Open 功能需要客户端和服务端同时支持，才有效果</span><br><span class="line"></span><br><span class="line">#### TCP 四次挥手的性能提升</span><br><span class="line"></span><br><span class="line">- 主动方的优化：</span><br><span class="line">  - 关闭连接的方式通常有两种，分别是 RST 报文关闭和 FIN 报文关闭。如果进程收到 RST 报文，就直接关闭连接了，不需要走四次挥手流程，是一个暴力关闭连接的方式。安全关闭连接的方式必须通过四次挥手，它由进程调用 `close` 和 `shutdown` 函数发起 FIN 报文（shutdown 参数须传入 SHUT_WR 或者 SHUT_RDWR 才会发送 FIN）</span><br><span class="line">  - 调用了 close 函数意味着完全断开连接，**完全断开不仅指无法传输数据，而且也不能发送数据。 此时，调用了 close 函数的一方的连接叫做「孤儿连接」，如果你用 netstat -p 命令，会发现连接对应的进程名为空。**使用 close 函数关闭连接是不优雅的。于是，就出现了一种优雅关闭连接的 `shutdown` 函数，**它可以控制只关闭一个方向的连接**</span><br><span class="line">  - FIN_WAIT1 状态的优化：当迟迟收不到对方返回的 ACK 时，连接就会一直处于 FIN_WAIT1 状态。此时，**内核会定时重发 FIN 报文，其中重发次数由 tcp_orphan_retries 参数控制**，如果 FIN_WAIT1 状态连接很多，就需要考虑降低 tcp_orphan_retries 的值，当重传次数超过 tcp_orphan_retries 时，连接就会直接关闭掉</span><br><span class="line">    - 如果遇到恶意攻击，FIN 报文根本无法发送出去，**调整 tcp_max_orphans 参数，它定义了「孤儿连接」的最大数量**</span><br><span class="line">  - FIN_WAIT2 状态的优化：**如果连接是用 shutdown 函数关闭的，连接可以一直处于 FIN_WAIT2 状态，因为它可能还可以发送或接收数据。但对于 close 函数关闭的孤儿连接，由于无法再发送和接收数据，所以这个状态不可以持续太久，而 tcp_fin_timeout 控制了这个状态下连接的持续时长**，默认值是60秒</span><br><span class="line">  - TIME_WAIT 状态的优化：</span><br><span class="line">    - TIME_WAIT 状态的连接，在主动方看来确实快已经关闭了。然后，被动方没有收到 ACK 报文前，还是处于 LAST_ACK 状态。如果这个 ACK 报文没有到达被动方，被动方就会重发 FIN 报文。重发次数仍然由前面介绍过的 tcp_orphan_retries 参数控制</span><br><span class="line">    - TIME-WAIT 的状态尤其重要，主要是两个原因：防止历史连接中的数据，被后面相同四元组的连接错误的接收；保证「被动关闭连接」的一方，能被正确的关闭</span><br><span class="line">    - 客户端在收到服务端重传的 FIN 报文时，TIME_WAIT 状态的等待时间，会重置回 2MSL。MSL 全称是 Maximum Segment Lifetime，它定义了一个报文在网络中的最长生存时间，相当于**至少允许报文丢失一次**</span><br><span class="line">    - **Linux 提供了 tcp_max_tw_buckets 参数，当 TIME_WAIT 的连接数量超过该参数时，新关闭的连接就不再经历 TIME_WAIT 而直接关闭**</span><br><span class="line">    - **可以在建立新连接时，复用处于 TIME_WAIT 状态的连接，那就是打开 tcp_tw_reuse 参数。但是需要注意，该参数是只用于客户端（建立连接的发起方），因为是在调用 connect() 时起作用的，而对于服务端（被动连接方）是没有用的**，使用这个选项，还有一个前提，需要打开对 TCP 时间戳的支持</span><br><span class="line">    - 可以在程序中设置 socket 选项，来设置调用 close 关闭连接行为。如果 `l_onoff` 为非 0， 且 `l_linger` 值为 0，**那么调用 close 后，会立该发送一个 RST 标志给对端，该 TCP 连接将跳过四次挥手，也就跳过了 TIME_WAIT 状态，直接关闭。**</span><br><span class="line">-  被动方的优化：</span><br><span class="line">  - 当被动方收到 FIN 报文时，内核会自动回复 ACK，同时连接处于 CLOSE_WAIT 状态，顾名思义，它表示等待应用进程调用 close 函数关闭连接。内核没有权利替代进程去关闭连接，因为如果主动方是通过 shutdown 关闭连接，那么它就是想在半关闭连接上接收数据或发送数据。因此，Linux 并没有限制 CLOSE_WAIT 状态的持续时间</span><br><span class="line">  - **当你用 netstat 命令发现大量 CLOSE_WAIT 状态。就需要排查你的应用程序，因为可能因为应用程序出现了 Bug，read 函数返回 0 时，没有调用 close 函数。**</span><br><span class="line">  - 如果迟迟收不到这个 ACK，内核就会重发 FIN 报文，重发次数仍然由 tcp_orphan_retries 参数控制，这与主动方重发 FIN 报文的优化策略一致</span><br><span class="line">  - 如果被动方迅速调用 close 函数，那么被动方的 ACK 和 FIN 有可能在一个报文中发送，这样看起来，四次挥手会变成三次挥手</span><br><span class="line">  - 如果连接双方同时关闭连接，两方发送 FIN 报文时，都认为自己是主动方，所以都进入了 FIN_WAIT1 状态，FIN 报文的重发次数仍由 tcp_orphan_retries 参数控制。接下来，**双方在等待 ACK 报文的过程中，都等来了 FIN 报文。这是一种新情况，所以连接会进入一种叫做 CLOSING 的新状态，它替代了 FIN_WAIT2 状态**。</span><br><span class="line"></span><br><span class="line">#### TCP 传输数据的性能提升</span><br><span class="line"></span><br><span class="line">- TCP 连接是由内核维护的，内核会为每个连接建立内存缓冲区：</span><br><span class="line">  - 如果连接的内存配置过小，就无法充分使用网络带宽，TCP 传输效率就会降低；</span><br><span class="line">  - 如果连接的内存配置过大，很容易把服务器资源耗尽，这样就会导致新连接无法建立；</span><br><span class="line"></span><br><span class="line">- 当接收方硬件不如发送方，或者系统繁忙、资源紧张时，是无法瞬间处理这么多报文的。于是，这些报文只能被丢掉，使得网络效率非常低。**为了解决这种现象发生，TCP 提供一种机制可以让「发送方」根据「接收方」的实际接收能力控制发送的数据量，这就是滑动窗口的由来**</span><br><span class="line">  - 接收窗口并不是恒定不变的，接收方会把当前可接收的大小放在 TCP 报文头部中的**窗口字段**，这样就可以起到窗口大小通知的作用</span><br><span class="line">  - **在 TCP 选项字段定义了窗口扩大因子，用于扩大 TCP 通告窗口，其值大小是 2^14，这样就使 TCP 的窗口大小从 16 位扩大为 30 位**</span><br><span class="line">  - **网络的传输能力是有限的，当发送方依据发送窗口，发送超过网络处理能力的报文时，路由器会直接丢弃这些报文。因此，缓冲区的内存并不是越大越好**</span><br><span class="line">- 如何计算网络的传输能力呢？</span><br><span class="line">  - 带宽时延积决定网络中飞行报文的大小，也就是带宽和时延的乘积，如果飞行报文超过了带宽时延积，就会导致网络过载，容易丢包；**由于发送缓冲区大小决定了发送窗口的上限，而发送窗口又决定了「已发送未确认」的飞行报文的上限。因此，发送缓冲区不能超过「带宽时延积」**</span><br><span class="line">- 在 Linux 中发送缓冲区和接收缓冲都是可以用参数调节的。设置完后，Linux 会根据你设置的缓冲区进行**动态调节**。</span><br><span class="line">  - 内核缓冲区决定了滑动窗口的上限，缓冲区可分为：发送缓冲区 tcp_wmem 和接收缓冲区 tcp_rmem。</span><br><span class="line">  - Linux 会对缓冲区动态调节，我们应该把缓冲区的上限设置为带宽时延积。发送缓冲区的调节功能是自动打开的，而接收缓冲区需要把 tcp_moderate_rcvbuf 设置为 1 来开启。其中，调节的依据是 TCP 内存范围 tcp_mem。</span><br><span class="line">  - 但需要注意的是，如果程序中的 socket 设置 SO_SNDBUF 和 SO_RCVBUF，则会关闭缓冲区的动态整功能，所以不建议在程序设置它俩，而是交给内核自动调整比较好。</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">### 4.6 如何理解是 TCP 面向字节流协议？</span><br><span class="line"></span><br><span class="line">- 如何理解字节流？</span><br><span class="line">  - 之所以会说 TCP 是面向字节流的协议，UDP 是面向报文的协议，是因为操作系统对 TCP 和 UDP 协议的**发送方的机制不同**，也就是问题原因在发送方</span><br><span class="line">- 为什么 UDP 是面向报文的协议？</span><br><span class="line">  - 当用户消息通过 UDP 协议传输时，**操作系统不会对消息进行拆分**，在组装好 UDP 头部后就交给网络层来处理，所以发出去的 UDP 报文中的数据部分就是完整的用户消息，也就是**每个 UDP 报文就是一个用户消息的边界**，这样接收方在接收到 UDP 报文后，读一个 UDP 报文就能读取到完整的用户消息</span><br><span class="line">  - 操作系统在收到 UDP 报文后，会将其插入到队列里，**队列里的每一个元素就是一个 UDP 报文**，这样当用户调用 recvfrom() 系统调用读数据的时候，就会从队列里取出一个数据，然后从内核里拷贝给用户缓冲区</span><br><span class="line">- 为什么 TCP 是面向字节流的协议？</span><br><span class="line">  - 当用户消息通过 TCP 协议传输时，**消息可能会被操作系统分组成多个的 TCP 报文**，也就是一个完整的用户消息被拆分成多个 TCP 报文进行传输；这时，接收方的程序如果不知道发送方发送的消息的长度，也就是不知道消息的边界时，是无法读出一个有效的用户消息的</span><br><span class="line">  - 在发送端，当我们调用 send 函数完成数据“发送”以后，数据并没有被真正从网络上发送出去，只是从应用程序拷贝到了操作系统内核协议栈中。至于什么时候真正被发送，**取决于发送窗口、拥塞窗口以及当前发送缓冲区的大小等条件**</span><br><span class="line">  - **不能认为一个用户消息对应一个 TCP 报文，正因为这样，所以 TCP 是面向字节流的协议**。</span><br><span class="line"></span><br><span class="line">- 当两个消息的某个部分内容被分到同一个 TCP 报文时，就是我们常说的 TCP 粘包问题，这时接收方不知道消息的边界的话，是无法读出有效的消息</span><br><span class="line">- 如何解决粘包？</span><br><span class="line">  - 固定长度的消息：每个用户消息都是固定长度的，比如规定一个消息的长度是 64 个字节，当接收方接满 64 个字节，就认为这个内容是一个完整且有效的消息</span><br><span class="line">  - 特殊字符作为边界：**两个用户消息之间**插入一个特殊的字符串，这样接收方在接收数据时，读到了这个特殊字符，就把认为已经读完一个完整的消息；HTTP 是一个非常好的例子</span><br><span class="line">  - 自定义消息结构。由包头和数据组成，其中包头包是固定大小的，而且包头里有一个字段来说明紧随其后的数据有多大</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">### 4.7 为什么 TCP 每次建立连接时，初始化序列号都要不一样呢？</span><br><span class="line"></span><br><span class="line">- 主要原因是为了防止历史报文被下一个相同四元组的连接接收。</span><br><span class="line">- TCP 四次挥手中的 TIME_WAIT 状态不是会持续 2 MSL 时长，历史报文不是早就在网络中消失了吗？</span><br><span class="line">  </span><br><span class="line">- 如果能正常四次挥手，由于 TIME_WAIT 状态会持续 2 MSL 时长，历史报文会在下一个连接之前就会自然消失。但是并不能保证每次连接都能通过四次挥手来正常关闭连接。</span><br><span class="line">  </span><br><span class="line">- 客户端和服务端的初始化序列号不一样不是也会发生这样的事情吗？</span><br><span class="line"></span><br><span class="line">  - 即使客户端和服务端的初始化序列号不一样，也会存在收到历史报文的可能。但是历史报文能否被对方接收，还要看该历史报文的序列号是否正好在对方接收窗口内，如果不在就会丢弃，如果在才会接收。</span><br><span class="line">  - 如果每次建立连接客户端和服务端的初始化序列号都「不一样」，就有大概率因为历史报文的序列号「不在」对方接收窗口，从而**很大程度上**避免了历史报文</span><br><span class="line"></span><br><span class="line">- 那客户端和服务端的初始化序列号都是随机的，那还是有可能随机成一样的呀？</span><br><span class="line"></span><br><span class="line">  初始化序列号 ISN 随机生成算法：ISN = M + F(localhost, localport, remotehost, remoteport)。</span><br><span class="line"></span><br><span class="line">  - M是一个计时器，这个计时器每隔 4 微秒加1。</span><br><span class="line">  - F 是一个 Hash 算法，根据源IP、目的IP、源端口、目的端口生成一个随机数值，要保证 hash 算法不能被外部轻易推算得出。</span><br><span class="line"></span><br><span class="line">  可以看到，随机数是会基于时钟计时器递增的，基本不可能会随机成一样的初始化序列号。</span><br><span class="line"></span><br><span class="line">- 客户端和服务端初始化序列号都是随机生成的话，也不是完全避免连接接收历史报文</span><br><span class="line"></span><br><span class="line">  - **序列号**，是 TCP 一个头部字段，标识了 TCP 发送端到 TCP 接收端的数据流的一个字节，因为 TCP 是面向字节流的可靠协议，为了保证消息的顺序性和可靠性，TCP 为每个传输方向上的每个字节都赋予了一个编号，以便于传输成功后确认、丢失后重传以及在接收端保证不会乱序。**序列号是一个 32 位的无符号数，因此在到达 4G 之后再循环回到 0**；**初始化序列号可被视为一个 32 位的计数器，该计数器的数值每 4 微秒加 1，循环一次需要 4.55 小时**。</span><br><span class="line">  - **序列号和初始化序列号并不是无限递增的，会发生回绕为初始值的情况，这意味着无法根据序列号来判断新老数据**。在一个速度足够快的网络中传输大量数据时，序列号的回绕时间就会变短。如果序列号回绕的时间极短就会再次面临之前延迟的报文抵达后序列号依然有效的问题</span><br><span class="line">  - 为了解决这个问题，就需要有 TCP 时间戳。tcp_timestamps 参数是默认开启的，开启了 tcp_timestamps 参数，TCP 头部就会使用时间戳选项，它有两个好处，**一个是便于精确计算 RTT ，另一个是能防止序列号回绕（PAWS）**</span><br><span class="line">  - 防回绕序列号算法要求连接双方维护最近一次收到的数据包的时间戳（Recent TSval），每收到一个新数据包都会读取数据包中的时间戳值跟 Recent TSval 值做比较，**如果发现收到的数据包中时间戳不是递增的，则表示该数据包是过期的，就会直接丢弃这个数据包**</span><br><span class="line"></span><br><span class="line">- 如果时间戳也回绕了怎么办？</span><br><span class="line"></span><br><span class="line">  - 时间戳的大小是 32 bit，所以理论上也是有回绕的可能性的。时间戳回绕的速度只与对端主机时钟频率有关。Linux 以本地时钟计数（jiffies）作为时间戳的值，不同的增长时间会有不同的问题：</span><br><span class="line">    - 如果时钟计数加 1 需要1ms，则需要约 24.8 天才能回绕一半</span><br><span class="line">    - 如果时钟计数提高到 1us 加1，则回绕需要约71.58分钟才能回绕</span><br><span class="line">    - 如果时钟计数提高到 0.1 us 加 1 回绕需要 7 分钟多一点，这时就可能会有问题了</span><br><span class="line">  - Linux 在 PAWS 检查做了一个特殊处理，如果一个 TCP 连接连续 24 天不收发数据则在接收第一个包时基于时间戳的 PAWS 会失效，也就是可以 PAWS 函数会放过这个特殊的情况，认为是合法的，可以接收该数据包</span><br><span class="line">  - 要解决时间戳回绕的问题，可以考虑以下解决方案：</span><br><span class="line">    - 增加时间戳的大小，由32 bit扩大到64bit</span><br><span class="line">    - 将一个与时钟频率无关的值作为时间戳，时钟频率可以增加但时间戳的增速不变</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">### 4.8 SYN 报文什么时候情况下会被丢弃？</span><br><span class="line"></span><br><span class="line">- SYN 报文被丢弃的两种场景：</span><br><span class="line"></span><br><span class="line">  - 开启 tcp_tw_recycle 参数，并且在 NAT 环境下，造成 SYN 报文被丢弃</span><br><span class="line">  - TCP 两个队列满了（半连接队列和全连接队列），造成 SYN 报文被丢弃</span><br><span class="line"></span><br><span class="line">- Linux 操作系统提供了两个可以系统参数来快速回收处于 TIME_WAIT 状态的连接，这两个参数都是默认关闭的：</span><br><span class="line"></span><br><span class="line">  - net.ipv4.tcp_tw_reuse，如果开启该选项的话，客户端（连接发起方） 在调用 connect() 函数时，**如果内核选择到的端口，已经被相同四元组的连接占用的时候，就会判断该连接是否处于 TIME_WAIT 状态，如果该连接处于 TIME_WAIT 状态并且 TIME_WAIT 状态持续的时间超过了 1 秒，那么就会重用这个连接，然后就可以正常使用该端口了。**所以该选项只适用于连接发起方。</span><br><span class="line">  - net.ipv4.tcp_tw_recycle，如果开启该选项的话，允许处于 TIME_WAIT 状态的连接被快速回收；</span><br><span class="line"></span><br><span class="line">  要使得这两个选项生效，有一个前提条件，就是要打开 TCP 时间戳，即 net.ipv4.tcp_timestamps=1（默认即为 1)）。</span><br><span class="line"></span><br><span class="line">- tcp_timestamps 选项开启之后， PAWS 机制会自动开启，它的作用是防止 TCP 包中的序列号发生绕回。</span><br><span class="line">  - TCP 的 SEQ 号是有限的，一共 32 bit，SEQ 开始是递增，溢出之后从 0 开始再次依次递增。所以当 SEQ 号出现溢出后单纯通过 SEQ 号无法标识数据包的唯一性，某个数据包延迟或因重发而延迟时可能导致连接传递的数据被破坏</span><br><span class="line">  - PAWS 要求连接双方维护最近一次收到的数据包的时间戳（Recent TSval），每收到一个新数据包都会读取数据包中的时间戳值跟 Recent TSval 值做比较，**如果发现收到的数据包中时间戳不是递增的，则表示该数据包是过期的，就会直接丢弃这个数据包**。</span><br><span class="line">- **tcp_tw_recycle 在使用了 NAT 的网络下是不安全的，**对于服务器来说，如果同时开启了recycle 和 timestamps 选项，则会开启一种称之为「 per-host 的 PAWS 机制」</span><br><span class="line">  - **per-host 是对「对端 IP 做 PAWS 检查」**，而非对「IP + 端口」四元组做 PAWS 检查</span><br><span class="line">  - 如果客户端网络环境是用了 NAT 网关，那么客户端环境的每一台机器通过 NAT 网关后，都会是相同的 IP 地址，在服务端看来，就好像只是在跟一个客户端打交道一样，无法区分出来</span><br><span class="line">  - Per-host PAWS 机制利用TCP option里的 timestamp 字段的增长来判断串扰数据，而 timestamp 是根据客户端各自的 CPU tick 得出的值</span><br><span class="line">- 服务端收到客户端发起的 SYN 请求后，**内核会把该连接存储到半连接队列**，并向客户端响应 SYN+ACK，接着客户端会返回 ACK，服务端收到第三次握手的 ACK 后，**内核会把连接从半连接队列移除，然后创建新的完全的连接，并将其添加到 accept 队列，等待进程调用 accept 函数时把连接取出来**</span><br><span class="line">  - 当服务器造成syn攻击，就有可能导致 **TCP 半连接队列满了，这时后面来的 syn 包都会被丢弃**。但是，**如果开启了syncookies 功能，即使半连接队列满了，也不会丢弃syn 包**</span><br><span class="line">  - **在服务端并发处理大量请求时，如果 TCP accpet 队列过小，或者应用程序调用 accept() 不及时，就会造成 accpet 队列满了 ，这时后续的连接就会被丢弃，这样就会出现服务端请求数量上不去的现象。**</span><br><span class="line"></span><br><span class="line">### 4.9 已建立连接的TCP，收到SYN会发生什么？</span><br><span class="line"></span><br><span class="line">- 一个已经建立的 TCP 连接，客户端中途宕机了，而服务端此时也没有数据要发送，一直处于 establish 状态，客户端恢复后，向服务端建立连接，此时服务端会怎么处理？TCP 连接是由「四元组」唯一确认的。然后这个场景中，客户端的IP、服务端IP、目的端口并没有变化，所以这个问题关键要看客户端发送的 SYN 报文中的源端口是否和上一次连接的源端口相同。</span><br><span class="line">  - 如果客户端恢复后发送的 SYN 报文中的源端口号跟上一次连接的源端口号不一样，此时服务端会认为是新的连接要建立，于是就会通过三次握手来建立新的连接。</span><br><span class="line">    - 旧连接里处于 establish 状态的服务端，如果服务端发送了数据包给客户端，由于客户端的连接已经被关闭了，此时客户的内核就会回 RST 报文，服务端收到后就会释放连接。如果服务端一直没有发送数据包给客户端，在超过一段时间后， TCP 保活机制就会启动，检测到客户端没有存活后，接着服务端就会释放掉该连接。</span><br><span class="line">  - 如果客户端恢复后，发送的 SYN 报文中的源端口号跟上一次连接的源端口号一样，**处于 establish 状态的服务端如果收到了客户端的 SYN 报文（注意此时的 SYN 报文其实是乱序的，因为 SYN 报文的初始化序列号其实是一个随机数），会回复一个携带了正确序列号和确认号的 ACK 报文，这个 ACK 被称之为 Challenge ACK。** **接着，客户端收到这个 Challenge ACK，发现序列号并不是自己期望收到的，于是就会回 RST 报文，服务端收到后，就会释放掉该连接**</span><br><span class="line">    - 处于 establish 状态的服务端，在收到报文后，首先会判断序列号是否在窗口内，如果不在，则看看 RST 标记有没有被设置，如果有就会丢掉。然后如果没有 RST 标志，就会判断是否有 SYN 标记，如果有 SYN 标记就会跳转到 syn_challenge 标签，然后执行 tcp_send_challenge_ack 函数。然后就会调用 tcp_send_ack 函数来回复一个携带了正确序列号和确认号的 ACK 报文</span><br><span class="line"></span><br><span class="line">- 如何关闭一个 TCP 连接？</span><br><span class="line"></span><br><span class="line">  - 第一反应是杀掉进程，杀掉客户端进程和服务端进程影响的范围会有所不同：</span><br><span class="line"></span><br><span class="line">    - 在客户端杀掉进程的话，就会发送 FIN 报文，来断开这个客户端进程与服务端建立的所有 TCP 连接，这种方式影响范围只有这个客户端进程所建立的连接，而其他客户端或进程不会受影响。</span><br><span class="line">    - 而在服务端杀掉进程影响就大了，此时所有的 TCP 连接都会被关闭，服务端无法继续提供访问服务。</span><br><span class="line"></span><br><span class="line">    所以，关闭进程的方式并不可取，最好的方式要精细到关闭某一条 TCP 连接。</span><br><span class="line"></span><br><span class="line">  - **要伪造一个能关闭 TCP 连接的 RST 报文，必须同时满足「四元组相同」和「序列号正好落在对方的滑动窗口内」这两个条件**</span><br><span class="line"></span><br><span class="line">    - 直接伪造符合预期的序列号是比较困难，因为如果一个正在传输数据的 TCP 连接，滑动窗口时刻都在变化，因此很难刚好伪造一个刚好落在对方滑动窗口内的序列号的 RST 报文</span><br><span class="line">    - **可以伪造一个四元组相同的 SYN 报文，来拿到“合法”的序列号**：如果处于 establish 状态的服务端，收到四元组相同的 SYN 报文后，**会回复一个 Challenge ACK，这个 ACK 报文里的「确认号」，正好是服务端下一次想要接收的序列号，说白了，就是可以通过这一步拿到服务端下一次预期接收的序列号。然后用这个确认号作为 RST 报文的序列号，发送给服务端，此时服务端会认为这个 RST 报文里的序列号是合法的，于是就会释放连接**</span><br><span class="line"></span><br><span class="line">  - 在 Linux 上有个叫 killcx 的工具，就是基于上面这样的方式实现的，它会主动发送 SYN 包获取 SEQ/ACK 号，然后利用 SEQ/ACK 号伪造两个 RST 报文分别发给客户端和服务端，这样双方的 TCP 连接都会被释放，这种方式活跃和非活跃的 TCP 连接都可以杀掉</span><br><span class="line"></span><br><span class="line">    - 它伪造客户端发送 SYN 报文，服务端收到后就会回复一个携带了正确「序列号和确认号」的 ACK 报文（Challenge ACK），然后就可以利用这个 ACK 报文里面的信息，伪造两个 RST 报文：</span><br><span class="line">      - 用 Challenge ACK 里的确认号伪造 RST 报文发送给服务端，服务端收到 RST 报文后就会释放连接。</span><br><span class="line">      - 用 Challenge ACK 里的序列号伪造 RST 报文发送给客户端，客户端收到 RST 也会释放连接。</span><br><span class="line">    - 正是通过这样的方式，成功将一个 TCP 连接关闭了；抓包中，如果莫名奇妙出现一个 SYN 包，有可能对方接下来想要对你发起的 RST 攻击，直接将你的 TCP 连接断开</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">### 4.10 四次挥手中收到乱序的 FIN 包会如何处理？</span><br><span class="line"></span><br><span class="line">- **在 FIN_WAIT_2 状态下，是如何处理收到的乱序到 FIN 报文，然后 TCP 连接又是什么时候才进入到 TIME_WAIT 状态?**</span><br><span class="line">  - **在 FIN_WAIT_2 状态时，如果收到乱序的 FIN 报文，那么就被会加入到「乱序队列」，并不会进入到 TIME_WAIT 状态**</span><br><span class="line">  - **等再次收到前面被网络延迟的数据包时，会判断乱序队列有没有数据，然后会检测乱序队列中是否有可用的数据，如果能在乱序队列中找到与当前报文的序列号保持的顺序的报文，就会看该报文是否有 FIN 标志，如果发现有 FIN 标志，这时才会进入 TIME_WAIT 状态。**</span><br><span class="line">- tcp_data_queue 函数里，如果收到的报文的序列号是我们预期的，也就是有序的话：</span><br><span class="line">  - 会判断该报文有没有 FIN 标志，如果有的话就会调用 tcp_fin 函数，这个函数负责将 FIN_WAIT_2 状态转换为 TIME_WAIT。</span><br><span class="line">  - 接着还会看乱序队列有没有数据，如果有的话会调用 tcp_ofo_queue 函数，这个函数负责检查乱序队列中是否有数据包可用，即能不能在乱序队列找到与当前数据包保持序列号连续的数据包。</span><br><span class="line">- 当收到的报文的序列号不是我们预期的，也就是乱序的话，则调用 tcp_data_queue_ofo 函数，将报文加入到乱序队列，这个队列的数据结构是红黑树。然后当客户端收到被网络延迟的数据包后，此时因为该数据包的序列号是期望的，然后又因为上一次收到的乱序 FIN 报文被加入到了乱序队列，表明乱序队列是有数据的，于是就会调用 tcp_ofo_queue 函数。</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">### 4.11 在 TCP 正常挥手过程中，处于 TIME_WAIT 状态的连接，收到相同四元组的 SYN 后会发生什么？</span><br><span class="line"></span><br><span class="line">- 针对这个问题，**关键是要看 SYN 的「序列号和时间戳」是否合法**，因为处于 TIME_WAIT 状态的连接收到 SYN 后，会判断 SYN 的「序列号和时间戳」是否合法，然后根据判断结果的不同做不同的处理</span><br><span class="line"></span><br><span class="line">  - **合法 SYN**：客户端的 SYN 的「序列号」比服务端「期望下一个收到的序列号」要**大**，**并且** SYN 的「时间戳」比服务端「最后收到的报文的时间戳」要**大**。</span><br><span class="line">  - **非法 SYN**：客户端的 SYN 的「序列号」比服务端「期望下一个收到的序列号」要**小**，**或者** SYN 的「时间戳」比服务端「最后收到的报文的时间戳」要**小**。</span><br><span class="line"></span><br><span class="line">- 如果双方开启了时间戳机制：</span><br><span class="line"></span><br><span class="line">  - 如果客户端的 SYN 的「序列号」比服务端「期望下一个收到的序列号」要**大**，**并且**SYN 的「时间戳」比服务端「最后收到的报文的时间戳」要**大**。那么就会重用该四元组连接，跳过 2MSL 而转变为 SYN_RECV 状态，接着就能进行建立连接过程。</span><br><span class="line"></span><br><span class="line">  - 如果客户端的 SYN 的「序列号」比服务端「期望下一个收到的序列号」要**小**，**或者**SYN 的「时间戳」比服务端「最后收到的报文的时间戳」要**小**。那么就会**再回复一个第四次挥手的 ACK 报文，客户端收到后，发现并不是自己期望收到确认号，就回 RST 报文给服务端**。</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">- 在 TIME_WAIT 状态，收到 RST 会断开连接吗？</span><br><span class="line"></span><br><span class="line">  - 如果 `net.ipv4.tcp_rfc1337` 参数为 0，则提前结束 TIME_WAIT 状态，释放连接。</span><br><span class="line"></span><br><span class="line">  - 如果 `net.ipv4.tcp_rfc1337` 参数为 1，则会丢掉该 RST 报文。</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">### 4.12 TCP 连接，一端断电和进程崩溃有什么区别？</span><br><span class="line"></span><br><span class="line">- 如果两端的 TCP 连接一直没有数据交互，达到了触发 TCP 保活机制的条件，那么内核里的 TCP 协议栈就会发送探测报文。</span><br><span class="line"></span><br><span class="line">  - 如果对端程序是正常工作的。当 TCP 保活的探测报文发送给对端, 对端会正常响应，这样 **TCP 保活时间会被重置**，等待下一个 TCP 保活时间的到来。</span><br><span class="line">  - 如果对端主机崩溃，或对端由于其他原因导致报文不可达。当 TCP 保活的探测报文发送给对端后，石沉大海，没有响应，连续几次，达到保活探测次数后，**TCP 会报告该 TCP 连接已经死亡**。</span><br><span class="line"></span><br><span class="line">  所以，TCP 保活机制可以在双方没有数据交互的情况，通过探测报文，来确定对方的 TCP 连接是否存活；应用程序若想使用 TCP 保活机制需要通过 socket 接口设置 `SO_KEEPALIVE` 选项才能够生效，如果没有设置，那么就无法使用 TCP 保活机制。</span><br><span class="line"></span><br><span class="line">- 在没有开启 TCP keepalive，且双方一直没有数据交互的情况下，如果客户端的「主机崩溃」了，会发生什么</span><br><span class="line"></span><br><span class="line">  - 客户端主机崩溃了，服务端是**无法感知到的**，在加上服务端没有开启 TCP keepalive，又没有数据交互的情况下，**服务端的 TCP 连接将会一直处于 ESTABLISHED 连接状态**，直到服务端重启进程。所以，在没有使用 TCP 保活机制且双方不传输数据的情况下，一方的 TCP 连接处在 ESTABLISHED 状态，并不代表另一方的连接还一定正常。</span><br><span class="line"></span><br><span class="line">- 如果「进程崩溃」了，会发生什么</span><br><span class="line"></span><br><span class="line">  - TCP 的连接信息是由内核维护的，所以当服务端的进程崩溃后，内核需要回收该进程的所有 TCP 连接资源，于是内核会发送第一次挥手 FIN 报文，后续的挥手过程也都是在内核完成，并不需要进程的参与，所以即使服务端的进程退出了，还是能与客户端完成 TCP四次挥手的过程</span><br><span class="line"></span><br><span class="line">- 客户端主机宕机，又迅速重启，会发生什么？</span><br><span class="line"></span><br><span class="line">  - 在客户端主机宕机后，服务端向客户端发送的报文会得不到任何的响应，在一定时长后，服务端就会触发**超时重传**机制，重传未得到响应的报文。</span><br><span class="line"></span><br><span class="line">  - 服务端重传报文的过程中，客户端主机重启完成后，客户端的内核就会接收重传的报文，然后根据报文的信息传递给对应的进程：</span><br><span class="line"></span><br><span class="line">    - 如果客户端主机上**没有**进程绑定该 TCP 报文的目标端口号，那么客户端内核就会**回复 RST 报文，重置该 TCP 连接**；</span><br><span class="line">    - 如果客户端主机上**有**进程绑定该 TCP 报文的目标端口号，由于客户端主机重启后，之前的 TCP 连接的数据结构已经丢失了，客户端内核里协议栈会发现找不到该 TCP 连接的 socket 结构体，于是就会**回复 RST 报文，重置该 TCP 连接**。</span><br><span class="line"></span><br><span class="line">    所以，**只要有一方重启完成后，收到之前 TCP 连接的报文，都会回复 RST 报文，以断开连接**</span><br><span class="line"></span><br><span class="line">- 客户端主机宕机，一直没有重启，会发生什么？</span><br><span class="line"></span><br><span class="line">  - 服务端超时重传报文的次数达到一定阈值后，内核就会判定出该 TCP 有问题，然后通过 Socket 接口告诉应用程序该 TCP 连接出问题了，于是服务端的 TCP 连接就会断开。</span><br><span class="line"></span><br><span class="line">- TCP 的数据报文具体重传几次呢？</span><br><span class="line"></span><br><span class="line">  - 在 Linux 系统中，提供一个叫 tcp_retries2 配置项，默认值是 15</span><br><span class="line">  - **内核会根据 tcp_retries2 设置的值，计算出一个 timeout**（*如果 tcp_retries2 =15，那么计算得到的 timeout = 924600 ms*），**如果重传间隔超过这个 timeout，则认为超过了阈值，就会停止重传，然后就会断开 TCP 连接**</span><br><span class="line"></span><br><span class="line">### 4.13 拔掉网线后， 原本的 TCP 连接还存在吗？</span><br><span class="line"></span><br><span class="line">- TCP 连接在 Linux 内核中是一个名为 `struct socket` 的结构体，该结构体的内容包含 TCP 连接的状态等信息。当拔掉网线的时候，操作系统并不会变更该结构体的任何内容，所以 TCP 连接的状态也不会发生改变。</span><br><span class="line"></span><br><span class="line">- 有数据传输的情况：</span><br><span class="line"></span><br><span class="line">  - 在客户端拔掉网线后，服务端向客户端发送的数据报文会得不到任何的响应，在等待一定时长后，服务端就会触发**超时重传**机制，重传未得到响应的数据报文。**如果在服务端重传报文的过程中，客户端刚好把网线插回去了**，由于拔掉网线并不会改变客户端的 TCP 连接状态，并且还是处于 ESTABLISHED 状态，所以这时客户端是可以正常接收服务端发来的数据报文的，然后客户端就会回 ACK 响应报文。此时，客户端和服务端的 TCP 连接依然存在的，就感觉什么事情都没有发生。</span><br><span class="line">  - **如果在服务端重传报文的过程中，客户端一直没有将网线插回去**，服务端超时重传报文的次数达到一定阈值后，内核就会判定出该 TCP 有问题，然后通过 Socket 接口告诉应用程序该 TCP 连接出问题了，于是服务端的 TCP 连接就会断开。而等客户端插回网线后，如果客户端向服务端发送了数据，由于服务端已经没有与客户端相同四元祖的 TCP 连接了，因此服务端内核就会回复 RST 报文，客户端收到后就会释放该 TCP 连接。</span><br><span class="line"></span><br><span class="line">- 针对拔掉网线后，没有数据传输的场景，还得看是否开启了 TCP keepalive 机制 （TCP 保活机制）。</span><br><span class="line"></span><br><span class="line">  - 如果**没有开启** TCP keepalive 机制，在客户端拔掉网线后，并且双方都没有进行数据传输，那么客户端和服务端的 TCP 连接将会一直保持存在。</span><br><span class="line"></span><br><span class="line">  - 而如果**开启**了 TCP keepalive 机制，在客户端拔掉网线后，即使双方都没有进行数据传输，在持续一段时间后，TCP 就会发送探测报文：</span><br><span class="line"></span><br><span class="line">    - 如果**对端是正常工作**的。当 TCP 保活的探测报文发送给对端, 对端会正常响应，这样 **TCP 保活时间会被重置**，等待下一个 TCP 保活时间的到来。</span><br><span class="line"></span><br><span class="line">    - 如果**对端主机崩溃，或对端由于其他原因导致报文不可达**。当 TCP 保活的探测报文发送给对端后，石沉大海，没有响应，连续几次，达到保活探测次数后，**TCP 会报告该 TCP 连接已经死亡**。</span><br><span class="line"></span><br><span class="line">  所以，TCP 保活机制可以在双方没有数据交互的情况，通过探测报文，来确定对方的 TCP 连接是否存活。</span><br><span class="line"></span><br><span class="line">### 4.14 tcp_tw_reuse 为什么默认是关闭的？</span><br><span class="line"></span><br><span class="line">- 开启 tcp_tw_reuse 参数可以快速复用处于 TIME_WAIT 状态的 TCP 连接时，相当于缩短了 TIME_WAIT 状态的持续时间，**如果 TIME_WAIT 状态持续时间过短或者没有，会有什么问题？**</span><br><span class="line"></span><br><span class="line">- 设计 TIME_WAIT 状态，主要有两个原因：</span><br><span class="line"></span><br><span class="line">  - 防止历史连接中的数据，被后面相同四元组的连接错误的接收；</span><br><span class="line">  - 保证「被动关闭连接」的一方，能被正确的关闭</span><br><span class="line"></span><br><span class="line">- 在 Linux 操作系统下，TIME_WAIT 状态的持续时间是 60 秒，这意味着这 60 秒内，客户端一直会占用着这个端口。要知道，端口资源也是有限的，一般可以开启的端口为 32768~61000 ，**如果客户端（主动关闭连接方）的 TIME_WAIT 状态过多**，占满了所有端口资源，那么就无法对「目的 IP+ 目的 PORT」都一样的服务器发起连接了，但是被使用的端口，还是可以继续对另外一个服务器发起连接的。</span><br><span class="line"></span><br><span class="line">  - 不过，即使是在这种场景下，只要连接的是不同的服务器，端口是可以重复使用的，所以客户端还是可以向其他服务器发起连接的，这是因为内核在定位一个连接的时候，是通过四元组（源IP、源端口、目的IP、目的端口）信息来定位的，并不会因为客户端的端口一样，而导致连接冲突。</span><br><span class="line"></span><br><span class="line">- Linux 操作系统提供了两个可以系统参数来快速回收处于 TIME_WAIT 状态的连接，这两个参数都是默认关闭的：</span><br><span class="line"></span><br><span class="line">  - net.ipv4.tcp_tw_reuse，如果开启该选项的话，客户端（连接发起方） 在调用 connect() 函数时，**如果内核选择到的端口，已经被相同四元组的连接占用的时候，就会判断该连接是否处于 TIME_WAIT 状态，如果该连接处于 TIME_WAIT 状态并且 TIME_WAIT 状态持续的时间超过了 1 秒，那么就会重用这个连接，然后就可以正常使用该端口了**。所以该选项只适用于连接发起方。</span><br><span class="line">  - net.ipv4.tcp_tw_recycle，如果开启该选项的话，允许处于 TIME_WAIT 状态的连接被快速回收，该参数在 **NAT 的网络下是不安全的**！</span><br><span class="line"></span><br><span class="line">  要使得上面这两个参数生效，有一个前提条件，就是要打开 TCP 时间戳，即 net.ipv4.tcp_timestamps=1（默认即为 1）。</span><br><span class="line"></span><br><span class="line">  - 开启了 tcp_timestamps 参数，TCP 头部就会使用时间戳选项，它有两个好处，**一个是便于精确计算 RTT ，另一个是能防止序列号回绕（PAWS）**</span><br><span class="line">  - 防回绕序列号算法要求连接双方维护最近一次收到的数据包的时间戳（Recent TSval），每收到一个新数据包都会读取数据包中的时间戳值跟 Recent TSval 值做比较，**如果发现收到的数据包中时间戳不是递增的，则表示该数据包是过期的，就会直接丢弃这个数据包**</span><br><span class="line"></span><br><span class="line">- 开启 tcp_tw_reuse 会有什么风险呢？</span><br><span class="line"></span><br><span class="line">  - 对于 **RST 报文的时间戳即使过期了，只要 RST 报文的序列号在对方的接收窗口内，也是能被接受的**。**因为快速复用 TIME_WAIT 状态的端口，导致新连接可能被回绕序列号的 RST 报文断开了，而如果不跳过 TIME_WAIT 状态，而是停留 2MSL 时长，那么这个 RST 报文就不会出现下一个新的连接**。</span><br><span class="line">    - 一个 HTTP 请求其实很快的，比如我下面这个抓包，只需要 0.2 秒就完成了，远小于 MSL，所以延迟的 RST 报文存活是有可能的</span><br><span class="line">  - 开启 tcp_tw_reuse 来快速复用 TIME_WAIT 状态的连接，如果第四次挥手的 ACK 报文丢失了，服务端会触发超时重传，重传第三次挥手报文，处于 syn_sent 状态的客户端收到服务端重传第三次挥手报文，则会回 RST 给服务端</span><br><span class="line"></span><br><span class="line">### 4.15 HTTPS 中 TLS 和 TCP 能同时握手吗？</span><br><span class="line"></span><br><span class="line">- **一般情况下，不管 TLS 握手次数如何，都得先经过 TCP 三次握手后才能进行**，因为 HTTPS 都是基于 TCP 传输协议实现的，得先建立完可靠的 TCP 连接才能做 TLS 握手的事情</span><br><span class="line">- HTTPS 中的 TLS 握手过程可以同时进行三次握手需要下面这两个条件同时满足才可以：</span><br><span class="line">  - **客户端和服务端都开启了 TCP Fast Open 功能，且 TLS 版本是 1.3；**</span><br><span class="line">  - **客户端和服务端已经完成过一次通信。**</span><br><span class="line"></span><br><span class="line">- TCP Fast Open 是为了绕过 TCP 三次握手发送数据，在 Linux 3.7 内核版本之后，提供了 TCP Fast Open 功能，这个功能可以减少 TCP 连接建立的时延。</span><br><span class="line">  - 要使用 TCP Fast Open 功能，客户端和服务端都要同时支持才会生效。不过，开启了 TCP Fast Open 功能，**想要绕过 TCP 三次握手发送数据，得建立第二次以后的通信过程**</span><br><span class="line">  - 第一次客户端和服务端通信的时候，还是需要正常的三次握手流程。随后，客户端就有了 Cookie 这个东西，它可以用来向服务器 TCP 证明先前与客户端 IP 地址的三向握手已成功完成</span><br><span class="line">  - 对于客户端与服务端的后续通信，客户端可以在第一次握手的时候携带应用数据，从而达到绕过三次握手发送数据的效果</span><br><span class="line">    - 支持 TCP Fast Open 的服务器会对收到 Cookie 进行校验：如果 Cookie 有效，服务器将在 SYN-ACK 报文中对 SYN 和「数据」进行确认，服务器随后将「应用数据」递送给对应的应用程序；如果 Cookie 无效，服务器将丢弃 SYN 报文中包含的「应用数据」，且其随后发出的 SYN-ACK 报文将只确认 SYN 的对应序列号；</span><br><span class="line">    - **如果服务器接受了 SYN 报文中的「应用数据」，服务器可在握手完成之前发送「响应数据」，这就减少了握手带来的 1 个 RTT 的时间消耗**</span><br><span class="line">- TLSv1.3 有个**会话恢复**机制，在**重连 TLvS1.3 只需要 0-RTT**，用“pre_shared_key”和“early_data”扩展，在 TCP 连接后立即就建立安全连接发送加密消息</span><br><span class="line">- **如果「TCP Fast Open + TLSv1.3」情况下，在第二次以后的通信过程中，TLS 和 TCP 的握手过程是可以同时进行的。**如果基于 TCP Fast Open 场景下的 TLSv1.3 0-RTT 会话恢复过程，不仅 TLS 和 TCP 的握手过程是可以同时进行的，而且 HTTP 请求也可以在这期间内一同完成</span><br><span class="line"></span><br><span class="line">### 4.16 TCP Keepalive 和 HTTP Keep-Alive 是一个东西吗？</span><br><span class="line"></span><br><span class="line">- HTTP 的 Keep-Alive 也叫 HTTP 长连接，该功能是由「应用程序」实现的，可以使得用同一个 TCP 连接来发送和接收多个 HTTP 请求/应答，减少了 HTTP 短连接带来的多次 TCP 连接建立和释放的开销。</span><br><span class="line"></span><br><span class="line">  - HTTP 协议采用的是「请求-应答」的模式，也就是客户端发起了请求，服务端才会返回响应，一来一回这样子。</span><br><span class="line"></span><br><span class="line">  - 由于 HTTP 是基于 TCP 传输协议实现的，客户端与服务端要进行 HTTP 通信前，需要先建立 TCP 连接，然后客户端发送 HTTP 请求，服务端收到后就返回响应，至此「请求-应答」的模式就完成了，随后就会释放 TCP 连接。</span><br><span class="line"></span><br><span class="line">  - 如果每次请求都要经历这样的过程：建立 TCP -&gt; 请求资源 -&gt; 响应资源 -&gt; 释放连接，那么此方式就是 **HTTP 短连接**</span><br><span class="line"></span><br><span class="line">  - HTTP 的 Keep-Alive 就是实现可以使用同一个 TCP 连接来发送和接收多个 HTTP 请求/应答，避免了连接建立和释放的开销，这个方法称为 **HTTP 长连接**</span><br><span class="line"></span><br><span class="line">  - HTTP 长连接的特点是，只要任意一端没有明确提出断开连接，则保持 TCP 连接状态。</span><br><span class="line"></span><br><span class="line">  - 在 HTTP 1.0 中默认是关闭的，如果浏览器要开启 Keep-Alive，它必须在请求的包头中添加：</span><br><span class="line"></span><br><span class="line">    ```text</span><br><span class="line">    Connection: Keep-Alive</span><br></pre></td></tr></table></figure>

当服务器收到请求，作出回应的时候，它也添加一个头在响应中
</code></pre>
</li>
<li><p><strong>从 HTTP 1.1 开始， 就默认是开启了 Keep-Alive</strong></p>
</li>
<li><p>HTTP 长连接不仅仅减少了 TCP 连接资源的开销，而且这给 <strong>HTTP 流水线</strong>技术提供了可实现的基础。所谓的 HTTP 流水线，是<strong>客户端可以先一次性发送多个请求，而在发送过程中不需先等待服务器的回应</strong>，可以减少整体的响应时间；但是<strong>服务器还是按照顺序响应</strong>，先回应 A 请求，完成后再回应 B 请求。而且要等服务器响应完客户端第一批发送的请求后，客户端才能发出下一批的请求，也就说如果服务器响应的过程发生了阻塞，那么客户端就无法发出下一批的请求，此时就造成了「队头阻塞」的问题</p>
</li>
<li><p>为了避免资源浪费的情况，web 服务软件一般都会提供 <code>keepalive_timeout</code> 参数，用来指定 HTTP 长连接的超时时间。</p>
</li>
</ul>
</li>
<li><p>TCP 的 Keepalive 也叫 TCP 保活机制，该功能是由「内核」实现的，当客户端和服务端长达一定时间没有进行数据交互时，内核为了确保该连接是否还有效，就会发送探测报文，来检测对方是否还在线，然后来决定是否要关闭该连接。</p>
<ul>
<li>如果对端程序是正常工作的。当 TCP 保活的探测报文发送给对端, 对端会正常响应，这样 <strong>TCP 保活时间会被重置</strong>，等待下一个 TCP 保活时间的到来。</li>
<li>如果对端主机崩溃，或对端由于其他原因导致报文不可达。当 TCP 保活的探测报文发送给对端后，石沉大海，没有响应，连续几次，达到保活探测次数后，<strong>TCP 会报告该 TCP 连接已经死亡</strong>。</li>
</ul>
</li>
</ul>
<h3 id="4-17-TCP-协议有什么缺陷？"><a href="#4-17-TCP-协议有什么缺陷？" class="headerlink" title="4.17 TCP 协议有什么缺陷？"></a>4.17 TCP 协议有什么缺陷？</h3><ul>
<li>升级 TCP 的工作很困难；<ul>
<li>但是 TCP 协议是在内核中实现的，应用程序只能使用不能修改，如果要想升级 TCP 协议，那么只能升级内核。</li>
<li>升级内核这个工作是很麻烦的事情，由于内核升级涉及到底层软件和运行库的更新，服务程序就需要回归测试是否兼容新的内核版本，所以服务器的内核升级也比较保守和缓慢。</li>
<li>很多 TCP 协议的新特性，都是需要客户端和服务端同时支持才能生效的</li>
</ul>
</li>
<li>TCP 建立连接的延迟；<ul>
<li>基于 TCP 实现的应用协议，都是需要先建立三次握手才能进行数据传输，比如 HTTP 1.0&#x2F;1.1、HTTP&#x2F;2、HTTPS。</li>
<li>TCP 三次握手的延迟被 TCP Fast Open （快速打开）这个特性解决了，这个特性可以在「第二次建立连接」时减少 TCP 连接建立的时延。TCP Fast Open 是在 2013 年提出的，所以市面上依然有很多老式的操作系统不支持，而升级操作系统是很麻烦的事情，因此 TCP Fast Open 很难被普及开来。</li>
<li>针对 HTTPS 来说，TLS 是在应用层实现的握手，而 TCP 是在内核实现的握手，这两个握手过程是无法结合在一起的，总是得先完成 TCP 握手，才能进行 TLS 握手。也正是 TCP 是在内核实现的，所以 TLS 是无法对 TCP 头部加密的，这意味着 TCP 的序列号都是明文传输，所以就存安全的问题。<ul>
<li>一个典型的例子就是攻击者伪造一个的 RST 报文强制关闭一条 TCP 连接，而攻击成功的关键则是 TCP 字段里的序列号位于接收方的滑动窗口内，该报文就是合法的</li>
<li>为此 TCP 也不得不进行三次握手来同步各自的序列号，而且初始化序列号时是采用随机的方式（不完全随机，而是随着时间流逝而线性增长，到了 2^32 尽头再回滚）来提升攻击者猜测序列号的难度，以增加安全性</li>
<li>这种方式只能避免攻击者预测出合法的 RST 报文，而无法避免攻击者截获客户端的报文，然后中途伪造出合法 RST 报文的攻击的方式。</li>
</ul>
</li>
<li>如果 TCP 的序列号也能被加密，或许真的不需要三次握手了，客户端和服务端的初始序列号都从 0 开始，也就不用做同步序列号的工作了，但是要实现这个要改造整个协议栈，太过于麻烦，即使实现出来了，很多老的网络设备未必能兼容</li>
</ul>
</li>
<li>TCP 存在队头阻塞问题；<ul>
<li>TCP 是字节流协议，<strong>TCP 层必须保证收到的字节数据是完整且有序的</strong>，如果序列号较低的 TCP 段在网络传输中丢失了，即使序列号较高的 TCP 段已经被接收了，应用层也无法从内核中读取到这部分数据</li>
<li>HTTP&#x2F;2 多个请求是跑在一个 TCP 连接中的，那么当 TCP 丢包时，整个 TCP 都要等待重传，那么就会阻塞该 TCP 连接中的所有请求，所以 HTTP&#x2F;2 队头阻塞问题就是因为 TCP 协议导致的</li>
</ul>
</li>
<li>网络迁移需要重新建立 TCP 连接<ul>
<li>基于 TCP 传输协议的 HTTP 协议，由于是通过四元组（源 IP、源端口、目的 IP、目的端口）确定一条 TCP 连接。<strong>当移动设备的网络从 4G 切换到 WIFI 时，意味着 IP 地址变化了，那么就必须要断开连接，然后重新建立 TCP 连接</strong>。</li>
<li>建立连接的过程包含 TCP 三次握手和 TLS 四次握手的时延，以及 TCP 慢启动的减速过程，给用户的感觉就是网络突然卡顿了一下，因此连接的迁移成本是很高的</li>
</ul>
</li>
</ul>
<h3 id="4-18-如何基于-UDP-协议实现可靠传输？"><a href="#4-18-如何基于-UDP-协议实现可靠传输？" class="headerlink" title="4.18 如何基于 UDP 协议实现可靠传输？"></a>4.18 如何基于 UDP 协议实现可靠传输？</h3><ul>
<li><p>TCP 协议四个方面的缺陷：</p>
<ul>
<li>升级 TCP 的工作很困难；</li>
<li>TCP 建立连接的延迟；</li>
<li>TCP 存在队头阻塞问题；</li>
<li>网络迁移需要重新建立 TCP 连接；</li>
</ul>
</li>
<li><p>QUIC 是如何实现可靠传输的？</p>
<p>要基于 UDP 实现的可靠传输协议，那么就要在应用层下功夫，也就是要设计好协议的头部字段</p>
<ul>
<li><p>Packet Header 首次建立连接时和日常传输数据时使用的 Header 是不同的; Packet Header 细分这两种：</p>
<ul>
<li>Long Packet Header 用于首次建立连接。</li>
<li>Short Packet Header 用于日常传输数据。不需要在传输 Source Connection ID 字段了，只需要传输 Destination Connection ID。</li>
</ul>
</li>
<li><p>QUIC 也是需要三次握手来建立连接的，主要目的是为了协商连接 ID。协商出连接 ID 后，后续传输时，双方只需要固定住连接 ID，从而实现连接迁移功能。</p>
</li>
<li><p>Short Packet Header 中的 <code>Packet Number</code> 是每个报文独一无二的编号，它是<strong>严格递增</strong>的，也就是说就算 Packet N 丢失了，重传的 Packet N 的 Packet Number 已经不是 N，而是一个比 N 大的值。</p>
<ul>
<li>解决了 TCP 重传的歧义问题从而导致的RTT计算不准</li>
<li>ACK 的 Packet Number 是 N+M，就根据重传报文计算采样 RTT。如果 ACK 的 Pakcet Number 是 N，就根据原始报文的时间计算采样 RTT，没有歧义性的问题。</li>
</ul>
</li>
<li><p><strong>QUIC 使用的 Packet Number 单调递增的设计，可以让数据包不再像 TCP 那样必须有序确认，QUIC 支持乱序确认，当数据包Packet N 丢失后，只要有新的已接收数据包确认，当前窗口就会继续向右滑动</strong></p>
<ul>
<li>待发送端获知数据包Packet N 丢失后，会将需要重传的数据包放到待发送队列，重新编号比如数据包Packet N+M 后重新发送给接收端，对重传数据包的处理跟发送新的数据包类似，这样就不会因为丢包重传将当前窗口阻塞在原地，从而解决了队头阻塞问题。</li>
</ul>
</li>
<li><p>一个 Packet 报文中可以存放多个 QUIC Frame。每一个 Frame 都有明确的类型，针对类型的不同，功能也不同，自然格式也不同。引入 Frame Header 这一层，<strong>通过 Stream ID + Offset 字段信息实现数据的有序性</strong>，通过比较两个数据包的 Stream ID 与 Stream Offset ，如果都是一致，就说明这两个数据包的内容一致。</p>
</li>
</ul>
</li>
<li><p>QUIC 是如何解决 TCP 队头阻塞问题的？</p>
<ul>
<li>TCP 必须按序处理数据，也就是 TCP 层为了保证数据的有序性，只有在处理完有序的数据后，滑动窗口才能往前滑动，否则就停留。<ul>
<li>停留「发送窗口」会使得发送方无法继续发送数据。</li>
<li>停留「接收窗口」会使得应用层无法读取新的数据。</li>
</ul>
</li>
<li>HTTP&#x2F;2 通过抽象出 Stream 的概念，实现了 HTTP 并发传输，一个 Stream 就代表 HTTP&#x2F;1.1 里的请求和响应。<strong>但是 HTTP&#x2F;2 多个 Stream 请求都是在一条 TCP 连接上传输，这意味着多个 Stream 共用同一个 TCP 滑动窗口，那么当发生数据丢失，滑动窗口是无法往前移动的，此时就会阻塞住所有的 HTTP 请求，这属于 TCP 层队头阻塞</strong>。</li>
<li><strong>QUIC 给每一个 Stream 都分配了一个独立的滑动窗口，这样使得一个连接上的多个 Stream 之间没有依赖关系，都是相互独立的，各自控制的滑动窗口</strong>。</li>
</ul>
</li>
<li><p>QUIC 是如何做流量控制的？</p>
<ul>
<li>TCP 流量控制是通过让「接收方」告诉「发送方」，它（接收方）的接收窗口有多大，从而让「发送方」根据「接收方」的实际接收能力控制发送的数据量。</li>
<li>QUIC 实现流量控制的方式：<ul>
<li>通过 window_update 帧告诉对端自己可以接收的字节数，这样发送方就不会发送超过这个数量的数据。</li>
<li>通过 BlockFrame 告诉对端由于流量控制被阻塞了，无法发送数据。</li>
</ul>
</li>
<li>QUIC 的滑动窗口滑动的条件跟 TCP 有一点差别，但是同一个 Stream 的数据也是要保证顺序的，不然无法实现可靠传输，因此同一个 Stream 的数据包丢失了，也会造成窗口无法滑动。</li>
<li>QUIC 实现了两种级别的流量控制，分别为 Stream 和 Connection 两种级别：<ul>
<li><strong>Stream 级别的流量控制</strong>：Stream 可以认为就是一条 HTTP 请求，每个 Stream 都有独立的滑动窗口，所以每个 Stream 都可以做流量控制，防止单个 Stream 消耗连接（Connection）的全部接收缓冲。</li>
<li><strong>Connection 流量控制</strong>：限制连接中所有 Stream 相加起来的总字节数，防止发送方超过连接的缓冲容量。</li>
</ul>
</li>
</ul>
</li>
<li><p>QUIC 对拥塞控制改进</p>
<ul>
<li>QUIC 是处于应用层的，应用程序层面就能实现不同的拥塞控制算法，不需要操作系统，不需要内核支持。这是一个飞跃，因为传统的 TCP 拥塞控制，必须要端到端的网络协议栈支持，才能实现控制效果。而内核和操作系统的部署成本非常高，升级周期很长，所以 TCP 拥塞控制算法迭代速度是很慢的。而 <strong>QUIC 可以随浏览器更新，QUIC 的拥塞控制算法就可以有较快的迭代速度</strong>。</li>
<li>TCP 更改拥塞控制算法是对系统中所有应用都生效，无法根据不同应用设定不同的拥塞控制策略。但是因为 QUIC 处于应用层，所以就<strong>可以针对不同的应用设置不同的拥塞控制算法</strong>，这样灵活性就很高了</li>
</ul>
</li>
<li><p>QUIC 更快的连接建立</p>
<ul>
<li>HTTP&#x2F;3 的 QUIC 协议并不是与 TLS 分层，而是<strong>QUIC 内部包含了 TLS，它在自己的帧会携带 TLS 里的“记录”，再加上 QUIC 使用的是 TLS1.3，因此仅需 1 个 RTT 就可以「同时」完成建立连接与密钥协商，甚至在第二次连接的时候，应用数据包可以和 QUIC 握手信息（连接信息 + TLS 信息）一起发送，达到 0-RTT 的效果</strong></li>
</ul>
</li>
<li><p>QUIC 是如何迁移连接的？</p>
<ul>
<li>QUIC 协议没有用四元组的方式来“绑定”连接，而是通过<strong>连接 ID</strong>来标记通信的两个端点，客户端和服务器可以各自选择一组 ID 来标记自己，因此即使移动设备的网络变化后，导致 IP 地址变化了，只要仍保有上下文信息（比如连接 ID、TLS 密钥等），就可以“无缝”地复用原连接，消除重连的成本，没有丝毫卡顿感，达到了<strong>连接迁移</strong>的功能。</li>
</ul>
</li>
</ul>
<h3 id="4-19-TCP-和-UDP-可以使用同一个端口吗？"><a href="#4-19-TCP-和-UDP-可以使用同一个端口吗？" class="headerlink" title="4.19 TCP 和 UDP 可以使用同一个端口吗？"></a>4.19 TCP 和 UDP 可以使用同一个端口吗？</h3><ul>
<li><p>TCP 和 UDP 可以同时绑定相同的端口吗？</p>
<ul>
<li>TCP 和 UDP 服务端网络相似的一个地方，就是会调用 bind 绑定端口。</li>
<li>在数据链路层中，通过 MAC 地址来寻找局域网中的主机。在网际层中，通过 IP 地址来寻找网络中互连的主机或路由器。在传输层中，需要通过端口进行寻址，来识别同一计算机中同时通信的不同应用程序。所以，传输层的「端口号」的作用，是为了区分同一个主机上不同应用程序的数据包。</li>
<li>传输层有两个传输协议分别是 TCP 和 UDP，在内核中是两个完全独立的软件模块。当主机收到数据包后，可以在 IP 包头的「协议号」字段知道该数据包是 TCP&#x2F;UDP，所以可以根据这个信息确定送给哪个模块（TCP&#x2F;UDP）处理，送给 TCP&#x2F;UDP 模块的报文根据「端口号」确定送给哪个应用程序处理。</li>
<li>因此， TCP&#x2F;UDP 各自的端口号也相互独立，如 TCP 有一个 80 号端口，UDP 也可以有一个 80 号端口，二者并不冲突。</li>
</ul>
</li>
<li><p>多个 TCP 服务进程可以绑定同一个端口吗？</p>
<ul>
<li><strong>如果两个 TCP 服务进程同时绑定的 IP 地址和端口都相同，那么执行 bind() 时候就会出错，错误是“Address already in use”</strong>。</li>
<li>如果 TCP 服务进程 A 绑定的地址是 0.0.0.0 和端口 8888，而如果 TCP 服务进程 B 绑定的地址是 192.168.1.100 地址（或者其他地址）和端口 8888，那么执行 bind() 时候也会出错；这是因为 0.0.0.0 地址比较特殊，代表任意地址，意味着绑定了 0.0.0.0 地址，相当于把主机上的所有 IP 地址都绑定了。</li>
<li><strong>当 TCP 服务进程重启时，服务端会出现 TIME_WAIT 状态的连接，TIME_WAIT 状态的连接使用的 IP+PORT 仍然被认为是一个有效的 IP+PORT 组合，相同机器上不能够在该 IP+PORT 组合上进行绑定，那么执行 bind() 函数的时候，就会返回了 Address already in use 的错误</strong>。而等 TIME_WAIT 状态的连接结束后，重启 TCP 服务进程就能成功。</li>
<li>可以在调用 bind 前，对 socket 设置 SO_REUSEADDR 属性，可以避免“Address in use”的报错信息。因为 SO_REUSEADDR 作用是：<strong>如果当前启动进程绑定的 IP+PORT 与处于TIME_WAIT 状态的连接占用的 IP+PORT 存在冲突，但是新启动的进程使用了 SO_REUSEADDR 选项，那么该进程就可以绑定成功</strong>。<strong>另外一个作用</strong>：绑定的 IP地址 + 端口时，只要 IP 地址不是正好(exactly)相同，那么允许绑定。</li>
</ul>
</li>
<li><p>客户端的端口可以重复使用吗？</p>
<ul>
<li>客户端在执行 connect 函数的时候，会在内核里随机选择一个端口，然后向服务端发起 SYN 报文，然后与服务端进行三次握手。所以，客户端的端口选择的发生在 connect 函数，内核在选择端口的时候，会从 <code>net.ipv4.ip_local_port_range</code> 这个内核参数指定的范围来选取一个端口作为客户端端口。</li>
<li><strong>TCP 连接是由四元组（源IP地址，源端口，目的IP地址，目的端口）唯一确认的，那么只要四元组中其中一个元素发生了变化，那么就表示不同的 TCP 连接的。所以如果客户端已使用端口 64992 与服务端 A 建立了连接，那么客户端要与服务端 B 建立连接，还是可以使用端口 64992 的，因为内核是通过四元祖信息来定位一个 TCP 连接的，并不会因为客户端的端口号相同，而导致连接冲突的问题。</strong></li>
<li>bind 函数虽然常用于服务端网络编程中，但是它也是用于客户端的。如果我们想自己指定连接的端口，就可以用 bind 函数来实现：客户端先通过 bind 函数绑定一个端口，然后调用 connect 函数就会跳过端口选择的过程了，转而使用 bind 时确定的端口。</li>
<li>多个客户端可以 bind 同一个端口吗？<ul>
<li>要看多个客户端绑定的 IP + PORT 是否都相同，如果都是相同的，那么在执行 bind() 时候就会出错，错误是“Address already in use”。</li>
<li>一般而言，客户端不建议使用 bind 函数，应该交由 connect 函数来选择端口会比较好，因为客户端的端口通常都没什么意义。</li>
</ul>
</li>
</ul>
</li>
<li><p>客户端 TCP 连接 TIME_WAIT 状态过多，会导致端口资源耗尽而无法建立新的连接吗？</p>
<ul>
<li>如果客户端都是与同一个服务器（目标地址和目标端口一样）建立连接，那么如果客户端 TIME_WAIT 状态的连接过多，当端口资源被耗尽，就无法与这个服务器再建立连接了。</li>
<li>但是，<strong>因为只要客户端连接的服务器不同，端口资源可以重复使用的</strong>。所以，如果客户端都是与不同的服务器建立连接，即使客户端端口资源只有几万个， 客户端发起百万级连接也是没问题的（当然这个过程还会受限于其他资源，比如文件描述符、内存、CPU 等）。</li>
</ul>
</li>
<li><p>如何解决客户端 TCP 连接 TIME_WAIT 过多，导致无法与同一个服务器建立连接的问题？</p>
<ul>
<li>打开 <code>net.ipv4.tcp_tw_reuse</code> 这个内核参数。<strong>因为开启了这个内核参数后，客户端调用 connect 函数时，如果选择到的端口，已经被相同四元组的连接占用的时候，就会判断该连接是否处于 TIME_WAIT 状态，如果该连接处于 TIME_WAIT 状态并且 TIME_WAIT 状态持续的时间超过了 1 秒，那么就会重用这个连接，然后就可以正常使用该端口了</strong></li>
</ul>
</li>
</ul>
<h3 id="4-20-服务端没有-listen，客户端发起连接建立，会发生什么？"><a href="#4-20-服务端没有-listen，客户端发起连接建立，会发生什么？" class="headerlink" title="4.20 服务端没有 listen，客户端发起连接建立，会发生什么？"></a>4.20 服务端没有 listen，客户端发起连接建立，会发生什么？</h3><ul>
<li><p><strong>服务端如果只 bind 了 IP 地址和端口，而没有调用 listen 的话，然后客户端对服务端发起了连接建立，服务端会回 RST 报文</strong></p>
<ul>
<li>Linux 内核处理收到 TCP 报文的入口函数是 tcp_v4_rcv，在收到 TCP 报文后，会调用 __inet_lookup_skb 函数找到 TCP 报文所属 socket </li>
<li>__inet_lookup_skb 函数首先查找连接建立状态的socket（__inet_lookup_established），在没有命中的情况下，才会查找监听套接口（__inet_lookup_listener）。</li>
<li>查找监听套接口（__inet_lookup_listener）这个函数的实现是，根据目的地址和目的端口算出一个哈希值，然后在哈希表找到对应监听该端口的 socket。</li>
</ul>
</li>
<li><p>不使用 listen ，可以建立 TCP 连接吗？</p>
<ul>
<li><p><strong>可以的，客户端是可以自己连自己的形成连接（TCP自连接），也可以两个客户端同时向对方发出请求建立连接（TCP同时打开），这两个情况都有个共同点，就是没有服务端参与，也就是没有listen，就能建立连接</strong>。</p>
</li>
<li><p>三次握手的过程中会在这两个队列中暂存连接信息。所以形成连接，前提是你得有个地方存放着，方便握手的时候能根据 IP + 端口等信息找到对应的 socket。</p>
</li>
</ul>
</li>
<li><p>客户端会有半连接队列吗？</p>
<ul>
<li>客户端没有执行listen，因为半连接队列和全连接队列都是在执行 listen 方法时，内核自动创建的。但内核还有个全局 hash 表，可以用于存放 sock 连接的信息。</li>
<li><strong>在 TCP 自连接的情况中，客户端在 connect 方法时，最后会将自己的连接信息放入到这个全局 hash 表中，然后将信息发出，消息在经过回环地址重新回到 TCP 传输层的时候，就会根据 IP + 端口信息，再一次从这个全局 hash 中取出信息。于是握手包一来一回，最后成功建立连接</strong>。</li>
</ul>
</li>
</ul>
<h3 id="4-21-没有-accept，能建立-TCP-连接吗？"><a href="#4-21-没有-accept，能建立-TCP-连接吗？" class="headerlink" title="4.21 没有 accept，能建立 TCP 连接吗？"></a>4.21 没有 accept，能建立 TCP 连接吗？</h3><ul>
<li><strong>每一个</strong><code>socket</code>执行<code>listen</code>时，内核都会自动创建一个半连接队列和全连接队列。第三次握手前，TCP连接会放在半连接队列中，直到第三次握手到来，才会被放到全连接队列中。</li>
<li><code>accept方法</code>只是为了从全连接队列中拿出一条连接，本身跟三次握手几乎<strong>毫无关系</strong>。</li>
<li>出于效率考虑，虽然都叫队列，但半连接队列其实被设计成了<strong>哈希表</strong>，而全连接队列本质是链表。</li>
<li>全连接队列满了，再来第三次握手也会丢弃，此时如果<code>tcp_abort_on_overflow=1</code>，还会直接发<code>RST</code>给客户端。</li>
<li>半连接队列满了，可能是因为受到了<code>SYN Flood</code>攻击，可以设置<code>tcp_syncookies</code>，绕开半连接队列。但是不能仅使用cookies，因为服务端并不会保存连接信息，所以如果传输过程中数据包丢了，也不会重发第二次握手的信息；而且可能引发ACK攻击，耗尽CPU资源</li>
<li>客户端没有半连接队列和全连接队列，但有一个<strong>全局hash</strong>，可以通过它实现自连接或TCP同时打开。</li>
</ul>
<h3 id="4-22-用了-TCP-协议，数据一定不会丢吗？"><a href="#4-22-用了-TCP-协议，数据一定不会丢吗？" class="headerlink" title="4.22 用了 TCP 协议，数据一定不会丢吗？"></a>4.22 用了 TCP 协议，数据一定不会丢吗？</h3><ul>
<li>一个数据包，从聊天框里发出，消息会从<strong>聊天软件</strong>所在的<strong>用户空间</strong>拷贝到<strong>内核空间</strong>的<strong>发送缓冲区（send buffer）</strong>，数据包就这样顺着<strong>传输层、网络层，进入到数据链路层，在这里数据包会经过流控（qdisc），再通过RingBuffer发到物理层的网卡</strong>。数据就这样顺着<strong>网卡</strong>发到了<strong>纷繁复杂</strong>的网络世界里。这里头数据会经过n多个<strong>路由器和交换机</strong>之间的跳转，最后到达<strong>目的机器的网卡</strong>处。此时目的机器的网卡会通知<strong>DMA</strong>将数据包信息放到<code>RingBuffer</code>中，再触发一个<strong>硬中断</strong>给<code>CPU</code>，<code>CPU</code>触发<strong>软中断</strong>让<code>ksoftirqd</code>去<code>RingBuffer</code>收包，于是一个数据包就这样顺着<strong>物理层，数据链路层，网络层，传输层</strong>，最后从内核空间拷贝到用户空间里的<strong>聊天软件</strong>里。</li>
<li>数据从发送端到接收端，链路很长，任何一个地方都可能发生丢包，几乎可以说丢包不可避免。比如建立连接时产生的丢包，ack队列满了的情况；流量控制丢包，流控队列溢出的问题；网卡丢包，RingBuffer过小导致丢包；接受缓冲区的丢包；两端之间的网络丢包</li>
<li>平时没事也不用关注丢包，大部分时候TCP的重传机制保证了消息可靠性。</li>
<li>当发现服务异常的时候，比如接口延时很高，总是失败的时候，可以用ping或者mtr命令看下是不是中间链路发生了丢包。</li>
<li>TCP只保证传输层的消息可靠性，并不保证应用层的消息可靠性。如果还想保证应用层的消息可靠性，就需要应用层自己去实现逻辑做保证。比如微信会引入第三端服务器进行保证可靠性</li>
</ul>
<h3 id="4-23-TCP-四次挥手，可以变成三次吗？"><a href="#4-23-TCP-四次挥手，可以变成三次吗？" class="headerlink" title="4.23 TCP 四次挥手，可以变成三次吗？"></a>4.23 TCP 四次挥手，可以变成三次吗？</h3><ul>
<li>TCP四次挥手细节复习：服务端（被挥手方）收到FIN报文后进入CLOSE_WAIT状态，TCP 协议栈会为 FIN 包插入一个文件结束符 EOF 到接收缓冲区中，服务端应用程序可以通过 read 调用来感知这个 FIN 包，这个 EOF 会被<strong>放在已排队等候的其他已接收的数据之后</strong>，所以必须要得继续 read 接收缓冲区已接收的数据；read到这个EOF之后就会返回0，这是看服务端应用程序是否还有数据需要发送，如果没有的话则直接发送FIN包，进入LASK_ACK状态</li>
<li>服务器收到客户端的 FIN 报文时，内核会马上回一个 ACK 应答报文，<strong>但是服务端应用程序可能还有数据要发送，所以并不能马上发送 FIN 报文，而是将发送 FIN 报文的控制权交给服务端应用程序</strong>；由应用程序决定什么时候调用关闭连接的函数，当调用了关闭连接的函数，内核就会发送 FIN 报文了</li>
<li>FIN 报文不一定得调用关闭连接的函数才会发送，如果进程退出了，不管是不是正常退出，还是异常退出（如进程崩溃），内核都会<strong>发送</strong> FIN 报文，与对方完成四次挥手</li>
<li>close函数同时关闭socket的读方向和写方向，其不再具备发送和接受数据的能力；如果有多进程&#x2F;多线程共享同一个 socket，如果有一个进程调用了 close 关闭只是让 socket 引用计数 -1，并不会导致 socket 不可用，同时也不会发出 FIN 报文，其他进程还是可以正常读写该 socket，直到引用计数变为 0，才会发出 FIN 报文；若调用close发出FIN报文后还收到了数据，则会直接发送RST报文，然后内核会释放连接，这时就不会经历完成的 TCP 四次挥手</li>
<li>shutdown 函数，可以指定 socket 只关闭发送方向而不关闭读取方向，也就是 socket 不再有发送数据的能力，但是还是具有接收数据的能力。如果有多进程&#x2F;多线程共享同一个 socket，shutdown 则不管引用计数，直接使得该 socket 不可用，然后发出 FIN 报文，如果有别的进程企图使用该 socket，将会受到影响；shutdown 函数也可以指定「只关闭读取方向，而不关闭发送方向」，但是这时候内核是不会发送 FIN 报文的，因为发送 FIN 报文是意味着我方将不再发送任何数据</li>
<li>当被动关闭方在 TCP 挥手过程中，如果「没有数据要发送」，同时「没有开启 TCP_QUICKACK（默认情况就是没有开启，没有开启 TCP_QUICKACK，等于就是在使用 TCP 延迟确认机制）」，那么第二和第三次挥手就会合并传输，这样就出现了三次挥手。<strong>出现三次挥手现象是因为 TCP 延迟确认机制导致的。</strong></li>
</ul>
<h3 id="4-23-TCP-序列号和确认号是如何变化的？"><a href="#4-23-TCP-序列号和确认号是如何变化的？" class="headerlink" title="4.23 TCP 序列号和确认号是如何变化的？"></a>4.23 TCP 序列号和确认号是如何变化的？</h3><ul>
<li><p><strong>发送的 TCP 报文：</strong></p>
<ul>
<li><strong>公式一：序列号 &#x3D; 上一次发送的序列号 + len（数据长度）。特殊情况，如果上一次发送的报文是 SYN 报文或者 FIN 报文，则改为 上一次发送的序列号 + 1。</strong></li>
<li><strong>公式二：确认号 &#x3D; 上一次收到的报文中的序列号 + len（数据长度）。特殊情况，如果收到的是 SYN 报文或者 FIN 报文，则改为上一次收到的报文中的序列号 + 1。</strong></li>
</ul>
</li>
<li><p>三次握手中 TCP 序列号和确认号的变化</p>
<ul>
<li>假设客户端的初始化序列号为 client_isn，服务端的初始化序列号为 server_isn</li>
<li>服务端收到客户端的 SYN 报文后，会将 SYN-ACK 报文（第二次握手报文）中序列号和确认号分别设置为：<ul>
<li>序列号设置为服务端随机初始化的序列号 server_isn。</li>
<li>确认号设置为 client_isn + 1，服务端上一次收到的报文是客户端发来的 SYN 报文，该报文的 seq &#x3D; client_isn，那么根据公式 2（<em>确认号 &#x3D; 上一次收到的报文中的序列号 + len。特殊情况，如果收到的是 SYN 报文或者 FIN 报文，则改为 + 1</em>），可以得出当前确认号 &#x3D; client_isn + 1。</li>
</ul>
</li>
<li>客户端收到服务端的 SYN-ACK 报文后，会将 ACK 报文（第三次握手报文）中序列号和确认号分别设置为：<ul>
<li>序列号设置为 client_isn + 1。客户端上一次发送报文是 SYN 报文，SYN 的序列号为 client_isn，根据公式 1（<em>序列号 &#x3D; 上一次发送的序列号 + len。特殊情况，如果上一次发送的报文是 SYN 报文或者 FIN 报文，则改为 + 1</em>），所以当前的序列号为 client_isn + 1。</li>
<li>确认号设置为 server_isn + 1，客户端上一次收到的报文是服务端发来的 SYN-ACK 报文，该报文的 seq &#x3D; server_isn，那么根据公式 2（<em>确认号 &#x3D; 收到的报文中的序列号 + len。特殊情况，如果收到的是 SYN 报文或者 FIN 报文，则改为 + 1</em>），可以得出当前确认号 &#x3D; server_isn + 1。</li>
</ul>
</li>
</ul>
</li>
<li><p>SYN 报文是特殊的 TCP 报文，用于建立连接时使用，虽然 SYN 报文不携带用户数据，但是 <strong>TCP 将 SYN 报文视为 1 字节的数据</strong>，当对方收到了 SYN 报文后，在回复 ACK 报文时，就需要将 ACK 报文中的确认号设置为 SYN 的序列号 + 1 ，这样做是有两个目的：</p>
<ul>
<li><strong>告诉对方，我方已经收到 SYN 报文。</strong></li>
<li><strong>告诉对方，我方下一次「期望」收到的报文的序列号为此确认号，比如客户端与服务端完成三次握手之后，服务端接下来期望收到的是序列号为 client_isn + 1 的 TCP 数据报文</strong></li>
</ul>
</li>
<li><p>数据传输阶段的变化</p>
<p>客户端发送 10 字节的数据，通常 TCP 数据报文的控制位是 [PSH, ACK]，此时该 TCP 数据报文的序列号和确认号分别设置为：</p>
<ul>
<li>序列号设置为 client_isn + 1。客户端上一次发送报文是 ACK 报文（第三次握手），该报文的 seq &#x3D; client_isn + 1，由于是一个单纯的 ACK 报文，没有携带用户数据，所以 len &#x3D; 0。根据公式 1（<em>序列号 &#x3D; 上一次发送的序列号 + len</em>），可以得出当前的序列号为 client_isn + 1 + 0，即 client_isn + 1。</li>
<li>确认号设置为 server_isn + 1。没错，还是和第三次握手的 ACK 报文的确认号一样，这是因为客户端三次握手之后，发送 TCP 数据报文 之前，如果没有收到服务端的 TCP 数据报文，确认号还是延用上一次的，其实根据公式 2 你也能得到这个结论。</li>
</ul>
<p>可以看到，<strong>客户端与服务端完成 TCP 三次握手后，发送的第一个 「TCP 数据报文的序列号和确认号」都是和「第三次握手的 ACK 报文中序列号和确认号」一样的</strong>。</p>
<p>接着，当服务端收到客户端 10 字节的 TCP 数据报文后，就需要回复一个 ACK 报文，此时该报文的序列号和确认号分别设置为：</p>
<ul>
<li>序列号设置为 server_isn + 1。服务端上一次发送报文是 SYN-ACK 报文，序列号为 server_isn，根据公式 1（<em>序列号 &#x3D; 上一次发送的序列号 + len。特殊情况，如果上一次发送的报文是 SYN 报文或者 FIN 报文，则改为 + 1</em>），所以当前的序列号为 server_isn + 1。</li>
<li>确认号设置为 client_isn + 11 。服务端上一次收到的报文是客户端发来的 10 字节 TCP 数据报文，该报文的 seq &#x3D; client_isn + 1，len &#x3D; 10。根据公式 2（<em>确认号 &#x3D; 上一次收到的报文中的序列号 + len</em>），也就是将「收到的 TCP 数据报文中的序列号 client_isn + 1，再加上 10（len &#x3D; 10） 」的值作为了确认号，表示自己收到了该 10 字节的数据报文。</li>
</ul>
</li>
<li><p>四次挥手阶段中，序列号和确认号的变化</p>
<p>数据传输阶段结束后，客户端发起了 FIN 报文，请求服务端端开该 TCP 连接，此时就进入了 TCP 四次挥手阶段</p>
<p>客户端发送的第一次挥手的序列号和确认号分别设置为：</p>
<ul>
<li>序列号设置为 client_isn + 11。客户端上一次发送的报文是 [PSH, ACK] ，该报文的 seq &#x3D; client_isn + 1, len &#x3D; 10，根据公式 1（<em>序列号 &#x3D; 上一次发送的序列号 + len</em>），可以得出当前的序列号为 client_isn + 11。</li>
<li>确认号设置为 server_isn + 1。客户端上一次收到的报文是服务端发来的 ACK 报文，该报文的 seq &#x3D; server_isn + 1，是单纯的 ACK 报文，不携带用户数据，所以 len 为 0。那么根据公式 2（确认号 &#x3D; 上一次收到的序列号 + len），可以得出当前的确认号为 server_isn + 1 + 0 （len &#x3D; 0），也就是 server_isn + 1。</li>
</ul>
<p>服务端发送的第二次挥手的序列号和确认号分别设置为：</p>
<ul>
<li>序列号设置为 server_isn + 1。服务端上一次发送的报文是 ACK 报文，该报文的 seq &#x3D; server_isn + 1，而该报文是单纯的 ACK 报文，不携带用户数据，所以 len 为 0，根据公式 1（<em>序列号 &#x3D; 上一次发送的序列号 + len</em>），可以得出当前的序列号为 server_isn + 1 + 0 （len &#x3D; 0），也就是 server_isn + 1。</li>
<li>确认号设置为 client_isn + 12。服务端上一次收到的报文是客户端发来的 FIN 报文，该报文的 seq &#x3D; client_isn + 11，根据公式 2（<em>确认号&#x3D; 上一次收到的序列号 + len，特殊情况，如果收到报文是 SYN 报文或者 FIN 报文，则改为 + 1</em>），可以得出当前的确认号为 client_isn + 11 + 1，也就是 client_isn + 12。</li>
</ul>
<p>服务端发送的第三次挥手的序列号和确认号还是和第二次挥手中的序列号和确认号一样。</p>
<ul>
<li>序列号设置为 server_isn + 1。</li>
<li>确认号设置为 client_isn + 12。</li>
</ul>
<p>客户端发送的四次挥手的序列号和确认号分别设置为：</p>
<ul>
<li>序列号设置为 client_isn + 12。客户端上一次发送的报文是 FIN 报文，该报文的 seq &#x3D; client_isn + 11，根据公式 1（<em>序列号 &#x3D; 上一次发送的序列号 + len。特殊情况，如果收到报文是 SYN 报文或者 FIN 报文，则改为 + 1</em>），可以得出当前的序列号为 client_isn + 11 + 1，也就是 client_isn + 12。</li>
<li>确认号设置为 server_isn + 2。客户端上一次收到的报文是服务端发来的 FIN 报文，该报文的 seq &#x3D; server_isn + 1，根据公式 2（确认号 &#x3D; <em>上一次收到的序列号 + len，特殊情况，如果收到报文是 SYN 报文或者 FIN 报文，则改为 + 1</em>），可以得出当前的确认号为 server_isn + 1 + 1，也就是 server_isn + 2。</li>
</ul>
</li>
</ul>
<h3 id="5-1-IP-基础知识全家桶"><a href="#5-1-IP-基础知识全家桶" class="headerlink" title="5.1 IP 基础知识全家桶"></a>5.1 IP 基础知识全家桶</h3><h4 id="IP-基本认识"><a href="#IP-基本认识" class="headerlink" title="IP 基本认识"></a>IP 基本认识</h4><ul>
<li>IP 在 TCP&#x2F;IP 参考模型中处于第三层，也就是<strong>网络层</strong>。网络层的主要作用是：<strong>实现主机与主机之间的通信，也叫点对点（end to end）通信</strong></li>
<li>IP（网络层） 和 MAC （数据链路层）之间的区别和关系： IP 的作用是主机之间通信用的，而 <strong>MAC 的作用则是实现「直连」的两个设备之间通信，而 IP 则负责在「没有直连」的两个网络之间进行通信传输</strong>；计算机网络中需要「数据链路层」和「网络层」这个分层才能实现向最终目标地址的通信；<strong>源IP地址和目标IP地址在传输过程中是不会变化的（前提：没有使用 NAT 网络），只有源 MAC 地址和目标 MAC 一直在变化</strong></li>
</ul>
<h4 id="IP-地址的基础知识"><a href="#IP-地址的基础知识" class="headerlink" title="IP 地址的基础知识"></a>IP 地址的基础知识</h4><ul>
<li>IP 地址（IPv4 地址）由 <code>32</code> 位正整数来表示，IP 地址在计算机是以二进制的方式处理的，人类为了方便记忆采用了<strong>点分十进制</strong>的标记方式，也就是将 32 位 IP 地址以每 8 位为组，共分为 <code>4</code> 组，每组以「<code>.</code>」隔开，再将每组转换成十进制</li>
<li>IP 地址的分类：IP 地址分类成了 5 种类型，分别是 A 类、B 类、C 类、D 类、E 类<ul>
<li>对于 A、B、C 类主要分为两个部分，分别是<strong>网络号和主机号</strong>；最大主机个数要看主机号的位数，主机号全为 1 指定某个网络下的所有主机，用于广播（广播地址用于在<strong>同一个链路中相互连接的主机之间发送数据包</strong>。）；主机号全为 0 指定某个网络<ul>
<li>广播地址可以分为本地广播和直接广播两种，<strong>在本网络内广播的叫做本地广播</strong>，<strong>在不同网络之间的广播叫做直接广播</strong></li>
</ul>
</li>
<li>D 类和 E 类地址是没有主机号的，所以不可用于主机 IP，D 类常被用于<strong>多播</strong>，E 类是预留的分类；多播用于将包发送给特定组内的所有主机</li>
</ul>
</li>
<li>IP 分类的优缺点：<ul>
<li>优点：不管是路由器还是主机解析到一个 IP 地址时候，我们判断其 IP 地址的首位是否为 0，为 0 则为 A 类地址，那么就能很快的找出网络地址和主机地址</li>
<li>缺点：<strong>同一网络下没有地址层次</strong>，<strong>缺少地址的灵活性</strong>；<strong>不能很好的与现实网络匹配</strong></li>
</ul>
</li>
<li>无分类地址 CIDR：32 比特的 IP 地址被划分为两部分，前面是<strong>网络号</strong>，后面是<strong>主机号</strong><ul>
<li>表示形式 <code>a.b.c.d/x</code>，其中 <code>/x</code> 表示前 x 位属于<strong>网络号</strong>， x 的范围是 <code>0 ~ 32</code>，这就使得 IP 地址更加具有灵活性</li>
<li>还有另一种划分网络号与主机号形式，那就是<strong>子网掩码</strong>，掩码的意思就是掩盖掉主机号，剩余的就是网络号，<strong>将子网掩码和 IP 地址按位计算 AND，就可得到网络号</strong></li>
<li>为什么要分离网络号和主机号？<ul>
<li>两台计算机要通讯，首先要判断是否处于同一个广播域内，即网络地址是否相同。如果网络地址相同，表明接受方在本网络上，那么可以把数据包直接发送到目标主机</li>
<li>路由器寻址工作中，也就是通过这样的方式来找到对应的网络号的，进而把数据包转发给对应的网络内</li>
</ul>
</li>
<li>子网掩码还有一个作用：<strong>划分子网</strong>，<strong>子网划分实际上是将主机地址分为两个部分：子网网络地址和子网主机地址</strong><ul>
<li>假设对 C 类地址进行子网划分，网络地址 192.168.1.0，使用子网掩码 255.255.255.192 对其进行子网划分；C 类地址中前 24 位是网络号，最后 8 位是主机号，根据子网掩码可知<strong>从 8 位主机号中借用 2 位作为子网号</strong></li>
</ul>
</li>
</ul>
</li>
<li>公有 IP 地址与私有 IP 地址<ul>
<li>在 A、B、C 分类地址，实际上有分公有 IP 地址和私有 IP 地址；平时我们办公室、家里、学校用的 IP 地址，一般都是私有 IP 地址。因为这些地址允许组织内部的 IT 人员自己管理、自己分配，而且可以重复；公有 IP 地址是有个组织统一分配的，并且公有 IP 地址基本上要在整个互联网范围内保持唯一</li>
<li>私有 IP 地址通常是内部的 IT 人员管理，公有 IP 地址是由 <code>ICANN</code> 组织管理，中文叫「互联网名称与数字地址分配机构」</li>
</ul>
</li>
<li>IP 地址与路由控制<ul>
<li>IP地址的<strong>网络地址</strong>这一部分是用于进行路由控制。路由控制表中记录着网络地址与下一步应该发送至路由器的地址。在主机和路由器上都会有各自的路由器控制表。</li>
<li>在发送 IP 包时，首先要确定 IP 包首部中的目标地址，再从路由控制表中找到与该地址具有<strong>相同网络地址</strong>的记录，根据该记录将 IP 包转发给相应的下一个路由器。如果路由控制表中存在多条相同网络地址的记录，就选择相同位数最多的网络地址，也就是最长匹配。</li>
<li>环回地址是在同一台计算机上的程序之间进行网络通信时所使用的一个默认地址。计算机使用一个特殊的 IP 地址 <strong>127.0.0.1 作为环回地址</strong>。与该地址具有相同意义的是一个叫做 <code>localhost</code> 的主机名。使用这个 IP 或主机名时，数据包不会流向网络</li>
</ul>
</li>
<li>IP 分片与重组<ul>
<li>每种数据链路的最大传输单元 <code>MTU</code> 都是不相同的，如 FDDI 数据链路 MTU 4352、以太网的 MTU 是 1500 字节等。每种数据链路的 MTU 之所以不同，是因为每个不同类型的数据链路的使用目的不同。使用目的不同，可承载的 MTU 也就不同。其中，我们最常见数据链路是以太网，它的 MTU 是 <code>1500</code> 字节。</li>
<li>那么当 IP 数据包大小大于 MTU 时， IP 数据包就会被分片;经过分片之后的 IP 数据报在被重组的时候，只能由目标主机进行，路由器是不会进行重组的。</li>
<li>在分片传输中，一旦某个分片丢失，则会造成整个 IP 数据报作废，所以 TCP 引入了 <code>MSS</code> 也就是在 TCP 层进行分片不由 IP 层分片，那么对于 UDP 我们尽量不要发送一个大于 <code>MTU</code> 的数据报文</li>
</ul>
</li>
</ul>
<h4 id="IPv6-基本认识"><a href="#IPv6-基本认识" class="headerlink" title="IPv6 基本认识"></a>IPv6 基本认识</h4><ul>
<li><p>IPv6 地址长度是 128 位，是以每 16 位作为一组，每组用冒号 「:」 隔开</p>
<ul>
<li>如果出现连续的 0 时还可以将这些 0 省略，并用两个冒号 「::」隔开。但是，一个 IP 地址中只允许出现一次两个连续的冒号</li>
</ul>
</li>
<li><p>IPv6 可自动配置，即使没有 DHCP 服务器也可以实现自动分配IP地址</p>
</li>
<li><p>IPv6 包头包首部长度采用固定的值 <code>40</code> 字节，去掉了包头校验和，简化了首部结构，减轻了路由器负荷，大大<strong>提高了传输的性能</strong></p>
</li>
<li><p>IPv6 有应对伪造 IP 地址的网络安全功能以及防止线路窃听的功能，大大<strong>提升了安全性</strong></p>
</li>
<li><p>IPv6 的地址主要有以下类型地址：</p>
<ul>
<li>单播地址，用于一对一的通信,主要划分了三类单播地址，每类地址的有效范围都不同<ul>
<li>在同一链路单播通信，不经过路由器，可以使用<strong>链路本地单播地址</strong>，IPv4 没有此类型</li>
<li>在内网里单播通信，可以使用<strong>唯一本地地址</strong>，相当于 IPv4 的私有 IP</li>
<li>在互联网通信，可以使用<strong>全局单播地址</strong>，相当于 IPv4 的公有 IP</li>
</ul>
</li>
<li>组播地址，用于一对多的通信</li>
<li>任播地址，用于通信最近的节点，最近的节点是由路由协议决定</li>
<li>没有广播地址</li>
</ul>
</li>
<li><p>IPv6 相比 IPv4 的首部改进：</p>
<ul>
<li><strong>取消了首部校验和字段。</strong> 因为在数据链路层和传输层都会校验，因此 IPv6 直接取消了 IP 的校验。</li>
<li><strong>取消了分片&#x2F;重新组装相关字段。</strong> 分片与重组是耗时的过程，IPv6 不允许在中间路由器进行分片与重组，这种操作只能在源与目标主机，这将大大提高了路由器转发的速度。</li>
<li><strong>取消选项字段。</strong> 选项字段不再是标准 IP 首部的一部分了，但它并没有消失，而是可能出现在 IPv6 首部中的「下一个首部」指出的位置上。删除该选项字段使的 IPv6 的首部成为固定长度的 <code>40</code> 字节</li>
</ul>
</li>
</ul>
<h4 id="IP-协议相关技术"><a href="#IP-协议相关技术" class="headerlink" title="IP 协议相关技术"></a>IP 协议相关技术</h4><p><strong>DNS</strong></p>
<ul>
<li>在上网的时候，通常使用的方式是域名，而不是 IP 地址，因为域名方便人类记忆。那么实现这一技术的就是 <strong>DNS 域名解析</strong>，DNS 可以将域名网址自动转换为具体的 IP 地址。</li>
<li>DNS 中的域名都是用<strong>句点</strong>来分隔的，比如 <code>www.server.com</code>，这里的句点代表了不同层次之间的<strong>界限</strong>。在域名中，<strong>越靠右</strong>的位置表示其层级<strong>越高</strong></li>
<li>所以域名的层级关系类似一个树状结构：<ul>
<li>根 DNS 服务器</li>
<li>顶级域 DNS 服务器（com）</li>
<li>权威 DNS 服务器（server.com）</li>
</ul>
</li>
<li>根域的 DNS 服务器信息保存在互联网中所有的 DNS 服务器中。这样一来，任何 DNS 服务器就都可以找到并访问根域 DNS 服务器了。因此，客户端只要能够找到任意一台 DNS 服务器，就可以通过它找到根域 DNS 服务器，然后再一路顺藤摸瓜找到位于下层的某台目标 DNS 服务器</li>
<li>域名解析的工作流程：浏览器缓存 -&gt; 系统本地缓存 -&gt; host文件 -&gt; 本地DNS -&gt; 根DNS -&gt; 顶级域名服务器(.com) -&gt; 权威域名服务器</li>
</ul>
<p><strong>ARP</strong></p>
<ul>
<li>在传输一个 IP 数据报的时候，确定了源 IP 地址和目标 IP 地址后，就会通过主机「路由表」确定 IP 数据包下一跳。然而，网络层的下一层是数据链路层，所以我们还要知道「下一跳」的 MAC 地址。由于主机的路由表中可以找到下一跳的 IP 地址，所以可以通过 <strong>ARP 协议</strong>，求得下一跳的 MAC 地址</li>
<li>ARP 是借助 <strong>ARP 请求与 ARP 响应</strong>两种类型的包确定 MAC 地址的<ul>
<li>主机会通过<strong>广播发送 ARP 请求</strong>，这个包中包含了想要知道的 MAC 地址的主机 IP 地址。</li>
<li>当同个链路中的所有设备收到 ARP 请求时，会去拆开 ARP 请求包里的内容，如果 ARP 请求包中的目标 IP 地址与自己的 IP 地址一致，那么这个设备就将自己的 MAC 地址塞入 <strong>ARP 响应包</strong>返回给主机</li>
</ul>
</li>
<li>操作系统通常会把第一次通过 ARP 获取的 MAC 地址缓存起来，以便下次直接从缓存中找到对应 IP 地址的 MAC 地址。不过，MAC 地址的缓存是有一定期限的，超过这个期限，缓存的内容将被清除</li>
<li>ARP 协议是已知 IP 地址求 MAC 地址，那 RARP 协议正好相反，它是<strong>已知 MAC 地址求 IP 地址</strong>。例如将打印机服务器等小型嵌入式设备接入到网络时就经常会用得到。</li>
</ul>
<p><strong>DHCP</strong></p>
<ul>
<li><p>我们的电脑通常都是通过 DHCP 动态获取 IP 地址，大大省去了配 IP 信息繁琐的过程</p>
</li>
<li><p>DHCP 客户端进程监听的是 68 端口号，DHCP 服务端进程监听的是 67 端口号。</p>
</li>
<li><p>整体步骤：</p>
<ul>
<li>客户端首先发起 <strong>DHCP 发现报文（DHCP DISCOVER）</strong> 的 IP 数据报，由于客户端没有 IP 地址，也不知道 DHCP 服务器的地址，所以使用的是 UDP <strong>广播</strong>通信，其使用的广播目的地址是 255.255.255.255（端口 67） 并且使用 0.0.0.0（端口 68） 作为源 IP 地址。DHCP 客户端将该 IP 数据报传递给链路层，链路层然后将帧广播到所有的网络中设备。</li>
<li>DHCP 服务器收到 DHCP 发现报文时，用 <strong>DHCP 提供报文（DHCP OFFER）</strong> 向客户端做出响应。该报文仍然使用 IP 广播地址 255.255.255.255，该报文信息携带服务器提供可租约的 IP 地址、子网掩码、默认网关、DNS 服务器以及 <strong>IP 地址租用期</strong>。</li>
<li>客户端收到一个或多个服务器的 DHCP 提供报文后，从中选择一个服务器，并向选中的服务器发送 <strong>DHCP 请求报文（DHCP REQUEST</strong>进行响应，回显配置的参数。</li>
<li>最后，服务端用 <strong>DHCP ACK 报文</strong>对 DHCP 请求报文进行响应，应答所要求的参数</li>
</ul>
</li>
<li><p>一旦客户端收到 DHCP ACK 后，交互便完成了，并且客户端能够在租用期内使用 DHCP 服务器分配的 IP 地址。</p>
</li>
<li><p>如果租约的 DHCP IP 地址快期后，客户端会向服务器发送 DHCP 请求报文：</p>
<ul>
<li>服务器如果同意继续租用，则用 DHCP ACK 报文进行应答，客户端就会延长租期。</li>
<li>服务器如果不同意继续租用，则用 DHCP NACK 报文，客户端就要停止使用租约的 IP 地址</li>
</ul>
</li>
<li><p>DHCP 交互中，<strong>全程都是使用 UDP 广播通信</strong>。如果 DHCP 服务器和客户端不是在同一个局域网内，路由器又不会转发广播包，那不是每个网络都要配一个 DHCP 服务器？</p>
<ul>
<li>为了解决这一问题，就出现了 <strong>DHCP 中继代理</strong>。有了 DHCP 中继代理以后，<strong>对不同网段的 IP 地址分配也可以由一个 DHCP 服务器统一进行管理。</strong></li>
<li>DHCP 客户端会向 DHCP 中继代理发送 DHCP 请求包，而 DHCP 中继代理在收到这个广播包以后，再以<strong>单播</strong>的形式发给 DHCP 服务器。</li>
<li>服务器端收到该包以后再向 DHCP 中继代理返回应答，并由 DHCP 中继代理将此包广播给 DHCP 客户端 。</li>
</ul>
<p>因此，DHCP 服务器即使不在同一个链路上也可以实现统一分配和管理IP地址</p>
</li>
</ul>
<p><strong>NAT</strong></p>
<ul>
<li>IPv4 的地址是非常紧缺的，于是，提出了一种<strong>网络地址转换 NAT</strong> 的方法，再次缓解了 IPv4 地址耗尽的问题</li>
<li>简单的来说 NAT 就是同个公司、家庭、教室内的主机对外部通信时，把私有 IP 地址转换成公有 IP 地址</li>
<li>普通的 NAT 转换没什么意义。由于绝大多数的网络应用都是使用传输层协议 TCP 或 UDP 来传输数据的。因此，可以把 IP 地址 + 端口号一起进行转换。这样，就用一个全球 IP 地址就可以了，这种转换技术就叫<strong>网络地址与端口转换 NAPT。</strong><ul>
<li><strong>两个私有 IP 地址都转换 IP 地址为公有地址 120.229.175.121，但是以不同的端口号作为区分</strong></li>
<li>生成一个 NAPT 路由器的转换表，就可以正确地转换地址跟端口的组合，令客户端 A、B 能同时与服务器之间进行通信。这种转换表在 NAT 路由器上自动生成。</li>
<li>在 TCP 的情况下，建立 TCP 连接首次握手时的 SYN 包一经发出，就会生成这个表。而后又随着收到关闭连接时发出 FIN 包的确认应答从表中被删除。</li>
</ul>
</li>
<li>由于 NAT&#x2F;NAPT 都依赖于自己的转换表，因此会有以下的问题：<ul>
<li>外部无法主动与 NAT 内部服务器建立连接，因为 NAPT 转换表没有转换记录。</li>
<li>转换表的生成与转换操作都会产生性能开销。</li>
<li>通信过程中，如果 NAT 路由器重启了，所有的 TCP 连接都将被重置</li>
</ul>
</li>
<li>解决的方法主要有两种方法。<ul>
<li><em>第一种就是改用 IPv6</em>：IPv6 可用范围非常大，以至于每台设备都可以配置一个公有 IP 地址，就不搞那么多花里胡哨的地址转换了，但是 IPv6 普及速度还需要一些时间。</li>
<li><em>第二种 NAT 穿透技术</em>：NAT 穿越技术拥有这样的功能，它能够让网络应用程序主动发现自己位于 NAT 设备之后，并且会主动获得 NAT 设备的公有 IP，并为自己建立端口映射条目，注意这些都是 NAT设备后的应用程序自动完成的。客户端主动从 NAT 设备获取公有 IP 地址，然后自己建立端口映射条目，然后用这个条目对外通信，就不需要 NAT 设备来进行转换了</li>
</ul>
</li>
</ul>
<p> <strong>ICMP</strong></p>
<ul>
<li>ICMP 全称是 <strong>Internet Control Message Protocol</strong>，也就是<strong>互联网控制报文协议</strong></li>
<li><code>ICMP</code> 主要的功能包括：<strong>确认 IP 包是否成功送达目标地址、报告发送过程中 IP 包被废弃的原因和改善网络设置等。</strong>在 <code>IP</code> 通信中如果某个 <code>IP</code> 包因为某种原因未能达到目标地址，那么这个具体的原因将<strong>由 ICMP 负责通知</strong>。<ul>
<li>ICMP 的这种通知消息会使用 <code>IP</code> 进行发送 。因此， 返回的 ICMP 包会按照往常的路由控制转发给主机 <code>A</code> 。收到该 ICMP 包的主机 <code>A</code> 则分解 ICMP 的首部和数据域以后得知具体发生问题的原因</li>
</ul>
</li>
<li>ICMP 大致可以分为两大类：<ul>
<li>一类是用于诊断的查询消息，也就是「<strong>查询报文类型</strong>」</li>
<li>另一类是通知出错原因的错误消息，也就是「<strong>差错报文类型</strong>」</li>
</ul>
</li>
</ul>
<p><strong>IGMP</strong></p>
<ul>
<li><strong>IGMP 是因特网组管理协议，工作在主机（组播成员）和最后一跳路由之间</strong><ul>
<li>IGMP 报文向路由器申请加入和退出组播组，默认情况下路由器是不会转发组播包到连接中的主机，除非主机通过 IGMP 加入到组播组，主机申请加入到组播组时，路由器就会记录 IGMP 路由器表，路由器后续就会转发组播包到对应的主机了。</li>
<li>IGMP 报文采用 IP 封装，IP 头部的协议号为 2，而且 TTL 字段值通常为 1，因为 IGMP 是工作在主机与连接的路由器之间。</li>
</ul>
</li>
<li><em>常规查询与响应工作机制</em>：<ul>
<li>路由器会周期性发送目的地址为 <code>224.0.0.1</code>（表示同一网段内所有主机和路由器） <strong>IGMP 常规查询报文</strong>。</li>
<li>主机1 和 主机 3 收到这个查询，随后会启动「报告延迟计时器」，计时器的时间是随机的，通常是 0~10 秒，计时器超时后主机就会发送 <strong>IGMP 成员关系报告报文</strong>（源 IP 地址为自己主机的 IP 地址，目的 IP 地址为组播地址）。如果在定时器超时之前，收到同一个组内的其他主机发送的成员关系报告报文，则自己不再发送，这样可以减少网络中多余的 IGMP 报文数量。</li>
<li>路由器收到主机的成员关系报文后，就会在 IGMP 路由表中加入该组播组，后续网络中一旦该组播地址的数据到达路由器，它会把数据包转发出去</li>
</ul>
</li>
<li><em>离开组播组工作机制</em><ul>
<li>网段中仍有该组播组：<ul>
<li>主机 1 要离开组 224.1.1.1，发送 IGMPv2 离组报文，报文的目的地址是 224.0.0.2（表示发向网段内的所有路由器）</li>
<li>路由器 收到该报文后，以 1 秒为间隔连续发送 IGMP 特定组查询报文（共计发送 2 个），以便确认该网络是否还有 224.1.1.1 组的其他成员。</li>
<li>主机 3 仍然是组 224.1.1.1 的成员，因此它立即响应这个特定组查询。路由器知道该网络中仍然存在该组播组的成员，于是继续向该网络转发 224.1.1.1 的组播数据包。</li>
</ul>
</li>
<li>网段中没有该组播组：<ul>
<li>主机 1 要离开组播组 224.1.1.1，发送 IGMP 离组报文。</li>
<li>路由器收到该报文后，以 1 秒为间隔连续发送 IGMP 特定组查询报文（共计发送 2 个）。此时在该网段内，组 224.1.1.1 已经没有其他成员了，因此没有主机响应这个查询。</li>
<li>一定时间后，路由器认为该网段中已经没有 224.1.1.1 组播组成员了，将不会再向这个网段转发该组播地址的数据包。</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="5-2-ping-的工作原理"><a href="#5-2-ping-的工作原理" class="headerlink" title="5.2 ping 的工作原理"></a>5.2 ping 的工作原理</h3><ul>
<li><p>ICMP 全称是 <strong>Internet Control Message Protocol</strong>，也就是<strong>互联网控制报文协议</strong>, 主要的功能包括：<strong>确认 IP 包是否成功送达目标地址、报告发送过程中 IP 包被废弃的原因和改善网络设置等</strong>；ICMP 报文封装在 IP 包里面，工作在网络层，是 IP 协议的助手，ICMP 包头的<strong>类型</strong>字段，大致可以分为两大类：查询报文类型（用于诊断）和差错报文类型（通知出错原因）</p>
</li>
<li><p><strong>查询报文类型</strong>：回送消息 —— 类型 <code>0</code> 和 <code>8</code></p>
<ul>
<li><p>用于进行通信的主机或路由器之间，判断所发送的数据包是否已经成功到达对端的一种消息，**<code>ping</code> 命令就是利用这个消息实现的**；</p>
</li>
<li><p>可以向对端主机发送<strong>回送请求</strong>的消息（<code>ICMP Echo Request Message</code>，类型 <code>8</code>）也可以接收对端主机发回来的<strong>回送应答</strong>消息（<code>ICMP Echo Reply Message</code>，类型 <code>0</code>）</p>
</li>
<li><p>相比原生的 ICMP，这里多了两个字段：</p>
<ul>
<li><strong>标识符</strong>：用以区分是哪个应用程序发 ICMP 包，比如用进程 <code>PID</code> 作为标识符；</li>
<li><strong>序号</strong>：序列号从 <code>0</code> 开始，每发送一次新的回送请求就会加 <code>1</code>， 可以用来确认网络包是否有丢失。</li>
</ul>
<p>在<strong>选项数据</strong>中，<code>ping</code> 还会存放发送请求的时间值，来计算往返时间，说明路程的长短</p>
</li>
</ul>
</li>
<li><p>常用的 ICMP 差错报文的例子：</p>
<ul>
<li>目标不可达消息 —— 类型 为 <code>3</code>：IP 路由器无法将 IP 数据包发送给目标地址，在这个消息中显示不可达的具体原因，原因记录在 ICMP 包头的<strong>代码</strong>字段。<ul>
<li>网络不可达代码为 <code>0</code>，路由器中的路由器表匹配不到接收方 IP 的网络号</li>
<li>主机不可达代码为 <code>1</code>，路由表中没有该主机的信息，或者该主机没有连接到网络</li>
<li>协议不可达代码为 <code>2</code>，对端主机的防火墙已经禁止 TCP 协议访问</li>
<li>端口不可达代码为 <code>3</code>，端主机没有进程监听 8080 端口</li>
<li>需要进行分片但设置了不分片位代码为 <code>4</code>， IP 首部的<strong>分片禁止标志位</strong>设置为<code>1</code>。根据这个标志位，途中的路由器遇到超过 MTU 大小的数据包时，不会进行分片，而是直接抛弃</li>
</ul>
</li>
<li>原点抑制消息 —— 类型 <code>4</code>：路由器向低速线路发送数据时，其发送队列的缓存变为零而无法发送出去时，可以向 IP 包的源地址发送一个 ICMP <strong>原点抑制消息</strong></li>
<li>重定向消息 —— 类型 <code>5</code>，路由器发现发送端主机使用了「不是最优」的路径发送数据，会返回一个 ICMP <strong>重定向消息</strong>给这个主机，在这个消息中包含了<strong>最合适的路由信息和源数据</strong>。</li>
<li>超时消息 —— 类型 <code>11</code>，IP 包中有一个字段叫做 <code>TTL</code> （<code>Time To Live</code>，生存周期），它的<strong>值随着每经过一次路由器就会减 1，直到减到 0 时该 IP 包会被丢弃。</strong></li>
</ul>
</li>
<li><p><code>ping</code> 的<strong>发送和接收过程</strong>：</p>
<ul>
<li>ping 命令执行的时候，源主机首先会构建一个 <strong>ICMP 回送请求消息</strong>数据包，最重要的是两个：第一个是<strong>类型</strong>，对于回送请求消息而言该字段为 <code>8</code>；另外一个是<strong>序号</strong>，主要用于区分连续 ping 的时候发出的多个数据包。每发出一个请求数据包，序号会自动加 <code>1</code>。为了能够计算往返时间 <code>RTT</code>，它会在报文的数据部分插入发送时间；由 ICMP 协议将这个数据包连同地址一起交给 IP 层，构建一个 <code>IP</code> 数据包</li>
<li>接下来，需要加入 <code>MAC</code> 头；如果在本地 ARP 映射表中查找出 IP 地址的MAC地址则可以直接使用，否则发送 <code>ARP</code> 协议查询 MAC 地址，由数据链路层构建一个数据帧</li>
<li>主机 <code>B</code> 收到这个数据帧后，先检查它的目的 MAC 地址，并和本机的 MAC 地址对比，如符合，则接收，否则就丢弃；接收后检查该数据帧，将 IP 数据包从帧中提取出来，交给本机的 IP 层。同样，IP 层检查后，将有用的信息提取后交给 ICMP 协议</li>
<li>主机 <code>B</code> 会构建一个 <strong>ICMP 回送响应消息</strong>数据包，回送响应数据包的<strong>类型</strong>字段为 <code>0</code>，<strong>序号</strong>为接收到的请求数据包中的序号，然后再发送出去给主机 A</li>
<li>在规定的时候间内，源主机如果没有接到 ICMP 的应答包，则说明目标主机不可达；如果接收到了 ICMP 回送响应消息，则说明目标主机可达。此时，源主机会检查，用当前时刻减去该数据包最初从源主机上发出的时刻，就是 ICMP 数据包的时间延迟。</li>
</ul>
<p> ping 这个程序是<strong>使用了 ICMP 里面的 ECHO REQUEST（类型为 8 ） 和 ECHO REPLY （类型为 0）</strong></p>
</li>
<li><p>traceroute —— 差错报文类型的使用：</p>
<ul>
<li><strong>故意设置特殊的 TTL，来追踪去往目的地时沿途经过的路由器</strong><ul>
<li>它的原理就是利用 IP 包的<strong>生存期限</strong> 从 <code>1</code> 开始按照顺序递增的同时发送 <strong>UDP 包</strong>，强制接收 <strong>ICMP 超时消息</strong>的一种方法</li>
<li>traceroute 在发送 <code>UDP</code> 包时，会填入一个<strong>不可能的端口号</strong>值作为 UDP 目标端口号（大于 <code>3000</code> ）。当目的主机，收到 UDP 包后，会返回 ICMP 差错报文消息，但这个差错报文消息的类型是「<strong>端口不可达</strong>」。<strong>当差错报文类型是端口不可达时，说明发送方发出的 UDP 包到达了目的主机。</strong></li>
</ul>
</li>
<li><strong>故意设置不分片，从而确定路径的 MTU</strong><ul>
<li>首先在发送端主机发送 <code>IP</code> 数据报时，将 <code>IP</code> 包首部的<strong>分片禁止标志位设置为 1</strong>。根据这个标志位，途中的路由器不会对大数据包进行分片，而是将包丢弃。</li>
<li>随后，通过一个 ICMP 的不可达消息将<strong>数据链路上 MTU 的值</strong>一起给发送主机，不可达消息的类型为「<strong>需要进行分片但设置了不分片位</strong>」。</li>
<li>发送主机端每次收到 ICMP 差错报文时就<strong>减少</strong>包的大小，以此来定位一个合适的 <code>MTU</code> 值，以便能到达目标主机。</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="MySQL"><a href="#MySQL" class="headerlink" title="MySQL"></a>MySQL</h2><blockquote>
<h3 id="公众号文章"><a href="#公众号文章" class="headerlink" title="公众号文章"></a>公众号文章</h3></blockquote>
<h3 id="MySQL-记录锁-间隙锁可以防止删除操作而导致的幻读吗？"><a href="#MySQL-记录锁-间隙锁可以防止删除操作而导致的幻读吗？" class="headerlink" title="MySQL 记录锁+间隙锁可以防止删除操作而导致的幻读吗？"></a><strong>MySQL 记录锁+间隙锁可以防止删除操作而导致的幻读吗</strong>？</h3><ul>
<li><p>幻读的定义：当同一个查询在不同的时间产生不同的结果集时，事务中就会出现所谓的幻象问题；</p>
</li>
<li><p>MySQL 可重复读隔离级别可以解决幻读问题，查询数据的操作有两种方式，所以解决的方式是不同的：</p>
<ul>
<li>针对<strong>快照读</strong>（普通 select 语句），是<strong>通过 MVCC 方式解决了幻读</strong>，因为可重复读隔离级别下，事务执行过程中看到的数据，一直跟这个事务启动时看到的数据是一致的，即使中途有其他事务插入了一条数据，是查询不出来这条数据的，所以就很好了避免幻读问题。</li>
<li>针对<strong>当前读</strong>（select … for update 等语句），是<strong>通过 next-key lock（记录锁+间隙锁）方式解决了幻读</strong>，因为当执行 select … for update 语句的时候，会加上 next-key lock，如果有其他事务在 next-key lock 锁范围内插入了一条记录，那么这个插入语句就会被阻塞，无法成功插入，所以就很好了避免幻读问题</li>
</ul>
</li>
<li><p>通过 <code>select * from performance_schema.data_locks\G;</code> 查看事务执行 SQL 过程中加了什么锁：</p>
<ul>
<li>表锁（<code>LOCK_TYPE: TABLE</code>）：X 类型的意向锁；</li>
<li>行锁（<code>LOCK_TYPE: RECORD</code>）：X 类型的 next-key 锁<ul>
<li>如果 LOCK_MODE 为 <code>X</code>，说明是 next-key 锁；</li>
<li>如果 LOCK_MODE 为 <code>X, REC_NOT_GAP</code>，说明是记录锁；</li>
<li>如果 LOCK_MODE 为 <code>X, GAP</code>，说明是间隙锁；</li>
</ul>
</li>
<li>如果 LOCK_MODE 是 next-key 锁或者间隙锁，那么 <strong>LOCK_DATA 就表示锁的范围最右值</strong>，而锁范围的最左值为 LOCK_DATA 的上一条记录的值</li>
</ul>
</li>
<li><p>实验分析，在可重复读隔离级别下，针对无索引的查询语句，<strong>相当于把整个表给锁住了，其他事务在对该表进行增、删、改操作的时候都会被阻塞</strong>；因为这条查询语句会进行<strong>全表扫描，锁是在遍历索引的时候加上的，并不是针对输出的结果加锁</strong>；因此，在线上在执行 update、delete、select … for update 等具有加锁性质的语句，一定要检查语句是否走了索引，如果是全表扫描的话，会对每一个索引加 next-key 锁</p>
</li>
<li><p>如果对查找字段建立了索引，则<strong>因为表中有两个索引，分别是主键索引和 age 索引，所以会分别对这两个索引加锁</strong>；查询语句是索引查询，并不会全表扫描，因此<strong>不会把整张表给锁住</strong></p>
<img src="https://mmbiz.qpic.cn/mmbiz_png/J0g14CUwaZfZJqiauZPNWqz1jmVXOQ5lDnpSiaM6mgX4gBFbg5wQvn7uicXuh2AqDyI4Z2D51F42p3nXhS3bRyQgQ/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1" alt="图片" style="zoom: 33%;" /></li>
</ul>
<h3 id="2-1-执行一条-select-语句，期间发生了什么？"><a href="#2-1-执行一条-select-语句，期间发生了什么？" class="headerlink" title="2.1 执行一条 select 语句，期间发生了什么？"></a>2.1 执行一条 select 语句，期间发生了什么？</h3><ul>
<li><p>MySQL 的架构共分为两层：<strong>Server 层和存储引擎层</strong>，</p>
<ul>
<li><strong>Server 层负责建立连接、分析和执行 SQL</strong>。MySQL 大多数的核心功能模块都在这实现，主要包括连接器，查询缓存、解析器、预处理器、优化器、执行器等。另外，所有的内置函数（如日期、时间、数学和加密函数等）和所有跨存储引擎的功能（如存储过程、触发器、视图等。）都在 Server 层实现。</li>
<li><strong>存储引擎层负责数据的存储和提取</strong>。支持 InnoDB、MyISAM、Memory 等多个存储引擎，不同的存储引擎共用一个 Server 层。常说的索引数据结构，就是由存储引擎层实现的，不同的存储引擎支持的索引类型也不相同，比如 InnoDB 支持索引类型是 B+树 ，在数据表中创建的主键索引和二级索引默认使用的是 B+ 树索引。</li>
</ul>
</li>
<li><p>第一步：连接器</p>
<ul>
<li>连接的过程需要先经过 TCP 三次握手，因为 MySQL 是基于 TCP 协议进行传输的；完成 TCP 连接的建立后，连接器就要开始验证用户名和密码，如果用户名或密码不对，就收到一个”Access denied for user”的错误，然后客户端程序结束执行；如果用户密码都没有问题，连接器就会获取该用户的权限，然后保存起来，后续该用户在此连接里的任何操作，都会基于连接开始时读到的权限进行权限逻辑的判断</li>
<li>执行 <code>show processlist</code> 命令进行查看MySQL 服务被多少个客户端连接；定义了空闲连接的最大空闲时长，由 <code>wait_timeout</code> 参数控制的，默认值是 8 小时（28880秒），如果空闲连接超过了这个时间，连接器就会自动将它断开；MySQL 服务支持的最大连接数由 max_connections 参数控制</li>
<li>MySQL 的连接也跟 HTTP 一样，有短连接和长连接的概念，使用长连接的好处就是可以减少建立连接和断开连接的过程，所以一般是推荐使用长连接；但是使用长连接后可能会占用内存增多，因为 MySQL 在执行查询过程中临时使用内存管理连接对象，这些连接对象资源只有在连接断开时才会释放。如果长连接累计很多，将导致 MySQL 服务占用内存太大，有可能会被系统强制杀掉，这样会发生 MySQL 服务异常重启的现象，有两种解决方式：<strong>定期断开长连接</strong>；<strong>客户端主动重置连接</strong></li>
</ul>
</li>
<li><p>第二步：查询缓存；以 key-value 形式保存在内存中的，key 为 SQL 查询语句，value 为 SQL 语句查询的结果；如果查询的语句命中查询缓存，那么就会直接返回 value 给客户端。对于更新比较频繁的表，查询缓存的命中率很低的，因为只要一个表有更新操作，那么这个表的查询缓存就会被清空，MySQL 8.0 版本直接将查询缓存删掉了</p>
</li>
<li><p>第三步：解析 SQL；解析器会做词法分析（构建出 SQL 语法树）和<strong>语法分析</strong>，输入的 SQL 语句语法不对，就会在解析器这个阶段报错；但是表不存在或者字段不存在，并不是在解析器里做的，而是在执行SQL的预处理阶段做的</p>
</li>
<li><p>第四步：执行 SQL；每条<code>SELECT</code> 查询语句流程主要可以分为下面这三个阶段：prepare 阶段，预处理阶段；optimize 阶段，优化阶段；execute 阶段，执行阶段</p>
<ul>
<li>预处理阶段检查 SQL 查询语句中的表或者字段是否存在；将 <code>select *</code> 中的 <code>*</code> 符号，扩展为表上的所有列</li>
<li><strong>优化器主要负责将 SQL 查询语句的执行方案确定下来</strong>，比如在表里面有多个索引的时候，优化器会基于查询成本的考虑，来决定选择使用哪个索引</li>
<li>确定了执行方案，接下来 MySQL 就真正开始执行语句了，这个工作是由「执行器」完成的。在执行的过程中，执行器就会和存储引擎交互了，交互是以记录为单位的</li>
</ul>
</li>
</ul>
<h3 id="3-1-索引常见面试题"><a href="#3-1-索引常见面试题" class="headerlink" title="3.1 索引常见面试题"></a>3.1 索引常见面试题</h3><h4 id="什么是索引？"><a href="#什么是索引？" class="headerlink" title="什么是索引？"></a>什么是索引？</h4><ul>
<li>索引的定义就是帮助存储引擎快速获取数据的一种数据结构，形象的说就是<strong>索引是数据的目录</strong></li>
<li>存储引擎就是如何存储数据、如何为存储的数据建立索引和如何更新、查询数据等技术的实现方法，索引和数据位于存储引擎中</li>
</ul>
<h4 id="索引的分类"><a href="#索引的分类" class="headerlink" title="索引的分类"></a>索引的分类</h4><ul>
<li>按「数据结构」分类：<strong>B+tree索引、Hash索引、Full-text索引</strong>。<ul>
<li>InnoDB 是在 MySQL 5.5 之后成为默认的 MySQL 存储引擎，B+Tree 索引类型也是 MySQL 存储引擎采用最多的索引类型</li>
<li><strong>创建的主键索引和二级索引默认使用的是 B+Tree 索引</strong></li>
</ul>
</li>
<li>按「物理存储」分类：<strong>聚簇索引（主键索引）、二级索引（辅助索引）</strong>。<ul>
<li>主键索引的 B+Tree 的叶子节点存放的是实际数据，所有完整的用户记录都存放在主键索引的 B+Tree 的叶子节点里；</li>
<li>二级索引的 B+Tree 的叶子节点存放的是主键值，而不是实际数据。</li>
</ul>
</li>
<li>按「字段特性」分类：<strong>主键索引、唯一索引、普通索引、前缀索引</strong>。<ul>
<li>主键索引就是建立在主键字段上的索引，通常在创建表的时候一起创建，一张表最多只有一个主键索引，索引列的值不允许有空值</li>
<li>唯一索引建立在 UNIQUE 字段上的索引，一张表可以有多个唯一索引，索引列的值必须唯一，但是允许有空值</li>
<li>普通索引就是建立在普通字段上的索引，既不要求字段为主键，也不要求字段为 UNIQUE</li>
<li>前缀索引是指对字符类型字段的前几个字符建立的索引，而不是在整个字段上建立的索引，前缀索引可以建立在字段类型为 char、 varchar、binary、varbinary 的列上；使用前缀索引的目的是为了减少索引占用的存储空间，提升查询效率</li>
</ul>
</li>
<li>按「字段个数」分类：<strong>单列索引、联合索引</strong><ul>
<li>通过将多个字段组合成一个索引，该索引就被称为联合索引，联合索引存在<strong>最左匹配原则</strong>，按照最左优先的方式进行索引的匹配</li>
<li>MySQL 5.6 引入的<strong>索引下推优化</strong>（index condition pushdown)， <strong>可以在联合索引遍历过程中，对联合索引中包含的字段先做判断，直接过滤掉不满足条件的记录，减少回表次数</strong></li>
<li>实际开发工作中<strong>建立联合索引时，要把区分度大的字段排在前面，这样区分度大的字段越有可能被更多的 SQL 使用到</strong></li>
</ul>
</li>
</ul>
<h4 id="什么时候需要-x2F-不需要创建索引？"><a href="#什么时候需要-x2F-不需要创建索引？" class="headerlink" title="什么时候需要 &#x2F; 不需要创建索引？"></a>什么时候需要 &#x2F; 不需要创建索引？</h4><ul>
<li><p>索引也是有缺点的，比如：</p>
<ul>
<li><p>需要占用物理空间，数量越大，占用空间越大；</p>
</li>
<li><p>创建索引和维护索引要耗费时间，这种时间随着数据量的增加而增大；</p>
</li>
<li><p>会降低表的增删改的效率，因为每次增删改索引，B+ 树为了维护索引有序性，都需要进行动态维护</p>
</li>
</ul>
</li>
<li><p>什么时候适用索引？</p>
<ul>
<li>字段有唯一性限制的，比如商品编码；</li>
<li>经常用于 <code>WHERE</code> 查询条件的字段，这样能够提高整个表的查询速度，如果查询条件不是一个字段，可以建立联合索引。</li>
<li>经常用于 <code>GROUP BY</code> 和 <code>ORDER BY</code> 的字段，这样在查询的时候就不需要再去做一次排序了，因为我们都已经知道了建立索引之后在 B+Tree 中的记录都是排序好的</li>
</ul>
</li>
<li><p>什么时候不需要创建索引？</p>
<ul>
<li><code>WHERE</code> 条件，<code>GROUP BY</code>，<code>ORDER BY</code> 里用不到的字段，索引的价值是快速定位，如果起不到定位的字段通常是不需要创建索引的，因为索引是会占用物理空间的。</li>
<li>字段中存在大量重复数据，不需要创建索引，MySQL 有一个查询优化器，查询优化器发现某个值出现在表的数据行中的百分比很高的时候，它一般会忽略索引，进行全表扫描</li>
<li>表数据太少的时候，不需要创建索引；</li>
<li>经常更新的字段不用创建索引，比如不要对电商项目的用户余额建立索引，因为索引字段频繁修改，由于要维护 B+Tree的有序性，那么就需要频繁的重建索引，这个过程是会影响数据库性能的</li>
</ul>
</li>
</ul>
<h4 id="有什么优化索引的方法？"><a href="#有什么优化索引的方法？" class="headerlink" title="有什么优化索引的方法？"></a>有什么优化索引的方法？</h4><ul>
<li>前缀索引优化；<ul>
<li>使用前缀索引是为了减小索引字段大小，可以增加一个索引页中存储的索引值，有效提高索引的查询速度</li>
<li>不过前缀索引有一定的局限性，例如：<ul>
<li>order by 就无法使用前缀索引；</li>
<li>无法把前缀索引用作覆盖索引</li>
</ul>
</li>
</ul>
</li>
<li>覆盖索引优化；<ul>
<li>覆盖索引是指 SQL 中 query 的所有字段，在索引 B+Tree 的叶子节点上都能找得到的那些索引，从二级索引中查询得到记录，而不需要通过聚簇索引查询获得，可以避免回表的操作</li>
</ul>
</li>
<li>主键索引最好是自增的；<ul>
<li><strong>如果使用自增主键</strong>，每次插入的新数据就会按顺序添加到当前索引节点的位置，不需要移动已有的数据，当页面写满，就会自动开辟一个新页面。因为每次<strong>插入一条新记录，都是追加操作，不需要重新移动数据</strong>，因此这种插入数据的方法效率非常高</li>
<li><strong>如果使用非自增主键</strong>，由于每次插入主键的索引值都是随机的，因此可能会插入到现有数据页中间的某个位置，这将不得不移动其它数据来满足新数据的插入，甚至需要从一个页面复制数据到另外一个页面，通常将这种情况称为<strong>页分裂</strong>。<strong>页分裂还有可能会造成大量的内存碎片，导致索引结构不紧凑，从而影响查询效率</strong>。</li>
</ul>
</li>
<li>索引最好设置为 NOT NULL：<ul>
<li>索引列存在 NULL 就会导致优化器在做索引选择的时候更加复杂，更加难以优化，因为可为 NULL 的列会使索引、索引统计和值比较都更复杂</li>
<li>NULL 值是一个没意义的值，但是它会占用物理空间，所以会带来的存储空间的问题，会导致更多的存储空间占用</li>
</ul>
</li>
<li>防止索引失效；<ul>
<li>使用左或者左右模糊匹配</li>
<li>在查询条件中对索引列做了计算、函数、类型转换操作</li>
<li>联合索引要能正确使用需要遵循最左匹配原则，也就是按照最左优先的方式进行索引的匹配，否则就会导致索引失效</li>
<li>WHERE 子句中，如果在 OR 前的条件列是索引列，而在 OR 后的条件列不是索引列，那么索引会失效</li>
</ul>
</li>
</ul>
<h3 id="3-2-从数据页的角度看-B-树"><a href="#3-2-从数据页的角度看-B-树" class="headerlink" title="3.2 从数据页的角度看 B+ 树"></a>3.2 从数据页的角度看 B+ 树</h3><ul>
<li><p>InnoDB 是如何存储数据的？</p>
<ul>
<li><p>记录是按照行来存储的，但是数据库的读取并不以「行」为单位，否则一次读取（也就是一次 I&#x2F;O 操作）只能处理一行数据，效率会非常低。因此，<strong>InnoDB 的数据是按「数据页」为单位来读写的</strong>，也就是说，当需要读一条记录的时候，并不是将这个记录本身从磁盘读出来，而是以页为单位，将其整体读入内存。</p>
<ul>
<li>数据库的 I&#x2F;O 操作的最小单位是页，<strong>InnoDB 数据页的默认大小是 16KB</strong>，意味着数据库每次读写都是以 16KB 为单位的，一次最少从磁盘中读取 16K 的内容到内存中，一次最少把内存中的 16K 内容刷新到磁盘中。</li>
</ul>
</li>
<li><p>数据页包括七个部分，分别是文件头、页头、最大最小记录、用户记录、空闲空间、页目录、文件尾；在 File Header 中有两个指针，分别指向上一个数据页和下一个数据页，连接起来的页相当于一个双向的链表，采用链表的结构是让数据页之间不需要是物理上的连续的，而是逻辑上的连续。</p>
</li>
<li><p><strong>数据页中的记录按照「主键」顺序组成单向链表</strong>，单向链表的特点就是插入、删除非常方便，但是检索效率不高，最差的情况下需要遍历链表上的所有节点才能完成检索。因此，数据页中有一个<strong>页目录</strong>，起到记录的索引作用</p>
<ul>
<li><strong>页目录就是由多个槽组成的，槽相当于分组记录的索引</strong>。然后，因为记录是按照「主键值」从小到大排序的，所以<strong>通过槽查找记录时，可以使用二分法快速定位要查询的记录在哪个槽（哪个记录分组），定位到槽后，再遍历槽内的所有记录，找到对应的记录</strong>，无需从最小记录开始遍历整个页中的记录链表</li>
</ul>
</li>
</ul>
</li>
<li><p>B+ 树是如何进行查询的？</p>
<ul>
<li>当需要存储大量的记录时，就需要多个数据页，这时就需要考虑如何建立合适的索引，才能方便定位记录所在的页；为了解决这个问题，<strong>InnoDB 采用了 B+ 树作为索引</strong>。磁盘的 I&#x2F;O 操作次数对索引的使用效率至关重要，因此在构造索引的时候，更倾向于采用“矮胖”的 B+ 树数据结构，这样所需要进行的磁盘 I&#x2F;O 次数更少，而且 B+ 树 更适合进行关键字的范围查询</li>
<li>InnoDB 里的 B+ 树中的<strong>每个节点都是一个数据页</strong></li>
<li>B+ 树的特点：<ul>
<li>只有叶子节点（最底层的节点）才存放了数据，非叶子节点（其他上层节）仅用来存放目录项作为索引。</li>
<li>非叶子节点分为不同层次，通过分层来降低每一层的搜索量；</li>
<li>所有节点按照索引键大小排序，构成一个双向链表，便于范围查询；</li>
</ul>
</li>
<li>在定位记录所在哪一个页时，也是通过二分法快速定位到包含该记录的页。定位到该页后，又会在该页内进行二分法快速定位记录所在的分组（槽号），最后在分组内进行遍历查找</li>
</ul>
</li>
<li><p>索引又可以分成聚簇索引和非聚簇索引（二级索引），它们区别就在于叶子节点存放的是什么数据：</p>
<ul>
<li>聚簇索引的叶子节点存放的是实际数据，所有完整的用户记录都存放在聚簇索引的叶子节点；<ul>
<li>因为表的数据都是存放在聚簇索引的叶子节点里，所以 InnoDB 存储引擎一定会为表创建一个聚簇索引，且由于数据在物理上只会保存一份，所以聚簇索引只能有一个</li>
<li>InnoDB 在创建聚簇索引时，会根据不同的场景选择不同的列作为索引：<ul>
<li>如果有主键，默认会使用主键作为聚簇索引的索引键；</li>
<li>如果没有主键，就选择第一个不包含 NULL 值的唯一列作为聚簇索引的索引键；</li>
<li>在上面两个都没有的情况下，InnoDB 将自动生成一个隐式自增 id 列作为聚簇索引的索引键；</li>
</ul>
</li>
</ul>
</li>
<li>二级索引的叶子节点存放的是主键值，而不是实际数据。<ul>
<li>一张表只能有一个聚簇索引，那为了实现非主键字段的快速搜索，就引出了二级索引（非聚簇索引&#x2F;辅助索引），它也是利用了 B+ 树的数据结构，但是二级索引的叶子节点存放的是主键值，不是实际数据。</li>
</ul>
</li>
<li><strong>如果某个查询语句使用了二级索引，但是查询的数据不是主键值，这时在二级索引找到主键值后，需要去聚簇索引中获得数据行，这个过程就叫作「回表」，也就是说要查两个 B+ 树才能查到数据。不过，当查询的数据是主键值时，因为只在二级索引就能查询到，不用再去聚簇索引查，这个过程就叫作「索引覆盖」，也就是只需要查一个 B+ 树就能找到数据</strong></li>
</ul>
</li>
</ul>
<h3 id="3-3-为什么-MySQL-采用-B-树作为索引？"><a href="#3-3-为什么-MySQL-采用-B-树作为索引？" class="headerlink" title="3.3 为什么 MySQL 采用 B+ 树作为索引？"></a>3.3 为什么 MySQL 采用 B+ 树作为索引？</h3><ul>
<li><p>由于数据库的索引是保存到磁盘上的，因此当我们通过索引查找某行数据的时候，就需要先从磁盘读取索引到内存，再通过索引从磁盘中找到某行数据，然后读入到内存，也就是说查询过程中会发生多次磁盘 I&#x2F;O，而磁盘 I&#x2F;O 次数越多，所消耗的时间也就越大。希望索引的数据结构能在尽可能少的磁盘的 I&#x2F;O 操作中完成查询工作，因为磁盘 I&#x2F;O 操作越少，所消耗的时间也就越小。</p>
</li>
<li><p>MySQL 是支持范围查找的，所以索引的数据结构不仅要能高效地查询某一个记录，而且也要能高效地执行范围查找。所以，要设计一个适合 MySQL 索引的数据结构，至少满足以下要求：</p>
<ul>
<li>能在尽可能少的磁盘的 I&#x2F;O 操作中完成查询工作；</li>
<li>要能高效地查询某一个记录，也要能高效地执行范围查找；</li>
</ul>
</li>
<li><p><strong>不管平衡二叉查找树还是红黑树，都会随着插入的元素增多，而导致树的高度变高，这就意味着磁盘 I&#x2F;O 操作次数多，会影响整体数据查询的效率</strong>。</p>
</li>
<li><p>为了解决降低树的高度的问题，后面就出来了 B 树，它不再限制一个节点就只能有 2 个子节点，而是允许 M 个子节点 (M&gt;2)，从而降低树的高度。B 树的每一个节点最多可以包括 M 个子节点，M 称为 B 树的阶，所以 B 树就是一个多叉树。</p>
<ul>
<li>但是 B 树的每个节点都包含数据（索引+记录），而用户的记录数据的大小很有可能远远超过了索引数据，这就需要花费更多的磁盘 I&#x2F;O 操作次数来读到「有用的索引数据」。</li>
<li>而且，在查询位于底层的某个节点（比如 A 记录）过程中，「非 A 记录节点」里的记录数据会从磁盘加载到内存，但是这些记录数据是没用的，我们只是想读取这些节点的索引数据来做比较查询，而「非 A 记录节点」里的记录数据对我们是没用的，这样不仅增多磁盘 I&#x2F;O 操作次数，也占用内存资源。</li>
<li>另外，如果使用 B 树来做范围查询的话，需要使用中序遍历，这会涉及多个节点的磁盘 I&#x2F;O 问题，从而导致整体速度下降。</li>
</ul>
</li>
<li><p>B+ 树就是对 B 树做了一个升级，MySQL 中索引的数据结构就是采用了 B+ 树，B+ 树与 B 树差异的点，主要是以下这几点：</p>
<ul>
<li>叶子节点（最底部的节点）才会存放实际数据（索引+记录），非叶子节点只会存放索引；</li>
<li>所有索引都会在叶子节点出现，叶子节点之间构成一个有序链表；</li>
<li>非叶子节点的索引也会同时存在在子节点中，并且是在子节点中所有索引的最大（或最小）。</li>
<li>非叶子节点中有多少个子节点，就有多少个索引；</li>
</ul>
</li>
<li><p>比较下 B+ 和 B 树的性能区别</p>
<ul>
<li>B 树进行单个索引查询时，最快可以在 O(1) 的时间代价内就查到，而从平均时间代价来看，会比 B+ 树稍快一些。但是 B 树的查询波动会比较大，因为每个节点即存索引又存记录，所以有时候访问到了非叶子节点就可以找到索引，而有时需要访问到叶子节点才能找到索引；<strong>B+ 树的非叶子节点不存放实际的记录数据，仅存放索引，因此数据量相同的情况下，相比存储即存索引又存记录的 B 树，B+树的非叶子节点可以存放更多的索引，因此 B+ 树可以比 B 树更「矮胖」，查询底层节点的磁盘 I&#x2F;O次数会更少</strong></li>
<li>B+ 树有大量的冗余节点，这样使得删除一个节点的时候，可以直接从叶子节点中删除，甚至可以不动非叶子节点，这样删除非常快；B 树则不同，B 树没有冗余节点，删除节点的时候非常复杂，比如删除根节点中的数据，可能涉及复杂的树的变形 ；B+ 树的插入也是一样，有冗余节点，插入可能存在节点的分裂（如果节点饱和），但是最多只涉及树的一条路径。而且 B+ 树会自动平衡，不需要像更多复杂的算法，类似红黑树的旋转操作等。</li>
<li><strong>B+ 树所有叶子节点间还有一个链表进行连接，这种设计对范围查找非常有帮助</strong>，而 B 树没有将所有叶子节点用链表串联起来的结构，因此只能通过树的遍历来完成范围查询，这会涉及多个节点的磁盘 I&#x2F;O 操作，范围查询效率不如 B+ 树。</li>
</ul>
</li>
<li><p>Innodb 使用的 B+ 树有一些特别的点，比如：</p>
</li>
<li><p>B+ 树的叶子节点之间是用「双向链表」进行连接，这样的好处是既能向右遍历，也能向左遍历。</p>
</li>
<li><p>B+ 树点节点内容是数据页，数据页里存放了用户的记录以及各种信息，每个数据页默认大小是 16 KB。</p>
</li>
</ul>
<h3 id="3-4-MySQL-单表不要超过-2000W-行，靠谱吗？"><a href="#3-4-MySQL-单表不要超过-2000W-行，靠谱吗？" class="headerlink" title="3.4 MySQL 单表不要超过 2000W 行，靠谱吗？"></a>3.4 MySQL 单表不要超过 2000W 行，靠谱吗？</h3><ul>
<li>MySQL 的表数据是以页的形式存放的，页在磁盘中不一定是连续的。</li>
<li>页的空间是 16K, 并不是所有的空间都是用来存放数据的，会有一些固定的信息，如，页头，页尾，页码，校验码等等。</li>
<li>在 B+ 树中，叶子节点和非叶子节点的数据结构是一样的，区别在于，叶子节点存放的是实际的行数据，而非叶子节点存放的是主键和页号。</li>
<li>索引结构不会影响单表最大行数，2000W 也只是推荐值，超过了这个值可能会导致 B + 树层级更高，影响查询性能。</li>
</ul>
<h3 id="3-5-索引失效有哪些？"><a href="#3-5-索引失效有哪些？" class="headerlink" title="3.5 索引失效有哪些？"></a>3.5 索引失效有哪些？</h3><ul>
<li>当我们使用左或者左右模糊匹配的时候，也就是 <code>like %xx</code> 或者 <code>like %xx%</code>这两种方式都会造成索引失效；<ul>
<li><strong>因为索引 B+ 树是按照「索引值」有序排列存储的，只能根据前缀进行比较。</strong></li>
</ul>
</li>
<li>当我们在查询条件中对索引列使用函数，就会导致索引失效。<ul>
<li>因为索引保存的是索引字段的原始值，而不是经过函数计算后的值，自然就没办法走索引了</li>
</ul>
</li>
<li>当我们在查询条件中对索引列进行表达式计算，也是无法走索引的。原因跟对索引使用函数差不多。</li>
<li>MySQL 在遇到字符串和数字比较的时候，<strong>会自动把字符串转为数字，然后再进行比较</strong>。如果字符串是索引列，而条件语句中的输入参数是数字的话，那么索引列会发生隐式类型转换，由于隐式类型转换是通过 CAST 函数实现的，等同于对索引列使用了函数，所以就会导致索引失效。</li>
<li>联合索引要能正确使用需要遵循最左匹配原则，也就是按照最左优先的方式进行索引的匹配，否则就会导致索引失效。<ul>
<li>MySQL 5.6 之后，有一个<strong>索引下推功能</strong>，可以在存储引擎层进行索引遍历过程中，对索引中包含的字段先做判断，直接过滤掉不满足条件的记录，再返还给 Server 层，从而减少回表次数</li>
<li>索引下推的大概原理是：截断的字段不会在 Server 层进行条件判断，而是会被下推到「存储引擎层」进行条件判断，然后过滤出符合条件的数据后再返回给 Server 层。由于在引擎层就过滤掉大量的数据，无需再回表读取数据来进行判断，减少回表次数，从而提升了性能。</li>
</ul>
</li>
<li>在 WHERE 子句中，如果在 OR 前的条件列是索引列，而在 OR 后的条件列不是索引列，那么索引会失效。<ul>
<li>因为 OR 的含义就是两个只要满足一个即可，因此只有一个条件列是索引列是没有意义的，只要有条件列不是索引列，就会进行全表扫描。</li>
</ul>
</li>
</ul>
<h3 id="3-6-MySQL-使用-like-“-x“，索引一定会失效吗"><a href="#3-6-MySQL-使用-like-“-x“，索引一定会失效吗" class="headerlink" title="3.6 MySQL 使用 like “%x“，索引一定会失效吗"></a>3.6 MySQL 使用 like “%x“，索引一定会失效吗</h3><ul>
<li><p>假设现在数据库表只有两个字段，一个是主键索引 id，另外一个是二级索引 name，则<code>select * from t_user where name like &quot;%xx&quot;;</code>用上了二级索引，而且从 Extra 里的 Using index 说明用上了覆盖索引</p>
<ul>
<li>这张表的字段没有「非索引」字段，所以 <code>select *</code> 相当于 <code>select id,name</code>，然后<strong>这个查询的数据都在二级索引的 B+ 树，因为二级索引的 B+ 树的叶子节点包含「索引值+主键值」，所以查二级索引的 B+ 树就能查到全部结果了，这个就是覆盖索引。</strong></li>
<li>执行计划里的 type 是 <code>index</code>，这代表着是通过全扫描二级索引的 B+ 树的方式查询到数据的，也就是遍历了整颗索引树。</li>
<li>执行计划中 type 如果是 <code>range</code>，表示对索引列进行范围查询，也就是利用了索引树的有序性的特点，通过查询比较的方式，快速定位到了数据行。所以，type&#x3D;range 的查询效率会比 type&#x3D;index 的高一些</li>
</ul>
</li>
<li><p>为什么选择全扫描二级索引树，而不扫描聚簇索引树呢？</p>
<ul>
<li>因为二级索引树的记录东西很少，就只有「索引列+主键值」，而聚簇索引记录的东西会更多，比如聚簇索引中的叶子节点则记录了主键值、事务 id、用于事务和 MVCC 的回滚指针以及所有的剩余列。</li>
<li>再加上，这个 select * 不用执行回表操作。</li>
<li>所以， MySQL 优化器认为直接遍历二级索引树要比遍历聚簇索引树的成本要小的多，因此 MySQL 选择了「全扫描二级索引树」的方式查询数据。</li>
</ul>
</li>
<li><p>为什么这个数据表加了非索引字段，执行同样的查询语句后，怎么变成走的是全表扫描呢？</p>
<ul>
<li>加了其他字段后，<code>select * from t_user where name like &quot;%xx&quot;;</code> 要查询的数据就不能只在二级索引树里找了，得需要回表操作才能完成查询的工作，再加上是左模糊匹配，无法利用索引树的有序性来快速定位数据，所以得在二级索引树逐一遍历，获取主键值后，再到聚簇索引树检索到对应的数据行，这样实在太累了。</li>
<li>所以，优化器认为上面这样的查询过程的成本实在太高了，所以直接选择全表扫描的方式来查询数据。</li>
</ul>
</li>
<li><p>使用左模糊匹配（like “%xx”）并不一定会走全表扫描，关键还是看数据表中的字段。如果数据库表中的字段只有主键+二级索引，那么即使使用了左模糊匹配，也不会走全表扫描（type&#x3D;all），而是走全扫描二级索引树(type&#x3D;index)。</p>
<ul>
<li>联合索引要遵循最左匹配才能走索引，但是如果数据库表中的字段都是索引的话，即使查询过程中，没有遵循最左匹配原则，也是走全扫描二级索引树(type&#x3D;index)</li>
</ul>
</li>
</ul>
<h3 id="3-7-count-和-count-1-有什么区别？哪个性能最好？"><a href="#3-7-count-和-count-1-有什么区别？哪个性能最好？" class="headerlink" title="3.7 count(*) 和 count(1) 有什么区别？哪个性能最好？"></a>3.7 count(*) 和 count(1) 有什么区别？哪个性能最好？</h3><ul>
<li><p>count() 是一个聚合函数，函数的参数不仅可以是字段名，也可以是其他任意表达式，该函数作用是<strong>统计符合查询条件的记录中，函数指定的参数不为 NULL 的记录有多少个</strong>。</p>
<ul>
<li><p>假设 count() 函数的参数是字段名，如下：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">select</span> <span class="built_in">count</span>(name) <span class="keyword">from</span> t_order;</span><br></pre></td></tr></table></figure>

<p>这条语句是统计「 t_order 表中，name 字段不为 NULL 的记录」有多少个。也就是说，如果某一条记录中的 name 字段的值为 NULL，则就不会被统计进去。</p>
</li>
<li><p>假设 count() 函数的参数是数字 1 这个表达式，如下：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">select</span> <span class="built_in">count</span>(<span class="number">1</span>) <span class="keyword">from</span> t_order;</span><br></pre></td></tr></table></figure>

<p>这条语句是统计「 t_order 表中，1 这个表达式不为 NULL 的记录」有多少个。1 这个表达式就是单纯数字，它永远都不是 NULL，所以上面这条语句，其实是在统计 t_order 表中有多少个记录。</p>
</li>
</ul>
</li>
<li><p>count(主键字段) 执行过程是怎样的？</p>
<ul>
<li>在通过 count 函数统计有多少个记录时，MySQL 的 server 层会维护一个名叫 count 的变量。server 层会循环向 InnoDB 读取一条记录，如果 count 函数指定的参数不为 NULL，那么就会将变量 count 加 1，直到符合查询的全部记录被读完，就退出循环。最后将 count 变量的值发送给客户端。</li>
<li>InnoDB 是通过 B+ 树来保存记录的，根据索引的类型又分为聚簇索引和二级索引；<ul>
<li>如果表里只有主键索引，没有二级索引时，那么，InnoDB 循环遍历聚簇索引，将读取到的记录返回给 server 层，然后读取记录中的 id 值，就会 id 值判断是否为 NULL，如果不为 NULL，就将 count 变量加 1。</li>
<li>如果表里有二级索引时，InnoDB 循环遍历的对象就不是聚簇索引，而是二级索引。相同数量的二级索引记录可以比聚簇索引记录占用更少的存储空间，所以二级索引树比聚簇索引树小，这样遍历二级索引的 I&#x2F;O 成本比遍历聚簇索引的 I&#x2F;O 成本小，因此「优化器」优先选择的是二级索引</li>
</ul>
</li>
</ul>
</li>
<li><p>count(1) 执行过程是怎样的？</p>
<ul>
<li>如果表里只有主键索引，没有二级索引时。InnoDB 循环遍历聚簇索引（主键索引），将读取到的记录返回给 server 层，<strong>但是不会读取记录中的任何字段的值</strong>，因为 count 函数的参数是 1，不是字段，所以不需要读取记录中的字段值。参数 1 很明显并不是 NULL，因此 server 层每从 InnoDB 读取到一条记录，就将 count 变量加 1。</li>
<li>count(1) 相比 count(主键字段) 少一个步骤，就是不需要读取记录中的字段值，所以通常会说 count(1) 执行效率会比 count(主键字段) 高一点。</li>
<li>如果表里有二级索引时，InnoDB 循环遍历的对象就二级索引</li>
</ul>
</li>
<li><p>count(*) 执行过程是怎样的？</p>
<ul>
<li>看到 <code>*</code> 这个字符的时候，是不是大家觉得是读取记录中的所有字段值？对于 <code>selete *</code> 这条语句来说是这个意思，但是在 count(*) 中并不是这个意思。</li>
<li><strong>count(<code>*</code>) 其实等于 count(<code>0</code>)<strong>，也就是说，当你使用 count(<code>*</code>) 时，MySQL 会将 <code>*</code> 参数转化为参数 0 来处理。所以，</strong>count(*) 执行过程跟 count(1) 执行过程基本一样的</strong>，性能没有什么差异。</li>
<li>而且 MySQL 会对 count(*) 和 count(1) 有个优化，如果有多个二级索引的时候，优化器会使用key_len 最小的二级索引进行扫描。只有当没有二级索引的时候，才会采用主键索引来进行统计。</li>
</ul>
</li>
<li><p>count(字段) 执行过程是怎样的？</p>
<ul>
<li><p>count(字段) 的执行效率相比前面的 count(1)、 count(*)、 count(主键字段) 执行效率是最差的。</p>
</li>
<li><pre><code class="sql">// name不是索引，普通字段
select count(name) from t_order;
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">    对于这个查询来说，会采用全表扫描的方式来计数，所以它的执行效率是比较差的。</span><br><span class="line"></span><br><span class="line">- 如果要执行 count(1)、 count(*)、 count(主键字段) 时，尽量在数据表上建立二级索引，这样优化器会自动采用 key_len 最小的二级索引进行扫描，相比于扫描主键索引效率会高一些。再来，就是不要使用 count(字段) 来统计记录个数，因为它的效率是最差的，会采用全表扫描的方式来统计。如果你非要统计表中该字段不为 NULL 的记录个数，建议给这个字段建立一个二级索引</span><br><span class="line"></span><br><span class="line">- 为什么 count 函数需要通过遍历的方式来统计记录个数？</span><br><span class="line">  - 在 MyISAM 存储引擎里，执行 count 函数的方式是不一样的，通常在没有任何查询条件下的 count(*)，MyISAM 的查询速度要明显快于 InnoDB。使用 MyISAM 引擎时，执行 count 函数只需要 O(1 )复杂度，这是因为每张 MyISAM 的数据表都有一个 meta 信息有存储了row_count值，由表级锁保证一致性，所以直接读取 row_count 值就是 count 函数的执行结果。</span><br><span class="line">  - 而 InnoDB 存储引擎是支持事务的，同一个时刻的多个查询，由于多版本并发控制（MVCC）的原因，InnoDB 表“应该返回多少行”也是不确定的，所以无法像 MyISAM一样，只维护一个 row_count 变量。</span><br><span class="line">  - 当带上 where 条件语句之后，MyISAM 跟 InnoDB 就没有区别了，它们都需要扫描表来进行记录个数的统计</span><br><span class="line">- 如何优化 count(*)？</span><br><span class="line">  - 如果你的业务对于统计个数不需要很精确，比如搜索引擎在搜索关键词的时候，给出的搜索结果条数是一个大概值。可以使用 show table status 或者 explain 命令来表进行估算。执行 explain 命令效率是很高的，因为它并不会真正的去查询，下图中的 rows 字段值就是 explain 命令对表 t_order 记录的估算值。</span><br><span class="line">  - 如果是想精确的获取表的记录总数，我们可以将这个计数值保存到单独的一张计数表中。当我们在数据表插入一条记录的同时，将计数表中的计数字段 + 1。也就是说，在新 增和删除操作时，我们需要额外维护这个计数表。</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">### 4.1 事务隔离级别是怎么实现的？</span><br><span class="line"></span><br><span class="line">- 事务是由 MySQL 的引擎来实现的，常见的 InnoDB 引擎它是支持事务的。要实现事务必须要遵守 4 个特性，分别如下：</span><br><span class="line">  - **原子性（Atomicity）**：一个事务中的所有操作，要么全部完成，要么全部不完成，不会结束在中间某个环节，而且事务在执行过程中发生错误，会被回滚到事务开始前的状态，就像这个事务从来没有执行过一样，就好比买一件商品，购买成功时，则给商家付了钱，商品到手；购买失败时，则商品在商家手中，消费者的钱也没花出去。</span><br><span class="line">  - **一致性（Consistency）**：是指事务操作前和操作后，数据满足完整性约束，数据库保持一致性状态。比如，用户 A 和用户 B 在银行分别有 800 元和 600 元，总共 1400 元，用户 A 给用户 B 转账 200 元，分为两个步骤，从 A 的账户扣除 200 元和对 B 的账户增加 200 元。一致性就是要求上述步骤操作后，最后的结果是用户 A 还有 600 元，用户 B 有 800 元，总共 1400 元，而不会出现用户 A 扣除了 200 元，但用户 B 未增加的情况（该情况，用户 A 和 B 均为 600 元，总共 1200 元）。</span><br><span class="line">  - **隔离性（Isolation）**：数据库允许多个并发事务同时对其数据进行读写和修改的能力，隔离性可以防止多个事务并发执行时由于交叉执行而导致数据的不一致，因为多个事务同时使用相同的数据时，不会相互干扰，每个事务都有一个完整的数据空间，对其他并发事务是隔离的。也就是说，消费者购买商品这个事务，是不影响其他消费者购买的。</span><br><span class="line">  - **持久性（Durability）**：事务处理结束后，对数据的修改就是永久的，即便系统故障也不会丢失。</span><br><span class="line">- InnoDB 引擎通过什么技术来保证事务的这四个特性的呢？</span><br><span class="line">  - 持久性是通过 redo log （重做日志）来保证的；</span><br><span class="line">  - 原子性是通过 undo log（回滚日志） 来保证的；</span><br><span class="line">  - 隔离性是通过 MVCC（多版本并发控制） 或锁机制来保证的；</span><br><span class="line">  - 一致性则是通过持久性+原子性+隔离性来保证；</span><br><span class="line">- MySQL 服务端是允许多个客户端连接的，这意味着 MySQL 会出现同时处理多个事务的情况。那么**在同时处理多个事务的时候，就可能出现脏读（dirty read）、不可重复读（non-repeatable read）、幻读（phantom read）的问题**。</span><br><span class="line">  - 如果一个事务「读到」了另一个「未提交事务修改过的数据」，就意味着发生了「脏读」现象。</span><br><span class="line">  - 在一个事务内多次读取同一个数据，如果出现前后两次读到的数据不一样的情况，就意味着发生了「不可重复读」现象。</span><br><span class="line">  - **在一个事务内多次查询某个符合查询条件的「记录数量」，如果出现前后两次查询到的记录数量不一样的情况，就意味着发生了「幻读」现象。**</span><br><span class="line"></span><br><span class="line">- SQL 标准提出了四种隔离级别来规避这些现象，隔离级别越高，性能效率就越低，这四个隔离级别如下：</span><br><span class="line">  - **读未提交（*read uncommitted*）**，指一个事务还没提交时，它做的变更就能被其他事务看到；</span><br><span class="line">  - **读提交（*read committed*）**，指一个事务提交之后，它做的变更才能被其他事务看到；</span><br><span class="line">  - **可重复读（*repeatable read*）**，指一个事务执行过程中看到的数据，一直跟这个事务启动时看到的数据是一致的，**MySQL InnoDB 引擎的默认隔离级别**；</span><br><span class="line">  - **串行化（*serializable* ）**；会对记录加上读写锁，在多个事务对这条记录进行读写操作时，如果发生了读写冲突的时候，后访问的事务必须等前一个事务执行完成，才能继续执行；</span><br><span class="line">  - 在「读未提交」隔离级别下，可能发生脏读、不可重复读和幻读现象；</span><br><span class="line">  - 在「读提交」隔离级别下，可能发生不可重复读和幻读现象，但是不可能发生脏读现象；</span><br><span class="line">  - 在「可重复读」隔离级别下，可能发生幻读现象，但是不可能脏读和不可重复读现象；</span><br><span class="line">  - 在「串行化」隔离级别下，脏读、不可重复读和幻读现象都不可能会发生。</span><br><span class="line">- MySQL 在「可重复读」隔离级别下，可以很大程度上避免幻读现象的发生（注意是很大程度避免，并不是彻底避免），所以 MySQL 并不会使用「串行化」隔离级别来避免幻读现象的发生，因为使用「串行化」隔离级别会影响性能；幻读解决的方案有两种：</span><br><span class="line">  - 针对**快照读**（普通 select 语句），是**通过 MVCC 方式解决了幻读**，因为可重复读隔离级别下，事务执行过程中看到的数据，一直跟这个事务启动时看到的数据是一致的，即使中途有其他事务插入了一条数据，是查询不出来这条数据的，所以就很好了避免幻读问题。</span><br><span class="line">  - 针对**当前读**（select ... for update 等语句），是**通过 next-key lock（记录锁+间隙锁）方式解决了幻读**，因为当执行 select ... for update 语句的时候，会加上 next-key lock，如果有其他事务在 next-key lock 锁范围内插入了一条记录，那么这个插入语句就会被阻塞，无法成功插入，所以就很好了避免幻读问题。</span><br><span class="line"></span><br><span class="line">- 四种隔离级别具体是如何实现的呢？</span><br><span class="line"></span><br><span class="line">  - 对于「读未提交」隔离级别的事务来说，因为可以读到未提交事务修改的数据，所以直接读取最新的数据就好了；</span><br><span class="line">  - 对于「串行化」隔离级别的事务来说，通过加读写锁的方式来避免并行访问；</span><br><span class="line">  - 对于「读提交」和「可重复读」隔离级别的事务来说，它们是通过 **Read View **来实现的，它们的区别在于创建 Read View 的时机不同，大家可以把 Read View 理解成一个数据快照，就像相机拍照那样，定格某一时刻的风景。「读提交」隔离级别是在「每个语句执行前」都会重新生成一个 Read View，而「可重复读」隔离级别是「启动事务时」生成一个 Read View，然后整个事务期间都在用这个 Read View。</span><br><span class="line"></span><br><span class="line">  执行「开始事务」命令，并不意味着启动了事务。在 MySQL 有两种开启事务的命令，分别是：</span><br><span class="line"></span><br><span class="line">  - 第一种：begin/start transaction 命令；</span><br><span class="line">  - 第二种：start transaction with consistent snapshot 命令；</span><br><span class="line"></span><br><span class="line">  这两种开启事务的命令，事务的启动时机是不同的：</span><br><span class="line"></span><br><span class="line">  - 执行了 begin/start transaction 命令后，并不代表事务启动了。只有在执行这个命令后，执行了增删查改操作的 SQL 语句，才是事务真正启动的时机；</span><br><span class="line">  - 执行了 start transaction with consistent snapshot 命令，就会马上启动事务。</span><br><span class="line"></span><br><span class="line">- Read View 有四个重要的字段：</span><br><span class="line"></span><br><span class="line">  - m_ids ：指的是在创建 Read View 时，当前数据库中「活跃事务」的**事务 id 列表**，注意是一个列表，**“活跃事务”指的就是，启动了但还没提交的事务**。</span><br><span class="line">  - min_trx_id ：指的是在创建 Read View 时，当前数据库中「活跃事务」中事务 **id 最小的事务**，也就是 m_ids 的最小值。</span><br><span class="line">  - max_trx_id ：这个并不是 m_ids 的最大值，而是**创建 Read View 时当前数据库中应该给下一个事务的 id 值**，也就是全局事务中最大的事务 id 值 + 1；</span><br><span class="line">  - creator_trx_id ：指的是**创建该 Read View 的事务的事务 id**</span><br><span class="line"></span><br><span class="line">  对于使用 InnoDB 存储引擎的数据库表，它的聚簇索引记录中都包含下面两个隐藏列：</span><br><span class="line"></span><br><span class="line">  - trx_id，当一个事务对某条聚簇索引记录进行改动时，就会**把该事务的事务 id 记录在 trx_id 隐藏列里**；</span><br><span class="line">  - roll_pointer，每次对某条聚簇索引记录进行改动时，都会把旧版本的记录写入到 undo 日志中，然后**这个隐藏列是个指针，指向每一个旧版本记录**，于是就可以通过它找到修改前的记录。</span><br><span class="line"></span><br><span class="line">- 在创建 Read View 后，可以将记录中的 trx_id 划分这三种情况：</span><br><span class="line"></span><br><span class="line">  &lt;img src=&quot;https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost4@main/mysql/%E4%BA%8B%E5%8A%A1%E9%9A%94%E7%A6%BB/ReadView.drawio.png&quot; alt=&quot;img&quot; style=&quot;zoom:50%;&quot; /&gt;</span><br><span class="line"></span><br><span class="line">- 一个事务去访问记录的时候，除了自己的更新记录总是可见之外，还有这几种情况：</span><br><span class="line"></span><br><span class="line">  - 如果记录的 trx_id 值小于 Read View 中的 `min_trx_id` 值，表示这个版本的记录是在创建 Read View **前**已经提交的事务生成的，所以该版本的记录对当前事务**可见**。</span><br><span class="line"></span><br><span class="line">  - 如果记录的 trx_id 值大于等于 Read View 中的 `max_trx_id` 值，表示这个版本的记录是在创建 Read View **后**才启动的事务生成的，所以该版本的记录对当前事务**不可见**。</span><br><span class="line"></span><br><span class="line">  - 如果记录的 trx_id 值在 Read View 的min_trx_id和max_trx_id之间，需要判断 trx_id 是否在 m_ids 列表中：</span><br><span class="line">    - 如果记录的 trx_id **在** `m_ids` 列表中，表示生成该版本记录的活跃事务依然活跃着（还没提交事务），所以该版本的记录对当前事务**不可见**。</span><br><span class="line">    - 如果记录的 trx_id **不在** `m_ids`列表中，表示生成该版本记录的活跃事务已经被提交，所以该版本的记录对当前事务**可见**。</span><br><span class="line"></span><br><span class="line">  **这种通过「版本链」来控制并发事务访问同一个记录时的行为就叫 MVCC（多版本并发控制）。**</span><br><span class="line"></span><br><span class="line">- **可重复读隔离级别是启动事务时生成一个 Read View，然后整个事务期间都在用这个 Read View**。</span><br><span class="line">  - 事务B 发现这条记录的 trx_id 值为 51，在事务 B 的 Read View 的 min_trx_id 和 max_trx_id 之间，则需要判断 trx_id 值是否在 m_ids 范围内，判断的结果是在的，那么说明这条记录是被还未提交的事务修改的，这时事务 B 并不会读取这个版本的记录。而是沿着 undo log 链条往下找旧版本的记录，直到找到 trx_id 「小于」事务 B 的 Read View 中的 min_trx_id 值的第一条记录</span><br><span class="line">  - 当事物 A 提交事务后，**由于隔离级别时「可重复读」，所以事务 B 再次读取记录时，还是基于启动事务时创建的 Read View 来判断当前版本的记录是否可见。**</span><br><span class="line"></span><br><span class="line">- **读提交隔离级别是在每次读取数据时，都会生成一个新的 Read View**。</span><br><span class="line">  - 在事务 A 提交后，**由于隔离级别是「读提交」，所以事务 B 在每次读数据的时候，会重新创建 Read View**</span><br><span class="line">  - 事务 B 会发现这条记录的 trx_id 是 51，比事务 B 的 Read View 中的 min_trx_id 值（52）还小，这意味着修改这条记录的事务早就在创建 Read View 前提交过了，所以该版本的记录对事务 B 是可见的</span><br><span class="line"></span><br><span class="line">### 4.2 MySQL 可重复读隔离级别，完全解决幻读了吗？</span><br><span class="line"></span><br><span class="line">- 可重复读隔离级是由 MVCC（多版本并发控制）实现的，实现的方式是启动事务后，在执行第一个查询语句后，会创建一个 Read View，**后续的查询语句利用这个 Read View，通过这个 Read View 就可以在 undo log 版本链找到事务开始时的数据，所以事务过程中每次查询的数据都是一样的**，即使中途有其他事务插入了新纪录，是查询不出来这条数据的，所以就很好了避免幻读问题。</span><br><span class="line">- **Innodb 引擎为了解决「可重复读」隔离级别使用「当前读」而造成的幻读问题，就引出了间隙锁**。</span><br><span class="line">  - 事务 B 在执行插入语句的时候，判断到插入的位置被事务 A （当前读语句）加了 next-key lock，于是事务 B 会生成一个插入意向锁，同时进入等待状态，直到事务 A 提交了事务。这就避免了由于事务 B 插入新记录而导致事务 A 发生幻读的现象</span><br><span class="line">- 对于快照读， MVCC 并不能完全避免幻读现象。因为当事务 A 更新了一条事务 B 插入的记录，那么事务 A 前后两次查询的记录条目就不一样了，所以就发生幻读</span><br><span class="line">- 对于当前读，如果事务开启后，并没有执行当前读，而是先快照读，然后这期间如果其他事务插入了一条记录，那么事务后续使用当前读进行查询的时候，就会发现两次查询的记录条目就不一样了，所以就发生幻读。要避免这类特殊场景下发生幻读的现象的话，就是尽量在开启事务之后，马上执行 select ... for update 这类当前读的语句，因为它会对记录加 next-key lock，从而避免其他事务插入一条新记录。</span><br><span class="line"></span><br><span class="line">### 5.1 MySQL 有哪些锁？</span><br><span class="line"></span><br><span class="line">在 MySQL 里，根据加锁的范围，可以分为**全局锁、表级锁和行锁**三类。</span><br><span class="line"></span><br><span class="line">#### 全局锁</span><br><span class="line"></span><br><span class="line">- 全局锁是怎么用的？</span><br><span class="line"></span><br><span class="line">  - ```sql</span><br><span class="line">    flush tables with read lock</span><br></pre></td></tr></table></figure>
</code></pre>
</li>
<li><p>执行后，<strong>整个数据库就处于只读状态了</strong>，这时其他线程执行以下操作，都会被阻塞：</p>
<ul>
<li>对数据的增删改操作，比如 insert、delete、update等语句；</li>
<li>对表结构的更改操作，比如 alter table、drop table 等语句。</li>
</ul>
</li>
<li><p>如果要释放全局锁，则要执行这条命令：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">unlock tables</span><br></pre></td></tr></table></figure></li>
</ul>
</li>
<li><p>全局锁应用场景是什么？</p>
<ul>
<li>全局锁主要应用于做<strong>全库逻辑备份</strong>，这样在备份数据库期间，不会因为数据或表结构的更新，而出现备份文件的数据与预期的不一样。</li>
</ul>
</li>
<li><p>加全局锁又会带来什么缺点呢？</p>
<ul>
<li>加上全局锁，意味着整个数据库都是只读状态。那么如果数据库里有很多数据，备份就会花费很多的时间，关键是备份期间，业务只能读数据，而不能更新数据，这样会造成业务停滞。</li>
</ul>
</li>
<li><p>既然备份数据库数据的时候，使用全局锁会影响业务，那有什么其他方式可以避免？</p>
<ul>
<li>如果数据库的引擎支持的事务支持<strong>可重复读的隔离级别</strong>，那么在备份数据库之前先开启事务，会先创建 Read View，然后整个事务执行期间都在用这个 Read View，而且由于 MVCC 的支持，备份期间业务依然可以对数据进行更新操作。因为在可重复读的隔离级别下，即使其他事务更新了表的数据，也不会影响备份数据库时的 Read View，这就是事务四大特性中的隔离性，这样备份期间备份的数据一直是在开启事务时的数据。</li>
<li>备份数据库的工具是 mysqldump，在使用 mysqldump 时加上 <code>–single-transaction</code> 参数的时候，就会在备份数据库之前先开启事务。这种方法只适用于支持「可重复读隔离级别的事务」的存储引擎。InnoDB 存储引擎默认的事务隔离级别正是可重复读，因此可以采用这种方式来备份数据库。</li>
</ul>
</li>
</ul>
<h4 id="表级锁"><a href="#表级锁" class="headerlink" title="表级锁"></a>表级锁</h4><ul>
<li><p>表锁；</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">lock tables t_student read;</span><br></pre></td></tr></table></figure>

<ul>
<li>表锁除了会限制别的线程的读写外，也会限制本线程接下来的读写操作。</li>
<li>如果本线程对学生表加了「共享表锁」，那么本线程接下来如果要对学生表执行写操作的语句，是会被阻塞的，当然其他线程对学生表进行写操作时也会被阻塞，直到锁被释放</li>
<li>尽量避免在使用 InnoDB 引擎的表使用表锁，因为表锁的颗粒度太大，会影响并发性能，<strong>InnoDB 牛逼的地方在于实现了颗粒度更细的行级锁</strong>。</li>
</ul>
</li>
<li><p>元数据锁（MDL）; </p>
<ul>
<li><p>MDL 是为了保证当用户对表执行 CRUD 操作时，防止其他线程对这个表结构做了变更。</p>
</li>
<li><p>对数据库表进行操作时，会自动给这个表加上 MDL：</p>
<ul>
<li><p>对一张表进行 CRUD 操作时，加的是 <strong>MDL 读锁</strong>；</p>
</li>
<li><p>对一张表做结构变更操作的时候，加的是 <strong>MDL 写锁</strong>；</p>
</li>
</ul>
</li>
<li><p>MDL 是在事务提交后才会释放，这意味着<strong>事务执行期间，MDL 是一直持有的</strong>。如果数据库有一个长事务，可能会有大量的线程被阻塞住，这时数据库的线程很快就会爆满</p>
</li>
<li><p>申请 MDL 锁的操作会形成一个队列，队列中<strong>写锁获取优先级高于读锁</strong>，一旦出现 MDL 写锁等待，会阻塞后续该表的所有 CRUD 操作</p>
</li>
</ul>
</li>
<li><p>意向锁；</p>
<ul>
<li>在使用 InnoDB 引擎的表里对某些记录加上「共享锁」之前，需要先在表级别加上一个「意向共享锁」；</li>
<li>在使用 InnoDB 引擎的表里对某些纪录加上「独占锁」之前，需要先在表级别加上一个「意向独占锁」；</li>
<li>普通的 select 是不会加行级锁的，普通的 select 语句是利用 MVCC 实现一致性读，是无锁的</li>
<li><strong>意向共享锁和意向独占锁是表级锁，不会和行级的共享锁和独占锁发生冲突，而且意向锁之间也不会发生冲突，只会和共享表锁和独占表锁发生冲突。</strong></li>
<li>表锁和行锁是满足读读共享、读写互斥、写写互斥的。</li>
<li>如果没有「意向锁」，那么加「独占表锁」时，就需要遍历表里所有记录，查看是否有记录存在独占锁，这样效率会很慢。有了「意向锁」，由于在对记录加独占锁前，先会加上表级别的意向独占锁，那么在加「独占表锁」时，直接查该表是否有意向独占锁，如果有就意味着表里已经有记录被加了独占锁，这样就不用去遍历表里的记录。所以，<strong>意向锁的目的是为了快速判断表里是否有记录被加锁</strong></li>
</ul>
</li>
<li><p>AUTO-INC 锁；</p>
<ul>
<li><p>表里的主键通常都会设置成自增的，这是通过对主键字段声明 <code>AUTO_INCREMENT</code> 属性实现的。之后可以在插入数据时，可以不指定主键的值，数据库会自动给主键赋值递增的值，这主要是通过 <strong>AUTO-INC 锁</strong>实现的。</p>
</li>
<li><p>AUTO-INC 锁是特殊的表锁机制，锁<strong>不是再一个事务提交后才释放，而是再执行完插入语句后就会立即释放</strong>。</p>
<ul>
<li><strong>在插入数据时，会加一个表级别的 AUTO-INC 锁</strong>，然后为被 <code>AUTO_INCREMENT</code> 修饰的字段赋值递增的值，等插入语句执行完成后，才会把 AUTO-INC 锁释放掉。</li>
<li>一个事务在持有 AUTO-INC 锁的过程中，其他事务的如果要向该表插入语句都会被阻塞，从而保证插入数据时，被 <code>AUTO_INCREMENT</code> 修饰的字段的值是连续递增的</li>
</ul>
</li>
<li><p>AUTO-INC 锁再对大量数据进行插入的时候，会影响插入性能，因为另一个事务中的插入会被阻塞。</p>
</li>
<li><p>在 MySQL 5.1.22 版本开始，InnoDB 存储引擎提供了一种<strong>轻量级的锁</strong>来实现自增。一样也是在插入数据的时候，会为被 <code>AUTO_INCREMENT</code> 修饰的字段加上轻量级锁，<strong>然后给该字段赋值一个自增的值，就把这个轻量级锁释放了，而不需要等待整个插入语句执行完后才释放锁</strong>。</p>
</li>
<li><p>InnoDB 存储引擎提供了个 innodb_autoinc_lock_mode 的系统变量，是用来控制选择用 AUTO-INC 锁，还是轻量级的锁。</p>
<ul>
<li>当 innodb_autoinc_lock_mode &#x3D; 0，就采用 AUTO-INC 锁，语句执行结束后才释放锁；</li>
<li>当 innodb_autoinc_lock_mode &#x3D; 2，就采用轻量级锁，申请自增主键后就释放锁，并不需要等语句执行后才释放。</li>
<li>当 innodb_autoinc_lock_mode &#x3D; 1：<ul>
<li>普通 insert 语句，自增锁在申请之后就马上释放；</li>
<li>类似 insert … select 这样的批量插入数据的语句，自增锁还是要等语句结束后才被释放；</li>
</ul>
</li>
</ul>
</li>
<li><p>当 innodb_autoinc_lock_mode &#x3D; 2 是性能最高的方式，但是当搭配 binlog 的日志格式是 statement 一起使用的时候，在「主从复制的场景」中会发生<strong>数据不一致的问题</strong>。要解决这问题，binlog 日志格式要设置为 row，这样在 binlog 里面记录的是主库分配的自增值，到备库执行的时候，主库的自增值是什么，从库的自增值就是什么。<strong>当 innodb_autoinc_lock_mode &#x3D; 2 时，并且 binlog_format &#x3D; row，既能提升并发性，又不会出现数据一致性问题</strong></p>
</li>
</ul>
</li>
</ul>
<h4 id="行级锁"><a href="#行级锁" class="headerlink" title="行级锁"></a>行级锁</h4><ul>
<li><p>普通的 select 语句是不会对记录加锁的，因为它属于快照读。如果要在查询时对记录加行锁，可以使用下面这两个方式，这种查询会加锁的语句称为<strong>锁定读</strong></p>
<ul>
<li>对读取的记录加共享锁：select … lock in share mode;</li>
<li>对读取的记录加独占锁:select … for update;</li>
<li>上面这两条语句必须在一个事务中，<strong>因为当事务提交了，锁就会被释放</strong>，所以在使用这两条语句的时候，要加上 begin、start transaction 或者 set autocommit &#x3D; 0。</li>
</ul>
</li>
<li><p>共享锁（S锁）满足读读共享，读写互斥。独占锁（X锁）满足写写互斥、读写互斥。</p>
</li>
<li><p>行级锁的类型主要有三类：</p>
<ul>
<li>Record Lock，记录锁，也就是仅仅把一条记录锁上；记录锁是有 S 锁和 X 锁之分的：<ul>
<li>当一个事务对一条记录加了 S 型记录锁后，其他事务也可以继续对该记录加 S 型记录锁（S 型与 S 锁兼容），但是不可以对该记录加 X 型记录锁（S 型与 X 锁不兼容）;</li>
<li>当一个事务对一条记录加了 X 型记录锁后，其他事务既不可以对该记录加 S 型记录锁（S 型与 X 锁不兼容），也不可以对该记录加 X 型记录锁（X 型与 X 锁不兼容）。</li>
</ul>
</li>
<li>Gap Lock，间隙锁，锁定一个范围，但是不包含记录本身；目的是为了解决可重复读隔离级别下幻读的现象<ul>
<li>间隙锁虽然存在 X 型间隙锁和 S 型间隙锁，但是并没有什么区别，<strong>间隙锁之间是兼容的，即两个事务可以同时持有包含共同间隙范围的间隙锁，并不存在互斥关系，因为间隙锁的目的是防止插入幻影记录而提出的</strong></li>
</ul>
</li>
<li>Next-Key Lock：Record Lock + Gap Lock 的组合，锁定一个范围，并且锁定记录本身<ul>
<li><strong>如果一个事务获取了 X 型的 next-key lock，那么另外一个事务在获取相同范围的 X 型的 next-key lock 时，是会被阻塞的</strong></li>
<li>虽然相同范围的间隙锁是多个事务相互兼容的，但对于记录锁，我们是要考虑 X 型与 S 型关系，X 型的记录锁与 X 型的记录锁是冲突的</li>
</ul>
</li>
</ul>
</li>
<li><p>一个事务在插入一条记录的时候，需要判断插入位置是否已被其他事务加了间隙锁（next-key lock 也包含间隙锁）。如果有的话，插入操作就会发生<strong>阻塞</strong>，直到拥有间隙锁的那个事务提交为止（释放间隙锁的时刻），在此期间会生成一个<strong>插入意向锁</strong>，表明有事务想在某个区间插入新记录，但是现在处于等待状态。</p>
<ul>
<li>插入意向锁名字虽然有意向锁，但是它并<strong>不是意向锁，它是一种特殊的间隙锁，属于行级别锁</strong>。</li>
<li>如果说间隙锁锁住的是一个区间，那么「插入意向锁」锁住的就是一个点。因而从这个角度来说，插入意向锁确实是一种特殊的间隙锁。</li>
<li>插入意向锁与间隙锁的另一个非常重要的差别是：尽管「插入意向锁」也属于间隙锁，但两个事务却不能在同一时间内，一个拥有间隙锁，另一个拥有该间隙区间内的插入意向锁</li>
</ul>
</li>
</ul>
<h3 id="5-2-MySQL-是怎么加锁的？"><a href="#5-2-MySQL-是怎么加锁的？" class="headerlink" title="5.2 MySQL 是怎么加锁的？"></a>5.2 MySQL 是怎么加锁的？</h3><ul>
<li><p>对记录加锁时，<strong>加锁的基本单位是 next-key lock</strong>，它是由记录锁和间隙锁组合而成的，<strong>next-key lock 是前开后闭区间，而间隙锁是前开后开区间</strong>。</p>
</li>
<li><p>next-key lock 在一些场景下会退化成记录锁或间隙锁。</p>
<ul>
<li>唯一索引等值查询：<ul>
<li>当查询的记录是存在的，next-key lock 会退化成「记录锁」。</li>
<li>当查询的记录是不存在的，next-key lock 会退化成「间隙锁」。</li>
</ul>
</li>
<li>非唯一索引等值查询：<ul>
<li>当查询的记录存在时，除了会加 next-key lock 外，还额外加间隙锁，也就是会加两把锁。</li>
<li>当查询的记录不存在时，只会加 next-key lock，然后会退化为间隙锁，也就是只会加一把锁。</li>
</ul>
</li>
<li>非唯一索引和主键索引的范围查询的加锁规则不同之处在于：<ul>
<li>唯一索引在满足一些条件的时候，next-key lock 退化为间隙锁和记录锁。</li>
<li>非唯一索引范围查询，next-key lock 不会退化为间隙锁和记录锁。</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="5-3-update-没加索引会锁全表？"><a href="#5-3-update-没加索引会锁全表？" class="headerlink" title="5.3 update 没加索引会锁全表？"></a>5.3 update 没加索引会锁全表？</h3><ul>
<li>InnoDB 存储引擎的默认事务隔离级别是「可重复读」，但是在这个隔离级别下，在多个事务并发的时候，会出现幻读的问题，所谓的幻读是指在同一事务下，连续执行两次同样的查询语句，第二次的查询语句可能会返回之前不存在的行。因此 InnoDB 存储引擎自己实现了行锁，通过 next-key 锁（记录锁和间隙锁的组合）来锁住记录本身和记录之间的“间隙”，防止其他事务在这个记录之间插入新的记录，从而避免了幻读现象。</li>
<li>当我们执行 update 语句时，实际上是会对记录加独占锁（X 锁）的，如果其他事务对持有独占锁的记录进行修改时是会被阻塞的。另外，这个锁并不是执行完 update 语句就会释放的，而是会等事务结束时才会释放。</li>
<li>在 InnoDB 事务中，对记录加锁带基本单位是 next-key 锁，但是会因为一些条件会退化成间隙锁，或者记录锁。加锁的位置准确的说，锁是加在索引上的而非行上。<ul>
<li>比如，在 update 语句的 where 条件使用了唯一索引，那么 next-key 锁会退化成记录锁，也就是只会给一行记录加锁。</li>
<li><strong>在 update 语句的 where 条件没有使用索引，就会全表扫描，于是就会对所有记录加上 next-key 锁（记录锁 + 间隙锁），相当于把整个表锁住了</strong>。</li>
<li>那 update 语句的 where 带上索引就能避免全表记录加锁了吗？并不是。<strong>关键还得看这条语句在执行过程种，优化器最终选择的是索引扫描，还是全表扫描，如果走了全表扫描，就会对全表的记录加锁了</strong>。</li>
</ul>
</li>
<li>如何避免这种事故的发生？<ul>
<li>可以将 MySQL 里的 <code>sql_safe_updates</code> 参数设置为 1，开启安全更新模式，当 sql_safe_updates 设置为 1 时：</li>
<li>update 语句必须满足如下条件之一才能执行成功：<ul>
<li>使用 where，并且 where 条件中必须有索引列；</li>
<li>使用 limit；</li>
<li>同时使用 where 和 limit，此时 where 条件中可以没有索引列；</li>
</ul>
</li>
<li>delete 语句必须满足以下条件能执行成功：<ul>
<li>同时使用 where 和 limit，此时 where 条件中可以没有索引列；</li>
</ul>
</li>
<li>如果 where 条件带上了索引列，但是优化器最终扫描选择的是全表，而不是索引的话，我们可以使用 <code>force index([index_name])</code> 可以告诉优化器使用哪个索引，以此避免有几率锁全表带来的隐患。</li>
</ul>
</li>
</ul>
<h3 id="5-4-MySQL-记录锁-间隙锁可以防止删除操作而导致的幻读吗？"><a href="#5-4-MySQL-记录锁-间隙锁可以防止删除操作而导致的幻读吗？" class="headerlink" title="5.4 MySQL 记录锁+间隙锁可以防止删除操作而导致的幻读吗？"></a>5.4 MySQL 记录锁+间隙锁可以防止删除操作而导致的幻读吗？</h3><ul>
<li>在 MySQL 的可重复读隔离级别下，针对当前读的语句会对<strong>索引</strong>加记录锁+间隙锁，这样可以避免其他事务执行增、删、改时导致幻读的问题。</li>
<li><strong>在线上在执行 update、delete、select … for update 等具有加锁性质的语句，一定要检查语句是否走了索引，如果是全表扫描的话，会对每一个索引加 next-key 锁，相当于把整个表锁住了</strong>，这是挺严重的问题。</li>
</ul>
<h3 id="5-5-MySQL-死锁了，怎么办？"><a href="#5-5-MySQL-死锁了，怎么办？" class="headerlink" title="5.5 MySQL 死锁了，怎么办？"></a>5.5 MySQL 死锁了，怎么办？</h3><ul>
<li><p>假设这时有两事务，一个事务要插入订单 1007 ，另外一个事务要插入订单 1008，因为需要对订单做幂等性校验，所以两个事务先要查询该订单是否存在，不存在才插入记录；两个事务都陷入了等待状态（前提没有打开死锁检测），也就是发生了死锁，因为都在相互等待对方释放锁。这里在查询记录是否存在的时候，使用了 <code>select ... for update</code> 语句，目的为了防止事务执行的过程中，有其他事务插入了记录，而出现幻读的问题。如果没有使用 <code>select ... for update</code> 语句，而使用了单纯的 select 语句，如果是两个订单号一样的请求同时进来，就会出现两个重复的订单，有可能出现幻读</p>
</li>
<li><p>为什么会产生死锁？</p>
<ul>
<li><p><strong>Innodb 引擎为了解决「可重复读」隔离级别下的幻读问题，就引出了 next-key 锁</strong>，它是记录锁和间隙锁的组合。</p>
<ul>
<li>Record Lock，记录锁，锁的是记录本身；</li>
<li>Gap Lock，间隙锁，锁的就是两个值之间的空隙，以防止其他事务在这个空隙间插入新的数据，从而避免幻读现象。</li>
</ul>
<p>普通的 select 语句是不会对记录加锁的，因为它是通过 MVCC 的机制实现的快照读</p>
</li>
<li><p>行锁的释放时机是在事务提交（commit）后，锁就会被释放，并不是一条语句执行完就释放行锁；如果 update 语句的 where 条件没有用到索引列，那么就会全表扫描，在一行行扫描的过程中，不仅给行记录加上了行锁，还给行记录两边的空隙也加上了间隙锁，相当于锁住整个表，然后直到事务结束才会释放锁</p>
</li>
<li><p>可以通过 <code>select * from performance_schema.data_locks\G;</code> 这条语句，查看事务执行 SQL 过程中加了什么锁</p>
</li>
<li><p><strong>插入意向锁与间隙锁是冲突的，所以当其它事务持有该间隙的间隙锁时，需要等待其它事务释放间隙锁之后，才能获取到插入意向锁。而间隙锁与间隙锁之间是兼容的，所以所以两个事务中 <code>select ... for update</code> 语句并不会相互影响</strong></p>
</li>
</ul>
</li>
<li><p>为什么间隙锁与间隙锁之间是兼容的？</p>
<ul>
<li><strong>间隙锁的意义只在于阻止区间被插入</strong>，因此是可以共存的。<strong>一个事务获取的间隙锁不会阻止另一个事务获取同一个间隙范围的间隙锁</strong>，共享和排他的间隙锁是没有区别的，他们相互不冲突，且功能相同，即两个事务可以同时持有包含共同间隙的间隙锁。这里的共同间隙包括两种场景：<ul>
<li>其一是两个间隙锁的间隙区间完全一样；</li>
<li>其二是一个间隙锁包含的间隙区间是另一个间隙锁包含间隙区间的子集。</li>
</ul>
</li>
<li>有一点要注意，<strong>next-key lock 是包含间隙锁+记录锁的，如果一个事务获取了 X 型的 next-key lock，那么另外一个事务在获取相同范围的 X 型的 next-key lock 时，是会被阻塞的</strong>。虽然相同范围的间隙锁是多个事务相互兼容的，但对于记录锁，我们是要考虑 X 型与 S 型关系。X 型的记录锁与 X 型的记录锁是冲突的，比如一个事务执行了 select … where id &#x3D; 1 for update，后一个事务在执行这条语句的时候，就会被阻塞的。</li>
<li>但是还要注意！对于这种范围为 (1006, +∞] 的 next-key lock，两个事务是可以同时持有的，不会冲突。因为 +∞ 并不是一个真实的记录，自然就不需要考虑 X 型与 S 型关系。</li>
</ul>
</li>
<li><p>插入意向锁是什么？</p>
<ul>
<li><strong>插入意向锁是一种特殊的间隙锁，但不同于间隙锁的是，该锁只用于并发插入操作</strong>。</li>
<li>如果说间隙锁锁住的是一个区间，那么「插入意向锁」锁住的就是一个点。因而从这个角度来说，插入意向锁确实是一种特殊的间隙锁。</li>
<li>插入意向锁与间隙锁的另一个非常重要的差别是：尽管「插入意向锁」也属于间隙锁，但两个事务却不能在同一时间内，一个拥有间隙锁，另一个拥有该间隙区间内的插入意向锁（当然，插入意向锁如果不在间隙锁区间内则是可以的）</li>
<li>插入意向锁的生成时机：每插入一条新记录，都需要看一下待插入记录的下一条记录上是否已经被加了间隙锁，如果已加间隙锁，此时会生成一个插入意向锁，然后锁的状态设置为等待状态（<em>PS：MySQL 加锁时，是先生成锁结构，然后设置锁的状态，如果锁状态是等待状态，并不是意味着事务成功获取到了锁，只有当锁状态为正常状态时，才代表事务成功获取到了锁</em>），现象就是 Insert 语句会被阻塞</li>
</ul>
</li>
<li><p>Insert 语句是怎么加行级锁的？</p>
<ul>
<li><p>Insert 语句在正常执行时是不会生成锁结构的，它是靠聚簇索引记录自带的 trx_id 隐藏列来作为<strong>隐式锁</strong>来保护记录的。</p>
</li>
<li><p>当事务需要加锁的时，如果这个锁不可能发生冲突，InnoDB会跳过加锁环节，这种机制称为隐式锁。隐式锁是 InnoDB 实现的一种延迟加锁机制，其特点是只有在可能发生冲突时才加锁，从而减少了锁的数量，提高了系统整体性能。</p>
</li>
<li><p>隐式锁就是在 Insert 过程中不加锁，只有在特殊情况下，才会将隐式锁转换为显示锁，这里我们列举两个场景。</p>
<ul>
<li><p>如果记录之间加有间隙锁，为了避免幻读，此时是不能插入记录的；</p>
</li>
<li><p>如果 Insert 的记录和已有记录存在唯一键冲突，此时也不能插入记录；</p>
<p>至于是行级锁的类型是记录锁，还是 next-key 锁，跟是「主键冲突」还是「唯一二级索引冲突」有关系。</p>
<p>如果主键索引重复：</p>
</li>
<li><p>当隔离级别为<strong>读已提交</strong>时，插入新记录的事务会给已存在的主键值重复的聚簇索引记录<strong>添加 S 型记录锁</strong>。</p>
</li>
<li><p>当隔离级别是<strong>可重复读</strong>（默认隔离级别），插入新记录的事务会给已存在的主键值重复的聚簇索引记录<strong>添加 S 型记录锁</strong>。</p>
<p>如果唯一二级索引列重复：</p>
</li>
<li><p><strong>不论是哪个隔离级别</strong>，插入新记录的事务都会给已存在的二级索引列值重复的二级索引记录<strong>添加 S 型 next-key 锁</strong>。</p>
</li>
</ul>
</li>
</ul>
</li>
<li><p>如何避免死锁？</p>
<ul>
<li>死锁的四个必要条件：<strong>互斥、占有且等待、不可强占用、循环等待</strong>。只要系统发生死锁，这些条件必然成立，但是只要破坏任意一个条件就死锁就不会成立。</li>
<li>在数据库层面，有两种策略通过「打破循环等待条件」来解除死锁状态：<ul>
<li><strong>设置事务等待锁的超时时间</strong>。当一个事务的等待时间超过该值后，就对这个事务进行回滚，于是锁就释放了，另一个事务就可以继续执行了。在 InnoDB 中，参数 <code>innodb_lock_wait_timeout</code> 是用来设置超时时间的，默认值时 50 秒</li>
<li><strong>开启主动死锁检测</strong>。主动死锁检测在发现死锁后，主动回滚死锁链条中的某一个事务，让其他事务得以继续执行。将参数 <code>innodb_deadlock_detect</code> 设置为 on，表示开启这个逻辑，默认就开启。</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="5-6-字节面试：加了什么锁，导致死锁的？"><a href="#5-6-字节面试：加了什么锁，导致死锁的？" class="headerlink" title="5.6 字节面试：加了什么锁，导致死锁的？"></a>5.6 字节面试：加了什么锁，导致死锁的？</h3><ul>
<li><p>通过 <code>select * from performance_schema.data_locks\G;</code> 这条语句，查看事务执行 SQL 过程中加了什么锁</p>
</li>
<li><p>Time 1 阶段，事务 A 执行以下语句：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">mysql<span class="operator">&gt;</span> <span class="keyword">update</span> t_student <span class="keyword">set</span> score <span class="operator">=</span> <span class="number">100</span> <span class="keyword">where</span> id <span class="operator">=</span> <span class="number">25</span>;</span><br></pre></td></tr></table></figure>

<p>加了两个锁，分别是：</p>
<ul>
<li>表锁：X 类型的意向锁；</li>
<li>行锁：X 类型的间隙锁；</li>
</ul>
<p><strong>此时事务 A 在主键索引（INDEX_NAME : PRIMARY）上加的是间隙锁，锁范围是<code>(20, 30)</code></strong></p>
</li>
<li><p>Time 2 阶段，事务B执行以下语句：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">mysql<span class="operator">&gt;</span> <span class="keyword">update</span> t_student <span class="keyword">set</span> score <span class="operator">=</span> <span class="number">100</span> <span class="keyword">where</span> id <span class="operator">=</span> <span class="number">26</span>;</span><br></pre></td></tr></table></figure>

<p>事务 A 和 事务 B 的间隙锁范围都是一样的，两个事务的间隙锁之间是相互兼容的，不会产生冲突。<strong>间隙锁的意义只在于阻止区间被插入</strong>，因此是可以共存的。<strong>一个事务获取的间隙锁不会阻止另一个事务获取同一个间隙范围的间隙锁</strong>，共享（S型）和排他（X型）的间隙锁是没有区别的，他们相互不冲突，且功能相同</p>
</li>
<li><p>Time 3，事务 A 插入了一条记录：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">mysql<span class="operator">&gt;</span> <span class="keyword">insert</span> <span class="keyword">into</span> t_student(id, <span class="keyword">no</span>, name, age,score) <span class="keyword">value</span> (<span class="number">25</span>, <span class="string">&#x27;S0025&#x27;</span>, <span class="string">&#x27;sony&#x27;</span>, <span class="number">28</span>, <span class="number">90</span>);</span><br></pre></td></tr></table></figure>

<p>此时，事务 A 就陷入了等待状态。事务 A 的状态为等待状态（LOCK_STATUS: WAITING），因为向事务 B 生成的间隙锁（范围 <code>(20, 30)</code>）中插入了一条记录，所以事务 A 的插入操作生成了一个插入意向锁（<code>LOCK_MODE:INSERT_INTENTION</code>）</p>
<p><strong>插入意向锁是一种特殊的间隙锁，但不同于间隙锁的是，该锁只用于并发插入操作</strong>。如果说间隙锁锁住的是一个区间，那么「插入意向锁」锁住的就是一个点</p>
<p>插入意向锁与间隙锁的另一个非常重要的差别是：<strong>尽管「插入意向锁」也属于间隙锁，但两个事务却不能在同一时间内，一个拥有间隙锁，另一个拥有该间隙区间内的插入意向锁（当然，插入意向锁如果不在间隙锁区间内则是可以的）。所以，插入意向锁和间隙锁之间是冲突的</strong>。</p>
</li>
<li><p>Time 4，事务 B 插入了一条记录：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">mysql<span class="operator">&gt;</span> <span class="keyword">insert</span> <span class="keyword">into</span> t_student(id, <span class="keyword">no</span>, name, age,score) <span class="keyword">value</span> (<span class="number">26</span>, <span class="string">&#x27;S0026&#x27;</span>, <span class="string">&#x27;ace&#x27;</span>, <span class="number">28</span>, <span class="number">90</span>);</span><br></pre></td></tr></table></figure>

<p>此时，事务 B 就陷入了等待状态。事务 B 在生成插入意向锁时而导致被阻塞，这是因为事务 B 向事务 A 生成的范围为 (20, 30) 的间隙锁插入了一条记录，而插入意向锁和间隙锁是冲突的，所以事务 B 在获取插入意向锁时就陷入了等待状态</p>
</li>
<li><p>事务 A 和事务 B 在执行完后 update 语句后都持有范围为<code>(20, 30）</code>的间隙锁，而接下来的插入操作为了获取到插入意向锁，都在等待对方事务的间隙锁释放，于是就造成了循环等待，满足了死锁的四个条件：<strong>互斥、占有且等待、不可强占用、循环等待</strong>，因此发生了死锁</p>
</li>
<li><p>两个事务即使生成的间隙锁的范围是一样的，也不会发生冲突，因为间隙锁目的是为了防止其他事务插入数据，因此间隙锁与间隙锁之间是相互兼容的。</p>
</li>
<li><p>在执行插入语句时，如果插入的记录在其他事务持有间隙锁范围内，插入语句就会被阻塞，因为插入语句在碰到间隙锁时，会生成一个插入意向锁，然后插入意向锁和间隙锁之间是互斥的关系。</p>
</li>
<li></li>
</ul>
<h3 id="6-1-MySQL-日志：undo-log、redo-log、binlog-有什么用？"><a href="#6-1-MySQL-日志：undo-log、redo-log、binlog-有什么用？" class="headerlink" title="6.1 MySQL 日志：undo log、redo log、binlog 有什么用？"></a>6.1 MySQL 日志：undo log、redo log、binlog 有什么用？</h3><ul>
<li>更新语句的流程会涉及到 undo log（回滚日志）、redo log（重做日志） 、binlog （归档日志）这三种日志：<ul>
<li><strong>undo log（回滚日志）</strong>：是 Innodb 存储引擎层生成的日志，实现了事务中的<strong>原子性</strong>，主要<strong>用于事务回滚和 MVCC</strong>。</li>
<li><strong>redo log（重做日志）</strong>：是 Innodb 存储引擎层生成的日志，实现了事务中的<strong>持久性</strong>，主要<strong>用于掉电等故障恢复</strong>；</li>
<li><strong>binlog （归档日志）</strong>：是 Server 层生成的日志，主要<strong>用于数据备份和主从复制</strong>；</li>
</ul>
</li>
</ul>
<h4 id="为什么需要-undo-log"><a href="#为什么需要-undo-log" class="headerlink" title="为什么需要 undo log"></a>为什么需要 undo log</h4><ul>
<li><p>每次在事务执行过程中，都记录下回滚时需要的信息到一个日志里，那么在事务执行中途发生了 MySQL 崩溃后，就不用担心无法回滚到事务之前的数据，可以通过这个日志回滚到事务之前的数据</p>
<ul>
<li><p><strong>实现事务回滚，保障事务的原子性</strong>；undo log 是一种用于撤销回退的日志。在事务没提交之前，MySQL 会先记录更新前的数据到 undo log 日志文件里面，当事务回滚时，可以利用 undo log 来进行回滚；在发生回滚时，就读取 undo log 里的数据，然后做原先相反操作</p>
</li>
<li><p>一条记录的每一次更新操作产生的 undo log 格式都有一个 roll_pointer 指针和一个 trx_id 事务id：</p>
<ul>
<li>通过 trx_id 可以知道该记录是被哪个事务修改的；</li>
<li>通过 roll_pointer 指针可以将这些 undo log 串成一个链表，这个链表就被称为版本链</li>
</ul>
</li>
<li><p><strong>undo log 还有一个作用，通过 ReadView + undo log 实现 MVCC（多版本并发控制）</strong></p>
<p>对于「读提交」和「可重复读」隔离级别的事务来说，它们的快照读（普通 select 语句）是通过 Read View + undo log 来实现的，它们的区别在于创建 Read View 的时机不同：</p>
<ul>
<li>「读提交」隔离级别是在每个 select 都会生成一个新的 Read View，也意味着，事务期间的多次读取同一条数据，前后两次读的数据可能会出现不一致，因为可能这期间另外一个事务修改了该记录，并提交了事务。</li>
<li>「可重复读」隔离级别是启动事务时生成一个 Read View，然后整个事务期间都在用这个 Read View，这样就保证了在事务期间读到的数据都是事务启动前的记录。</li>
</ul>
<p>这两个隔离级别实现是通过「事务的 Read View 里的字段」和「记录中的两个隐藏列（trx_id 和 roll_pointer）」的比对，如果不满足可见行，就会顺着 undo log 版本链里找到满足其可见性的记录，从而控制并发事务访问同一个记录时的行为，这就叫 MVCC（多版本并发控制）</p>
</li>
</ul>
</li>
</ul>
<h4 id="为什么需要-Buffer-Pool"><a href="#为什么需要-Buffer-Pool" class="headerlink" title="为什么需要 Buffer Pool"></a>为什么需要 Buffer Pool</h4><ul>
<li>MySQL 的数据都是存在磁盘中的，那么我们要更新一条记录的时候，得先要从磁盘读取该记录，然后在内存中修改这条记录。那修改完这条记录选择缓存起来好，这样下次有查询语句命中了这条记录，直接读取缓存中的记录，就不需要从磁盘获取数据。为此，Innodb 存储引擎设计了一个<strong>缓冲池（Buffer Pool）</strong>，来提高数据库的读写性能。</li>
<li>当读取数据时，如果数据存在于 Buffer Pool 中，客户端就会直接读取 Buffer Pool 中的数据，否则再去磁盘中读取。<ul>
<li>当修改数据时，如果数据存在于 Buffer Pool 中，那直接修改 Buffer Pool 中数据所在的页，然后将其页设置为脏页（该页的内存数据和磁盘上的数据已经不一致），为了减少磁盘I&#x2F;O，不会立即将脏页写入磁盘，后续由后台线程选择一个合适的时机将脏页写入到磁盘</li>
<li>Buffer Pool 缓存什么？在 MySQL 启动的时候，<strong>InnoDB 会为 Buffer Pool 申请一片连续的内存空间，然后按照默认的<code>16KB</code>的大小划分出一个个的页， Buffer Pool 中的页就叫做缓存页；</strong>Buffer Pool 除了缓存「索引页」和「数据页」，还包括了 Undo 页，插入缓存、自适应哈希索引、锁信息等等</li>
</ul>
</li>
</ul>
<h4 id="为什么需要-redo-log"><a href="#为什么需要-redo-log" class="headerlink" title="为什么需要 redo log"></a>为什么需要 redo log</h4><ul>
<li><p>Buffer Pool 是基于内存的，而内存总是不可靠，万一断电重启，还没来得及落盘的脏页数据就会丢失。为了防止断电导致数据丢失的问题，当有一条记录需要更新的时候，InnoDB 引擎就会先更新内存（同时标记为脏页），然后将本次对这个页的修改以 redo log 的形式记录下来，<strong>这个时候更新就算完成</strong>;InnoDB 引擎会在适当的时候，由后台线程将缓存在 Buffer Pool 的脏页刷新到磁盘里，这就是 <strong>WAL （Write-Ahead Logging）技术</strong></p>
<ul>
<li><p><strong>WAL 技术指的是， MySQL 的写操作并不是立刻写到磁盘上，而是先写日志，然后在合适的时间再写到磁盘上</strong>。</p>
</li>
<li><p>redo log 是物理日志，记录了某个数据页做了什么修改，比如<strong>对 XXX 表空间中的 YYY 数据页 ZZZ 偏移量的地方做了AAA 更新</strong>，每当执行一个事务就会产生这样的一条或者多条物理日志;当系统崩溃时，虽然脏页数据没有持久化，但是 redo log 已经持久化，接着 MySQL 重启后，可以根据 redo log 的内容，将所有数据恢复到最新的状态。</p>
</li>
<li><p>被修改 Undo 页面，需要记录对应 redo log 吗？</p>
<ul>
<li>需要的。开启事务后，InnoDB 层更新记录前，首先要记录相应的 undo log，如果是更新操作，需要把被更新的列的旧值记下来，也就是要生成一条 undo log，undo log 会写入 Buffer Pool 中的 Undo 页面。不过，<strong>在内存修改该 Undo 页面后，需要记录对应的 redo log</strong>。</li>
</ul>
</li>
<li><p>这两种日志是属于 InnoDB 存储引擎的日志，它们的区别在于：</p>
<ul>
<li>redo log 记录了此次事务「<strong>完成后</strong>」的数据状态，记录的是更新<strong>之后</strong>的值；</li>
<li>undo log 记录了此次事务「<strong>开始前</strong>」的数据状态，记录的是更新<strong>之前</strong>的值；</li>
</ul>
<p>事务提交之前发生了崩溃，重启后会通过 undo log 回滚事务，事务提交之后发生了崩溃，重启后会通过 redo log 恢复事务，<strong>实现事务的持久性，让 MySQL 有 crash-safe 的能力</strong>，能够保证 MySQL 在任何时间段突然崩溃，重启后之前已提交的记录都不会丢失</p>
</li>
<li><p>redo log 要写到磁盘，数据也要写磁盘，为什么要多此一举？</p>
<ul>
<li>写入 redo log 的方式使用了追加操作， 所以磁盘操作是<strong>顺序写</strong>，而写入数据需要先找到写入位置，然后才写到磁盘，所以磁盘操作是<strong>随机写</strong>。磁盘的「顺序写 」比「随机写」 高效的多，因此 redo log 写入磁盘的开销更小</li>
<li>可以说这是 WAL 技术的另外一个优点：<strong>MySQL 的写操作从磁盘的「随机写」变成了「顺序写」</strong>，提升语句的执行性能。这是因为 MySQL 的写操作并不是立刻更新到磁盘上，而是先记录在日志上，然后在合适的时间再更新到磁盘上</li>
</ul>
</li>
<li><p>产生的 redo log 是直接写入磁盘的吗？</p>
<ul>
<li>执行一个事务的过程中，产生的 redo log 也不是直接写入磁盘的，因为这样会产生大量的 I&#x2F;O 操作，而且磁盘的运行速度远慢于内存。</li>
<li>redo log 也有自己的缓存—— <strong>redo log buffer</strong>，每当产生一条 redo log 时，会先写入到 redo log buffer，后续在持久化到磁盘</li>
</ul>
</li>
</ul>
</li>
<li><p>redo log 什么时候刷盘？</p>
<ul>
<li>MySQL 正常关闭时；</li>
<li>当 redo log buffer 中记录的写入量大于 redo log buffer 内存空间的一半时，会触发落盘；</li>
<li>InnoDB 的后台线程每隔 1 秒，将 redo log buffer 持久化到磁盘。</li>
<li>每次事务提交时都将缓存在 redo log buffer 里的 redo log 直接持久化到磁盘<ul>
<li>单独执行一个更新语句的时候，InnoDB 引擎会自己启动一个事务，在执行更新语句的过程中，生成的 redo log 先写入到 redo log buffer 中，然后等事务提交的时候，再将缓存在 redo log buffer 中的 redo log 按组的方式「顺序写」到磁盘</li>
<li>InnoDB 还提供了另外两种策略，由参数 <code>innodb_flush_log_at_trx_commit</code> 参数控制，可取的值有：0（不会主动触发）、1、2（写入<strong>redo log 文件</strong>，操作系统的文件缓存），默认值为 1（每次都刷）</li>
</ul>
</li>
<li>innodb_flush_log_at_trx_commit 为 0 和 2 的时候，什么时候才将 redo log 写入磁盘？<ul>
<li>InnoDB 的后台线程每隔 1 秒：</li>
<li>针对参数 0 ：会把缓存在 redo log buffer 中的 redo log ，通过调用 <code>write()</code> 写到操作系统的 Page Cache，然后调用 <code>fsync()</code> 持久化到磁盘。<strong>所以参数为 0 的策略，MySQL 进程的崩溃会导致上一秒钟所有事务数据的丢失</strong>;</li>
<li>针对参数 2 ：调用 fsync，将缓存在操作系统中 Page Cache 里的 redo log 持久化到磁盘。<strong>所以参数为 2 的策略，较取值为 0 情况下更安全，因为 MySQL 进程的崩溃并不会丢失数据，只有在操作系统崩溃或者系统断电的情况下，上一秒钟所有事务数据才可能丢失</strong></li>
</ul>
</li>
</ul>
</li>
<li><p>redo log 文件写满了怎么办？</p>
<ul>
<li>InnoDB 存储引擎有 1 个重做日志文件组( redo log Group），重做日志文件组由 2 个 redo log 文件组成，每个 redo log File 的大小是固定且一致的，假设每个 redo log File 设置的上限是 1 GB，那么总共就可以记录 2GB 的操作。</li>
<li>重做日志文件组是以<strong>循环写</strong>的方式工作的，从头开始写，写到末尾就又回到开头，相当于一个环形，InnoDB 用 write pos 表示 redo log 当前记录写到的位置，用 checkpoint 表示当前要擦除的位置</li>
<li>如果 write pos 追上了 checkpoint，就意味着 <strong>redo log 文件满了，这时 MySQL 不能再执行新的更新操作，也就是说 MySQL 会被阻塞</strong>（<em>因此所以针对并发量大的系统，适当设置 redo log 的文件大小非常重要</em>），此时会停下来将 Buffer Pool 中的脏页刷新到磁盘中，然后标记 redo log 哪些记录可以被擦除，接着对旧的 redo log 记录进行擦除，等擦除完旧记录腾出了空间，checkpoint 就会往后移动，然后 MySQL 恢复正常运行，继续执行新的更新操作</li>
</ul>
</li>
</ul>
<h4 id="为什么需要-binlog-？"><a href="#为什么需要-binlog-？" class="headerlink" title="为什么需要 binlog ？"></a>为什么需要 binlog ？</h4><ul>
<li><p>MySQL 在完成一条更新操作后，Server 层还会生成一条 binlog，等之后事务提交的时候，会将该事物执行过程中产生的所有 binlog 统一写 入 binlog 文件。binlog 文件是记录了所有数据库表结构变更和表数据修改的日志，不会记录查询类的操作</p>
</li>
<li><p>redo log 和 binlog 有什么区别？</p>
<p><em>1、适用对象不同：</em></p>
<ul>
<li>binlog 是 MySQL 的 Server 层实现的日志，所有存储引擎都可以使用；</li>
<li>redo log 是 Innodb 存储引擎实现的日志；</li>
</ul>
<p><em>2、文件格式不同：</em></p>
<ul>
<li>binlog 有 3 种格式类型，分别是 STATEMENT（默认格式）、ROW、 MIXED，区别如下：<ul>
<li>STATEMENT：每一条修改数据的 SQL 都会被记录到 binlog 中（相当于记录了逻辑操作，所以针对这种格式， binlog 可以称为逻辑日志），主从复制中 slave 端再根据 SQL 语句重现。</li>
<li>ROW：记录行数据最终被修改成什么样了（这种格式的日志，就不能称为逻辑日志了），不会出现 STATEMENT 下动态函数的问题。但 ROW 的缺点是每行数据的变化结果都会被记录，比如执行批量 update 语句，更新多少行数据就会产生多少条记录，使 binlog 文件过大，而在 STATEMENT 格式下只会记录一个 update 语句而已；</li>
<li>MIXED：包含了 STATEMENT 和 ROW 模式，它会根据不同的情况自动使用 ROW 模式和 STATEMENT 模式；</li>
</ul>
</li>
<li>redo log 是物理日志，记录的是在某个数据页做了什么修改，比如对 XXX 表空间中的 YYY 数据页 ZZZ 偏移量的地方做了AAA 更新；</li>
</ul>
<p><em>3、写入方式不同：</em></p>
<ul>
<li>binlog 是追加写，写满一个文件，就创建一个新的文件继续写，不会覆盖以前的日志，保存的是全量的日志。</li>
<li>redo log 是循环写，日志空间大小是固定，全部写满就从头开始，保存未被刷入磁盘的脏页日志。</li>
</ul>
<p><em>4、用途不同：</em></p>
<ul>
<li>binlog 用于备份恢复、主从复制；</li>
<li>redo log 用于掉电等故障恢复。</li>
</ul>
</li>
<li><p>如果不小心整个数据库的数据被删除了，能使用 redo log 文件恢复数据吗？</p>
<ul>
<li>不可以使用 redo log 文件恢复，只能使用 binlog 文件恢复。</li>
<li>因为 redo log 文件是循环写，是会边写边擦除日志的，只记录未被刷入磁盘的数据的物理日志，已经刷入磁盘的数据都会从 redo log 文件里擦除。</li>
<li>binlog 文件保存的是全量的日志，也就是保存了所有数据变更的情况，理论上只要记录在 binlog 上的数据，都可以恢复，所以如果不小心整个数据库的数据被删除了，得用 binlog 文件恢复数据</li>
</ul>
</li>
<li><p>主从复制是怎么实现？</p>
<ul>
<li>MySQL 的主从复制依赖于 binlog ，也就是记录 MySQL 上的所有变化并以二进制形式保存在磁盘上。复制的过程就是将 binlog 中的数据从主库传输到从库上；这个过程一般是<strong>异步</strong>的，也就是主库上执行事务操作的线程不会等待复制 binlog 的线程同步完成。</li>
<li>MySQL 集群的主从复制过程梳理成 3 个阶段：<ul>
<li><strong>写入 Binlog</strong>：主库写 binlog 日志，提交事务，并更新本地存储数据。</li>
<li><strong>同步 Binlog</strong>：把 binlog 复制到所有从库上，每个从库把 binlog 写到暂存日志中。</li>
<li><strong>回放 Binlog</strong>：回放 binlog，并更新存储引擎中的数据。</li>
</ul>
</li>
</ul>
</li>
<li><p>从库是不是越多越好？</p>
<ul>
<li>从库数量增加，从库连接上来的 I&#x2F;O 线程也比较多，<strong>主库也要创建同样多的 log dump 线程来处理复制的请求，对主库资源消耗比较高，同时还受限于主库的网络带宽</strong></li>
<li>在实际使用中，一个主库一般跟 2～3 个从库（1 套数据库，1 主 2 从 1 备主），这就是一主多从的 MySQL 集群结构</li>
</ul>
</li>
<li><p>binlog 什么时候刷盘？</p>
<ul>
<li>事务执行过程中，先把日志写到 binlog cache（Server 层的 cache），事务提交的时候，再把 binlog cache 写到 binlog 文件中。</li>
<li>MySQL 给 binlog cache 分配了一片内存，每个线程一个，参数 binlog_cache_size 用于控制单个线程内 binlog cache 所占内存的大小。如果超过了这个参数规定的大小，就要暂存到磁盘</li>
<li>在事务提交的时候，执行器把 binlog cache 里的完整事务写入到 binlog 文件中，并清空 binlog cache。虽然每个线程有自己 binlog cache，但是最终都写到同一个 binlog 文件</li>
<li>MySQL提供一个 sync_binlog 参数来控制数据库的 binlog 刷到磁盘上的频率：<ul>
<li>sync_binlog &#x3D; 0 的时候，表示每次提交事务都只 write，不 fsync，后续交由操作系统决定何时将数据持久化到磁盘；</li>
<li>sync_binlog &#x3D; 1 的时候，表示每次提交事务都会 write，然后马上执行 fsync；</li>
<li>sync_binlog &#x3D;N(N&gt;1) 的时候，表示每次提交事务都 write，但累积 N 个事务后才 fsync。</li>
</ul>
</li>
</ul>
</li>
<li><p>具体更新一条记录 <code>UPDATE t_user SET name = &#39;xiaolin&#39; WHERE id = 1;</code> 的流程如下:</p>
</li>
</ul>
<ol>
<li>执行器负责具体执行，会调用存储引擎的接口，通过主键索引树搜索获取 id &#x3D; 1 这一行记录：<ul>
<li>如果 id&#x3D;1 这一行所在的数据页本来就在 buffer pool 中，就直接返回给执行器更新；</li>
<li>如果记录不在 buffer pool，将数据页从磁盘读入到 buffer pool，返回记录给执行器。</li>
</ul>
</li>
<li>执行器得到聚簇索引记录后，会看一下更新前的记录和更新后的记录是否一样：<ul>
<li>如果一样的话就不进行后续更新流程；</li>
<li>如果不一样的话就把更新前的记录和更新后的记录都当作参数传给 InnoDB 层，让 InnoDB 真正的执行更新记录的操作；</li>
</ul>
</li>
<li>开启事务， InnoDB 层更新记录前，首先要记录相应的 undo log，因为这是更新操作，需要把被更新的列的旧值记下来，也就是要生成一条 undo log，undo log 会写入 Buffer Pool 中的 Undo 页面，不过在内存修改该 Undo 页面后，需要记录对应的 redo log。</li>
<li>InnoDB 层开始更新记录，会先更新内存（同时标记为脏页），然后将记录写到 redo log 里面，这个时候更新就算完成了。为了减少磁盘I&#x2F;O，不会立即将脏页写入磁盘，后续由后台线程选择一个合适的时机将脏页写入到磁盘。这就是 <strong>WAL 技术</strong>，MySQL 的写操作并不是立刻写到磁盘上，而是先写 redo 日志，然后在合适的时间再将修改的行数据写到磁盘上。</li>
<li>至此，一条记录更新完了。</li>
<li>在一条更新语句执行完成后，然后开始记录该语句对应的 binlog，此时记录的 binlog 会被保存到 binlog cache，并没有刷新到硬盘上的 binlog 文件，在事务提交时才会统一将该事务运行过程中的所有 binlog 刷新到硬盘。</li>
<li>事务提交：<ul>
<li><strong>prepare 阶段</strong>：将 redo log 对应的事务状态设置为 prepare，然后将 redo log 刷新到硬盘；</li>
<li><strong>commit 阶段</strong>：将 binlog 刷新到磁盘，接着调用引擎的提交事务接口，将 redo log 状态设置为 commit（将事务设置为 commit 状态后，刷入到磁盘 redo log 文件）；</li>
</ul>
</li>
<li>至此，一条更新语句执行完成。</li>
</ol>
<h4 id="为什么需要两阶段提交？"><a href="#为什么需要两阶段提交？" class="headerlink" title="为什么需要两阶段提交？"></a>为什么需要两阶段提交？</h4><ul>
<li><p>事务提交后，redo log 和 binlog 都要持久化到磁盘，但是这两个是独立的逻辑，可能出现半成功的状态，这样就造成两份日志之间的逻辑不一致。这是因为 redo log 影响主库的数据，binlog 影响从库的数据，所以 redo log 和 binlog 必须保持一致才能保证主从数据一致。</p>
</li>
<li><p>两阶段提交其实是分布式事务一致性协议，它可以保证多个逻辑操作要不全部成功，要不全部失败，不会出现半成功的状态；<strong>两阶段提交把单个事务的提交拆分成了 2 个阶段，分别是「准备（Prepare）阶段」和「提交（Commit）阶段」</strong>，每个阶段都由协调者（Coordinator）和参与者（Participant）共同完成</p>
</li>
<li><p>当客户端执行 commit 语句或者在自动提交的情况下，MySQL 内部开启一个 XA 事务，<strong>分两阶段来完成 XA 事务的提交</strong>，事务的提交过程有两个阶段，就是<strong>将 redo log 的写入拆成了两个步骤：prepare 和 commit，中间再穿插写入binlog</strong>，具体如下：</p>
<ul>
<li><strong>prepare 阶段</strong>：将 XID（内部 XA 事务的 ID） 写入到 redo log，同时将 redo log 对应的事务状态设置为 prepare，然后将 redo log 刷新到硬盘；</li>
<li><strong>commit 阶段</strong>：把 XID 写入到 binlog，然后将 binlog 刷新到磁盘，接着调用引擎的提交事务接口，将 redo log 状态设置为 commit（将事务设置为 commit 状态后，刷入到磁盘 redo log 文件，所以 commit 状态也是会刷盘的）；</li>
</ul>
</li>
<li><p>在两阶段提交的不同时刻，MySQL 异常重启会出现什么现象：在 MySQL 重启后会按顺序扫描 redo log 文件，碰到处于 prepare 状态的 redo log，就拿着 redo log 中的 XID 去 binlog 查看是否存在此 XID：</p>
<ul>
<li><strong>如果 binlog 中没有当前内部 XA 事务的 XID，说明 redolog 完成刷盘，但是 binlog 还没有刷盘，则回滚事务</strong>。对应时刻 A 崩溃恢复的情况。</li>
<li><strong>如果 binlog 中有当前内部 XA 事务的 XID，说明 redolog 和 binlog 都已经完成了刷盘，则提交事务</strong>。对应时刻 B 崩溃恢复的情况。</li>
</ul>
<p><strong>两阶段提交是以 binlog 写成功为事务提交成功的标识</strong>，因为 binlog 写成功了，就意味着能在 binlog 中查找到与 redo log 相同的 XID</p>
</li>
<li><p>处于 prepare 阶段的 redo log 加上完整 binlog，重启就提交事务，MySQL 为什么要这么设计?</p>
<ul>
<li>binlog 已经写入了，之后就会被从库（或者用这个 binlog 恢复出来的库）使用。所以，在主库上也要提交这个事务。采用这个策略，主库和备库的数据就保证了一致性。</li>
</ul>
</li>
<li><p>事务没提交的时候，redo log 会被持久化到磁盘吗？</p>
<ul>
<li>会的。事务执行中间过程的 redo log 也是直接写在 redo log buffer 中的，这些缓存在 redo log buffer 里的 redo log 也会被「后台线程」每隔一秒一起持久化到磁盘。</li>
<li>如果 mysql 崩溃了，还没提交事务的 redo log 已经被持久化磁盘了，mysql 重启后，数据不就不一致了？这种情况 mysql 重启会进行回滚操作，因为事务没提交的时候，binlog 是还没持久化到磁盘的。</li>
<li>redo log 可以在事务没提交之前持久化到磁盘，但是 binlog 必须在事务提交之后，才可以持久化到磁盘</li>
</ul>
</li>
<li><p>两阶段提交有什么问题？</p>
<ul>
<li><strong>磁盘 I&#x2F;O 次数高</strong>：对于“双1”配置，每个事务提交都会进行两次 fsync（刷盘），一次是 redo log 刷盘，另一次是 binlog 刷盘。</li>
<li><strong>锁竞争激烈</strong>：两阶段提交虽然能够保证「单事务」两个日志的内容一致，但在「多事务」的情况下，却不能保证两者的提交顺序一致，因此，在两阶段提交的流程基础上，还需要加一个锁来保证提交的原子性，从而保证多事务的情况下，两个日志的提交顺序一致。</li>
</ul>
</li>
<li><p>为什么两阶段提交的磁盘 I&#x2F;O 次数会很高？</p>
<ul>
<li>binlog 和 redo log 在内存中都对应的缓存空间，binlog 会缓存在 binlog cache，redo log 会缓存在 redo log buffer，它们持久化到磁盘的时机分别由下面这两个参数控制。一般为了避免日志丢失的风险，会将这两个参数设置为 1：<ul>
<li>当 sync_binlog &#x3D; 1 的时候，表示每次提交事务都会将 binlog cache 里的 binlog 直接持久到磁盘；</li>
<li>当 innodb_flush_log_at_trx_commit &#x3D; 1 时，表示每次事务提交时，都将缓存在 redo log buffer 里的 redo log 直接持久化到磁盘；</li>
</ul>
</li>
<li>如果 sync_binlog 和 当 innodb_flush_log_at_trx_commit 都设置为 1，那么在每个事务提交过程中， 都会至少调用 2 次刷盘操作，一次是 redo log 刷盘，一次是 binlog 落盘，所以这会成为性能瓶颈。</li>
</ul>
</li>
<li><p>为什么锁竞争激烈？</p>
<ul>
<li>在早期的 MySQL 版本中，通过使用 prepare_commit_mutex 锁来保证事务提交的顺序，在一个事务获取到锁时才能进入 prepare 阶段，一直到 commit 阶段结束才能释放锁，下个事务才可以继续进行 prepare 操作。</li>
<li>通过加锁虽然完美地解决了顺序一致性的问题，但在并发量较大的时候，就会导致对锁的争用，性能不佳。</li>
</ul>
</li>
<li><p><strong>MySQL 引入了 binlog 组提交（group commit）机制，当有多个事务提交的时候，会将多个 binlog 刷盘操作合并成一个，从而减少磁盘 I&#x2F;O 的次数</strong>；引入了组提交机制后，prepare 阶段不变，只针对 commit 阶段，将 commit 阶段拆分为三个过程：</p>
<ul>
<li><strong>flush 阶段</strong>：多个事务按进入的顺序将 binlog 从 cache 写入文件（不刷盘）；</li>
<li><strong>sync 阶段</strong>：对 binlog 文件做 fsync 操作（多个事务的 binlog 合并一次刷盘）；</li>
<li><strong>commit 阶段</strong>：各个事务按顺序做 InnoDB commit 操作；</li>
</ul>
<p>上面的<strong>每个阶段都有一个队列</strong>，每个阶段有锁进行保护，因此保证了事务写入的顺序，第一个进入队列的事务会成为 leader，leader领导所在队列的所有事务，全权负责整队的操作，完成后通知队内其他事务操作结束。对每个阶段引入了队列后，锁就只针对每个队列进行保护，不再锁住提交事务的整个过程，可以看的出来，<strong>锁粒度减小了，这样就使得多个阶段可以并发执行，从而提升效率</strong>。</p>
</li>
<li><p>如果想提升 binlog 组提交的效果，可以通过设置下面这两个参数来实现：</p>
<ul>
<li><code>binlog_group_commit_sync_delay= N</code>，表示在等待 N 微妙后，直接调用 fsync，将处于文件系统中 page cache 中的 binlog 刷盘，也就是将「 binlog 文件」持久化到磁盘。</li>
<li><code>binlog_group_commit_sync_no_delay_count = N</code>，表示如果队列中的事务数达到 N 个，就忽视binlog_group_commit_sync_delay 的设置，直接调用 fsync，将处于文件系统中 page cache 中的 binlog 刷盘。</li>
</ul>
</li>
<li><p>MySQL 磁盘 I&#x2F;O 很高，有什么优化的方法？</p>
<ul>
<li>事务在提交的时候，需要将 binlog 和 redo log 持久化到磁盘，那么如果出现 MySQL 磁盘 I&#x2F;O 很高的现象，可以通过控制以下参数，来 “延迟” binlog 和 redo log 刷盘的时机，从而降低磁盘 I&#x2F;O 的频率：<ul>
<li>设置组提交的两个参数： binlog_group_commit_sync_delay 和 binlog_group_commit_sync_no_delay_count 参数，延迟 binlog 刷盘的时机，从而减少 binlog 的刷盘次数。这个方法是基于“额外的故意等待”来实现的，因此可能会增加语句的响应时间，但即使 MySQL 进程中途挂了，也没有丢失数据的风险，因为 binlog 早被写入到 page cache 了，只要系统没有宕机，缓存在 page cache 里的 binlog 就会被持久化到磁盘。</li>
<li>将 sync_binlog 设置为大于 1 的值（比较常见是 100~1000），表示每次提交事务都 write，但累积 N 个事务后才 fsync，相当于延迟了 binlog 刷盘的时机。但是这样做的风险是，主机掉电时会丢 N 个事务的 binlog 日志。</li>
<li>将 innodb_flush_log_at_trx_commit 设置为 2。表示每次事务提交时，都只是缓存在 redo log buffer 里的 redo log 写到 redo log 文件，注意写入到「 redo log 文件」并不意味着写入到了磁盘，因为操作系统的文件系统中有个 Page Cache，专门用来缓存文件数据的，所以写入「 redo log文件」意味着写入到了操作系统的文件缓存，然后交由操作系统控制持久化到磁盘的时机。但是这样做的风险是，主机掉电的时候会丢数据</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="7-1-揭开-Buffer-Pool-的面纱"><a href="#7-1-揭开-Buffer-Pool-的面纱" class="headerlink" title="7.1 揭开 Buffer Pool 的面纱"></a>7.1 揭开 Buffer Pool 的面纱</h3><ul>
<li><p>为什么要有 Buffer Pool？</p>
<ul>
<li>虽然说 MySQL 的数据是存储在磁盘里的，但是也不能每次都从磁盘里面读取数据，这样性能是极差的。要想提升查询性能，加个缓存就行了嘛。所以，当数据从磁盘中取出后，缓存内存中，下次查询同样的数据的时候，直接从内存中读取。为此，Innodb 存储引擎设计了一个<strong>缓冲池（Buffer Pool）</strong>，来提高数据库的读写性能。</li>
<li>有了缓冲池后：<ul>
<li>当读取数据时，如果数据存在于 Buffer Pool 中，客户端就会直接读取 Buffer Pool 中的数据，否则再去磁盘中读取。</li>
<li>当修改数据时，首先是修改 Buffer Pool 中数据所在的页，然后将其页设置为脏页，最后由后台线程将脏页写入到磁盘。</li>
</ul>
</li>
</ul>
</li>
<li><p>Buffer Pool 有多大？</p>
<ul>
<li>Buffer Pool 是在 MySQL 启动的时候，向操作系统申请的一片连续的内存空间，默认配置下 Buffer Pool 只有 <code>128MB</code> 。</li>
<li>可以通过调整 <code>innodb_buffer_pool_size</code> 参数来设置 Buffer Pool 的大小，一般建议设置成可用物理内存的 60%~80%</li>
</ul>
</li>
<li><p>Buffer Pool 缓存什么？</p>
<ul>
<li>InnoDB 会把存储的数据划分为若干个「页」，以页作为磁盘和内存交互的基本单位，一个页的默认大小为 16KB。因此，Buffer Pool 同样需要按「页」来划分。</li>
<li>在 MySQL 启动的时候，<strong>InnoDB 会为 Buffer Pool 申请一片连续的内存空间，然后按照默认的<code>16KB</code>的大小划分出一个个的页， Buffer Pool 中的页就叫做缓存页</strong>。此时这些缓存页都是空闲的，之后随着程序的运行，才会有磁盘上的页被缓存到 Buffer Pool 中。<ul>
<li>MySQL 刚启动的时候，你会观察到使用的虚拟内存空间很大，而使用到的物理内存空间却很小，这是因为只有这些虚拟内存被访问后，操作系统才会触发缺页中断，接着将虚拟地址和物理地址建立映射关系。</li>
</ul>
</li>
<li>Buffer Pool 除了缓存「索引页」和「数据页」，还包括了 undo 页，插入缓存、自适应哈希索引、锁信息等等。为了更好的管理这些在 Buffer Pool 中的缓存页，InnoDB 为每一个缓存页都创建了一个<strong>控制块</strong>，控制块信息包括「缓存页的表空间、页号、缓存页地址、链表节点」等等。控制块也是占有内存空间的，它是放在 Buffer Pool 的最前面，接着才是缓存页</li>
<li>为什么会有碎片空间呢？<ul>
<li>每一个控制块都对应一个缓存页，那在分配足够多的控制块和缓存页后，可能剩余的那点儿空间不够一对控制块和缓存页的大小，自然就用不到喽，这个用不到的那点儿内存空间就被称为碎片</li>
</ul>
</li>
<li>查询一条记录，就只需要缓冲一条记录吗？<ul>
<li>当我们查询一条记录时，InnoDB 是会把整个页的数据加载到 Buffer Pool 中，因为，通过索引只能定位到磁盘中的页，而不能定位到页中的一条记录。将页加载到 Buffer Pool 后，再通过页里的页目录去定位到某条具体的记录。</li>
</ul>
</li>
</ul>
</li>
<li><p>如何管理 Buffer Pool？</p>
<ul>
<li>如何管理空闲页？<ul>
<li>Buffer Pool 是一片连续的内存空间，当 MySQL 运行一段时间后，这片连续的内存空间中的缓存页既有空闲的，也有被使用的。那当我们从磁盘读取数据的时候，总不能通过遍历这一片连续的内存空间来找到空闲的缓存页吧，这样效率太低了。</li>
<li>为了能够快速找到空闲的缓存页，可以使用链表结构，将空闲缓存页的「控制块」作为链表的节点，这个链表称为 <strong>Free 链表</strong>（空闲链表）。</li>
<li>Free 链表上除了有控制块，还有一个头节点，该头节点包含链表的头节点地址，尾节点地址，以及当前链表中节点的数量等信息。Free 链表节点是一个一个的控制块，而每个控制块包含着对应缓存页的地址，所以相当于 Free 链表节点都对应一个空闲的缓存页。</li>
<li>有了 Free 链表后，每当需要从磁盘中加载一个页到 Buffer Pool 中时，就从 Free链表中取一个空闲的缓存页，并且把该缓存页对应的控制块的信息填上，然后把该缓存页对应的控制块从 Free 链表中移除</li>
</ul>
</li>
<li>如何管理脏页？<ul>
<li>设计 Buffer Pool 除了能提高读性能，还能提高写性能，也就是更新数据的时候，不需要每次都要写入磁盘，而是将 Buffer Pool 对应的缓存页标记为<strong>脏页</strong>，然后再由后台线程将脏页写入到磁盘。</li>
<li>那为了能快速知道哪些缓存页是脏的，于是就设计出 <strong>Flush 链表</strong>，它跟 Free 链表类似的，链表的节点也是控制块，区别在于 Flush 链表的元素都是脏页。</li>
</ul>
</li>
<li>如何提高缓存命中率？<ul>
<li>Buffer Pool 的大小是有限的，对于一些频繁访问的数据我们希望可以一直留在 Buffer Pool 中，而一些很少访问的数据希望可以在某些时机可以淘汰掉，从而保证 Buffer Pool 不会因为满了而导致无法再缓存新的数据，同时还能保证常用数据留在 Buffer Pool 中。</li>
<li>最容易想到的就是 LRU（Least recently used）算法。该算法的思路是，链表头部的节点是最近使用的，而链表末尾的节点是最久没被使用的。那么，当空间不够了，就淘汰最久没被使用的节点，从而腾出空间。</li>
<li>简单的 LRU 算法的实现思路是这样的：<ul>
<li>当访问的页在 Buffer Pool 里，就直接把该页对应的 LRU 链表节点移动到链表的头部。</li>
<li>当访问的页不在 Buffer Pool 里，除了要把页放入到 LRU 链表的头部，还要淘汰 LRU 链表末尾的节点</li>
</ul>
</li>
<li>Buffer Pool 里有三种页和链表来管理数据。<ul>
<li>Free Page（空闲页），表示此页未被使用，位于 Free 链表；</li>
<li>Clean Page（干净页），表示此页已被使用，但是页面未发生修改，位于LRU 链表。</li>
<li>Dirty Page（脏页），表示此页「已被使用」且「已经被修改」，其数据和磁盘上的数据已经不一致。当脏页上的数据写入磁盘后，内存数据和磁盘数据一致，那么该页就变成了干净页。脏页同时存在于 LRU 链表和 Flush 链表。</li>
</ul>
</li>
<li>简单的 LRU 算法并没有被 MySQL 使用，因为简单的 LRU 算法无法避免下面这两个问题：<ul>
<li>预读失效；</li>
<li>Buffer Pool 污染；</li>
</ul>
</li>
<li>什么是预读失效？<ul>
<li>MySQL 在加载数据页时，会提前把它相邻的数据页一并加载进来，目的是为了减少磁盘 IO。但是可能这些<strong>被提前加载进来的数据页，并没有被访问</strong>，相当于这个预读是白做了，这个就是<strong>预读失效</strong></li>
<li>如果使用简单的 LRU 算法，就会把预读页放到 LRU 链表头部，而当 Buffer Pool空间不够的时候，还需要把末尾的页淘汰掉。如果这些预读页如果一直不会被访问到，就会出现一个很奇怪的问题，不会被访问的预读页却占用了 LRU 链表前排的位置，而末尾淘汰的页，可能是频繁访问的页，这样就大大降低了缓存命中率。</li>
</ul>
</li>
<li>怎么解决预读失效而导致缓存命中率降低的问题？<ul>
<li>要避免预读失效带来影响，最好就是<strong>让预读的页停留在 Buffer Pool 里的时间要尽可能的短，让真正被访问的页才移动到 LRU 链表的头部，从而保证真正被读取的热数据留在 Buffer Pool 里的时间尽可能长</strong>。</li>
<li>MySQL 改进了 LRU 算法，将 LRU 划分了 2 个区域：<strong>old 区域 和 young 区域</strong>。young 区域在 LRU 链表的前半部分，old 区域则是在后半部分；old 区域占整个 LRU 链表长度的比例可以通过 <code>innodb_old_blocks_pc</code> 参数来设置，默认是 37，代表整个 LRU 链表中 young 区域与 old 区域比例是 63:37。<strong>划分这两个区域后，预读的页就只需要加入到 old 区域的头部，当页被真正访问的时候，才将页插入 young 区域的头部</strong>。如果预读的页一直没有被访问，就会从 old 区域移除，这样就不会影响 young 区域中的热点数据。</li>
</ul>
</li>
<li>什么是 Buffer Pool 污染？<ul>
<li>当某一个 SQL 语句<strong>扫描了大量的数据</strong>时，在 Buffer Pool 空间比较有限的情况下，可能会将 <strong>Buffer Pool 里的所有页都替换出去，导致大量热数据被淘汰了</strong>，等这些热数据又被再次访问的时候，由于缓存未命中，就会产生大量的磁盘 IO，MySQL 性能就会急剧下降，这个过程被称为 <strong>Buffer Pool 污染</strong>。</li>
</ul>
</li>
<li>怎么解决出现 Buffer Pool 污染而导致缓存命中率下降的问题？<ul>
<li>全表扫描的查询，很多缓冲页其实只会被访问一次，但是它却只因为被访问了一次而进入到 young 区域，从而导致热点数据被替换了。LRU 链表中 young 区域就是热点数据，只要我们提高进入到 young 区域的门槛，就能有效地保证 young 区域里的热点数据不会被替换掉。</li>
<li>MySQL 是这样做的，进入到 young 区域条件增加了一个<strong>停留在 old 区域的时间判断</strong>。在对某个处在 old 区域的缓存页进行第一次访问时，就在它对应的控制块中记录下来这个访问时间：<ul>
<li>如果后续的访问时间与第一次访问的时间<strong>在某个时间间隔内</strong>，那么<strong>该缓存页就不会被从 old 区域移动到 young 区域的头部</strong>；</li>
<li>如果后续的访问时间与第一次访问的时间<strong>不在某个时间间隔内</strong>，那么<strong>该缓存页移动到 young 区域的头部</strong>；</li>
</ul>
</li>
<li><strong>只有同时满足「被访问」与「在 old 区域停留时间超过 1 秒」两个条件，才会被插入到 young 区域头部</strong>，这样就解决了 Buffer Pool 污染的问题 。</li>
<li>另外，MySQL 针对 young 区域其实做了一个优化，为了防止 young 区域节点频繁移动到头部。young 区域前面 1&#x2F;4 被访问不会移动到链表头部，只有后面的 3&#x2F;4被访问了才会</li>
</ul>
</li>
</ul>
</li>
<li>脏页什么时候会被刷入磁盘？<ul>
<li>脏页需要被刷入磁盘，保证缓存和磁盘数据一致，但是若每次修改数据都刷入磁盘，则性能会很差，因此一般都会在一定时机进行批量刷盘。</li>
<li>InnoDB 的更新操作采用的是 Write Ahead Log 策略，即先写日志，再写入磁盘，通过 redo log 日志让 MySQL 拥有了崩溃恢复能力。下面几种情况会触发脏页的刷新：<ul>
<li>当 redo log 日志满了的情况下，会主动触发脏页刷新到磁盘；</li>
<li>Buffer Pool 空间不足时，需要将一部分数据页淘汰掉，如果淘汰的是脏页，需要先将脏页同步到磁盘；</li>
<li>MySQL 认为空闲时，后台线程回定期将适量的脏页刷入到磁盘；</li>
<li>MySQL 正常关闭之前，会把所有的脏页刷入到磁盘</li>
</ul>
</li>
<li>在开启了慢 SQL 监控后，如果你发现「偶尔」会出现一些用时稍长的 SQL，这可因为脏页在刷新到磁盘时导致数据库性能抖动。如果在很短的时间出现这种现象，就需要调大 Buffer Pool 空间或 redo log 日志的大小。</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="Redis"><a href="#Redis" class="headerlink" title="Redis"></a>Redis</h2><h3 id="2-1-Redis-常见面试题"><a href="#2-1-Redis-常见面试题" class="headerlink" title="2.1 Redis 常见面试题"></a>2.1 Redis 常见面试题</h3><h4 id="认识Redis"><a href="#认识Redis" class="headerlink" title="认识Redis"></a>认识Redis</h4><ul>
<li>什么是 Redis？<ul>
<li>Redis 是一种基于内存的数据库，对数据的读写操作都是在内存中完成，因此<strong>读写速度非常快</strong>，常用于<strong>缓存，消息队列、分布式锁等场景</strong></li>
<li>Redis 提供了多种数据类型来支持不同的业务场景，比如 String(字符串)、Hash(哈希)、 List (列表)、Set(集合)、Zset(有序集合)、Bitmaps（位图）、HyperLogLog（基数统计）、GEO（地理信息）、Stream（流），并且对数据类型的操作都是<strong>原子性</strong>的，因为执行命令由单线程负责的，不存在并发竞争的问题</li>
<li>除此之外，Redis 还支持<strong>事务 、持久化、Lua 脚本、多种集群方案（主从复制模式、哨兵模式、切片机群模式）、发布&#x2F;订阅模式，内存淘汰机制、过期删除机制</strong>等等</li>
</ul>
</li>
<li>Redis 和 Memcached 有什么区别？<ul>
<li>Redis 与 Memcached <strong>共同点</strong>：<ol>
<li>都是基于内存的数据库，一般都用来当做缓存使用。</li>
<li>都有过期策略。</li>
<li>两者的性能都非常高。</li>
</ol>
</li>
<li>Redis 与 Memcached <strong>区别</strong>：<ul>
<li>Redis 支持的数据类型更丰富（String、Hash、List、Set、ZSet），而 Memcached 只支持最简单的 key-value 数据类型；</li>
<li>Redis <strong>支持数据的持久化</strong>，可以将内存中的数据保持在磁盘中，重启的时候可以再次加载进行使用，而 Memcached 没有持久化功能，数据全部存在内存之中，Memcached 重启或者挂掉后，数据就没了；</li>
<li>Redis 原生<strong>支持集群模式</strong>，Memcached 没有原生的集群模式，需要依靠客户端来实现往集群中分片写入数据；</li>
<li>Redis 支持<strong>发布订阅模型、Lua 脚本、事务</strong>等功能，而 Memcached 不支持</li>
</ul>
</li>
</ul>
</li>
<li>为什么用 Redis 作为 MySQL 的缓存？<ul>
<li><em><strong>Redis 具备高性能</strong></em>，操作 Redis 缓存就是直接操作内存，所以速度相当快</li>
<li><em><strong>Redis 具备高并发</strong></em>，单台设备的 Redis 的 QPS 是 MySQL 的 10 倍，直接访问 Redis 能够承受的请求是远远大于直接访问 MySQL 的，所以我们可以考虑把数据库中的部分数据转移到缓存中去，这样用户的一部分请求会直接到缓存这里而不用经过数据库</li>
</ul>
</li>
</ul>
<h4 id="Redis-数据结构"><a href="#Redis-数据结构" class="headerlink" title="Redis 数据结构"></a>Redis 数据结构</h4><ul>
<li><p>Redis 数据类型以及使用场景分别是什么？</p>
<p>常见的有五种数据类型：<strong>String（字符串），Hash（哈希），List（列表），Set（集合）、Zset（有序集合）</strong></p>
<p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/redis/%E5%85%AB%E8%82%A1%E6%96%87/%E4%BA%94%E7%A7%8D%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B.png" alt="img"></p>
<ul>
<li>Redis 五种数据类型的应用场景：<ul>
<li>String 类型的应用场景：缓存对象、常规计数、分布式锁、共享 session 信息等。</li>
<li>List 类型的应用场景：消息队列（但是有两个问题：1. 生产者需要自行实现全局唯一 ID；2. 不能以消费组形式消费数据）等。</li>
<li>Hash 类型：缓存对象、购物车等。</li>
<li>Set 类型：聚合计算（并集、交集、差集）场景，比如点赞、共同关注、抽奖活动等。</li>
<li>Zset 类型：排序场景，比如排行榜、电话和姓名排序等。</li>
</ul>
</li>
<li>Redis 后续版本又支持四种数据类型，它们的应用场景如下：<ul>
<li>BitMap（2.2 版新增）：二值状态统计的场景，比如签到、判断用户登陆状态、连续签到用户总数等；</li>
<li>HyperLogLog（2.8 版新增）：海量数据基数统计的场景，比如百万级网页 UV 计数等；</li>
<li>GEO（3.2 版新增）：存储地理位置信息的场景，比如滴滴叫车；</li>
<li>Stream（5.0 版新增）：消息队列，相比于基于 List 类型实现的消息队列，有这两个特有的特性：自动生成全局唯一消息ID，支持以消费组形式消费数据。</li>
</ul>
</li>
</ul>
</li>
<li><p>五种常见的 Redis 数据类型是怎么实现？</p>
<ul>
<li><p>String 类型内部实现：String 类型的底层的数据结构实现主要是 SDS（简单动态字符串），之所以没有使用 C 语言的字符串表示，因为 SDS 相比于 C 的原生字符串：</p>
<ul>
<li><strong>SDS 不仅可以保存文本数据，还可以保存二进制数据</strong>。因为 SDS 使用 len 属性的值而不是空字符来判断字符串是否结束，并且 SDS 的所有 API 都会以处理二进制的方式来处理 SDS 存放在 buf[] 数组里的数据。所以 SDS 不光能存放文本数据，而且能保存图片、音频、视频、压缩文件这样的二进制数据。</li>
<li>**SDS 获取字符串长度的时间复杂度是 O(1)**。因为 C 语言的字符串并不记录自身长度，所以获取长度的复杂度为 O(n)；而 SDS 结构里用 len 属性记录了字符串长度，所以复杂度为 O(1)。</li>
<li><strong>Redis 的 SDS API 是安全的，拼接字符串不会造成缓冲区溢出</strong>。因为 SDS 在拼接字符串之前会检查 SDS 空间是否满足要求，如果空间不够会自动扩容，所以不会导致缓冲区溢出的问题。</li>
</ul>
</li>
<li><p>List 类型内部实现：List 类型的底层数据结构是由<strong>双向链表或压缩列表</strong>实现的：</p>
<ul>
<li>如果列表的元素个数小于 512 个（默认值，可由 list-max-ziplist-entries 配置），列表每个元素的值都小于 64 字节（默认值，可由 list-max-ziplist-value 配置），Redis 会使用<strong>压缩列表</strong>作为 List 类型的底层数据结构；</li>
<li>如果列表的元素不满足上面的条件，Redis 会使用<strong>双向链表</strong>作为 List 类型的底层数据结构；</li>
</ul>
<p>但是<strong>在 Redis 3.2 版本之后，List 数据类型底层数据结构就只由 quicklist 实现了，替代了双向链表和压缩列表</strong></p>
</li>
<li><p>Hash 类型内部实现：Hash 类型的底层数据结构是由<strong>压缩列表或哈希表</strong>实现的：</p>
<ul>
<li>如果哈希类型元素个数小于 512 个（默认值，可由 hash-max-ziplist-entries 配置），所有值小于 64 字节（默认值，可由 hash-max-ziplist-value 配置）的话，Redis 会使用<strong>压缩列表</strong>作为 Hash 类型的底层数据结构；</li>
<li>如果哈希类型元素不满足上面条件，Redis 会使用<strong>哈希表</strong>作为 Hash 类型的底层数据结构。</li>
</ul>
<p><strong>在 Redis 7.0 中，压缩列表数据结构已经废弃了，交由 listpack 数据结构来实现了</strong></p>
</li>
<li><p>Set 类型内部实现：Set 类型的底层数据结构是由<strong>哈希表或整数集合</strong>实现的：</p>
<ul>
<li>如果集合中的元素都是整数且元素个数小于 512 （默认值，set-maxintset-entries配置）个，Redis 会使用<strong>整数集合</strong>作为 Set 类型的底层数据结构；</li>
<li>如果集合中的元素不满足上面条件，则 Redis 使用<strong>哈希表</strong>作为 Set 类型的底层数据结构。</li>
</ul>
</li>
<li><p>ZSet 类型内部实现：Zset 类型的底层数据结构是由<strong>压缩列表或跳表</strong>实现的：</p>
<ul>
<li>如果有序集合的元素个数小于 128 个，并且每个元素的值小于 64 字节时，Redis 会使用<strong>压缩列表</strong>作为 Zset 类型的底层数据结构；</li>
<li>如果有序集合的元素不满足上面的条件，Redis 会使用<strong>跳表</strong>作为 Zset 类型的底层数据结构；</li>
</ul>
<p><strong>在 Redis 7.0 中，压缩列表数据结构已经废弃了，交由 listpack 数据结构来实现了</strong></p>
</li>
</ul>
</li>
</ul>
<h4 id="Redis-线程模型"><a href="#Redis-线程模型" class="headerlink" title="Redis 线程模型"></a>Redis 线程模型</h4><ul>
<li><p>Redis 是单线程吗？</p>
<ul>
<li><strong>Redis 单线程指的是「接收客户端请求-&gt;解析请求 -&gt;进行数据读写等操作-&gt;发送数据给客户端」这个过程是由一个线程（主线程）来完成的</strong></li>
<li><strong>Redis 程序并不是单线程的</strong>，Redis 在启动的时候，是会<strong>启动后台线程</strong>（BIO）的；之所以 Redis 为「关闭文件、AOF 刷盘、释放内存」这些任务创建单独的线程来处理，是因为这些任务的操作都是很耗时的，如果把这些任务都放在主线程来处理，那么 Redis 主线程就很容易发生阻塞，这样就无法处理后续的请求<ul>
<li>后台线程相当于一个消费者，生产者把耗时任务丢到任务队列中，消费者（BIO）不停轮询这个队列，拿出任务就去执行对应的方法即可</li>
</ul>
</li>
</ul>
</li>
<li><p>Redis 单线程模式是怎样的？</p>
<ul>
<li>网络 I&#x2F;O 和命令处理都是单线程。 Redis 初始化的时候，会做下面这几件事情：<ul>
<li>首先，调用 epoll_create() 创建一个 epoll 对象和调用 socket() 一个服务端 socket</li>
<li>然后，调用 bind() 绑定端口和调用 listen() 监听该 socket；</li>
<li>然后，将调用 epoll_ctl() 将 listen socket 加入到 epoll，同时注册「连接事件」处理函数。</li>
</ul>
</li>
<li>初始化完后，主线程就进入到一个<strong>事件循环函数</strong>，主要会做以下事情：<ul>
<li>首先，先调用<strong>处理发送队列函数</strong>，看是发送队列里是否有任务，如果有发送任务，则通过 write 函数将客户端发送缓存区里的数据发送出去，如果这一轮数据没有发送完，就会注册写事件处理函数，等待 epoll_wait 发现可写后再处理 。</li>
<li>接着，调用 epoll_wait 函数等待事件的到来：<ul>
<li>如果是<strong>连接事件</strong>到来，则会调用<strong>连接事件处理函数</strong>，该函数会做这些事情：调用 accpet 获取已连接的 socket -&gt; 调用 epoll_ctl 将已连接的 socket 加入到 epoll -&gt; 注册「读事件」处理函数；</li>
<li>如果是<strong>读事件</strong>到来，则会调用<strong>读事件处理函数</strong>，该函数会做这些事情：调用 read 获取客户端发送的数据 -&gt; 解析命令 -&gt; 处理命令 -&gt; 将客户端对象添加到发送队列 -&gt; 将执行结果写到发送缓存区等待发送；</li>
<li>如果是<strong>写事件</strong>到来，则会调用<strong>写事件处理函数</strong>，该函数会做这些事情：通过 write 函数将客户端发送缓存区里的数据发送出去，如果这一轮数据没有发送完，就会继续注册写事件处理函数，等待 epoll_wait 发现可写后再处理 。</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li><p>Redis 采用单线程为什么还这么快？</p>
<ul>
<li>Redis 的大部分操作<strong>都在内存中完成</strong>，并且采用了高效的数据结构，因此 Redis 瓶颈可能是机器的内存或者网络带宽，而并非 CPU，既然 CPU 不是瓶颈，那么自然就采用单线程的解决方案了；</li>
<li>Redis 采用单线程模型可以<strong>避免了多线程之间的竞争</strong>，省去了多线程切换带来的时间和性能上的开销，而且也不会导致死锁问题。</li>
<li>Redis 采用了 <strong>I&#x2F;O 多路复用机制</strong>处理大量的客户端 Socket 请求。简单来说，在 Redis 只运行单线程的情况下，该机制允许内核中，同时存在多个监听 Socket 和已连接 Socket。内核会一直监听这些 Socket 上的连接请求或数据请求。一旦有请求到达，就会交给 Redis 线程处理，这就实现了一个 Redis 线程处理多个 IO 流的效果</li>
</ul>
</li>
<li><p>Redis 6.0 之前为什么使用单线程？</p>
<ul>
<li><strong>CPU 并不是制约 Redis 性能表现的瓶颈所在</strong>，更多情况下是受到内存大小和网络I&#x2F;O的限制，所以 Redis 核心网络模型使用单线程并没有什么问题，如果你想要使用服务的多核CPU，可以在一台服务器上启动多个节点或者采用分片集群的方式</li>
<li>使用了单线程后，可维护性高，多线程模型虽然在某些方面表现优异，但是它却引入了程序执行顺序的不确定性，带来了并发读写的一系列问题，<strong>增加了系统复杂度、同时可能存在线程切换、甚至加锁解锁、死锁造成的性能损耗</strong></li>
</ul>
</li>
<li><p>Redis 6.0 之后为什么引入了多线程？</p>
<ul>
<li><strong>随着网络硬件的性能提升，Redis 的性能瓶颈有时会出现在网络 I&#x2F;O 的处理上</strong>，为了提高网络 I&#x2F;O 的并行度，Redis 6.0 对于网络 I&#x2F;O 采用多线程来处理。</li>
<li><strong>但是对于命令的执行，Redis 仍然使用单线程来处理</strong></li>
<li>Redis 6.0 版本之后，Redis 在启动的时候，默认情况下会创建 6 个线程：<ul>
<li>Redis-server ： Redis的主线程，主要负责执行命令；</li>
<li>bio_close_file、bio_aof_fsync、bio_lazy_free：三个后台线程，分别异步处理关闭文件任务、AOF刷盘任务、释放内存任务；</li>
<li>io_thd_1、io_thd_2、io_thd_3：三个 I&#x2F;O 线程，io-threads 默认是 4 ，所以会启动 3（4-1）个 I&#x2F;O 多线程，用来分担 Redis 网络 I&#x2F;O 的压力</li>
</ul>
</li>
</ul>
</li>
</ul>
<h4 id="Redis-持久化"><a href="#Redis-持久化" class="headerlink" title="Redis 持久化"></a>Redis 持久化</h4><ul>
<li><p>Redis 如何实现数据不丢失？</p>
<ul>
<li><strong>AOF 日志</strong>：每执行一条写操作命令，就把该命令以追加的方式写入到一个文件里；</li>
<li><strong>RDB 快照</strong>：将某一时刻的内存数据，以二进制的方式写入磁盘；</li>
<li><strong>混合持久化方式</strong>：Redis 4.0 新增的方式，集成了 AOF 和 RBD 的优点</li>
</ul>
</li>
<li><p>AOF 日志是如何实现的？</p>
<ul>
<li><p>Redis 在执行完一条写操作命令后，就会把该命令以追加的方式写入到一个文件里，然后 Redis 重启时，会读取该文件记录的命令，然后逐一执行命令的方式来进行数据恢复</p>
</li>
<li><p>Reids 是先执行写操作命令后，才将该命令记录到 AOF 日志里的，这么做其实有两个好处。</p>
<ul>
<li><strong>避免额外的检查开销</strong>：因为如果先将写操作命令记录到 AOF 日志里，再执行该命令的话，如果当前的命令语法有问题，那么如果不进行命令语法检查，该错误的命令记录到 AOF 日志里后，Redis 在使用日志恢复数据时，就可能会出错。</li>
<li><strong>不会阻塞当前写操作命令的执行</strong>：因为当写操作命令执行成功后，才会将命令记录到 AOF 日志。</li>
</ul>
<p>当然，这样做也会带来风险：</p>
<ul>
<li><strong>数据可能会丢失：</strong> 执行写操作命令和记录日志是两个过程，那当 Redis 在还没来得及将命令写入到硬盘时，服务器发生宕机了，这个数据就会有丢失的风险。</li>
<li><strong>可能阻塞其他操作：</strong> 由于写操作命令执行成功后才记录到 AOF 日志，所以不会阻塞当前命令的执行，但因为 AOF 日志也是在主线程中执行，所以当 Redis 把日志文件写入磁盘的时候，还是会阻塞后续的操作无法执行。</li>
</ul>
</li>
</ul>
</li>
<li><p>AOF 写回策略有几种？</p>
<ul>
<li>Redis 执行完写操作命令后，会将命令追加到 server.aof_buf 缓冲区；然后通过 write() 系统调用，将 aof_buf 缓冲区的数据写入到 AOF 文件，此时数据并没有写入到硬盘，而是拷贝到了内核缓冲区 page cache，等待内核将数据写入硬盘；具体内核缓冲区的数据什么时候写入到硬盘，由内核决定</li>
<li>在 Redis.conf 配置文件中的 appendfsync 配置项可以有以下 3 种参数可填：<ul>
<li><strong>Always</strong>，每次写操作命令执行完后，同步将 AOF 日志数据写回硬盘；</li>
<li><strong>Everysec</strong>，每次写操作命令执行完后，先将命令写入到 AOF 文件的内核缓冲区，然后每隔一秒将缓冲区里的内容写回到硬盘；</li>
<li><strong>No</strong>，意味着不由 Redis 控制写回硬盘的时机，转交给操作系统控制写回的时机，也就是每次写操作命令执行完后，先将命令写入到 AOF 文件的内核缓冲区，再由操作系统决定何时将缓冲区内容写回硬盘。</li>
</ul>
</li>
</ul>
</li>
<li><p>AOF 日志过大，会触发什么机制？</p>
<ul>
<li>为了避免 AOF 文件越写越大导致的性能问题（重启 Redis 后，需要读 AOF 文件的内容以恢复数据），提供了 <strong>AOF 重写机制</strong>，当 AOF 文件的大小超过所设定的阈值后，Redis 就会启用 AOF 重写机制，来压缩 AOF 文件</li>
<li>AOF 重写机制是在重写时，读取当前数据库中的所有键值对，然后将每一个键值对用一条命令记录到「新的 AOF 文件」，等到全部记录完后，就将新的 AOF 文件替换掉现有的 AOF 文件</li>
</ul>
</li>
<li><p>重写 AOF 日志的过程是怎样的？</p>
<ul>
<li>Redis 的<strong>重写 AOF 过程是由后台子进程 bgrewriteaof 来完成的</strong>，这么做可以达到两个好处：<ul>
<li>子进程进行 AOF 重写期间，主进程可以继续处理命令请求，从而避免阻塞主进程；</li>
<li>子进程带有主进程的数据副本，这里使用子进程而不是线程，因为如果是使用线程，多线程之间会共享内存，那么在修改共享内存数据的时候，需要通过加锁来保证数据的安全，而这样就会降低性能。而使用子进程，创建子进程时，父子进程是共享内存数据的，不过这个共享的内存只能以只读的方式，而当父子进程任意一方修改了该共享内存，就会发生「写时复制」，于是父子进程就有了独立的数据副本，就不用加锁来保证数据安全。</li>
</ul>
</li>
<li>针对写时复制导致 key-value 数据在子进程的内存数据就跟主进程的内存数据不一致的问题，Redis 设置了一个 <strong>AOF 重写缓冲区</strong>；在重写 AOF 期间，当 Redis 执行完一个写命令之后，它会<strong>同时将这个写命令写入到 「AOF 缓冲区」和 「AOF 重写缓冲区」</strong></li>
<li>当子进程完成 AOF 重写工作（<em>扫描数据库中所有数据，逐一把内存数据的键值对转换成一条命令，再将命令记录到重写日志</em>）后，会向主进程发送一条信号，信号是进程间通讯的一种方式，且是异步的。主进程收到该信号后，会调用一个信号处理函数，该函数主要做以下工作：<ul>
<li>将 AOF 重写缓冲区中的所有内容追加到新的 AOF 的文件中，使得新旧两个 AOF 文件所保存的数据库状态一致；</li>
<li>新的 AOF 的文件进行改名，覆盖现有的 AOF 文件。</li>
</ul>
</li>
</ul>
</li>
<li><p>RDB 快照是如何实现的呢？</p>
<ul>
<li>AOF 日志记录的是操作命令，不是实际的数据，所以用 AOF 方法做故障恢复时，需要全量把日志都执行一遍，一旦 AOF 日志非常多，势必会造成 Redis 的恢复操作缓慢，为了解决这个问题，Redis 增加了 RDB 快照。</li>
<li>RDB 快照就是记录某一个瞬间的内存数据，记录的是实际数据，而 AOF 文件记录的是命令操作的日志，而不是实际的数据；在 Redis 恢复数据时， RDB 恢复数据的效率会比 AOF 高些，因为直接将 RDB 文件读入内存就可以，不需要像 AOF 那样还需要额外执行操作命令的步骤才能恢复数据</li>
<li>Redis 的快照是<strong>全量快照</strong>，也就是说每次执行快照，都是把内存中的「所有数据」都记录到磁盘中。所以执行快照是一个比较重的操作，如果频率太频繁，可能会对 Redis 性能产生影响。如果频率太低，服务器故障时，丢失的数据会更多</li>
</ul>
</li>
<li><p>RDB 做快照时会阻塞线程吗？</p>
<ul>
<li>Redis 提供了两个命令来生成 RDB 文件，分别是 save 和 bgsave，他们的区别就在于是否在「主线程」里执行：<ul>
<li>执行了 save 命令，就会在主线程生成 RDB 文件，由于和执行操作命令在同一个线程，所以如果写入 RDB 文件的时间太长，<strong>会阻塞主线程</strong>；</li>
<li>执行了 bgsave 命令，会创建一个子进程来生成 RDB 文件，这样可以<strong>避免主线程的阻塞</strong>；</li>
</ul>
</li>
</ul>
</li>
<li><p>RDB 在执行快照的时候，数据能修改吗？</p>
<ul>
<li>执行 bgsave 过程中，Redis 依然<strong>可以继续处理操作命令</strong>的，也就是数据是能被修改的，关键的技术就在于<strong>写时复制技术（Copy-On-Write, COW）</strong></li>
<li>如果主线程执行写操作，则被修改的数据会复制一份副本，然后 bgsave 子进程会把该副本数据写入 RDB 文件，在这个过程中，主线程仍然可以直接修改原来的数据</li>
</ul>
</li>
<li><p>为什么会有混合持久化？</p>
<ul>
<li>RDB 优点是数据恢复速度快，但是快照的频率不好把握。频率太低，丢失的数据就会比较多，频率太高，就会影响性能。AOF 优点是丢失数据少，但是数据恢复不快。为了集成了两者的优点， Redis 4.0 提出了<strong>混合使用 AOF 日志和内存快照</strong>，也叫混合持久化，既保证了 Redis 重启速度，又降低数据丢失风险</li>
<li>混合持久化工作在 <strong>AOF 日志重写过程</strong>，当开启了混合持久化时，在 AOF 重写日志时，fork 出来的重写子进程会先将与主线程共享的内存数据以 RDB 方式写入到 AOF 文件，然后主线程处理的操作命令会被记录在重写缓冲区里，重写缓冲区里的增量命令会以 AOF 方式写入到 AOF 文件，写入完成后通知主进程将新的含有 RDB 格式和 AOF 格式的 AOF 文件替换旧的的 AOF 文件</li>
<li>使用了混合持久化，AOF 文件的<strong>前半部分是 RDB 格式的全量数据，后半部分是 AOF 格式的增量数据</strong>；重启 Redis 加载数据的时候，由于前半部分是 RDB 内容，这样<strong>加载的时候速度会很快</strong>。加载后半部分的 AOF 内容可以使得<strong>数据更少的丢失</strong></li>
</ul>
</li>
</ul>
<h4 id="Redis-集群"><a href="#Redis-集群" class="headerlink" title="Redis 集群"></a>Redis 集群</h4><ul>
<li>Redis 如何实现服务高可用？<ul>
<li>要想设计一个高可用的 Redis 服务，一定要从 Redis 的多服务节点来考虑，比如 Redis 的主从复制、哨兵模式、切片集群</li>
<li>主从复制是 Redis 高可用服务的最基础的保证，实现方案就是将从前的一台 Redis 服务器，同步数据到多台从 Redis 服务器上，即一主多从的模式，且主从服务器之间采用的是「读写分离」的方式；<ul>
<li>主服务器可以进行读写操作，当发生写操作时自动将写操作同步给从服务器，而从服务器一般是只读，并接受主服务器同步过来写操作命令，然后执行这条命令；所有的数据修改只在主服务器上进行，然后将最新的数据同步给从服务器，这样就使得主从服务器的数据是一致的</li>
<li>主从服务器之间的命令复制是<strong>异步</strong>进行的；在主从服务器命令传播阶段，主服务器收到新的写命令后，会发送给从服务器。但是，主服务器并不会等到从服务器实际执行完命令后，再把结果返回给客户端，而是主服务器自己在本地执行完命令后，就会向客户端返回结果了。如果从服务器还没有执行主服务器同步过来的命令，主从服务器间的数据就不一致了。所以，无法实现强一致性保证（主从数据时时刻刻保持一致），数据不一致是难以避免的</li>
</ul>
</li>
<li>当 Redis 的主从服务器出现故障宕机时，需要手动进行恢复。为了解决这个问题，Redis 增加了哨兵模式（<strong>Redis Sentinel</strong>），因为哨兵模式做到了可以监控主从服务器，并且提供<strong>主从节点故障转移的功能</strong></li>
<li>当 Redis 缓存数据量大到一台服务器无法缓存时，就需要使用 <strong>Redis 切片集群</strong>（Redis Cluster ）方案，它将数据分布在不同的服务器上，以此来降低系统对单主节点的依赖，从而提高 Redis 服务的读写性能<ul>
<li>Redis Cluster 方案采用哈希槽（Hash Slot），来处理数据和节点之间的映射关系。在 Redis Cluster 方案中，<strong>一个切片集群共有 16384 个哈希槽</strong>，这些哈希槽类似于数据分区，每个键值对都会根据它的 key，被映射到一个哈希槽中，具体执行过程分为两大步：<ul>
<li>根据键值对的 key，按照 CRC16 计算一个 16 bit 的值</li>
<li>再用 16bit 值对 16384 取模，得到 0~16383 范围内的模数，每个模数代表一个相应编号的哈希槽</li>
</ul>
</li>
<li>哈希槽怎么被映射到具体的 Redis 节点上的呢？<ul>
<li><strong>平均分配：</strong> 在使用 cluster create 命令创建 Redis 集群时，Redis 会自动把所有哈希槽平均分布到集群节点上。比如集群中有 9 个节点，则每个节点上槽的个数为 16384&#x2F;9 个。</li>
<li><strong>手动分配：</strong> 可以使用 cluster meet 命令手动建立节点间的连接，组成集群，再使用 cluster addslots 命令，指定每个节点上的哈希槽个数。在手动分配哈希槽时，需要把 16384 个槽都分配完，否则 Redis 集群无法正常工作</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>集群脑裂导致数据丢失怎么办？<ul>
<li>脑裂现象：由于网络问题，集群节点之间失去联系。主从数据不同步；重新平衡选举，产生两个主服务。等网络恢复，旧主节点会降级为从节点，再与新主节点进行同步复制的时候，由于会从节点会清空自己的缓冲区，所以导致之前客户端写入的数据丢失了</li>
<li>解决方案：当主节点发现从节点下线或者通信超时的总数量小于阈值时，那么禁止主节点进行写数据，直接把错误返回给客户端。<ul>
<li>把 min-slaves-to-write 和 min-slaves-max-lag 这两个配置项搭配起来使用，分别给它们设置一定的阈值，假设为 N 和 T</li>
<li>这两个配置项组合后的要求是，主库连接的从库中至少有 N 个从库，和主库进行数据复制时的 ACK 消息延迟不能超过 T 秒，否则，主库就不会再接收客户端的写请求了</li>
</ul>
</li>
</ul>
</li>
</ul>
<h4 id="Redis-过期删除与内存淘汰"><a href="#Redis-过期删除与内存淘汰" class="headerlink" title="Redis 过期删除与内存淘汰"></a>Redis 过期删除与内存淘汰</h4><ul>
<li><p>Redis 使用的过期删除策略是什么？</p>
<ul>
<li><p>每当我们对一个 key 设置了过期时间时，Redis 会把该 key 带上过期时间存储到一个<strong>过期字典</strong>（expires dict）中，也就是说「过期字典」保存了数据库中所有 key 的过期时间</p>
</li>
<li><p>当我们查询一个 key 时，Redis 首先检查该 key 是否存在于过期字典中：</p>
<ul>
<li>如果不在，则正常读取键值；</li>
<li>如果存在，则会获取该 key 的过期时间，然后与当前系统时间进行比对，如果比系统时间大，那就没有过期，否则判定该 key 已过期。</li>
</ul>
<p>Redis 使用的过期删除策略是「<strong>惰性删除+定期删除</strong>」这两种策略配和使用</p>
</li>
<li><p>惰性删除策略的做法是，<strong>不主动删除过期键，每次从数据库访问 key 时，都检测 key 是否过期，如果过期则删除该 key。</strong>每次访问时，才会检查 key 是否过期惰性删除策略对 CPU 时间最友好。但是只要这个过期 key 一直没有被访问，它所占用的内存就不会释放，造成了一定的内存空间浪费。所以，惰性删除策略对内存不友好。</p>
</li>
<li><p>定期删除策略的做法是，<strong>每隔一段时间「随机」从数据库中取出一定数量的 key 进行检查，并删除其中的过期key。</strong>定期删除是一个循环的流程。 Redis 为了保证定期删除不会出现循环过度，导致线程卡死现象，为此增加了定期删除循环流程的时间上限，默认不会超过 25ms</p>
<ul>
<li>通过限制删除操作执行的时长和频率，来减少删除操作对 CPU 的影响，同时也能删除一部分过期的数据减少了过期键对空间的无效占用</li>
<li>难以确定删除操作执行的时长和频率。如果执行的太频繁，就会对 CPU 不友好；如果执行的太少，那又和惰性删除一样了，过期 key 占用的内存不会及时得到释放</li>
</ul>
</li>
<li><p><strong>Redis 选择「惰性删除+定期删除」这两种策略配和使用</strong>，以求在合理使用 CPU 时间和避免内存浪费之间取得平衡</p>
</li>
</ul>
</li>
<li><p>Redis 持久化时，对过期键会如何处理的？</p>
<ul>
<li><strong>RDB 文件生成阶段</strong>：从内存状态持久化成 RDB（文件）的时候，会对 key 进行过期检查，<strong>过期的键「不会」被保存到新的 RDB 文件中</strong>，因此 Redis 中的过期键不会对生成新 RDB 文件产生任何影响。</li>
<li>RDB 加载阶段：RDB 加载阶段时，要看服务器是主服务器还是从服务器，分别对应以下两种情况：<ul>
<li><strong>如果 Redis 是「主服务器」运行模式的话，在载入 RDB 文件时，程序会对文件中保存的键进行检查，过期键「不会」被载入到数据库中</strong>。所以过期键不会对载入 RDB 文件的主服务器造成影响；</li>
<li><strong>如果 Redis 是「从服务器」运行模式的话，在载入 RDB 文件时，不论键是否过期都会被载入到数据库中</strong>。但由于主从服务器在进行数据同步时，从服务器的数据会被清空。所以一般来说，过期键对载入 RDB 文件的从服务器也不会造成影响</li>
</ul>
</li>
<li><strong>AOF 文件写入阶段</strong>：当 Redis 以 AOF 模式持久化时，<strong>如果数据库某个过期键还没被删除，那么 AOF 文件会保留此过期键，当此过期键被删除后，Redis 会向 AOF 文件追加一条 DEL 命令来显式地删除该键值</strong>。</li>
<li><strong>AOF 重写阶段</strong>：执行 AOF 重写时，会对 Redis 中的键值对进行检查，<strong>已过期的键不会被保存到重写后的 AOF 文件中</strong>，因此不会对 AOF 重写造成任何影响</li>
</ul>
</li>
<li><p>Redis 主从模式中，对过期键会如何处理？</p>
<ul>
<li>当 Redis 运行在主从模式下时，<strong>从库不会进行过期扫描，从库对过期的处理是被动的</strong>。也就是即使从库中的 key 过期了，如果有客户端访问从库时，依然可以得到 key 对应的值，像未过期的键值对一样返回。</li>
<li>从库的过期键处理依靠主服务器控制，<strong>主库在 key 到期时，会在 AOF 文件里增加一条 del 指令，同步到所有的从库</strong>，从库通过执行这条 del 指令来删除过期的 key。</li>
</ul>
</li>
<li><p>Redis 内存满了，会发生什么？</p>
<ul>
<li>在 Redis 的运行内存达到了某个阀值，就会触发<strong>内存淘汰机制</strong>，这个阀值就是我们设置的最大运行内存，此值在 Redis 的配置文件中可以找到，配置项为 maxmemory</li>
</ul>
</li>
<li><p>Redis 内存淘汰策略有哪些？</p>
<ul>
<li>Redis 内存淘汰策略共有八种，主要分成不进行数据淘汰（不再提供服务，直接返回错误）和进行数据淘汰，后者分为针对设置了过期时间的volatile淘汰和all key淘汰，volatile淘汰有四种策略，分别是随机淘汰、优先淘汰更早过期的键值、lru和lfu；all key则少了ttl淘汰方法其余一样</li>
</ul>
</li>
<li><p>LRU 算法和 LFU 算法有什么区别？</p>
<ul>
<li>传统 LRU 算法的实现是基于「链表」结构,存在两个问题：<ul>
<li>需要用链表管理所有的缓存数据，这会带来额外的空间开销；</li>
<li>当有数据被访问时，需要在链表上把该数据移动到头端，如果有大量数据被访问，就会带来很多链表移动操作，会很耗时，进而会降低 Redis 缓存性能</li>
</ul>
</li>
<li>Redis采用一种近似<strong>LRU</strong>算法，为了更好的节约内存，它的<strong>实现方式是在 Redis 的对象结构体中添加一个额外的字段，用于记录此数据的最后一次访问时间</strong>。当 Redis 进行内存淘汰时，会使用<strong>随机采样的方式来淘汰数据</strong>，它是随机取 5 个值（此值可配置），然后<strong>淘汰最久没有使用的那个</strong>；但是针对单次访问大量数据的场景下会产生缓存污染问题</li>
<li>而LFU算法就是针对该缺陷提出的，其根据数据访问次数来淘汰数据的，会记录每个数据的访问次数，当一个数据被再次访问时，就会增加该数据的访问次数，这样子就能够解决偶尔访问一次导致的缓存污染问题；LFU算法针对redis中的lru字段进行了修改，其高16bit仍然记录时间戳，低8bit则用为记录访问频次；其访问频次不是简单的+1-1，而是先按照上次访问距离当前的时长，来对 logc 进行衰减；然后，再按照一定概率增加 logc 的值，这样子主要是为了充份利用仅有的低8bit的255数据范围</li>
<li>LRU策略更关注数据的时效性，而实际应用的负载具有较好的时间局部性，因此LRU应用更加广泛；但是再扫描式查询的应用场景中，LFU可以更好的解决缓存污染问题；如果业务中有短时高频访问的数据，可以优先使用volatile-LFU策略，并根据这些数据的访问时限设置他们的过期时间</li>
</ul>
</li>
</ul>
<h4 id="Redis-缓存设计"><a href="#Redis-缓存设计" class="headerlink" title="Redis 缓存设计"></a>Redis 缓存设计</h4><ul>
<li><p>如何避免缓存雪崩?</p>
<ul>
<li>缓存雪崩：当<strong>大量缓存数据在同一时间过期（失效）</strong>时，如果此时有大量的用户请求，都无法在 Redis 中处理，于是全部请求都直接访问数据库，从而导致数据库的压力骤增，严重的会造成数据库宕机，从而形成一系列连锁反应，造成整个系统崩溃；</li>
<li>采用两种方案解决：<ul>
<li><strong>将缓存失效时间随机打散：</strong> 我们可以在原有的失效时间基础上增加一个随机值（比如 1 到 10 分钟）这样每个缓存的过期时间都不重复了，也就降低了缓存集体失效的概率</li>
<li><strong>设置缓存不过期：</strong> 我们可以通过后台服务来更新缓存数据，从而避免因为缓存失效造成的缓存雪崩，也可以在一定程度上避免缓存并发问题</li>
</ul>
</li>
</ul>
</li>
<li><p>如何避免缓存击穿？</p>
<ul>
<li>缓存击穿：如果缓存中的<strong>某个热点数据过期</strong>了，此时大量的请求访问了该热点数据，就无法从缓存中读取，直接访问数据库，数据库很容易就被高并发的请求冲垮</li>
<li>应对缓存击穿可以采取两种方案：<ul>
<li>互斥锁方案（Redis 中使用 setNX 方法设置一个状态位，表示这是一种锁定状态），保证同一时间只有一个业务线程请求缓存，未能获取互斥锁的请求，要么等待锁释放后重新读取缓存，要么就返回空值或者默认值。</li>
<li>不给热点数据设置过期时间，由后台异步更新缓存，或者在热点数据准备要过期前，提前通知后台线程更新缓存以及重新设置过期时间</li>
</ul>
</li>
</ul>
</li>
<li><p>如何避免缓存穿透？</p>
<ul>
<li>缓存穿透：当用户访问的数据，<strong>既不在缓存中，也不在数据库中</strong>，导致请求在访问缓存时，发现缓存缺失，再去访问数据库时，发现数据库中也没有要访问的数据，没办法构建缓存数据，来服务后续的请求。那么当有大量这样的请求到来时，数据库的压力骤增</li>
<li>缓存穿透的发生一般有这两种情况：<ul>
<li>业务误操作，缓存中的数据和数据库中的数据都被误删除了，所以导致缓存和数据库中都没有数据；</li>
<li>黑客恶意攻击，故意大量访问某些读取不存在数据的业务</li>
</ul>
</li>
<li>应对缓存穿透的方案，常见的方案有三种。<ul>
<li><strong>非法请求的限制</strong>：当有大量恶意请求访问不存在的数据的时候，也会发生缓存穿透，因此在 API 入口处我们要判断求请求参数是否合理，请求参数是否含有非法值、请求字段是否存在，如果判断出是恶意请求就直接返回错误，避免进一步访问缓存和数据库。</li>
<li><strong>设置空值或者默认值</strong>：当我们线上业务发现缓存穿透的现象时，可以针对查询的数据，在缓存中设置一个空值或者默认值，这样后续请求就可以从缓存中读取到空值或者默认值，返回给应用，而不会继续查询数据库。</li>
<li><strong>使用布隆过滤器快速判断数据是否存在，避免通过查询数据库来判断数据是否存在</strong>：我们可以在写入数据库数据时，使用布隆过滤器做个标记，然后在用户请求到来时，业务线程确认缓存失效后，可以通过查询布隆过滤器快速判断数据是否存在，如果不存在，就不用通过查询数据库来判断数据是否存在，即使发生了缓存穿透，大量请求只会查询 Redis 和布隆过滤器，而不会查询数据库，保证了数据库能正常运行，Redis 自身也是支持布隆过滤器的</li>
</ul>
</li>
</ul>
</li>
<li><p>如何设计一个缓存策略，可以动态缓存热点数据呢？</p>
<ul>
<li><p>由于数据存储受限，系统并不是将所有数据都需要存放到缓存中的，而<strong>只是将其中一部分热点数据缓存起来</strong></p>
</li>
<li><p>热点数据动态缓存的策略总体思路：<strong>通过数据最新访问时间来做排名，并过滤掉不常访问的数据，只留下经常访问的数据</strong></p>
</li>
<li><p>以电商平台场景中的例子，现在要求只缓存用户经常访问的 Top 1000 的商品。具体细节如下：</p>
<ul>
<li>先通过缓存系统做一个排序队列（比如存放 1000 个商品），系统会根据商品的访问时间，更新队列信息，越是最近访问的商品排名越靠前；</li>
<li>同时系统会定期过滤掉队列中排名最后的 200 个商品，然后再从数据库中随机读取出 200 个商品加入队列中；</li>
<li>这样当请求每次到达的时候，会先从队列中获取商品 ID，如果命中，就根据 ID 再从另一个缓存数据结构中读取实际的商品信息，并返回。</li>
</ul>
<p>在 Redis 中可以用 zadd 方法和 zrange 方法来完成排序队列和获取 200 个商品的操作</p>
</li>
</ul>
</li>
<li><p>说说常见的缓存更新策略？</p>
<ul>
<li>Cache Aside（旁路缓存）策略；应用程序直接与「数据库、缓存」交互，并负责对缓存的维护，该策略又可以细分为「读策略」和「写策略」<ul>
<li><strong>写策略的步骤：</strong>先更新数据库中的数据，再删除缓存中的数据。</li>
<li><strong>读策略的步骤：</strong>如果读取的数据命中了缓存，则直接返回数据；如果读取的数据没有命中缓存，则从数据库中读取数据，然后将数据写入到缓存，并且返回给用户。</li>
<li>写策略的步骤的顺序顺序不能倒过来，即<strong>不能先删除缓存再更新数据库</strong>，原因是在「读+写」并发的时候，会出现缓存和数据库的数据不一致性的问题。</li>
<li><strong>Cache Aside 策略适合读多写少的场景，不适合写多的场景</strong>，因为当写入比较频繁时，缓存中的数据会被频繁地清理，这样会对缓存的命中率有一些影响。</li>
</ul>
</li>
<li>Read&#x2F;Write Through（读穿 &#x2F; 写穿）策略；<ul>
<li><em><strong>Read Through 策略</strong></em>：先查询缓存中数据是否存在，如果存在则直接返回，如果不存在，则由缓存组件负责从数据库查询数据，并将结果写入到缓存组件，最后缓存组件将数据返回给应用。</li>
<li><em><strong>Write Through 策略</strong></em>：当有数据更新的时候，先查询要写入的数据在缓存中是否已经存在：<ul>
<li>如果缓存中数据已经存在，则更新缓存中的数据，并且由缓存组件同步更新到数据库中，然后缓存组件告知应用程序更新完成。</li>
<li>如果缓存中数据不存在，直接更新数据库，然后返回；</li>
</ul>
</li>
</ul>
</li>
<li>Write Back（写回）策略；在更新数据的时候，只更新缓存，同时将缓存数据设置为脏的，然后立马返回，并不会更新数据库。对于数据库的更新，会通过批量异步更新的方式进行<ul>
<li><strong>Write Back 策略特别适合写多的场景</strong>，因为发生写操作的时候， 只需要更新缓存，就立马返回了。比如，写文件的时候，实际上是写入到文件系统的缓存就返回了，并不会写磁盘</li>
<li><strong>但是带来的问题是，数据不是强一致性的，而且会有数据丢失的风险</strong>，因为缓存一般使用内存，而内存是非持久化的，所以一旦缓存机器掉电，就会造成原本缓存中的脏数据丢失。所以你会发现系统在掉电之后，之前写入的文件会有部分丢失，就是因为 Page Cache 还没有来得及刷盘造成的</li>
</ul>
</li>
</ul>
<p>实际开发中，Redis 和 MySQL 的更新策略用的是 Cache Aside，另外两种策略应用不了</p>
</li>
</ul>
<h4 id="Redis-实战"><a href="#Redis-实战" class="headerlink" title="Redis 实战"></a>Redis 实战</h4><ul>
<li><p>Redis 如何实现延迟队列？</p>
<ul>
<li>延迟队列是指把当前要做的事情，往后推迟一段时间再做。</li>
<li>在 Redis 可以使用有序集合（ZSet）的方式来实现延迟消息队列的，ZSet 有一个 Score 属性可以用来存储延迟执行的时间。</li>
</ul>
</li>
<li><p>Redis 的大 key 如何处理？</p>
<ul>
<li>大 key 并不是指 key 的值很大，而是 key 对应的 value 很大。一般而言，下面这两种情况被称为大 key：<ul>
<li>String 类型的值大于 10 KB；</li>
<li>Hash、List、Set、ZSet 类型的元素的个数超过 5000个；</li>
</ul>
</li>
<li>大 key 会带来以下四种影响：<ul>
<li><strong>客户端超时阻塞</strong>。由于 Redis 执行命令是单线程处理，然后在操作大 key 时会比较耗时，那么就会阻塞 Redis，从客户端这一视角看，就是很久很久都没有响应。</li>
<li><strong>引发网络阻塞</strong>。每次获取大 key 产生的网络流量较大，如果一个 key 的大小是 1 MB，每秒访问量为 1000，那么每秒会产生 1000MB 的流量，这对于普通千兆网卡的服务器来说是灾难性的。</li>
<li><strong>阻塞工作线程</strong>。如果使用 del 删除大 key 时，会阻塞工作线程，这样就没办法处理后续的命令。</li>
<li><strong>内存分布不均</strong>。集群模型在 slot 分片均匀情况下，会出现数据和查询倾斜情况，部分有大 key 的 Redis 节点占用内存多，QPS 也会比较大。</li>
</ul>
</li>
<li>如何找到大 key ？<ul>
<li><em><strong>redis-cli –bigkeys 查找大key</strong></em>：这个方法只能返回每种类型中最大的那个 bigkey，无法得到大小排在前 N 位的 bigkey；对于集合类型来说，这个方法只统计集合元素个数的多少，而不是实际占用的内存量</li>
<li><em><strong>使用 SCAN 命令查找大 key</strong></em>：使用 SCAN 命令对数据库扫描，然后用 TYPE 命令获取返回的每一个 key 的类型</li>
<li><em><strong>使用 RdbTools 工具查找大 key</strong></em></li>
</ul>
</li>
<li>如何删除大 key？<ul>
<li>删除操作的本质是要释放键值对占用的内存空间，释放内存只是第一步，为了更加高效地管理内存空间，在应用程序释放内存时，操作系统需要把释放掉的内存块插入一个空闲内存块的链表，以便后续进行管理和再分配。这个过程本身需要一定时间，而且会阻塞当前释放内存的应用程序。如果一下子释放了大量内存，空闲内存块链表操作时间就会增加，相应地就会造成 Redis 主线程的阻塞</li>
<li>删除大 key 这一个动作给出两种方法：<ul>
<li>分批次删除：对于<strong>删除大 Hash</strong>，使用 <code>hscan</code> 命令，每次获取 100 个字段，再用 <code>hdel</code> 命令，每次删除 1 个字段</li>
<li>异步删除（Redis 4.0版本以上），<strong>用 unlink 命令代替 del 来删除</strong>。这样 Redis 会将这个 key 放入到一个异步线程中进行删除，这样不会阻塞主线程。</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li><p>Redis 管道有什么用？</p>
<ul>
<li>管道技术（Pipeline）是客户端提供的一种批处理技术，用于一次处理多个 Redis 命令，从而提高整个交互的性能。</li>
<li>使用<strong>管道技术可以解决多个命令执行时的网络等待</strong>，它是把多个命令整合到一起发送给服务器端处理之后统一返回给客户端，这样就免去了每条命令执行后都要等待的情况，从而有效地提高了程序的执行效率。</li>
<li>但使用管道技术也要注意避免发送的命令过大，或管道内的数据太多而导致的网络阻塞。要注意的是，管道技术本质上是客户端提供的功能，而非 Redis 服务器端的功能</li>
</ul>
</li>
<li><p>Redis 事务支持回滚吗？</p>
<ul>
<li><p>MySQL 在执行事务时，会提供回滚机制，当事务执行发生错误时，事务中的所有操作都会撤销，已经修改的数据也会被恢复到事务执行前的状态。</p>
</li>
<li><p><strong>Redis 中并没有提供回滚机制</strong>，虽然 Redis 提供了 DISCARD 命令，但是这个命令只能用来主动放弃事务执行，把暂存的命令队列清空，起不到回滚的效果。</p>
</li>
<li><p>不支持事务回滚的原因有以下两个：</p>
<ul>
<li>Redis 事务的执行时，错误通常都是编程错误造成的，这种错误通常只会出现在开发环境中，而很少会在实际的生产环境中出现，所以没有必要为 Redis 开发事务回滚功能；</li>
<li>不支持事务回滚是因为这种复杂的功能和 Redis 追求的简单高效的设计主旨不符合。</li>
</ul>
<p>这里不支持事务回滚，指的是不支持事务运行时错误的事务回滚</p>
</li>
</ul>
</li>
<li><p>如何用 Redis 实现分布式锁的？</p>
<ul>
<li>分布式锁是用于分布式环境下并发控制的一种机制，用于控制某个资源在同一时刻只能被一个应用所使用</li>
<li>Redis 本身可以被多个客户端共享访问，正好就是一个共享存储系统，可以用来保存分布式锁，而且 Redis 的读写性能高，可以应对高并发的锁操作场景。</li>
<li>Redis 的 SET 命令有个 NX 参数可以实现「key不存在才插入」，所以可以用它来实现分布式锁：<ul>
<li>如果 key 不存在，则显示插入成功，可以用来表示加锁成功；</li>
<li>如果 key 存在，则会显示插入失败，可以用来表示加锁失败。</li>
</ul>
</li>
<li>基于 Redis 节点实现分布式锁时，对于加锁操作，我们需要满足三个条件。<ul>
<li>加锁包括了读取锁变量、检查锁变量值和设置锁变量值三个操作，但需要以原子操作的方式完成，所以，我们使用 SET 命令带上 NX 选项来实现加锁；</li>
<li>锁变量需要设置过期时间，以免客户端拿到锁后发生异常，导致锁一直无法释放，所以，我们在 SET 命令执行时加上 EX&#x2F;PX 选项，设置其过期时间；</li>
<li>锁变量的值需要能区分来自不同客户端的加锁操作，以免在释放锁时，出现误释放操作，所以，我们使用 SET 命令设置锁变量值时，每个客户端设置的值是一个唯一值，用于标识客户端；</li>
</ul>
</li>
</ul>
</li>
<li><p>基于 Redis 实现分布式锁有什么优缺点？</p>
<ul>
<li>基于 Redis 实现分布式锁的<strong>优点</strong>：<ol>
<li>性能高效（这是选择缓存实现分布式锁最核心的出发点）。</li>
<li>实现方便。很多研发工程师选择使用 Redis 来实现分布式锁，很大成分上是因为 Redis 提供了 setnx 方法，实现分布式锁很方便。</li>
<li>避免单点故障（因为 Redis 是跨集群部署的，自然就避免了单点故障）。</li>
</ol>
</li>
<li>基于 Redis 实现分布式锁的<strong>缺点</strong>：<ul>
<li>超时时间不好设置。如果锁的超时时间设置过长，会影响性能，如果设置的超时时间过短会保护不到共享资源。比如在有些场景中，一个线程 A 获取到了锁之后，由于业务代码执行时间可能比较长，导致超过了锁的超时时间，自动失效，注意 A 线程没执行完，后续线程 B 又意外的持有了锁，意味着可以操作共享资源，那么两个线程之间的共享资源就没办法进行保护了。<ul>
<li><strong>那么如何合理设置超时时间呢？</strong> 我们可以基于续约的方式设置超时时间：先给锁设置一个超时时间，然后启动一个守护线程，让守护线程在一段时间后，重新设置这个锁的超时时间。实现方式就是：写一个守护线程，然后去判断锁的情况，当锁快失效的时候，再次进行续约加锁，当主线程执行完成后，销毁续约锁即可，不过这种方式实现起来相对复杂。</li>
</ul>
</li>
<li><strong>Redis 主从复制模式中的数据是异步复制的，这样导致分布式锁的不可靠性</strong>。如果在 Redis 主节点获取到锁后，在没有同步到其他节点时，Redis 主节点宕机了，此时新的 Redis 主节点依然可以获取锁，所以多个应用服务就可以同时获取到锁。</li>
</ul>
</li>
</ul>
</li>
<li><p>Redis 如何解决集群情况下分布式锁的可靠性？</p>
<ul>
<li>为了保证集群环境下分布式锁的可靠性，Redis 官方已经设计了一个分布式锁算法 Redlock（红锁）。它是基于<strong>多个 Redis 节点</strong>的分布式锁，即使有节点发生了故障，锁变量仍然是存在的，客户端还是可以完成锁操作。官方推荐是至少部署 5 个 Redis 节点，而且都是主节点，它们之间没有任何关系，都是一个个孤立的节点。</li>
<li>Redlock 算法的基本思路，<strong>是让客户端和多个独立的 Redis 节点依次请求申请加锁，如果客户端能够和半数以上的节点成功地完成加锁操作，那么我们就认为，客户端成功地获得分布式锁，否则加锁失败</strong>。这样一来，即使有某个 Redis 节点发生故障，因为锁的数据在其他节点上也有保存，所以客户端仍然可以正常地进行锁操作，锁的数据也不会丢失。</li>
</ul>
</li>
</ul>
<h3 id="3-1-Redis-常见数据类型和应用场景"><a href="#3-1-Redis-常见数据类型和应用场景" class="headerlink" title="3.1 Redis 常见数据类型和应用场景"></a>3.1 Redis 常见数据类型和应用场景</h3><h4 id="String"><a href="#String" class="headerlink" title="String"></a>String</h4><ul>
<li><p>String 是最基本的 key-value 结构，key 是唯一标识，value 是具体的值，value其实不仅是字符串， 也可以是数字（整数或浮点数），value 最多可以容纳的数据长度是 <code>512M</code>。</p>
</li>
<li><p>String 类型的底层的数据结构实现主要是 int 和 SDS（简单动态字符串）。SDS 和我们认识的 C 字符串不太一样，之所以没有使用 C 语言的字符串表示，因为 SDS 相比于 C 的原生字符串：</p>
<ul>
<li><strong>SDS 不仅可以保存文本数据，还可以保存二进制数据</strong>。因为 <code>SDS</code> 使用 <code>len</code> 属性的值而不是空字符来判断字符串是否结束，并且 SDS 的所有 API 都会以处理二进制的方式来处理 SDS 存放在 <code>buf[]</code> 数组里的数据。所以 SDS 不光能存放文本数据，而且能保存图片、音频、视频、压缩文件这样的二进制数据。</li>
<li>**SDS 获取字符串长度的时间复杂度是 O(1)**。因为 C 语言的字符串并不记录自身长度，所以获取长度的复杂度为 O(n)；而 SDS 结构里用 <code>len</code> 属性记录了字符串长度，所以复杂度为 <code>O(1)</code>。</li>
<li><strong>Redis 的 SDS API 是安全的，拼接字符串不会造成缓冲区溢出</strong>。因为 SDS 在拼接字符串之前会检查 SDS 空间是否满足要求，如果空间不够会自动扩容，所以不会导致缓冲区溢出的问题。</li>
</ul>
</li>
<li><p>字符串对象的内部编码（encoding）有 3 种 ：<strong>int、raw和 embstr</strong>。</p>
<ul>
<li><p>如果一个字符串对象保存的是整数值，并且这个整数值可以用<code>long</code>类型来表示，那么字符串对象会将整数值保存在字符串对象结构的<code>ptr</code>属性里面（将<code>void*</code>转换成 long），并将字符串对象的编码设置为<code>int</code>。</p>
</li>
<li><p>如果字符串对象保存的是一个字符串，并且这个字符申的长度小于等于 32 字节（redis 2.+版本），那么字符串对象将使用一个简单动态字符串（SDS）来保存这个字符串，并将对象的编码设置为<code>embstr</code>， <code>embstr</code>编码是专门用于保存短字符串的一种优化编码方式</p>
</li>
<li><p>如果字符串对象保存的是一个字符串，并且这个字符串的长度大于 32 字节（redis 2.+版本），那么字符串对象将使用一个简单动态字符串（SDS）来保存这个字符串，并将对象的编码设置为<code>raw</code></p>
</li>
<li><p><code>embstr</code>和<code>raw</code>编码都会使用<code>SDS</code>来保存值，但不同之处在于<code>embstr</code>会通过一次内存分配函数来分配一块连续的内存空间来保存<code>redisObject</code>和<code>SDS</code>，而<code>raw</code>编码会通过调用两次内存分配函数来分别分配两块空间来保存<code>redisObject</code>和<code>SDS</code>。Redis这样做会有很多好处：</p>
<ul>
<li><code>embstr</code>编码将创建字符串对象所需的内存分配次数从 <code>raw</code> 编码的两次降低为一次；</li>
<li>释放 <code>embstr</code>编码的字符串对象同样只需要调用一次内存释放函数；</li>
<li>因为<code>embstr</code>编码的字符串对象的所有数据都保存在一块连续的内存里面可以更好的利用 CPU 缓存提升性能。</li>
</ul>
<p>但是 embstr 也有缺点的：</p>
<ul>
<li>如果字符串的长度增加需要重新分配内存时，整个redisObject和sds都需要重新分配空间，所以<strong>embstr编码的字符串对象实际上是只读的</strong>，redis没有为embstr编码的字符串对象编写任何相应的修改程序。当我们对embstr编码的字符串对象执行任何修改命令（例如append）时，程序会先将对象的编码从embstr转换成raw，然后再执行修改命令</li>
</ul>
</li>
</ul>
</li>
<li><p>常用指令</p>
<ul>
<li>普通字符串的基本操作：SET、GET、EXISTS、STRLEN、DEL</li>
<li>批量设置 : MSET、MGET</li>
<li>计数器（字符串的内容为整数的时候可以使用）：INCR、INCRBY、DECR、DECRBY </li>
<li>过期（默认为永不过期）：EXPIRE 、TTL 、SET key  value EX 60、SETEX key  60 value</li>
<li>不存在就插入：SETNX key value</li>
</ul>
</li>
<li><p>应用场景</p>
<ul>
<li><p>缓存对象：使用 String 来缓存对象有两种方式：</p>
<ul>
<li>直接缓存整个对象的 JSON，命令例子： <code>SET user:1 &#39;&#123;&quot;name&quot;:&quot;xiaolin&quot;, &quot;age&quot;:18&#125;&#39;</code>。</li>
<li>采用将 key 进行分离为 user:ID:属性，采用 MSET 存储，用 MGET 获取各属性值</li>
</ul>
</li>
<li><p>常规计数：因为 Redis 处理命令是单线程，所以执行命令的过程是原子的。因此 String 数据类型适合计数场景，比如计算访问次数、点赞、转发、库存数量等等。</p>
</li>
<li><p>分布式锁：SET 命令有个 NX 参数可以实现「key不存在才插入」，可以用它来实现分布式锁：</p>
<ul>
<li>如果 key 不存在，则显示插入成功，可以用来表示加锁成功；</li>
<li>如果 key 存在，则会显示插入失败，可以用来表示加锁失败。</li>
</ul>
<p>一般而言，还会对分布式锁加上过期时间 PX 10000</p>
<ul>
<li>而解锁的过程就是将 lock_key 键删除，但不能乱删，要保证执行操作的客户端就是加锁的客户端。所以，解锁的时候，我们要先判断锁的 unique_value 是否为加锁客户端，是的话，才将 lock_key 键删除。解锁是有两个操作，这时就需要 Lua 脚本来保证解锁的原子性，因为 Redis 在执行 Lua 脚本时，可以以原子性的方式执行，保证了锁释放操作的原子性。</li>
</ul>
</li>
<li><p>共享 Session 信息：通常在开发后台管理系统时，会使用 Session 来保存用户的会话(登录)状态，这些 Session 信息会被保存在服务器端，但这只适用于单系统应用，如果是分布式系统此模式将不再适用。</p>
<ul>
<li>需要借助 Redis 对这些 Session 信息进行统一的存储和管理，这样无论请求发送到那台服务器，服务器都会去同一个 Redis 获取相关的 Session 信息，这样就解决了分布式系统下 Session 存储的问题。</li>
</ul>
</li>
</ul>
</li>
</ul>
<h4 id="List"><a href="#List" class="headerlink" title="List"></a>List</h4><ul>
<li><p>List 列表是简单的字符串列表，<strong>按照插入顺序排序</strong>，可以从头部或尾部向 List 列表添加元素。列表的最大长度为 <code>2^32 - 1</code>，也即每个列表支持超过 <code>40 亿</code>个元素</p>
</li>
<li><p>List 类型的底层数据结构是由<strong>双向链表或压缩列表</strong>实现的</p>
<ul>
<li>如果列表的元素个数小于 <code>512</code> 个（默认值，可由 <code>list-max-ziplist-entries</code> 配置），列表每个元素的值都小于 <code>64</code> 字节（默认值，可由 <code>list-max-ziplist-value</code> 配置），Redis 会使用<strong>压缩列表</strong>作为 List 类型的底层数据结构；</li>
<li>如果列表的元素不满足上面的条件，Redis 会使用<strong>双向链表</strong>作为 List 类型的底层数据结构；</li>
</ul>
</li>
<li><p>常用命令：LPUSH 、RPUSH 、LPOP、RPOP、LRANGE 、BLPOP 、BRPOP </p>
</li>
<li><p>应用场景：消息队列：消息队列在存取消息时，必须要满足三个需求，分别是<strong>消息保序、处理重复的消息和保证消息可靠性</strong>。</p>
<ul>
<li><p>Redis 的 List 和 Stream 两种数据类型，就可以满足消息队列的这三个需求。</p>
</li>
<li><p>List 本身就是按先进先出的顺序对数据进行存取的，所以，如果使用 List 作为消息队列保存消息的话，就已经能满足消息保序的需求了。</p>
</li>
<li><p>即使没有新消息写入List，消费者也要不停地调用 RPOP 命令，这就会导致消费者程序的 CPU 一直消耗在执行 RPOP 命令上，带来不必要的性能损失。为了解决这个问题，Redis提供了 BRPOP 命令。<strong>BRPOP命令也称为阻塞式读取，客户端在没有读到队列数据时，自动阻塞，直到有新的数据写入队列，再开始读取新数据</strong></p>
</li>
<li><p>消费者要实现重复消息的判断，需要 2 个方面的要求：</p>
<ul>
<li>每个消息都有一个全局的 ID。</li>
<li>消费者要记录已经处理过的消息的 ID。</li>
</ul>
<p><strong>List 并不会为每个消息生成 ID 号，所以我们需要自行为每个消息生成一个全局唯一ID</strong>，生成之后，我们在用 LPUSH 命令把消息插入 List 时，需要在消息中包含这个全局唯一 ID</p>
</li>
<li><p>为了留存消息，List 类型提供了 <code>BRPOPLPUSH</code> 命令，这个命令的<strong>作用是让消费者程序从一个 List 中读取消息，同时，Redis 会把这个消息再插入到另一个 List（可以叫作备份 List）留存</strong>。</p>
</li>
</ul>
</li>
<li><p><strong>List 不支持多个消费者消费同一条消息</strong>，因为一旦消费者拉取一条消息后，这条消息就从 List 中删除了，无法被其它消费者再次消费。要实现一条消息可以被多个消费者消费，那么就要将多个消费者组成一个消费组，使得多个消费者可以消费同一条消息，但是 <strong>List 类型并不支持消费组的实现</strong>。</p>
</li>
</ul>
<h4 id="Hash"><a href="#Hash" class="headerlink" title="Hash"></a>Hash</h4><ul>
<li><p>Hash 是一个键值对（key - value）集合，其中 value 的形式如： <code>value=[&#123;field1，value1&#125;，...&#123;fieldN，valueN&#125;]</code>。Hash 特别适合用于存储对象。</p>
</li>
<li><p>Hash 类型的底层数据结构是由<strong>压缩列表或哈希表</strong>实现的：</p>
<ul>
<li>如果哈希类型元素个数小于 <code>512</code> 个（默认值，可由 <code>hash-max-ziplist-entries</code> 配置），所有值小于 <code>64</code> 字节（默认值，可由 <code>hash-max-ziplist-value</code> 配置）的话，Redis 会使用<strong>压缩列表</strong>作为 Hash 类型的底层数据结构；</li>
<li>如果哈希类型元素不满足上面条件，Redis 会使用<strong>哈希表</strong>作为 Hash 类型的 底层数据结构。</li>
</ul>
</li>
<li><p>常用命令：HSET 、HGET 、HMSET 、HMGET 、HDEL 、HLEN 、HGETALL 、HINCRBY </p>
</li>
<li><p>应用场景：</p>
<ul>
<li>缓存对象：Hash 类型的 （key，field， value） 的结构与对象的（对象id， 属性， 值）的结构相似，也可以用来存储对象。一般对象用 String + Json 存储，对象中某些频繁变化的属性可以考虑抽出来用 Hash 类型存储</li>
<li>购物车：以用户 id 为 key，商品 id 为 field，商品数量为 value，恰好构成了购物车的3个要素</li>
</ul>
</li>
</ul>
<h4 id="Set"><a href="#Set" class="headerlink" title="Set"></a>Set</h4><ul>
<li>Set 类型是一个无序并唯一的键值集合，它的存储顺序不会按照插入的先后顺序进行存储。一个集合最多可以存储 <code>2^32-1</code> 个元素。概念和数学中个的集合基本类似，可以交集，并集，差集等等，所以 Set 类型除了支持集合内的增删改查，同时还支持多个集合取交集、并集、差集。</li>
<li>Set 类型和 List 类型的区别如下：<ul>
<li>List 可以存储重复元素，Set 只能存储非重复元素；</li>
<li>List 是按照元素的先后顺序存储元素的，而 Set 则是无序方式存储元素的。</li>
</ul>
</li>
<li>Set 类型的底层数据结构是由<strong>哈希表或整数集合</strong>实现的：<ul>
<li>如果集合中的元素都是整数且元素个数小于 <code>512</code> （默认值，<code>set-maxintset-entries</code>配置）个，Redis 会使用<strong>整数集合</strong>作为 Set 类型的底层数据结构；</li>
<li>如果集合中的元素不满足上面条件，则 Redis 使用<strong>哈希表</strong>作为 Set 类型的底层数据结构。</li>
</ul>
</li>
<li>常用命令：<ul>
<li>Set常用操作：SADD、SREM 、SMEMBERS 、SCARD 、SISMEMBER 、SRANDMEMBER 、SPOP </li>
<li>Set运算操作：SINTER 、SINTERSTORE 、SUNION、SUNIONSTORE 、SDIFF 、SDIFFSTORE</li>
</ul>
</li>
<li>应用场景：<ul>
<li>集合的主要几个特性，无序、不可重复、支持并交差等操作。因此 Set 类型比较适合用来数据去重和保障数据的唯一性，还可以用来统计多个集合的交集、错集和并集等，当我们存储的数据是无序并且需要去重的情况下，比较适合使用集合类型进行存储。</li>
<li><strong>Set 的差集、并集和交集的计算复杂度较高，在数据量较大的情况下，如果直接执行这些计算，会导致 Redis 实例阻塞</strong>。在主从集群中，为了避免主库因为 Set 做聚合计算（交集、差集、并集）时导致主库被阻塞，我们可以选择一个从库完成聚合统计，或者把数据返回给客户端，由客户端来完成聚合统计。</li>
<li>点赞：Set 类型可以保证一个用户只能点一个赞，这里举例子一个场景，key 是文章id，value 是用户id。</li>
<li>共同关注：Set 类型支持交集运算，所以可以用来计算共同关注的好友、公众号等。</li>
<li>抽奖活动：存储某活动中中奖的用户名 ，Set 类型因为有去重功能，可以保证同一个用户不会中奖两次。</li>
</ul>
</li>
</ul>
<h4 id="Zset"><a href="#Zset" class="headerlink" title="Zset"></a>Zset</h4><ul>
<li>Zset 类型（有序集合类型）相比于 Set 类型多了一个排序属性 score（分值），对于有序集合 ZSet 来说，每个存储元素相当于有两个值组成的，一个是有序结合的元素值，一个是排序值。有序集合保留了集合不能有重复成员的特性（分值可以重复），但不同的是，有序集合中的元素可以排序。</li>
<li>Zset 类型的底层数据结构是由<strong>压缩列表或跳表</strong>实现的：<ul>
<li>如果有序集合的元素个数小于 <code>128</code> 个，并且每个元素的值小于 <code>64</code> 字节时，Redis 会使用<strong>压缩列表</strong>作为 Zset 类型的底层数据结构；</li>
<li>如果有序集合的元素不满足上面的条件，Redis 会使用<strong>跳表</strong>作为 Zset 类型的底层数据结构；</li>
</ul>
</li>
<li>常用命令：<ul>
<li>Zset 常用操作：ZADD 、ZREM 、ZSCORE、ZCARD 、ZINCRBY 、ZRANGE 、ZREVRANGE 、ZRANGEBYSCORE 、ZRANGEBYLEX 、ZREVRANGEBYLEX </li>
<li>Zset 运算操作（相比于 Set 类型，ZSet 类型没有支持差集运算）：ZUNIONSTORE 、ZINTERSTORE</li>
</ul>
</li>
<li>应用场景<ul>
<li>Zset 类型（Sorted Set，有序集合） 可以根据元素的权重来排序，我们可以自己来决定每个元素的权重值。比如说，我们可以根据元素插入 Sorted Set 的时间确定权重值，先插入的元素权重小，后插入的元素权重大。在面对需要展示最新列表、排行榜等场景时，如果数据更新频繁或者需要分页显示，可以优先考虑使用 Sorted Set。</li>
<li>排行榜：有序集合比较典型的使用场景就是排行榜。例如学生成绩的排名榜、游戏积分排行榜、视频播放排名、电商系统中商品的销量排名等。</li>
<li>电话、姓名排序：使用有序集合的 <code>ZRANGEBYLEX</code> 或 <code>ZREVRANGEBYLEX</code> 可以帮助我们实现电话号码或姓名的排序，我们以 <code>ZRANGEBYLEX</code> （返回指定成员区间内的成员，按 key 正序排列，分数必须相同）为例。</li>
</ul>
</li>
</ul>
<h4 id="BitMap"><a href="#BitMap" class="headerlink" title="BitMap"></a>BitMap</h4><ul>
<li><p>Bitmap，即位图，是一串连续的二进制数组（0和1），可以通过偏移量（offset）定位元素。BitMap通过最小的单位bit来进行<code>0|1</code>的设置，表示某个元素的值或者状态，时间复杂度为O(1)。由于 bit 是计算机中最小的单位，使用它进行储存将非常节省空间，特别适合一些数据量大且使用<strong>二值统计的场景</strong>。</p>
</li>
<li><p>Bitmap 本身是用 String 类型作为底层数据结构实现的一种统计二值状态的数据类型。String 类型是会保存为二进制的字节数组，所以，Redis 就把字节数组的每个 bit 位利用起来，用来表示一个元素的二值状态，你可以把 Bitmap 看作是一个 bit 数组</p>
</li>
<li><p>常用命令：</p>
<ul>
<li>bitmap 基本操作：SETBIT 、GETBIT 、BITCOUNT </li>
<li>bitmap 运算操作：AND、OR 、XOR、NOT 、BITOP、BITPOS</li>
</ul>
</li>
<li><p>应用场景</p>
<ul>
<li>Bitmap 类型非常适合二值状态统计的场景，这里的二值状态就是指集合元素的取值就只有 0 和 1 两种，在记录海量数据时，Bitmap 能够有效地节省内存空间</li>
<li>签到统计：在签到打卡的场景中，我们只用记录签到（1）或未签到（0），所以它就是非常典型的二值状态。</li>
<li>判断用户登陆态：<ul>
<li>Bitmap 提供了 <code>GETBIT、SETBIT</code> 操作，通过一个偏移值 offset 对 bit 数组的 offset 位置的 bit 位进行读写操作，需要注意的是 offset 从 0 开始。</li>
<li>只需要一个 key &#x3D; login_status 表示存储用户登陆状态集合数据， 将用户 ID 作为 offset，在线就设置为 1，下线设置 0。通过 <code>GETBIT</code>判断对应的用户是否在线。 50000 万 用户只需要 6 MB 的空间。</li>
</ul>
</li>
<li>连续签到用户总数：<ul>
<li>把每天的日期作为 Bitmap 的 key，userId 作为 offset，若是打卡则将 offset 位置的 bit 设置成 1。</li>
<li>key 对应的集合的每个 bit 位的数据则是一个用户在该日期的打卡记录。</li>
<li>一共有 7 个这样的 Bitmap，如果我们能对这 7 个 Bitmap 的对应的 bit 位做 『与』运算。同样的 UserID offset 都是一样的，当一个 userID 在 7 个 Bitmap 对应对应的 offset 位置的 bit &#x3D; 1 就说明该用户 7 天连续打卡</li>
</ul>
</li>
</ul>
</li>
</ul>
<h4 id="HyperLogLog"><a href="#HyperLogLog" class="headerlink" title="HyperLogLog"></a>HyperLogLog</h4><ul>
<li>Redis HyperLogLog 是 Redis 2.8.9 版本新增的数据类型，是一种用于「统计基数」的数据集合类型，基数统计就是指统计一个集合中不重复的元素个数。但要注意，HyperLogLog 是统计规则是基于概率完成的，不是非常准确，标准误算率是 0.81%。所以，简单来说 HyperLogLog <strong>提供不精确的去重计数</strong>。</li>
<li>HyperLogLog 的优点是，在输入元素的数量或者体积非常非常大时，计算基数所需的内存空间总是固定的、并且是很小的。在 Redis 里面，<strong>每个 HyperLogLog 键只需要花费 12 KB 内存，就可以计算接近 <code>2^64</code> 个不同元素的基数</strong>，和元素越多就越耗费内存的 Set 和 Hash 类型相比，HyperLogLog 就非常节省空间。</li>
<li>HyperLogLog 命令：PFADD 、PFCOUNT 、PFMERGE </li>
<li>应用场景：<ul>
<li>百万级网页 UV 计数：Redis HyperLogLog 优势在于只需要花费 12 KB 内存，就可以计算接近 2^64 个元素的基数，和元素越多就越耗费内存的 Set 和 Hash 类型相比，HyperLogLog 就非常节省空间。</li>
</ul>
</li>
</ul>
<h4 id="GEO"><a href="#GEO" class="headerlink" title="GEO"></a>GEO</h4><ul>
<li><p>Redis GEO 是 Redis 3.2 版本新增的数据类型，主要用于存储地理位置信息，并对存储的信息进行操作。在日常生活中，我们越来越依赖搜索“附近的餐馆”、在打车软件上叫车，这些都离不开基于位置信息服务（Location-Based Service，LBS）的应用。LBS 应用访问的数据是和人或物关联的一组经纬度信息，而且要能查询相邻的经纬度范围，GEO 就非常适合应用在 LBS 服务的场景中</p>
</li>
<li><p>GEO 本身并没有设计新的底层数据结构，而是直接使用了 Sorted Set 集合类型。GEO 类型使用 GeoHash 编码方法实现了经纬度到 Sorted Set 中元素权重分数的转换，这其中的两个关键机制就是「对二维地图做区间划分」和「对区间进行编码」。一组经纬度落在某个区间后，就用区间的编码值来表示，并把编码值作为 Sorted Set 元素的权重分数。这样一来，我们就可以把经纬度保存到 Sorted Set 中，利用 Sorted Set 提供的“按权重进行有序范围查找”的特性，实现 LBS 服务中频繁使用的“搜索附近”的需求</p>
</li>
<li><p>常用命令：GEOADD 、GEOPOS 、GEODIST 、GEORADIUS </p>
</li>
<li><p>应用场景：</p>
<ul>
<li>滴滴叫车：可以用一个 GEO 集合保存所有车辆的经纬度，集合 key 是 cars:locations。</li>
</ul>
</li>
</ul>
<h4 id="Stream"><a href="#Stream" class="headerlink" title="Stream"></a>Stream</h4><ul>
<li><p>Redis Stream 是 Redis 5.0 版本新增加的数据类型，Redis 专门为消息队列设计的数据类型。在 Redis 5.0 Stream 没出来之前，消息队列的实现方式都有着各自的缺陷，例如：</p>
<ul>
<li>发布订阅模式，不能持久化也就无法可靠的保存消息，并且对于离线重连的客户端不能读取历史消息的缺陷；</li>
<li>List 实现消息队列的方式不能重复消费，一个消息消费完就会被删除，而且生产者需要自行实现全局唯一 ID。</li>
</ul>
<p>基于以上问题，Redis 5.0 便推出了 Stream 类型也是此版本最重要的功能，用于完美地实现消息队列，它支持消息的持久化、支持自动生成全局唯一 ID、支持 ack 确认消息的模式、支持消费组模式等，让消息队列更加的稳定和可靠</p>
</li>
<li><p>Stream 消息队列操作命令：</p>
<ul>
<li>XADD：插入消息，保证有序，可以自动生成全局唯一 ID；</li>
<li>XLEN ：查询消息长度；</li>
<li>XREAD：用于读取消息，可以按 ID 读取数据；</li>
<li>XDEL ： 根据消息 ID 删除消息；</li>
<li>DEL ：删除整个 Stream；</li>
<li>XRANGE ：读取区间消息</li>
<li>XREADGROUP：按消费组形式读取消息；</li>
<li>XPENDING 和 XACK：<ul>
<li>XPENDING 命令可以用来查询每个消费组内所有消费者「已读取、但尚未确认」的消息；</li>
<li>XACK 命令用于向消息队列确认消息处理已完成；</li>
</ul>
</li>
</ul>
</li>
<li><p>应用场景</p>
<ul>
<li><p>消息队列：生产者通过 XADD 命令插入一条消息，插入成功后会返回全局唯一的 ID：”1654254953808-0”。消息的全局唯一 ID 由两部分组成：</p>
<ul>
<li>第一部分“1654254953808”是数据插入时，以毫秒为单位计算的当前服务器时间；</li>
<li>第二部分表示插入消息在当前毫秒内的消息序号，这是从 0 开始编号的。例如，“1654254953808-0”就表示在“1654254953808”毫秒内的第 1 条消息。</li>
</ul>
<p>消费者通过 XREAD 命令从消息队列中读取消息时，可以指定一个消息 ID，并从这个消息 ID 的下一条消息开始进行读取；如果<strong>想要实现阻塞读（当没有数据时，阻塞住），可以调用 XRAED 时设定 BLOCK 配置项</strong>，实现类似于 BRPOP 的阻塞读取操作。</p>
</li>
<li><p>Stream 可以以使用 <strong>XGROUP 创建消费组</strong>，创建消费组之后，Stream 可以使用 XREADGROUP 命令让消费组内的消费者读取消息。</p>
<ul>
<li><strong>消息队列中的消息一旦被消费组里的一个消费者读取了，就不能再被该消费组内的其他消费者读取了，即同一个消费组里的消费者不能消费同一条消息</strong>。</li>
<li><strong>不同消费组的消费者可以消费同一条消息（但是有前提条件，创建消息组的时候，不同消费组指定了相同位置开始读取消息）</strong>。</li>
</ul>
</li>
<li><p>Streams 会自动使用内部队列（也称为 PENDING List）留存消费组里每个消费者读取的消息，直到消费者使用 XACK 命令通知 Streams“消息已经处理完成”。消费确认增加了消息的可靠性，一般在业务处理完成之后，需要执行 XACK 命令确认消息已经被消费完成</p>
</li>
</ul>
</li>
<li><p>Redis 基于 Stream 消息队列与专业的消息队列有哪些差距？</p>
<ul>
<li>使用一个消息队列，其实就分为三大块：<strong>生产者、队列中间件、消费者</strong>，所以要保证消息就是保证三个环节都不能丢失数据。</li>
<li>Redis 生产者会不会丢消息？生产者会不会丢消息，取决于生产者对于异常情况的处理是否合理。 从消息被生产出来，然后提交给 MQ 的过程中，只要能正常收到 （ MQ 中间件） 的 ack 确认响应，就表示发送成功，所以只要处理好返回值和异常，如果返回异常则进行消息重发，那么这个阶段是不会出现消息丢失的。</li>
<li>Redis 消费者会不会丢消息？不会，因为 Stream （ MQ 中间件）会自动使用内部队列（也称为 PENDING List）留存消费组里每个消费者读取的消息，但是未被确认的消息。消费者可以在重启后，用 XPENDING 命令查看已读取、但尚未确认处理完成的消息。等到消费者执行完业务逻辑后，再发送消费确认 XACK 命令，也能保证消息的不丢失。</li>
<li>Redis 消息中间件会不会丢消息？会，Redis 在以下 2 个场景下，都会导致数据丢失：<ul>
<li>AOF 持久化配置为每秒写盘，但这个写盘过程是异步的，Redis 宕机时会存在数据丢失的可能</li>
<li>主从复制也是异步的，主从切换时，也存在丢失数据的可能。</li>
</ul>
</li>
<li>Redis 的数据都存储在内存中，这就意味着一旦发生消息积压，则会导致 Redis 的内存持续增长，如果超过机器内存上限，就会面临被 OOM 的风险。所以 Redis 的 Stream 提供了可以指定队列最大长度的功能，就是为了避免这种情况发生。当指定队列最大长度时，队列长度超过上限后，旧消息会被删除，只保留固定长度的新消息。这么来看，Stream 在消息积压时，如果指定了最大长度，还是有可能丢失消息的。但 Kafka、RabbitMQ 专业的消息队列它们的数据都是存储在磁盘上，当消息积压时，无非就是多占用一些磁盘空间。因此，把 Redis 当作队列来使用时，会面临的 2 个问题：<ul>
<li>Redis 本身可能会丢数据；</li>
<li>面对消息挤压，内存资源会紧张；</li>
</ul>
</li>
<li>能不能将 Redis 作为消息队列来使用，关键看你的业务场景：<ul>
<li>如果你的业务场景足够简单，对于数据丢失不敏感，而且消息积压概率比较小的情况下，把 Redis 当作队列是完全可以的。</li>
<li>如果你的业务有海量消息，消息积压的概率比较大，并且不能接受数据丢失，那么还是用专业的消息队列中间件吧。</li>
</ul>
</li>
</ul>
</li>
<li><p>Redis 发布&#x2F;订阅机制为什么不可以作为消息队列？</p>
<p>发布订阅机制存在以下缺点，都是跟丢失数据有关：</p>
<ol>
<li>发布&#x2F;订阅机制没有基于任何数据类型实现，所以不具备「数据持久化」的能力，也就是发布&#x2F;订阅机制的相关操作，不会写入到 RDB 和 AOF 中，当 Redis 宕机重启，发布&#x2F;订阅机制的数据也会全部丢失。</li>
<li>发布订阅模式是“发后既忘”的工作模式，如果有订阅者离线重连之后不能消费之前的历史消息。</li>
<li>当消费端有一定的消息积压时，也就是生产者发送的消息，消费者消费不过来时，如果超过 32M 或者是 60s 内持续保持在 8M 以上，消费端会被强行断开，这个参数是在配置文件中设置的，默认值是 <code>client-output-buffer-limit pubsub 32mb 8mb 60</code>。</li>
</ol>
<p>所以，发布&#x2F;订阅机制只适合即使通讯的场景，比如构建哨兵集群的场景采用了发布&#x2F;订阅机制</p>
</li>
</ul>
<h3 id="3-2-Redis-数据结构介绍"><a href="#3-2-Redis-数据结构介绍" class="headerlink" title="3.2 Redis 数据结构介绍"></a>3.2 Redis 数据结构介绍</h3><ul>
<li><p>SDS，从C语言字符串的缺陷介绍，引入改进点，介绍结构</p>
<ul>
<li>C语言字符串获取字符串长度的时间复杂度为 O（N）；</li>
<li>C语言字符串的结尾是以 “\0” 字符标识，字符串里面不能包含有 “\0” 字符，因此不能保存二进制数据；</li>
<li>C语言字符串操作函数不高效且不安全，比如有缓冲区溢出的风险，有可能会造成程序运行终止；</li>
<li>Redis 的 SDS 结构在原本字符数组之上，增加了三个元数据：len、alloc、flags，用来解决 C 语言字符串的缺陷</li>
<li>加入了 len 成员变量，那么<strong>获取字符串长度的时候，直接返回这个成员变量的值就行，所以复杂度只有 O（1）</strong></li>
<li><strong>有个专门的 len 成员变量来记录长度，所以可存储包含 “\0” 的数据</strong>，SDS 的 API 都是以处理二进制的方式来处理 SDS 存放在 buf[] 里的数据，程序不会对其中的数据做任何限制</li>
<li><strong>当判断出缓冲区大小不够用时，Redis 会自动将扩大 SDS 的空间大小（小于 1MB 翻倍扩容，大于 1MB 按 1MB 扩容）</strong>，以满足修改所需的大小</li>
<li>SDS 结构中有个 flags 成员变量，表示的是 SDS 类型。<strong>设计不同类型的结构体，是为了能灵活保存不同大小的字符串，从而有效节省内存空间</strong></li>
</ul>
</li>
<li><p>链表，双向链表，提供链表节点个数快速访问，但是无法很好利用CPU缓存</p>
<ul>
<li><strong>获取某个节点的前置节点或后置节点的时间复杂度只需O(1)，而且这两个指针都可以指向 NULL，所以链表是无环链表</strong>；</li>
<li>提供了表头指针 head 和表尾节点 tail，所以**获取链表的表头节点和表尾节点的时间复杂度只需O(1)**；</li>
<li>提供了链表节点数量 len，所以**获取链表中的节点数量的时间复杂度只需O(1)**；</li>
<li>使用 void* 指针保存节点值，并且可以通过 list 结构的 dup、free、match 函数指针为节点设置该节点类型特定的函数，因此<strong>链表节点可以保存各种不同类型的值</strong>；</li>
<li>链表每个节点之间的内存都是不连续的，意味着<strong>无法很好利用 CPU 缓存</strong></li>
<li>保存一个链表节点的值都需要一个链表节点结构头的分配，<strong>内存开销较大</strong>。</li>
</ul>
</li>
<li><p>压缩列表，连续内存块组成的顺序型数据结构，构造压缩列表节点entry实现根据数据大小和类型进行不同的空间大小分配，但是又连锁更新的问题</p>
<ul>
<li><strong>虽然压缩列表紧凑型的内存布局能节省内存开销，但是如果保存的元素数量增加了，或是元素变大了，会导致内存重新分配，最糟糕的是会有「连锁更新」的问题</strong>。<strong>连锁更新一旦发生，就会导致压缩列表占用的内存空间要多次重新分配，这就会直接影响到压缩列表的访问性能</strong></li>
<li>因此，<strong>压缩列表只会用于保存的节点数量不多的场景</strong>，只要节点数量足够小，即使发生连锁更新，也是能接受的</li>
</ul>
</li>
<li><p>哈希表，主要介绍了哈希冲突和rehash</p>
<ul>
<li><strong>Redis 采用了「链式哈希」来解决哈希冲突</strong>，在不扩容哈希表的前提下，将具有相同哈希值的数据串起来，形成链接起，以便这些数据在表中仍然可以被查询到</li>
<li>Redis 使用 dictht 结构体表示哈希表。不过，在实际使用哈希表时，Redis 定义一个 dict 结构体，这个结构体里定义了<strong>两个哈希表（ht[2]）</strong>进行 rehash 的时候，需要用上 2 个哈希表</li>
<li>为了避免 rehash 在数据迁移过程中，因拷贝数据的耗时，影响 Redis 性能的情况，所以 Redis 采用了<strong>渐进式 rehash</strong>，也就是将数据的迁移的工作不再是一次性迁移完成，而是分多次迁移</li>
<li>触发 rehash 操作的条件，主要有两个：<ul>
<li><strong>当负载因子大于等于 1 ，并且 Redis 没有在执行 bgsave 命令或者 bgrewiteaof 命令，也就是没有执行 RDB 快照或没有进行 AOF 重写的时候，就会进行 rehash 操作。</strong></li>
<li><strong>当负载因子大于等于 5 时，此时说明哈希冲突非常严重了，不管有没有有在执行 RDB 快照或 AOF 重写，都会强制进行 rehash 操作</strong></li>
</ul>
</li>
</ul>
</li>
<li><p>整数集合，本质上是一块连续内存空间，<strong>节省内存资源</strong>，但是不支持降级操作</p>
</li>
<li><p>跳表，介绍实现的原理以及底层结构，查询的过程和层数设置</p>
<ul>
<li><strong>跳表是在链表基础上改进过来的，实现了一种「多层」的有序链表</strong>，这样的好处是能快读定位数据</li>
<li><strong>跳表的相邻两层的节点数量最理想的比例是 2:1，查找复杂度可以降低到 O(logN)<strong>。</strong>跳表在创建节点的时候，随机生成每个节点的层数</strong>，并没有严格维持相邻两层的节点数量比例为 2 : 1 的情况。</li>
<li>具体的做法是，<strong>跳表在创建节点时候，会生成范围为[0-1]的一个随机数，如果这个随机数小于 0.25（相当于概率 25%），那么层数就增加 1 层，然后继续生成下一个随机数，直到随机数的结果大于 0.25 结束，最终确定该节点的层数</strong>。</li>
<li>为什么 Zset 的实现用跳表而不用平衡树<ul>
<li><strong>从内存占用上来比较，跳表比平衡树更灵活一些</strong>。平衡树每个节点包含 2 个指针（分别指向左右子树），而跳表每个节点包含的指针数目平均为 1&#x2F;(1-p)，具体取决于参数 p 的大小。如果像 Redis里的实现一样，取 p&#x3D;1&#x2F;4，那么平均每个节点包含 1.33 个指针，比平衡树更有优势</li>
<li><strong>在做范围查找的时候，跳表比平衡树操作要简单</strong>。在平衡树上，我们找到指定范围的小值之后，还需要以中序遍历的顺序继续寻找其它不超过大值的节点。如果不对平衡树进行一定的改造，这里的中序遍历并不容易实现。而在跳表上进行范围查找就非常简单，只需要在找到小值之后，对第 1 层链表进行若干步的遍历就可以实现</li>
<li><strong>从算法实现难度上来比较，跳表比平衡树要简单得多</strong>。平衡树的插入和删除操作可能引发子树的调整，逻辑复杂，而跳表的插入和删除只需要修改相邻节点的指针，操作简单又快速</li>
</ul>
</li>
</ul>
</li>
<li><p>quicklist，改进的压缩列表，「双向链表 + 压缩列表」组合，通过控制每个链表节点中的压缩列表的大小或者元素个数，来规避连锁更新的问题</p>
</li>
<li><p>listpack，每个节点不再包含前一个节点的长度，解决连锁更新问题，<strong>listpack 只记录当前节点的长度，当我们向 listpack 加入一个新元素的时候，不会影响其他节点的长度字段的变化，从而避免了压缩列表的连锁更新问题</strong>。</p>
</li>
</ul>
<h3 id="4-1-AOF-持久化是怎么实现的？"><a href="#4-1-AOF-持久化是怎么实现的？" class="headerlink" title="4.1 AOF 持久化是怎么实现的？"></a>4.1 AOF 持久化是怎么实现的？</h3><ul>
<li><p>如果 Redis 每执行一条写操作命令，就把该命令以追加的方式写入到一个文件里，然后重启 Redis 的时候，先去读取这个文件里的命令，并且执行它，这就相当于恢复了缓存数据了；这种保存写操作命令到日志的持久化方式，就是 Redis 里的 <strong>AOF (<em>Append Only File</em>)</strong> 持久化功能，<strong>注意只会记录写操作命令，读操作命令是不会被记录的</strong>，因为没意义</p>
</li>
<li><p>Redis 是先执行写操作命令后，才将该命令记录到 AOF 日志里的，这么做其实有两个好处。</p>
<ul>
<li>第一个好处，<strong>避免额外的检查开销，保证记录在 AOF 日志里的命令都是可执行并且正确的</strong></li>
<li>第二个好处，<strong>不会阻塞当前写操作命令的执行</strong>，因为当写操作命令执行成功后，才会将命令记录到 AOF 日志</li>
</ul>
</li>
<li><p>AOF 持久化功能也不是没有潜在风险。</p>
<ul>
<li>第一个风险，执行写操作命令和记录日志是两个过程，那当 Redis 在还没来得及将命令写入到硬盘时，服务器发生宕机了，这个数据就会有<strong>丢失的风险</strong>。</li>
<li>第二个风险，由于写操作命令执行成功后才记录到 AOF 日志，所以不会阻塞当前写操作命令的执行，但是<strong>可能会给「下一个」命令带来阻塞风险</strong>。将命令写入到日志的这个操作也是在主进程完成的</li>
<li>如果在将日志内容写入到硬盘时，服务器的硬盘的 I&#x2F;O 压力太大，就会导致写硬盘的速度很慢，进而阻塞住了，也就会导致后续的命令无法执行。其实这两个风险都有一个共性，都跟「 AOF 日志写回硬盘的时机」有关</li>
</ul>
</li>
<li><p>Redis 写入 AOF 日志的过程：</p>
<ul>
<li>Redis 执行完写操作命令后，会将命令追加到 <code>server.aof_buf</code> 缓冲区；</li>
<li>然后通过 write() 系统调用，将 aof_buf 缓冲区的数据写入到 AOF 文件，此时数据并没有写入到硬盘，而是拷贝到了内核缓冲区 page cache，等待内核将数据写入硬盘；</li>
<li>具体内核缓冲区的数据什么时候写入到硬盘，由内核决定。</li>
</ul>
</li>
<li><p>Redis 提供了 3 种写回硬盘的策略，在 <code>redis.conf</code> 配置文件中的 <code>appendfsync</code> 配置项可以有以下 3 种参数可填：</p>
<ul>
<li><strong>Always</strong>，每次写操作命令执行完后，同步将 AOF 日志数据写回硬盘；</li>
<li><strong>Everysec</strong>，每次写操作命令执行完后，先将命令写入到 AOF 文件的内核缓冲区，然后每隔一秒将缓冲区里的内容写回到硬盘；</li>
<li><strong>No</strong>，意味着不由 Redis 控制写回硬盘的时机，转交给操作系统控制写回的时机，也就是每次写操作命令执行完后，先将命令写入到 AOF 文件的内核缓冲区，再由操作系统决定何时将缓冲区内容写回硬盘。</li>
</ul>
<p>根据自己的业务场景进行选择：</p>
<ul>
<li>如果要高性能，就选择 No 策略；</li>
<li>如果要高可靠，就选择 Always 策略；</li>
<li>如果允许数据丢失一点，但又想性能高，就选择 Everysec 策略。</li>
</ul>
<p>这三种策略只是在控制 <code>fsync()</code> 函数的调用时机，当应用程序向文件写入数据时，内核通常先将数据复制到内核缓冲区中，然后排入队列，然后由内核决定何时写入硬盘。如果想要应用程序向文件写入数据后，能立马将数据同步到硬盘，就可以调用 <code>fsync()</code> 函数，这样内核就会将内核缓冲区的数据直接写入到硬盘，等到硬盘写操作完成后，该函数才会返回。</p>
</li>
<li><p>Redis 为了避免 AOF 文件越写越大，提供了 <strong>AOF 重写机制</strong>，当 AOF 文件的大小超过所设定的阈值后，Redis 就会启用 AOF 重写机制，来压缩 AOF 文件。AOF 重写机制是在重写时，读取当前数据库中的所有键值对，然后将每一个键值对用一条命令记录到「新的 AOF 文件」，等到全部记录完后，就将新的 AOF 文件替换掉现有的 AOF 文件。尽管某个键值对被多条写命令反复修改，<strong>最终也只需要根据这个「键值对」当前的最新状态，然后用一条命令去记录键值对</strong>，代替之前记录这个键值对的多条命令</p>
<ul>
<li>为什么重写 AOF 的时候，不直接复用现有的 AOF 文件，而是先写到新的 AOF 文件再覆盖过去：<strong>如果 AOF 重写过程中失败了，现有的 AOF 文件就会造成污染</strong>，可能无法用于恢复使用</li>
</ul>
</li>
<li><p>Redis 的<strong>重写 AOF 过程是由后台子进程 <em>bgrewriteaof</em> 来完成的</strong>，这么做可以达到两个好处：</p>
<ul>
<li>子进程进行 AOF 重写期间，主进程可以继续处理命令请求，从而避免阻塞主进程；</li>
<li>子进程带有主进程的数据副本，这里使用子进程而不是线程，因为如果是使用线程，多线程之间会共享内存，那么在修改共享内存数据的时候，需要通过加锁来保证数据的安全，而这样就会降低性能。而使用子进程，创建子进程时，父子进程是共享内存数据的，不过这个共享的内存只能以只读的方式，而当父子进程任意一方修改了该共享内存，就会发生「写时复制」，于是父子进程就有了独立的数据副本，就不用加锁来保证数据安全。</li>
</ul>
</li>
<li><p>子进程是怎么拥有主进程一样的数据副本的呢？</p>
<ul>
<li>主进程在通过 <code>fork</code> 系统调用生成 bgrewriteaof 子进程时，操作系统会把主进程的「<strong>页表</strong>」复制一份给子进程，这个页表记录着虚拟地址和物理地址映射关系，而不会复制物理内存，也就是说，两者的虚拟空间不同，但其对应的物理空间是同一个。</li>
<li>子进程就共享了父进程的物理内存数据了，这样能够<strong>节约物理内存资源</strong>，页表对应的页表项的属性会标记该物理内存的权限为<strong>只读</strong>。</li>
<li>当父进程或者子进程在向这个内存发起写操作时，CPU 就会触发<strong>缺页中断</strong>，这个缺页中断是由于违反权限导致的，然后操作系统会在「缺页异常处理函数」里进行<strong>物理内存的复制</strong>，并重新设置其内存映射关系，将父子进程的内存读写权限设置为<strong>可读写</strong>，最后才会对内存进行写操作，这个过程被称为<strong>写时复制</strong></li>
</ul>
</li>
<li><p>子进程重写过程中，主进程依然可以正常处理命令。如果此时<strong>主进程修改了已经存在 key-value，就会发生写时复制，注意这里只会复制主进程修改的物理内存数据，没修改物理内存还是与子进程共享的</strong>。所以如果这个阶段修改的是一个 bigkey，也就是数据量比较大的 key-value 的时候，这时复制的物理内存数据的过程就会比较耗时，有阻塞主进程的风险</p>
</li>
<li><p>重写 AOF 日志过程中，如果主进程修改了已经存在 key-value，此时这个 key-value 数据在子进程的内存数据就跟主进程的内存数据不一致了，这时要怎么办呢？</p>
<ul>
<li>为了解决这种数据不一致问题，Redis 设置了一个 <strong>AOF 重写缓冲区</strong>，这个缓冲区在创建 bgrewriteaof 子进程之后开始使用。在重写 AOF 期间，当 Redis 执行完一个写命令之后，它会<strong>同时将这个写命令写入到 「AOF 缓冲区」和 「AOF 重写缓冲区」</strong></li>
<li>在 bgrewriteaof 子进程执行 AOF 重写期间，主进程需要执行以下三个工作:<ul>
<li>执行客户端发来的命令；</li>
<li>将执行后的写命令追加到 「AOF 缓冲区」；</li>
<li>将执行后的写命令追加到 「AOF 重写缓冲区」；</li>
</ul>
</li>
</ul>
</li>
<li><p>用 AOF 日志的方式来恢复数据其实是很慢的，因为 Redis 执行命令由单线程负责的，而 AOF 日志恢复数据的方式是顺序执行日志里的每一条命令，如果 AOF 日志很大，这个「重放」的过程就会很慢了</p>
</li>
</ul>
<h3 id="4-2-RDB-快照是怎么实现的？"><a href="#4-2-RDB-快照是怎么实现的？" class="headerlink" title="4.2 RDB 快照是怎么实现的？"></a>4.2 RDB 快照是怎么实现的？</h3><ul>
<li><p>RDB 快照就是记录某一个瞬间的内存数据，记录的是实际数据，而 AOF 文件记录的是命令操作的日志，而不是实际的数据。因此在 Redis 恢复数据时， RDB 恢复数据的效率会比 AOF 高些，因为直接将 RDB 文件读入内存就可以，不需要像 AOF 那样还需要额外执行操作命令的步骤才能恢复数据。</p>
</li>
<li><p>Redis 提供了两个命令来生成 RDB 文件，分别是 <code>save</code> 和 <code>bgsave</code>，他们的区别就在于是否在「主线程」里执行：</p>
<ul>
<li>执行了 save 命令，就会在主线程生成 RDB 文件，由于和执行操作命令在同一个线程，所以如果写入 RDB 文件的时间太长，<strong>会阻塞主线程</strong>；</li>
<li>执行了 bgsave 命令，会创建一个子进程来生成 RDB 文件，这样可以<strong>避免主线程的阻塞</strong>；</li>
</ul>
<p>RDB 文件的加载工作是在服务器启动时自动执行的，Redis 并没有提供专门用于加载 RDB 文件的命令</p>
</li>
<li><p>Redis 的快照是<strong>全量快照</strong>，也就是说每次执行快照，都是把内存中的「所有数据」都记录到磁盘中。所以可以认为，执行快照是一个比较重的操作，如果频率太频繁，可能会对 Redis 性能产生影响。如果频率太低，服务器故障时，丢失的数据会更多。</p>
<ul>
<li>通常可能设置至少 5 分钟才保存一次快照，这时如果 Redis 出现宕机等情况，则意味着最多可能丢失 5 分钟数据。</li>
<li>这就是 RDB 快照的缺点，在服务器发生故障时，丢失的数据会比 AOF 持久化的方式更多，因为 RDB 快照是全量快照的方式，因此执行的频率不能太频繁，否则会影响 Redis 性能，而 AOF 日志可以以秒级的方式记录操作命令，所以丢失的数据就相对更少</li>
</ul>
</li>
<li><p>执行 bgsave 过程中，Redis 依然<strong>可以继续处理操作命令</strong>的，也就是数据是能被修改的。关键的技术就在于<strong>写时复制技术（Copy-On-Write, COW）。</strong></p>
<ul>
<li>执行 bgsave 命令的时候，会通过 <code>fork()</code> 创建子进程，此时子进程和父进程是共享同一片内存数据的，因为创建子进程的时候，会复制父进程的页表，但是页表指向的物理内存还是一个；只有在发生修改内存数据的情况时，物理内存才会被复制一份。</li>
<li>bgsave 快照过程中，如果主线程修改了共享数据，<strong>发生了写时复制后，RDB 快照保存的是原本的内存数据</strong>，而主线程刚修改的数据，是被办法在这一时间写入 RDB 文件的，只能交由下一次的 bgsave 快照。</li>
<li>在 Redis 执行 RDB 持久化期间，刚 fork 时，主进程和子进程共享同一物理内存，但是途中主进程处理了写操作，修改了共享内存，于是当前被修改的数据的物理内存就会被复制一份。那么极端情况下，<strong>如果所有的共享内存都被修改，则此时的内存占用是原先的 2 倍。</strong></li>
</ul>
</li>
<li><p><strong>混合使用 AOF 日志和内存快照</strong>，也叫混合持久化。</p>
<ul>
<li>当开启了混合持久化时，在 AOF 重写日志时，<code>fork</code> 出来的重写子进程会先将与主线程共享的内存数据以 RDB 方式写入到 AOF 文件，然后主线程处理的操作命令会被记录在重写缓冲区里，重写缓冲区里的增量命令会以 AOF 方式写入到 AOF 文件，写入完成后通知主进程将新的含有 RDB 格式和 AOF 格式的 AOF 文件替换旧的的 AOF 文件。</li>
<li>使用了混合持久化，AOF 文件的<strong>前半部分是 RDB 格式的全量数据，后半部分是 AOF 格式的增量数据</strong>。这样的好处在于，重启 Redis 加载数据的时候，由于前半部分是 RDB 内容，这样<strong>加载的时候速度会很快</strong>。</li>
<li>加载完 RDB 的内容后，才会加载后半部分的 AOF 内容，这里的内容是 Redis 后台子进程重写 AOF 期间，主线程处理的操作命令，可以使得<strong>数据更少的丢失</strong>。</li>
</ul>
</li>
</ul>
<h3 id="4-3-Redis-大-Key-对持久化有什么影响？"><a href="#4-3-Redis-大-Key-对持久化有什么影响？" class="headerlink" title="4.3 Redis 大 Key 对持久化有什么影响？"></a>4.3 Redis 大 Key 对持久化有什么影响？</h3><ul>
<li><p>Redis 提供了 3 种 AOF 日志写回硬盘的策略，分别是：</p>
<ul>
<li>Always，每次写操作命令执行完后，同步将 AOF 日志数据写回硬盘；</li>
<li>Everysec，每次写操作命令执行完后，先将命令写入到 AOF 文件的内核缓冲区，然后每隔一秒将缓冲区里的内容写回到硬盘；</li>
<li>No，意味着不由 Redis 控制写回硬盘的时机，转交给操作系统控制写回的时机，也就是每次写操作命令执行完后，先将命令写入到 AOF 文件的内核缓冲区，再由操作系统决定何时将缓冲区内容写回硬盘</li>
<li>这三种策略只是在控制 fsync() 函数的调用时机。当应用程序向文件写入数据时，内核通常先将数据复制到内核缓冲区中，然后排入队列，然后由内核决定何时写入硬盘</li>
</ul>
</li>
<li><p>大 Key 对 AOF 日志的影响</p>
<ul>
<li><strong>当使用 Always 策略的时候，如果写入是一个大 Key，主线程在执行 fsync() 函数的时候，阻塞的时间会比较久，因为当写入的数据量很大的时候，数据同步到硬盘这个过程是很耗时的</strong></li>
<li>当使用 Everysec 策略的时候，由于是异步执行 fsync() 函数，所以大 Key 持久化的过程（数据同步磁盘）不会影响主线程</li>
<li>当使用 No 策略的时候，由于永不执行 fsync() 函数，所以大 Key 持久化的过程不会影响主线程</li>
<li>当 AOF 日志写入了很多的大 Key，AOF 日志文件的大小会很大，那么很快就会触发 <strong>AOF 重写机制</strong>。AOF 重写机制和 RDB 快照（bgsave 命令）的过程，都会分别通过 <code>fork()</code> 函数创建一个子进程来处理任务</li>
</ul>
</li>
<li><p>大 Key 对 AOF 重写和 RDB 的影响</p>
<ul>
<li>随着 Redis 存在越来越多的大 Key，那么 Redis 就会占用很多内存，对应的页表就会越大；在通过 <code>fork()</code> 函数创建子进程的时候，虽然不会复制父进程的物理内存，但是<strong>内核会把父进程的页表复制一份给子进程，如果页表很大，那么这个复制过程是会很耗时的，那么在执行 fork 函数的时候就会发生阻塞现象</strong>；而且，fork 函数是由 Redis 主线程调用的，如果 fork 函数发生阻塞，那么意味着就会阻塞 Redis 主线程。由于 Redis 执行命令是在主线程处理的，所以当 Redis 主线程发生阻塞，就无法处理后续客户端发来的命令</li>
<li>如果 fork 耗时很大，比如超过1秒，则需要做出优化调整：<ul>
<li>单个实例的内存占用控制在 10 GB 以下，这样 fork 函数就能很快返回</li>
<li>如果 Redis 只是当作纯缓存使用，不关心 Redis 数据安全性问题，可以考虑关闭 AOF 和 AOF 重写，这样就不会调用 fork 函数了</li>
<li>在主从架构中，要适当调大 repl-backlog-size，避免因为 repl_backlog_buffer 不够大，导致主节点频繁地使用全量同步的方式，全量同步的时候，是会创建 RDB 文件的，也就是会调用 fork 函数</li>
</ul>
</li>
<li>如果创建完子进程后，<strong>父进程对共享内存中的大 Key 进行了修改，那么内核就会发生写时复制，会把物理内存复制一份，由于大 Key 占用的物理内存是比较大的，那么在复制物理内存这一过程中，也是比较耗时的，于是父进程（主线程）就会发生阻塞</strong></li>
</ul>
</li>
<li><p>当 AOF 写回策略配置了 Always 策略，如果写入是一个大 Key，主线程在执行 fsync() 函数的时候，阻塞的时间会比较久，因为当写入的数据量很大的时候，数据同步到硬盘这个过程是很耗时的</p>
</li>
<li><p>AOF 重写机制和 RDB 快照（bgsave 命令）的过程，都会分别通过 <code>fork()</code> 函数创建一个子进程来处理任务。会有两个阶段会导致阻塞父进程（主线程）：</p>
<ul>
<li>创建子进程的途中，由于要复制父进程的页表等数据结构，阻塞的时间跟页表的大小有关，页表越大，阻塞的时间也越长；</li>
<li>创建完子进程后，如果父进程修改了共享数据中的大 Key，就会发生写时复制，这期间会拷贝物理内存，由于大 Key 占用的物理内存会很大，那么在复制物理内存这一过程，就会比较耗时，所以有可能会阻塞父进程。</li>
</ul>
</li>
<li><p>大 key 除了会影响持久化之外，还会有以下的影响：</p>
<ul>
<li>客户端超时阻塞。由于 Redis 执行命令是单线程处理，然后在操作大 key 时会比较耗时，那么就会阻塞 Redis，从客户端这一视角看，就是很久很久都没有响应。</li>
<li>引发网络阻塞。每次获取大 key 产生的网络流量较大，如果一个 key 的大小是 1 MB，每秒访问量为 1000，那么每秒会产生 1000MB 的流量，这对于普通千兆网卡的服务器来说是灾难性的。</li>
<li>阻塞工作线程。如果使用 del 删除大 key 时，会阻塞工作线程，这样就没办法处理后续的命令。</li>
<li>内存分布不均。集群模型在 slot 分片均匀情况下，会出现数据和查询倾斜情况，部分有大 key 的 Redis 节点占用内存多，QPS 也会比较大。</li>
</ul>
</li>
<li><p>如何避免大 Key 呢？</p>
<ul>
<li>最好在设计阶段，就把大 key 拆分成一个一个小 key。或者，定时检查 Redis 是否存在大 key ，如果该大 key 是可以删除的，不要使用 DEL 命令删除，因为该命令删除过程会阻塞主线程，而是用 unlink 命令（Redis 4.0+）删除大 key，因为该命令的删除过程是异步的，不会阻塞主线程。</li>
</ul>
</li>
</ul>
<h3 id="5-1-Redis-过期删除策略和内存淘汰策略有什么区别？"><a href="#5-1-Redis-过期删除策略和内存淘汰策略有什么区别？" class="headerlink" title="5.1 Redis 过期删除策略和内存淘汰策略有什么区别？"></a>5.1 Redis 过期删除策略和内存淘汰策略有什么区别？</h3><ul>
<li>Redis的过期删除策略是针对过期的key进行删除的，Redis 会把该 key 带上过期时间存储到一个<strong>过期字典</strong>中，当查询一个key时，redis首先看是否在过期字典中，若在则于当前时间比对，比当前系统时间大则没有过期</li>
<li>过期删除策略：<ul>
<li>定时删除：构造一个定时事件，时间到达时CPU自动执行key的删除操作，对内存较友好但是对CPU不友好，可能会影响响应时间和吞吐量</li>
<li>惰性删除：不主动删除过期的key，而是每次访问时再进行检测判断，对CPU友好单对内存不友好，造成一定的内存空间浪费</li>
<li>定期删除：每隔一段时间「随机」从数据库中取出一定数量的 key 进行检查，并删除其中的过期key，但是难以确定删除操作执行的时长和频率</li>
</ul>
</li>
<li><strong>Redis 选择「惰性删除+定期删除」这两种策略配合使用</strong>，以求在合理使用 CPU 时间和避免内存浪费之间取得平衡；其定期删除是一个循环的流程：1.从过期字典中随机抽取 20 个 key；2.检查这 20 个 key 是否过期，并删除已过期的 key；3.如果本轮检查的已过期 key 的数量，超过 5 个（20&#x2F;4），也就是「已过期 key 的数量」占比「随机抽取 key 的数量」大于 25%，则继续重复步骤 1；如果已过期的 key 比例小于 25%，则停止继续删除过期 key，然后等待下一轮再检查。另外还限定了时间上限，放置循环过度</li>
<li>当 Redis 的运行内存已经超过 Redis 设置的最大内存之后，则会使用内存淘汰策略删除符合条件的 key，以此来保障 Redis 高效的运行</li>
<li>Redis 内存淘汰策略共有八种，主要分成不进行数据淘汰（不再提供服务，直接返回错误）和进行数据淘汰，后者分为针对设置了过期时间的volatile淘汰和all key淘汰，volatile淘汰有四种策略，分别是随机淘汰、优先淘汰更早过期的键值、lru和lfu；all key则少了ttl淘汰方法其余一样</li>
<li>Redis采用一种近似<strong>LRU</strong>算法，为了更好的节约内存，它的<strong>实现方式是在 Redis 的对象结构体中添加一个额外的字段，用于记录此数据的最后一次访问时间</strong>。当 Redis 进行内存淘汰时，会使用<strong>随机采样的方式来淘汰数据</strong>，它是随机取 5 个值（此值可配置），然后<strong>淘汰最久没有使用的那个</strong>；但是针对单次访问大量数据的场景下会产生缓存污染问题</li>
<li>而LFU算法就是针对该缺陷提出的，其根据数据访问次数来淘汰数据的，会记录每个数据的访问次数，当一个数据被再次访问时，就会增加该数据的访问次数，这样子就能够解决偶尔访问一次导致的缓存污染问题；LFU算法针对redis中的lru字段进行了修改，其高16bit仍然记录时间戳，低8bit则用为记录访问频次；其访问频次不是简单的+1-1，而是先按照上次访问距离当前的时长，来对 logc 进行衰减；然后，再按照一定概率增加 logc 的值，这样子主要是为了充份利用仅有的低8bit的255数据范围</li>
<li>LRU策略更关注数据的时效性，而实际应用的负载具有较好的时间局部性，因此LRU应用更加广泛；但是再扫描式查询的应用场景中，LFU可以更好的解决缓存污染问题；如果业务中有短时高频访问的数据，可以优先使用volatile-LFU策略，并根据这些数据的访问时限设置他们的过期时间</li>
</ul>
<h3 id="6-1-主从复制是怎么实现的？"><a href="#6-1-主从复制是怎么实现的？" class="headerlink" title="6.1 主从复制是怎么实现的？"></a>6.1 主从复制是怎么实现的？</h3><ul>
<li><p>为了避免单点故障，redis一般会采用多台服务器存储数据，服务器之间的数据一致性由主从复制模式保证；redis主从服务器之间一般采用读写分离的方式，从服务器一般是只读，并接受主服务器同步过来写操作命令，然后执行这条命令</p>
</li>
<li><p>主从服务器的第一次同步可以分为三个阶段</p>
<ul>
<li>第一阶段是建立链接、协商同步；从服务器就会给主服务器发送 <code>psync</code> 命令（包含两个参数，分别是<strong>主服务器的 runID</strong> 和<strong>复制进度 offset</strong>），主服务器收到 psync 命令后，会用 <code>FULLRESYNC</code>（全量复制） 作为响应命令返回给对方。并且这个响应命令会带上两个参数：主服务器的 runID 和主服务器目前的复制进度 offset</li>
<li>第二阶段是主服务器同步数据给从服务器；主服务器会执行 bgsave 命令（子进程异步处理，此时同样可以处理命令）来生成 RDB 文件，然后把文件发送给从服务器；这期间的写操作命令并没有记录到刚刚生成的 RDB 文件中，因此需要将生成RDB文件、传递RDB文件、从服务器加载RDB文件期间的写操作命令写入到replication buffer 缓冲区</li>
<li>第三阶段是主服务器发送新写操作命令给从服务器，「从服务器」重新执行这些操作，至此主从服务器的数据就一致了</li>
</ul>
</li>
<li><p>主从服务器在完成第一次同步后，双方之间就会维护一个 TCP 长连接，避免频繁的 TCP 连接和断开带来的性能开销；服务器是可以有多个从服务器的，如果从服务器数量非常多，而且都与主服务器进行全量同步的话，就会带来Redis 性能问题，因此从服务器可以有自己的从服务器从而分担主服务器的压力</p>
</li>
<li><p>由于网络延迟导致的数据不同步问题，主从服务器之间会采用增量复制的方式实现同步：</p>
<ul>
<li>从服务器在恢复网络后，会发送 psync 命令给主服务器，此时的 psync 命令里的 offset 参数是自己的复制偏移量</li>
<li>主服务器收到该命令后，然后用 CONTINUE 响应命令告诉从服务器接下来采用增量复制的方式同步数据</li>
<li>然后主服务将主从服务器断线期间，所执行的写命令发送给从服务器，然后从服务器执行这些命令</li>
</ul>
</li>
<li><p>增量复制的实现基于repl_backlog_buffer，其是一个「<strong>环形</strong>」缓冲区，用于主从服务器断连后，从中找到差异的数据；<strong>replication offset</strong>标记缓冲区的同步进度，主从服务器都有各自的偏移量，主服务器使用 master_repl_offset 来记录自己「<em>写</em>」到的位置，从服务器使用 slave_repl_offset 来记录自己「<em>读</em>」到的位置；主服务器根据自己的 master_repl_offset 和 slave_repl_offset 之间的差距，然后来决定对从服务器执行哪种同步操作，还在repl_backlog_buffer缓冲区内则采用增量复制，否则采用全量复制</p>
</li>
<li><p>如果repl_backlog_buffer配置的过小，主从服务器网络恢复时，可能发生「从服务器」想读的数据已经被覆盖了，那么这时就会导致主服务器采用全量复制的方式。所以为了避免这种情况的频繁发生，要调大这个参数的值，以降低主从服务器断开后全量同步的概率</p>
</li>
<li><p>redis 判断接点是否正常工作，基本都是通过互相的 ping-pong 心态检测机制，如果有一半以上的节点去 ping 一个节点的时候没有 pong 回应，集群就会认为这个节点挂掉了，会断开与这个节点的连接</p>
</li>
<li><p>replication buffer 是在全量复制阶段会出现，<strong>主库会给每个新连接的从库，分配一个</strong> replication buffer；repl backlog buffer 是在增量复制阶段出现，<strong>一个主库只分配一个</strong>repl backlog buffer；repl backlog buffer，因为是环形结构，会直接<strong>覆盖起始位置数据</strong>，replication buffer则会导致连接断开，删除缓存，从库重新连接，<strong>重新开始全量复制</strong></p>
</li>
<li><p>redis 主从切换如何减少数据丢失：客户端将数据暂时写入本地缓存和磁盘中，在一段时间后将本地缓存或者磁盘的数据发送给主节点，来保证数据不丢失；客户端将数据写入到消息队列中，发送一个延时消费消息，比如10分钟后再消费消息队列中的数据，然后再写到主节点</p>
</li>
<li><p>集群脑裂现象：由于网络问题，集群节点之间失去联系。主从数据不同步；重新平衡选举，产生两个主服务。等网络恢复，旧主节点会降级为从节点，再与新主节点进行同步复制的时候，由于会从节点会清空自己的缓冲区，所以导致之前客户端写入的数据丢失了。<strong>解决方案：</strong>当主节点发现从节点下线或者通信超时的总数量小于阈值时(主库连接的从库中至少有 N (min-slaves-to-write)个从库，和主库进行数据复制时的 ACK 消息延迟不能超过 T (min-slaves-max-lag)秒)，那么禁止主节点进行写数据，直接把错误返回给客户端</p>
</li>
</ul>
<h3 id="6-2-为什么要有哨兵？"><a href="#6-2-为什么要有哨兵？" class="headerlink" title="6.2 为什么要有哨兵？"></a>6.2 为什么要有哨兵？</h3><ul>
<li>在 Redis 的主从架构中，由于主从模式是读写分离的，如果主节点（master）挂了，那么将没有主节点来服务客户端的写操作请求，也没有主节点给从节点（slave）进行数据同步。<strong>哨兵（<em>Sentinel</em>）机制</strong>，它的作用是实现<strong>主从节点故障转移</strong>。它会监测主节点是否存活，如果发现主节点挂了，它就会选举一个从节点切换为主节点，并且把新主节点的相关信息通知给从节点和客户端</li>
<li>哨兵其实是一个运行在特殊模式下的 Redis 进程，所以它也是一个节点。哨兵节点主要负责三件事情：<strong>监控、选主、通知</strong><ul>
<li><strong>监控</strong>：哨兵会每隔 1 秒给所有主从节点发送 PING 命令，当主从节点收到 PING 命令后，会发送一个响应命令给哨兵，这样就可以判断它们是否在正常运行；如果主节点或者从节点没有在规定的时间内响应哨兵的 PING 命令，哨兵就会将它们标记为「<strong>主观下线</strong>」。当一个哨兵判断主节点为「主观下线」后，就会向其他哨兵发起命令，其他哨兵收到这个命令后，就会根据自身和主节点的网络状况，做出赞成投票或者拒绝投票的响应。当这个哨兵的赞同票数达到哨兵配置文件中的 quorum 配置项设定的值（一般设置为哨兵个数的1&#x2F;2+1）后，这时主节点就会被该哨兵标记为「客观下线」<ul>
<li>之所以针对「主节点」设计「主观下线」和「客观下线」两个状态，是因为有可能「主节点」其实并没有故障，可能只是因为主节点的系统压力比较大或者网络发送了拥塞，导致主节点没有在规定时间内响应哨兵的 PING 命令</li>
<li>为了减少误判的情况，哨兵在部署的时候不会只部署一个节点，而是用多个节点部署成<strong>哨兵集群</strong>（<em>最少需要三台机器来部署哨兵集群</em>，数量应该是奇数），<strong>通过多个哨兵节点一起判断，就可以就可以避免单个哨兵因为自身网络状况不好，而误判主节点下线的情况</strong></li>
</ul>
</li>
<li><strong>选主</strong>：需要在哨兵集群中选出一个 leader，让 leader 来执行主从切换，选举 leader 的过程其实是一个投票的过程，哪个哨兵节点判断主节点为「客观下线」就作为「候选者」；候选者会向其他哨兵发送命令，表明希望成为 Leader 来执行主从切换，并让所有其他哨兵对它进行投票；每个哨兵只有一次投票机会，如果用完后就不能参与投票了，可以投给自己或投给别人，但是只有候选者才能把票投给自己；那么在投票过程中，任何一个「候选者」，要满足两个条件：<ul>
<li>第一，拿到半数以上的赞成票；</li>
<li>第二，拿到的票数同时还需要大于等于哨兵配置文件中的 quorum 值。</li>
</ul>
</li>
<li><strong>通知</strong>：主从故障转移操作包含以下四个步骤：<ul>
<li>第一步：在已下线主节点（旧主节点）属下的所有「从节点」里面，挑选出一个从节点，并将其转换为主节点。首先要把网络状态不好的从节点（或者已经离线的从节点）给过滤掉，接下来要对所有从节点进行三轮考察：<strong>优先级、复制进度、ID 号</strong>，在进行每一轮考察的时候，哪个从节点优先胜出，就选择其作为新主节点</li>
<li>第二步：让已下线主节点属下的所有「从节点」修改复制目标，修改为复制「新主节点」；这一动作可以通过向「从节点」发送 <code>SLAVEOF</code> 命令来实现</li>
<li>第三步：将新主节点的 IP 地址和信息，通过「发布者&#x2F;订阅者机制」通知给客户端；每个哨兵节点提供发布者&#x2F;订阅者机制，客户端可以从哨兵订阅消息。哨兵提供的消息订阅频道有很多，不同频道包含了主从节点切换过程中的不同关键事件；主从切换完成后，哨兵就会向 <code>+switch-master</code> 频道发布新主节点的 IP 地址和端口的消息，这个时候客户端就可以收到这条信息，然后用这里面的新主节点的 IP 地址和端口进行通信了</li>
<li>第四步：继续监视旧主节点，当这个旧主节点重新上线时，将它设置为新主节点的从节点</li>
</ul>
</li>
</ul>
</li>
<li>哨兵集群是如何组成的？<strong>哨兵节点之间是通过 Redis 的发布者&#x2F;订阅者机制来相互发现的</strong>。在主从集群中，主节点上有一个名为<code>__sentinel__:hello</code>的频道，不同哨兵就是通过它来相互发现，实现互相通信的</li>
<li>哨兵集群会对「从节点」的运行状态进行监控，那哨兵集群如何知道「从节点」的信息？<ul>
<li>主节点知道所有「从节点」的信息，所以哨兵会每 10 秒一次的频率向主节点发送 INFO 命令来获取所有「从节点」的信息。正式通过 Redis 的发布者&#x2F;订阅者机制，哨兵之间可以相互感知，然后组成集群，同时，哨兵又通过 INFO 命令，在主节点里获得了所有从节点连接信息，于是就能和从节点建立连接，并进行监控了。</li>
</ul>
</li>
</ul>
<h3 id="7-1-什么是缓存雪崩、击穿、穿透？"><a href="#7-1-什么是缓存雪崩、击穿、穿透？" class="headerlink" title="7.1 什么是缓存雪崩、击穿、穿透？"></a>7.1 什么是缓存雪崩、击穿、穿透？</h3><ul>
<li><p>通常为了保证缓存中的数据与数据库中的数据一致性，会给 Redis 里的数据设置过期时间，当缓存数据过期后，用户访问的数据如果不在缓存里，业务系统需要重新生成缓存，因此就会访问数据库，并将数据更新到 Redis 里，这样后续请求都可以直接命中缓存。当<strong>大量缓存数据在同一时间过期（失效）或者 Redis 故障宕机</strong>时，如果此时有大量的用户请求，都无法在 Redis 中处理，于是全部请求都直接访问数据库，从而导致数据库的压力骤增，严重的会造成数据库宕机，从而形成一系列连锁反应，造成整个系统崩溃，这就是<strong>缓存雪崩</strong>的问题。发生缓存雪崩有两个原因：</p>
<ul>
<li>大量数据同时过期；针对大量数据同时过期而引发的缓存雪崩问题，常见的应对方法有下面这几种：<ul>
<li>均匀设置过期时间；<strong>给这些数据的过期时间加上一个随机数</strong>，这样就保证数据不会在同一时间过期。</li>
<li>互斥锁；<strong>如果发现访问的数据不在 Redis 里，就加个互斥锁，保证同一时间内只有一个请求来构建缓存</strong>；实现互斥锁的时候，最好设置<strong>超时时间</strong>，不然第一个请求拿到了锁，然后这个请求发生了某种意外而一直阻塞，一直不释放锁，这时其他请求也一直拿不到锁，整个系统就会出现无响应的现象。</li>
<li>双 key 策略；对缓存数据可以使用两个 key，一个是<strong>主 key，会设置过期时间</strong>，一个是<strong>备 key，不会设置过期</strong>，它们只是 key 不一样，但是 value 值是一样的，相当于给缓存数据做了个副本；当业务线程访问不到「主 key 」的缓存数据时，就直接返回「备 key 」的缓存数据，然后在更新缓存的时候，<strong>同时更新「主 key 」和「备 key 」的数据。</strong></li>
<li>后台更新缓存；业务线程不再负责更新缓存，缓存也不设置有效期，而是<strong>让缓存“永久有效”，并将更新缓存的工作交由后台线程定时更新</strong>。<ul>
<li>缓存数据不设置有效期，并不是意味着数据一直能在内存里，因为<strong>当系统内存紧张的时候，有些缓存数据会被“淘汰”</strong>，而在缓存被“淘汰”到下一次后台定时更新缓存的这段时间内，业务线程读取缓存失败就返回空值，业务的视角就以为是数据丢失了</li>
<li>解决上面的问题的方式有两种。第一种方式，后台线程不仅负责定时更新缓存，而且也负责<strong>频繁地检测缓存是否有效</strong>，检测到缓存失效了，原因可能是系统紧张而被淘汰的，于是就要马上从数据库读取数据，并更新到缓存。</li>
<li>第二种方式，在业务线程发现缓存数据失效后（缓存数据被淘汰），<strong>通过消息队列发送一条消息通知后台线程更新缓存</strong>，后台线程收到消息后，在更新缓存前可以判断缓存是否存在，存在就不执行更新缓存操作；不存在就读取数据库数据，并将数据加载到缓存。这种方式相比第一种方式缓存的更新会更及时，用户体验也比较好。</li>
</ul>
</li>
</ul>
</li>
<li>Redis 故障宕机；针对 Redis 故障宕机而引发的缓存雪崩问题，常见的应对方法有下面这几种：<ul>
<li>服务熔断或请求限流机制；<ul>
<li><strong>暂停业务应用对缓存服务的访问，直接返回错误</strong>，不用再继续访问数据库，从而降低对数据库的访问压力，保证数据库系统的正常运行，然后等到 Redis 恢复正常后，再允许业务应用访问缓存服务。</li>
<li>为了减少对业务的影响，我们可以启用<strong>请求限流</strong>机制，<strong>只将少部分请求发送到数据库进行处理，再多的请求就在入口直接拒绝服务</strong>，等到 Redis 恢复正常并把缓存预热完后，再解除请求限流的机制。</li>
</ul>
</li>
<li>构建 Redis 缓存高可靠集群；通过<strong>主从节点的方式构建 Redis 缓存高可靠集群</strong>。如果 Redis 缓存的主节点故障宕机，从节点可以切换成为主节点，继续提供缓存服务，避免了由于 Redis 故障宕机而导致的缓存雪崩问题</li>
</ul>
</li>
</ul>
</li>
<li><p>如果缓存中的<strong>某个热点数据过期</strong>了，此时大量的请求访问了该热点数据，就无法从缓存中读取，直接访问数据库，数据库很容易就被高并发的请求冲垮，这就是<strong>缓存击穿</strong>的问题。应对缓存击穿可以采取前面说到两种方案：</p>
<ul>
<li>互斥锁方案，保证同一时间只有一个业务线程更新缓存，未能获取互斥锁的请求，要么等待锁释放后重新读取缓存，要么就返回空值或者默认值。</li>
<li>不给热点数据设置过期时间，由后台异步更新缓存，或者在热点数据准备要过期前，提前通知后台线程更新缓存以及重新设置过期时间；</li>
</ul>
</li>
<li><p>当用户访问的数据，<strong>既不在缓存中，也不在数据库中</strong>，导致请求在访问缓存时，发现缓存缺失，再去访问数据库时，发现数据库中也没有要访问的数据，没办法构建缓存数据，来服务后续的请求。那么当有大量这样的请求到来时，数据库的压力骤增，这就是<strong>缓存穿透</strong>的问题。缓存穿透的发生一般有这两种情况：</p>
<ul>
<li>业务误操作，缓存中的数据和数据库中的数据都被误删除了，所以导致缓存和数据库中都没有数据；</li>
<li>黑客恶意攻击，故意大量访问某些读取不存在数据的业务；</li>
</ul>
<p>应对缓存穿透的方案，常见的方案有三种。</p>
<ul>
<li>第一种方案，非法请求的限制；请求参数是否含有非法值、请求字段是否存在，如果判断出是恶意请求就直接返回错误，避免进一步访问缓存和数据库。</li>
<li>第二种方案，缓存空值或者默认值；后续请求就可以从缓存中读取到空值或者默认值，返回给应用，而不会继续查询数据库</li>
<li>第三种方案，使用布隆过滤器快速判断数据是否存在，避免通过查询数据库来判断数据是否存在；即使发生了缓存穿透，大量请求只会查询 Redis 和布隆过滤器，而不会查询数据库，保证了数据库能正常运行，Redis 自身也是支持布隆过滤器的</li>
</ul>
</li>
<li><p>布隆过滤器由「初始值都为 0 的位图数组」和「 N 个哈希函数」两部分组成。当我们在写入数据库数据时，在布隆过滤器里做个标记，这样下次查询数据是否在数据库时，只需要查询布隆过滤器，如果查询到数据没有被标记，说明不在数据库中。布隆过滤器会通过 3 个操作完成标记：</p>
<ul>
<li>第一步，使用 N 个哈希函数分别对数据做哈希计算，得到 N 个哈希值；</li>
<li>第二步，将第一步得到的 N 个哈希值对位图数组的长度取模，得到每个哈希值在位图数组的对应位置。</li>
<li>第三步，将每个哈希值在位图数组的对应位置的值设置为 1；</li>
</ul>
<p>布隆过滤器由于是基于哈希函数实现查找的，高效查找的同时<strong>存在哈希冲突的可能性</strong>，比如数据 x 和数据 y 可能都落在第 1、4、6 位置，而事实上，可能数据库中并不存在数据 y，存在误判的情况。所以，<strong>查询布隆过滤器说数据存在，并不一定证明数据库中存在这个数据，但是查询到数据不存在，数据库中一定就不存在这个数据</strong>。</p>
</li>
</ul>
<h3 id="7-2-数据库和缓存如何保证一致性？"><a href="#7-2-数据库和缓存如何保证一致性？" class="headerlink" title="7.2 数据库和缓存如何保证一致性？"></a>7.2 数据库和缓存如何保证一致性？</h3><ul>
<li><p>在客户端请求数据时，如果能在缓存中命中数据，那就查询缓存，不用在去查询数据库，从而减轻数据库的压力，提高服务器的性能。<strong>由于引入了缓存，那么在数据更新时，不仅要更新数据库，而且要更新缓存，这两个更新操作存在前后的问题</strong>：</p>
<ul>
<li>先更新数据库，再更新缓存；<ul>
<li>A 请求先将数据库的数据更新为 1，然后在更新缓存前，请求 B 将数据库的数据更新为 2，紧接着也把缓存更新为 2，然后 A 请求更新缓存为 1。此时，数据库中的数据是 2，而缓存中的数据却是 1，<strong>出现了缓存和数据库中的数据不一致的现象</strong></li>
</ul>
</li>
<li>先更新缓存，再更新数据库；<ul>
<li>A 请求先将缓存的数据更新为 1，然后在更新数据库前，B 请求来了， 将缓存的数据更新为 2，紧接着把数据库更新为 2，然后 A 请求将数据库的数据更新为 1。此时，数据库中的数据是 1，而缓存中的数据却是 2，<strong>出现了缓存和数据库中的数据不一致的现象</strong></li>
</ul>
</li>
</ul>
<p><strong>无论是「先更新数据库，再更新缓存」，还是「先更新缓存，再更新数据库」，这两个方案都存在并发问题，当两个请求并发更新同一条数据的时候，可能会出现缓存和数据库中的数据不一致的现象</strong></p>
</li>
<li><p>在更新数据时，<strong>不更新缓存，而是删除缓存中的数据。然后，到读取数据时，发现缓存中没了数据之后，再从数据库中读取数据，更新到缓存中。</strong>即 <strong>Cache Aside 策略</strong>，中文是叫旁路缓存策略。该策略又可以细分为「读策略」和「写策略」。</p>
<ul>
<li><strong>写策略的步骤：</strong><ul>
<li>更新数据库中的数据；</li>
<li>删除缓存中的数据。</li>
</ul>
</li>
<li><strong>读策略的步骤：</strong><ul>
<li>如果读取的数据命中了缓存，则直接返回数据；</li>
<li>如果读取的数据没有命中缓存，则从数据库中读取数据，然后将数据写入到缓存，并且返回给用户。</li>
</ul>
</li>
</ul>
</li>
<li><p>写策略又可以选择两种顺序：</p>
<ul>
<li>先删除缓存，再更新数据库；<ul>
<li>假设某个用户的年龄是 20，请求 A 要更新用户年龄为 21，所以它会删除缓存中的内容。这时，另一个请求 B 要读取这个用户的年龄，它查询缓存发现未命中后，会从数据库中读取到年龄为 20，并且写入到缓存中，然后请求 A 继续更改数据库，将用户的年龄更新为 21。</li>
<li><strong>先删除缓存，再更新数据库，在「读 + 写」并发的时候，还是会出现缓存和数据库的数据不一致的问题</strong>，解决办法是「<strong>延迟双删</strong>」</li>
</ul>
</li>
<li>先更新数据库，再删除缓存。<ul>
<li>理论上分析，先更新数据库，再删除缓存也是会出现数据不一致性的问题，<strong>但是在实际中，这个问题出现的概率并不高</strong>。<strong>因为缓存的写入通常要远远快于数据库的写入</strong>，所以在实际中很难出现请求 B 已经更新了数据库并且删除了缓存，请求 A 才更新完缓存的情况。</li>
<li>而一旦请求 A 早于请求 B 删除缓存之前更新了缓存，那么接下来的请求就会因为缓存不命中而从数据库中重新读取数据，所以不会出现这种不一致的情况。</li>
</ul>
</li>
</ul>
</li>
<li><p>「先更新数据库， 再删除缓存」其实是两个操作，<strong>在删除缓存的时候失败了，导致缓存中的数据是旧值</strong>。如果没有过期时间的设定，那后续的请求读到的就会一直是缓存中的旧数据；有两种方法解决：</p>
<ul>
<li><strong>重试机制：</strong>引入<strong>消息队列</strong>，将第二个操作（删除缓存）要操作的数据加入到消息队列，由消费者来操作数据。<ul>
<li>如果应用<strong>删除缓存失败</strong>，可以从消息队列中重新读取数据，然后再次删除缓存，这个就是<strong>重试机制</strong>。当然，如果重试超过的一定次数，还是没有成功，我们就需要向业务层发送报错信息了。</li>
<li>如果<strong>删除缓存成功</strong>，就要把数据从消息队列中移除，避免重复操作，否则就继续重试。</li>
</ul>
</li>
<li><strong>订阅 MySQL binlog，再操作缓存：</strong>通过订阅 binlog 日志，拿到具体要操作的数据，然后再执行缓存删除，阿里巴巴开源的 Canal 中间件就是基于这个实现的。</li>
</ul>
</li>
<li><p>「先更新数据库，再删除缓存」的方案虽然保证了数据库与缓存的数据一致性，但是每次更新数据的时候，缓存的数据都会被删除，这样会对缓存的命中率带来影响。<strong>如果我们的业务对缓存命中率有很高的要求，我们可以采用「更新数据库 + 更新缓存」的方案，因为更新缓存并不会出现缓存未命中的情况、</strong></p>
<ul>
<li>在更新缓存前先加个<strong>分布式锁</strong>，保证同一时间只运行一个请求更新缓存，就会不会产生并发问题了，当然引入了锁后，对于写入的性能就会带来影响。</li>
<li>在更新完缓存时，给缓存加上较短的<strong>过期时间</strong>，这样即时出现缓存不一致的情况，缓存的数据也会很快过期，对业务还是能接受的。</li>
</ul>
</li>
</ul>
</article><div class="post-tools" id="post-tools"><div class="post-tools-left"><div class="rewardLeftButton"><div class="post-reward" onclick="anzhiyu.addRewardMask()"><div class="reward-button button--animated" title="赞赏作者"><i class="anzhiyufont anzhiyu-icon-hand-heart-fill"></i>打赏作者</div><div class="reward-main"><div class="reward-all"><span class="reward-title">感谢你赐予我前进的力量</span><ul class="reward-group"><li class="reward-item"><a href="https://acallcf.oss-cn-qingdao.aliyuncs.com/images/202307192211377.png" target="_blank"><img class="post-qr-code-img" src="https://acallcf.oss-cn-qingdao.aliyuncs.com/images/202307192211377.png" alt="wechat"/></a><div class="post-qr-code-desc">wechat</div></li><li class="reward-item"><a href="https://acallcf.oss-cn-qingdao.aliyuncs.com/images/202307192207910.png" target="_blank"><img class="post-qr-code-img" src="https://acallcf.oss-cn-qingdao.aliyuncs.com/images/202307192207910.png" alt="alipayautoh"/></a><div class="post-qr-code-desc">alipayautoh</div></li></ul><a class="reward-main-btn" href="/about/#about-reward" target="_blank"><div class="reward-text">赞赏者名单</div><div class="reward-dec">因为你们的支持让我意识到写文章的价值🙏</div></a></div></div></div><div id="quit-box" onclick="anzhiyu.removeRewardMask()" style="display: none"></div></div><div class="shareRight"><div class="share-link mobile"><div class="share-qrcode"><div class="share-button" title="使用手机访问这篇文章"><i class="anzhiyufont anzhiyu-icon-qrcode"></i></div><div class="share-main"><div class="share-main-all"><div id="qrcode" title="http://acall.love/2023/04/05/2.%E7%B3%BB%E5%88%97%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93/"></div><div class="reward-dec">使用手机访问这篇文章</div></div></div></div></div><div class="share-link weibo"><a class="share-button" target="_blank" href="https://service.weibo.com/share/share.php?title=undefined&amp;url=http://acall.love/2023/04/05/2.%E7%B3%BB%E5%88%97%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93/&amp;pic=undefined" rel="external nofollow noreferrer noopener"><i class="anzhiyufont anzhiyu-icon-weibo"></i></a></div><div class="share-link copyurl"><div class="share-button" id="post-share-url" title="复制链接" onclick="rm.copyPageUrl()"><i class="anzhiyufont anzhiyu-icon-link"></i></div></div></div></div><div class="post-tools-right"><div class="tag_share"><div class="post-meta__box"><div class="post-meta__box__tag-list"><a class="post-meta__box__tags" href="/tags/C/"><span class="tags-punctuation"> <i class="anzhiyufont anzhiyu-icon-tag"></i></span>C++<span class="tagsPageCount">23</span></a><a class="post-meta__box__tags" href="/tags/%E5%90%8E%E7%AB%AF%E5%BC%80%E5%8F%91/"><span class="tags-punctuation"> <i class="anzhiyufont anzhiyu-icon-tag"></i></span>后端开发<span class="tagsPageCount">22</span></a><a class="post-meta__box__tags" href="/tags/%E9%9D%A2%E8%AF%95/"><span class="tags-punctuation"> <i class="anzhiyufont anzhiyu-icon-tag"></i></span>面试<span class="tagsPageCount">3</span></a></div></div></div><div class="post_share"><div class="social-share" data-image="https://acallcf.oss-cn-qingdao.aliyuncs.com/images/d6g1gl.webp" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://npm.elemecdn.com/butterfly-extsrc@1.1.3/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"/><script src="https://npm.elemecdn.com/butterfly-extsrc@1.1.3/sharejs/dist/js/social-share.min.js" defer="defer"></script></div></div></div><div class="post-copyright"><i class="anzhiyufont anzhiyu-icon-copyright"></i><div class="post-copyright__author"><a class="post-copyright__original" title="该文章为原创文章，注意版权协议" href="http://acall.love/2023/04/05/2.%E7%B3%BB%E5%88%97%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93/">原创</a><a class="post-copyright-title"><span>2.系统知识点整理</span></a></div><div class="post-copyright-info-box"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"></span><a class="link" href="http://acall.love">🎵张小佑♪</a></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a class="link" href="http://acall.love/2023/04/05/2.%E7%B3%BB%E5%88%97%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93/">http://acall.love/2023/04/05/2.%E7%B3%BB%E5%88%97%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93/</a></span><span class="copy-button" onclick="rm.copyPageUrl('http://acall.love/2023/04/05/2.%E7%B3%BB%E5%88%97%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93/')"><i class="anzhiyufont anzhiyu-icon-copy"></i></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="http://acall.love" target="_blank">♪张小佑</a>！</span></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/2023/04/01/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%B9%8B%E7%BE%8E%20%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/"><img class="prev-cover" src="https://acallcf.oss-cn-qingdao.aliyuncs.com/images/jx5yq5.webp" onerror="onerror=null;src='/img/404.jpg'" alt="cover of previous post"><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">设计模式之美 读书心得</div></div></a></div><div class="next-post pull-right"><a href="/2023/05/01/%E7%A7%8B%E6%8B%9B%E9%9D%A2%E8%AF%95%E8%AE%B0%E5%BD%95/"><img class="next-cover" src="https://acallcf.oss-cn-qingdao.aliyuncs.com/images/kxw3p1.webp" onerror="onerror=null;src='/img/404.jpg'" alt="cover of next post"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">秋招面试记录</div></div></a></div></nav><div class="relatedPosts"><div class="headline"><i class="anzhiyufont anzhiyu-icon-thumbs-up fa-fw" style="font-size: 1.5rem; margin-right: 4px"></i><span>相关推荐</span></div><div class="relatedPosts-list"><div><a href="/2023/05/01/1.%E4%B8%AA%E4%BA%BA%E9%97%AE%E9%A2%98%E6%95%B4%E7%90%86/" title="1.个人问题"><img class="cover" src="https://acallcf.oss-cn-qingdao.aliyuncs.com/images/p9918p.webp" alt="cover"><div class="content is-center"><div class="date"><i class="anzhiyufont anzhiyu-icon-calendar-days fa-fw"></i> 2023-05-01</div><div class="title">1.个人问题</div></div></a></div><div><a href="/2023/03/01/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E9%9D%A2%E7%BB%8F%E6%95%B4%E7%90%86/" title="学习笔记面试合集"><img class="cover" src="https://acallcf.oss-cn-qingdao.aliyuncs.com/images/iTab-vqm813.webp" alt="cover"><div class="content is-center"><div class="date"><i class="anzhiyufont anzhiyu-icon-calendar-days fa-fw"></i> 2023-03-01</div><div class="title">学习笔记面试合集</div></div></a></div><div><a href="/2023/06/05/2.C++%20%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/" title="2.C++读书笔记"><img class="cover" src="https://acallcf.oss-cn-qingdao.aliyuncs.com/images/gp5k23.webp" alt="cover"><div class="content is-center"><div class="date"><i class="anzhiyufont anzhiyu-icon-calendar-days fa-fw"></i> 2023-06-05</div><div class="title">2.C++读书笔记</div></div></a></div><div><a href="/2023/06/01/1.C++%E5%B2%97%E4%BD%8D%E9%9D%A2%E8%AF%95%E7%9C%9F%E9%A2%98%E5%AE%9D%E5%85%B8/" title="1.C++岗位面试真题宝典"><img class="cover" src="https://acallcf.oss-cn-qingdao.aliyuncs.com/images/iTab-p92mj3%20(2).webp" alt="cover"><div class="content is-center"><div class="date"><i class="anzhiyufont anzhiyu-icon-calendar-days fa-fw"></i> 2023-06-01</div><div class="title">1.C++岗位面试真题宝典</div></div></a></div><div><a href="/2023/05/05/2.%E6%9E%81%E5%AE%A2%E4%B8%93%E6%A0%8F%E7%AC%94%E8%AE%B0/" title="2.极客笔记"><img class="cover" src="https://acallcf.oss-cn-qingdao.aliyuncs.com/images/o5g6r7.webp" alt="cover"><div class="content is-center"><div class="date"><i class="anzhiyufont anzhiyu-icon-calendar-days fa-fw"></i> 2023-05-05</div><div class="title">2.极客笔记</div></div></a></div><div><a href="/2023/06/10/3.C++%20%E9%9D%A2%E8%AF%95%E7%AA%81%E7%A0%B4/" title="3.面试突破"><img class="cover" src="https://acallcf.oss-cn-qingdao.aliyuncs.com/images/d6g1gl.webp" alt="cover"><div class="content is-center"><div class="date"><i class="anzhiyufont anzhiyu-icon-calendar-days fa-fw"></i> 2023-06-10</div><div class="title">3.面试突破</div></div></a></div></div></div></div><div class="aside-content" id="aside-content"><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="anzhiyufont anzhiyu-icon-bars"></i><span>文章目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#%E7%B3%BB%E5%88%97%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93"><span class="toc-number">1.</span> <span class="toc-text">系列知识点总结</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F"><span class="toc-number">1.1.</span> <span class="toc-text">操作系统</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#2-1-CPU-%E6%98%AF%E5%A6%82%E4%BD%95%E6%89%A7%E8%A1%8C%E7%A8%8B%E5%BA%8F%E7%9A%84%EF%BC%9F"><span class="toc-number">1.1.1.</span> <span class="toc-text">2.1 CPU 是如何执行程序的？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-3-%E5%A6%82%E4%BD%95%E5%86%99%E5%87%BA%E8%AE%A9-CPU-%E8%B7%91%E5%BE%97%E6%9B%B4%E5%BF%AB%E7%9A%84%E4%BB%A3%E7%A0%81%EF%BC%9F"><span class="toc-number">1.1.2.</span> <span class="toc-text">2.3 如何写出让 CPU 跑得更快的代码？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-4-CPU-%E7%BC%93%E5%AD%98%E4%B8%80%E8%87%B4%E6%80%A7"><span class="toc-number">1.1.3.</span> <span class="toc-text">2.4 CPU 缓存一致性</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-5-CPU-%E6%98%AF%E5%A6%82%E4%BD%95%E6%89%A7%E8%A1%8C%E4%BB%BB%E5%8A%A1%E7%9A%84%EF%BC%9F"><span class="toc-number">1.1.4.</span> <span class="toc-text">2.5 CPU 是如何执行任务的？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-6-%E4%BB%80%E4%B9%88%E6%98%AF%E8%BD%AF%E4%B8%AD%E6%96%AD%EF%BC%9F"><span class="toc-number">1.1.5.</span> <span class="toc-text">2.6 什么是软中断？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-7-%E4%B8%BA%E4%BB%80%E4%B9%88-0-1-0-2-%E4%B8%8D%E7%AD%89%E4%BA%8E-0-3-%EF%BC%9F"><span class="toc-number">1.1.6.</span> <span class="toc-text">2.7 为什么 0.1 + 0.2 不等于 0.3 ？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-1-Linux-%E5%86%85%E6%A0%B8-vs-Windows-%E5%86%85%E6%A0%B8"><span class="toc-number">1.1.7.</span> <span class="toc-text">3.1 Linux 内核 vs Windows 内核</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-1-%E4%B8%BA%E4%BB%80%E4%B9%88%E8%A6%81%E6%9C%89%E8%99%9A%E6%8B%9F%E5%86%85%E5%AD%98%EF%BC%9F"><span class="toc-number">1.1.8.</span> <span class="toc-text">4.1 为什么要有虚拟内存？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-2-malloc-%E6%98%AF%E5%A6%82%E4%BD%95%E5%88%86%E9%85%8D%E5%86%85%E5%AD%98%E7%9A%84%EF%BC%9F"><span class="toc-number">1.1.9.</span> <span class="toc-text">4.2 malloc 是如何分配内存的？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-3-%E5%86%85%E5%AD%98%E6%BB%A1%E4%BA%86%EF%BC%8C%E4%BC%9A%E5%8F%91%E7%94%9F%E4%BB%80%E4%B9%88%EF%BC%9F"><span class="toc-number">1.1.10.</span> <span class="toc-text">4.3 内存满了，会发生什么？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-4-%E5%9C%A8-4GB-%E7%89%A9%E7%90%86%E5%86%85%E5%AD%98%E7%9A%84%E6%9C%BA%E5%99%A8%E4%B8%8A%EF%BC%8C%E7%94%B3%E8%AF%B7-8G-%E5%86%85%E5%AD%98%E4%BC%9A%E6%80%8E%E4%B9%88%E6%A0%B7%EF%BC%9F"><span class="toc-number">1.1.11.</span> <span class="toc-text">4.4 在 4GB 物理内存的机器上，申请 8G 内存会怎么样？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-5-%E5%A6%82%E4%BD%95%E9%81%BF%E5%85%8D%E9%A2%84%E8%AF%BB%E5%A4%B1%E6%95%88%E5%92%8C%E7%BC%93%E5%AD%98%E6%B1%A1%E6%9F%93%E7%9A%84%E9%97%AE%E9%A2%98%EF%BC%9F"><span class="toc-number">1.1.12.</span> <span class="toc-text">4.5 如何避免预读失效和缓存污染的问题？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#5-1-%E8%BF%9B%E7%A8%8B%E3%80%81%E7%BA%BF%E7%A8%8B%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86"><span class="toc-number">1.1.13.</span> <span class="toc-text">5.1 进程、线程基础知识</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E8%BF%9B%E7%A8%8B"><span class="toc-number">1.1.13.1.</span> <span class="toc-text">进程</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E7%BA%BF%E7%A8%8B"><span class="toc-number">1.1.13.2.</span> <span class="toc-text">线程</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E8%B0%83%E5%BA%A6"><span class="toc-number">1.1.13.3.</span> <span class="toc-text">调度</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#5-2-%E8%BF%9B%E7%A8%8B%E9%97%B4%E6%9C%89%E5%93%AA%E4%BA%9B%E9%80%9A%E4%BF%A1%E6%96%B9%E5%BC%8F%EF%BC%9F"><span class="toc-number">1.1.14.</span> <span class="toc-text">5.2 进程间有哪些通信方式？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#5-3-%E5%A4%9A%E7%BA%BF%E7%A8%8B%E5%86%B2%E7%AA%81%E4%BA%86%E6%80%8E%E4%B9%88%E5%8A%9E%EF%BC%9F"><span class="toc-number">1.1.15.</span> <span class="toc-text">5.3 多线程冲突了怎么办？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#5-4-%E6%80%8E%E4%B9%88%E9%81%BF%E5%85%8D%E6%AD%BB%E9%94%81%EF%BC%9F"><span class="toc-number">1.1.16.</span> <span class="toc-text">5.4 怎么避免死锁？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#5-5-%E4%BB%80%E4%B9%88%E6%98%AF%E6%82%B2%E8%A7%82%E9%94%81%E3%80%81%E4%B9%90%E8%A7%82%E9%94%81%EF%BC%9F"><span class="toc-number">1.1.17.</span> <span class="toc-text">5.5 什么是悲观锁、乐观锁？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#5-6-%E4%B8%80%E4%B8%AA%E8%BF%9B%E7%A8%8B%E6%9C%80%E5%A4%9A%E5%8F%AF%E4%BB%A5%E5%88%9B%E5%BB%BA%E5%A4%9A%E5%B0%91%E4%B8%AA%E7%BA%BF%E7%A8%8B%EF%BC%9F"><span class="toc-number">1.1.18.</span> <span class="toc-text">5.6 一个进程最多可以创建多少个线程？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#5-7-%E7%BA%BF%E7%A8%8B%E5%B4%A9%E6%BA%83%E4%BA%86%EF%BC%8C%E8%BF%9B%E7%A8%8B%E4%B9%9F%E4%BC%9A%E5%B4%A9%E6%BA%83%E5%90%97%EF%BC%9F"><span class="toc-number">1.1.19.</span> <span class="toc-text">5.7 线程崩溃了，进程也会崩溃吗？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#6-1-%E8%BF%9B%E7%A8%8B%E8%B0%83%E5%BA%A6-x2F-%E9%A1%B5%E9%9D%A2%E7%BD%AE%E6%8D%A2-x2F-%E7%A3%81%E7%9B%98%E8%B0%83%E5%BA%A6%E7%AE%97%E6%B3%95"><span class="toc-number">1.1.20.</span> <span class="toc-text">6.1 进程调度&#x2F;页面置换&#x2F;磁盘调度算法</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E8%BF%9B%E7%A8%8B%E8%B0%83%E5%BA%A6%E7%AE%97%E6%B3%95"><span class="toc-number">1.1.20.1.</span> <span class="toc-text">进程调度算法</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%86%85%E5%AD%98%E9%A1%B5%E9%9D%A2%E7%BD%AE%E6%8D%A2%E7%AE%97%E6%B3%95"><span class="toc-number">1.1.20.2.</span> <span class="toc-text">内存页面置换算法</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E7%A3%81%E7%9B%98%E8%B0%83%E5%BA%A6%E7%AE%97%E6%B3%95"><span class="toc-number">1.1.20.3.</span> <span class="toc-text">磁盘调度算法</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#7-1-%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E5%85%A8%E5%AE%B6%E6%A1%B6"><span class="toc-number">1.1.21.</span> <span class="toc-text">7.1 文件系统全家桶</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#7-2-%E8%BF%9B%E7%A8%8B%E5%86%99%E6%96%87%E4%BB%B6%E6%97%B6%EF%BC%8C%E8%BF%9B%E7%A8%8B%E5%8F%91%E7%94%9F%E4%BA%86%E5%B4%A9%E6%BA%83%EF%BC%8C%E5%B7%B2%E5%86%99%E5%85%A5%E7%9A%84%E6%95%B0%E6%8D%AE%E4%BC%9A%E4%B8%A2%E5%A4%B1%E5%90%97%EF%BC%9F"><span class="toc-number">1.1.22.</span> <span class="toc-text">7.2 进程写文件时，进程发生了崩溃，已写入的数据会丢失吗？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#8-1-%E9%94%AE%E7%9B%98%E6%95%B2%E5%85%A5-A-%E5%AD%97%E6%AF%8D%E6%97%B6%EF%BC%8C%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E6%9C%9F%E9%97%B4%E5%8F%91%E7%94%9F%E4%BA%86%E4%BB%80%E4%B9%88%EF%BC%9F"><span class="toc-number">1.1.23.</span> <span class="toc-text">8.1 键盘敲入 A 字母时，操作系统期间发生了什么？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#9-1-%E4%BB%80%E4%B9%88%E6%98%AF%E9%9B%B6%E6%8B%B7%E8%B4%9D"><span class="toc-number">1.1.24.</span> <span class="toc-text">9.1 什么是零拷贝</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#9-2-I-x2F-O-%E5%A4%9A%E8%B7%AF%E5%A4%8D%E7%94%A8%EF%BC%9Aselect-x2F-poll-x2F-epoll"><span class="toc-number">1.1.25.</span> <span class="toc-text">9.2 I&#x2F;O 多路复用：select&#x2F;poll&#x2F;epoll</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#9-3-%E9%AB%98%E6%80%A7%E8%83%BD%E7%BD%91%E7%BB%9C%E6%A8%A1%E5%BC%8F%EF%BC%9AReactor-%E5%92%8C-Proactor"><span class="toc-number">1.1.26.</span> <span class="toc-text">9.3 高性能网络模式：Reactor 和 Proactor</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#9-4-%E4%BB%80%E4%B9%88%E6%98%AF%E4%B8%80%E8%87%B4%E6%80%A7%E5%93%88%E5%B8%8C%EF%BC%9F"><span class="toc-number">1.1.27.</span> <span class="toc-text">9.4 什么是一致性哈希？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#10-1-%E5%A6%82%E4%BD%95%E6%9F%A5%E7%9C%8B%E7%BD%91%E7%BB%9C%E7%9A%84%E6%80%A7%E8%83%BD%E6%8C%87%E6%A0%87%EF%BC%9F"><span class="toc-number">1.1.28.</span> <span class="toc-text">10.1 如何查看网络的性能指标？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#10-2-%E5%A6%82%E4%BD%95%E4%BB%8E%E6%97%A5%E5%BF%97%E5%88%86%E6%9E%90-PV%E3%80%81UV%EF%BC%9F"><span class="toc-number">1.1.29.</span> <span class="toc-text">10.2 如何从日志分析 PV、UV？</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C"><span class="toc-number">1.2.</span> <span class="toc-text">计算机网络</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#2-2-%E9%94%AE%E5%85%A5%E7%BD%91%E5%9D%80%E5%88%B0%E7%BD%91%E9%A1%B5%E6%98%BE%E7%A4%BA%EF%BC%8C%E6%9C%9F%E9%97%B4%E5%8F%91%E7%94%9F%E4%BA%86%E4%BB%80%E4%B9%88%EF%BC%9F"><span class="toc-number">1.2.1.</span> <span class="toc-text">2.2 键入网址到网页显示，期间发生了什么？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-3-Linux-%E7%B3%BB%E7%BB%9F%E6%98%AF%E5%A6%82%E4%BD%95%E6%94%B6%E5%8F%91%E7%BD%91%E7%BB%9C%E5%8C%85%E7%9A%84%EF%BC%9F"><span class="toc-number">1.2.2.</span> <span class="toc-text">2.3 Linux 系统是如何收发网络包的？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-1-HTTP-%E5%B8%B8%E8%A7%81%E9%9D%A2%E8%AF%95%E9%A2%98"><span class="toc-number">1.2.3.</span> <span class="toc-text">3.1 HTTP 常见面试题</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#1-HTTP-%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5"><span class="toc-number">1.2.3.1.</span> <span class="toc-text">1.HTTP 基本概念</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2-GET-%E4%B8%8E-POST"><span class="toc-number">1.2.3.2.</span> <span class="toc-text">2. GET 与 POST</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#3-HTTP-%E7%BC%93%E5%AD%98%E6%8A%80%E6%9C%AF"><span class="toc-number">1.2.3.3.</span> <span class="toc-text">3.HTTP 缓存技术</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#4-HTTP-%E7%89%B9%E6%80%A7"><span class="toc-number">1.2.3.4.</span> <span class="toc-text">4.HTTP 特性</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#5-HTTP-%E4%B8%8E-HTTPS"><span class="toc-number">1.2.3.5.</span> <span class="toc-text">5. HTTP 与 HTTPS</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#6-HTTP-x2F-1-1%E3%80%81HTTP-x2F-2%E3%80%81HTTP-x2F-3-%E6%BC%94%E5%8F%98"><span class="toc-number">1.2.3.6.</span> <span class="toc-text">6. HTTP&#x2F;1.1、HTTP&#x2F;2、HTTP&#x2F;3 演变</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-2-HTTP-x2F-1-1%E5%A6%82%E4%BD%95%E4%BC%98%E5%8C%96%EF%BC%9F"><span class="toc-number">1.2.4.</span> <span class="toc-text">3.2 HTTP&#x2F;1.1如何优化？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-3-HTTPS-RSA-%E6%8F%A1%E6%89%8B%E8%A7%A3%E6%9E%90"><span class="toc-number">1.2.5.</span> <span class="toc-text">3.3 HTTPS RSA 握手解析</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-4-HTTPS-ECDHE-%E6%8F%A1%E6%89%8B%E8%A7%A3%E6%9E%90"><span class="toc-number">1.2.6.</span> <span class="toc-text">3.4 HTTPS ECDHE 握手解析</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-5-HTTPS-%E5%A6%82%E4%BD%95%E4%BC%98%E5%8C%96%EF%BC%9F"><span class="toc-number">1.2.7.</span> <span class="toc-text">3.5 HTTPS 如何优化？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-6-HTTP-x2F-2-%E7%89%9B%E9%80%BC%E5%9C%A8%E5%93%AA%EF%BC%9F"><span class="toc-number">1.2.8.</span> <span class="toc-text">3.6 HTTP&#x2F;2 牛逼在哪？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-7-HTTP-x2F-3-%E5%BC%BA%E5%8A%BF%E6%9D%A5%E8%A2%AD"><span class="toc-number">1.2.9.</span> <span class="toc-text">3.7 HTTP&#x2F;3 强势来袭</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-1-TCP-%E4%B8%89%E6%AC%A1%E6%8F%A1%E6%89%8B%E4%B8%8E%E5%9B%9B%E6%AC%A1%E6%8C%A5%E6%89%8B%E9%9D%A2%E8%AF%95%E9%A2%98"><span class="toc-number">1.2.10.</span> <span class="toc-text">4.1 TCP 三次握手与四次挥手面试题</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#1-TCP-%E5%9F%BA%E6%9C%AC%E8%AE%A4%E8%AF%86"><span class="toc-number">1.2.10.1.</span> <span class="toc-text">1. TCP 基本认识</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2-TCP-%E8%BF%9E%E6%8E%A5%E5%BB%BA%E7%AB%8B"><span class="toc-number">1.2.10.2.</span> <span class="toc-text">2. TCP 连接建立</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#3-TCP-%E8%BF%9E%E6%8E%A5%E6%96%AD%E5%BC%80"><span class="toc-number">1.2.10.3.</span> <span class="toc-text">3. TCP 连接断开</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#4-Socket-%E7%BC%96%E7%A8%8B"><span class="toc-number">1.2.10.4.</span> <span class="toc-text">4. Socket 编程</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-17-TCP-%E5%8D%8F%E8%AE%AE%E6%9C%89%E4%BB%80%E4%B9%88%E7%BC%BA%E9%99%B7%EF%BC%9F"><span class="toc-number">1.2.11.</span> <span class="toc-text">4.17 TCP 协议有什么缺陷？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-18-%E5%A6%82%E4%BD%95%E5%9F%BA%E4%BA%8E-UDP-%E5%8D%8F%E8%AE%AE%E5%AE%9E%E7%8E%B0%E5%8F%AF%E9%9D%A0%E4%BC%A0%E8%BE%93%EF%BC%9F"><span class="toc-number">1.2.12.</span> <span class="toc-text">4.18 如何基于 UDP 协议实现可靠传输？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-19-TCP-%E5%92%8C-UDP-%E5%8F%AF%E4%BB%A5%E4%BD%BF%E7%94%A8%E5%90%8C%E4%B8%80%E4%B8%AA%E7%AB%AF%E5%8F%A3%E5%90%97%EF%BC%9F"><span class="toc-number">1.2.13.</span> <span class="toc-text">4.19 TCP 和 UDP 可以使用同一个端口吗？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-20-%E6%9C%8D%E5%8A%A1%E7%AB%AF%E6%B2%A1%E6%9C%89-listen%EF%BC%8C%E5%AE%A2%E6%88%B7%E7%AB%AF%E5%8F%91%E8%B5%B7%E8%BF%9E%E6%8E%A5%E5%BB%BA%E7%AB%8B%EF%BC%8C%E4%BC%9A%E5%8F%91%E7%94%9F%E4%BB%80%E4%B9%88%EF%BC%9F"><span class="toc-number">1.2.14.</span> <span class="toc-text">4.20 服务端没有 listen，客户端发起连接建立，会发生什么？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-21-%E6%B2%A1%E6%9C%89-accept%EF%BC%8C%E8%83%BD%E5%BB%BA%E7%AB%8B-TCP-%E8%BF%9E%E6%8E%A5%E5%90%97%EF%BC%9F"><span class="toc-number">1.2.15.</span> <span class="toc-text">4.21 没有 accept，能建立 TCP 连接吗？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-22-%E7%94%A8%E4%BA%86-TCP-%E5%8D%8F%E8%AE%AE%EF%BC%8C%E6%95%B0%E6%8D%AE%E4%B8%80%E5%AE%9A%E4%B8%8D%E4%BC%9A%E4%B8%A2%E5%90%97%EF%BC%9F"><span class="toc-number">1.2.16.</span> <span class="toc-text">4.22 用了 TCP 协议，数据一定不会丢吗？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-23-TCP-%E5%9B%9B%E6%AC%A1%E6%8C%A5%E6%89%8B%EF%BC%8C%E5%8F%AF%E4%BB%A5%E5%8F%98%E6%88%90%E4%B8%89%E6%AC%A1%E5%90%97%EF%BC%9F"><span class="toc-number">1.2.17.</span> <span class="toc-text">4.23 TCP 四次挥手，可以变成三次吗？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-23-TCP-%E5%BA%8F%E5%88%97%E5%8F%B7%E5%92%8C%E7%A1%AE%E8%AE%A4%E5%8F%B7%E6%98%AF%E5%A6%82%E4%BD%95%E5%8F%98%E5%8C%96%E7%9A%84%EF%BC%9F"><span class="toc-number">1.2.18.</span> <span class="toc-text">4.23 TCP 序列号和确认号是如何变化的？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#5-1-IP-%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%E5%85%A8%E5%AE%B6%E6%A1%B6"><span class="toc-number">1.2.19.</span> <span class="toc-text">5.1 IP 基础知识全家桶</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#IP-%E5%9F%BA%E6%9C%AC%E8%AE%A4%E8%AF%86"><span class="toc-number">1.2.19.1.</span> <span class="toc-text">IP 基本认识</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#IP-%E5%9C%B0%E5%9D%80%E7%9A%84%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86"><span class="toc-number">1.2.19.2.</span> <span class="toc-text">IP 地址的基础知识</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#IPv6-%E5%9F%BA%E6%9C%AC%E8%AE%A4%E8%AF%86"><span class="toc-number">1.2.19.3.</span> <span class="toc-text">IPv6 基本认识</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#IP-%E5%8D%8F%E8%AE%AE%E7%9B%B8%E5%85%B3%E6%8A%80%E6%9C%AF"><span class="toc-number">1.2.19.4.</span> <span class="toc-text">IP 协议相关技术</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#5-2-ping-%E7%9A%84%E5%B7%A5%E4%BD%9C%E5%8E%9F%E7%90%86"><span class="toc-number">1.2.20.</span> <span class="toc-text">5.2 ping 的工作原理</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#MySQL"><span class="toc-number">1.3.</span> <span class="toc-text">MySQL</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%85%AC%E4%BC%97%E5%8F%B7%E6%96%87%E7%AB%A0"><span class="toc-number">1.3.1.</span> <span class="toc-text">公众号文章</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#MySQL-%E8%AE%B0%E5%BD%95%E9%94%81-%E9%97%B4%E9%9A%99%E9%94%81%E5%8F%AF%E4%BB%A5%E9%98%B2%E6%AD%A2%E5%88%A0%E9%99%A4%E6%93%8D%E4%BD%9C%E8%80%8C%E5%AF%BC%E8%87%B4%E7%9A%84%E5%B9%BB%E8%AF%BB%E5%90%97%EF%BC%9F"><span class="toc-number">1.3.2.</span> <span class="toc-text">MySQL 记录锁+间隙锁可以防止删除操作而导致的幻读吗？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-1-%E6%89%A7%E8%A1%8C%E4%B8%80%E6%9D%A1-select-%E8%AF%AD%E5%8F%A5%EF%BC%8C%E6%9C%9F%E9%97%B4%E5%8F%91%E7%94%9F%E4%BA%86%E4%BB%80%E4%B9%88%EF%BC%9F"><span class="toc-number">1.3.3.</span> <span class="toc-text">2.1 执行一条 select 语句，期间发生了什么？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-1-%E7%B4%A2%E5%BC%95%E5%B8%B8%E8%A7%81%E9%9D%A2%E8%AF%95%E9%A2%98"><span class="toc-number">1.3.4.</span> <span class="toc-text">3.1 索引常见面试题</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%BB%80%E4%B9%88%E6%98%AF%E7%B4%A2%E5%BC%95%EF%BC%9F"><span class="toc-number">1.3.4.1.</span> <span class="toc-text">什么是索引？</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E7%B4%A2%E5%BC%95%E7%9A%84%E5%88%86%E7%B1%BB"><span class="toc-number">1.3.4.2.</span> <span class="toc-text">索引的分类</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%BB%80%E4%B9%88%E6%97%B6%E5%80%99%E9%9C%80%E8%A6%81-x2F-%E4%B8%8D%E9%9C%80%E8%A6%81%E5%88%9B%E5%BB%BA%E7%B4%A2%E5%BC%95%EF%BC%9F"><span class="toc-number">1.3.4.3.</span> <span class="toc-text">什么时候需要 &#x2F; 不需要创建索引？</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%9C%89%E4%BB%80%E4%B9%88%E4%BC%98%E5%8C%96%E7%B4%A2%E5%BC%95%E7%9A%84%E6%96%B9%E6%B3%95%EF%BC%9F"><span class="toc-number">1.3.4.4.</span> <span class="toc-text">有什么优化索引的方法？</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-2-%E4%BB%8E%E6%95%B0%E6%8D%AE%E9%A1%B5%E7%9A%84%E8%A7%92%E5%BA%A6%E7%9C%8B-B-%E6%A0%91"><span class="toc-number">1.3.5.</span> <span class="toc-text">3.2 从数据页的角度看 B+ 树</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-3-%E4%B8%BA%E4%BB%80%E4%B9%88-MySQL-%E9%87%87%E7%94%A8-B-%E6%A0%91%E4%BD%9C%E4%B8%BA%E7%B4%A2%E5%BC%95%EF%BC%9F"><span class="toc-number">1.3.6.</span> <span class="toc-text">3.3 为什么 MySQL 采用 B+ 树作为索引？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-4-MySQL-%E5%8D%95%E8%A1%A8%E4%B8%8D%E8%A6%81%E8%B6%85%E8%BF%87-2000W-%E8%A1%8C%EF%BC%8C%E9%9D%A0%E8%B0%B1%E5%90%97%EF%BC%9F"><span class="toc-number">1.3.7.</span> <span class="toc-text">3.4 MySQL 单表不要超过 2000W 行，靠谱吗？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-5-%E7%B4%A2%E5%BC%95%E5%A4%B1%E6%95%88%E6%9C%89%E5%93%AA%E4%BA%9B%EF%BC%9F"><span class="toc-number">1.3.8.</span> <span class="toc-text">3.5 索引失效有哪些？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-6-MySQL-%E4%BD%BF%E7%94%A8-like-%E2%80%9C-x%E2%80%9C%EF%BC%8C%E7%B4%A2%E5%BC%95%E4%B8%80%E5%AE%9A%E4%BC%9A%E5%A4%B1%E6%95%88%E5%90%97"><span class="toc-number">1.3.9.</span> <span class="toc-text">3.6 MySQL 使用 like “%x“，索引一定会失效吗</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-7-count-%E5%92%8C-count-1-%E6%9C%89%E4%BB%80%E4%B9%88%E5%8C%BA%E5%88%AB%EF%BC%9F%E5%93%AA%E4%B8%AA%E6%80%A7%E8%83%BD%E6%9C%80%E5%A5%BD%EF%BC%9F"><span class="toc-number">1.3.10.</span> <span class="toc-text">3.7 count(*) 和 count(1) 有什么区别？哪个性能最好？</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E8%A1%A8%E7%BA%A7%E9%94%81"><span class="toc-number">1.3.10.1.</span> <span class="toc-text">表级锁</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E8%A1%8C%E7%BA%A7%E9%94%81"><span class="toc-number">1.3.10.2.</span> <span class="toc-text">行级锁</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#5-2-MySQL-%E6%98%AF%E6%80%8E%E4%B9%88%E5%8A%A0%E9%94%81%E7%9A%84%EF%BC%9F"><span class="toc-number">1.3.11.</span> <span class="toc-text">5.2 MySQL 是怎么加锁的？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#5-3-update-%E6%B2%A1%E5%8A%A0%E7%B4%A2%E5%BC%95%E4%BC%9A%E9%94%81%E5%85%A8%E8%A1%A8%EF%BC%9F"><span class="toc-number">1.3.12.</span> <span class="toc-text">5.3 update 没加索引会锁全表？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#5-4-MySQL-%E8%AE%B0%E5%BD%95%E9%94%81-%E9%97%B4%E9%9A%99%E9%94%81%E5%8F%AF%E4%BB%A5%E9%98%B2%E6%AD%A2%E5%88%A0%E9%99%A4%E6%93%8D%E4%BD%9C%E8%80%8C%E5%AF%BC%E8%87%B4%E7%9A%84%E5%B9%BB%E8%AF%BB%E5%90%97%EF%BC%9F"><span class="toc-number">1.3.13.</span> <span class="toc-text">5.4 MySQL 记录锁+间隙锁可以防止删除操作而导致的幻读吗？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#5-5-MySQL-%E6%AD%BB%E9%94%81%E4%BA%86%EF%BC%8C%E6%80%8E%E4%B9%88%E5%8A%9E%EF%BC%9F"><span class="toc-number">1.3.14.</span> <span class="toc-text">5.5 MySQL 死锁了，怎么办？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#5-6-%E5%AD%97%E8%8A%82%E9%9D%A2%E8%AF%95%EF%BC%9A%E5%8A%A0%E4%BA%86%E4%BB%80%E4%B9%88%E9%94%81%EF%BC%8C%E5%AF%BC%E8%87%B4%E6%AD%BB%E9%94%81%E7%9A%84%EF%BC%9F"><span class="toc-number">1.3.15.</span> <span class="toc-text">5.6 字节面试：加了什么锁，导致死锁的？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#6-1-MySQL-%E6%97%A5%E5%BF%97%EF%BC%9Aundo-log%E3%80%81redo-log%E3%80%81binlog-%E6%9C%89%E4%BB%80%E4%B9%88%E7%94%A8%EF%BC%9F"><span class="toc-number">1.3.16.</span> <span class="toc-text">6.1 MySQL 日志：undo log、redo log、binlog 有什么用？</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%B8%BA%E4%BB%80%E4%B9%88%E9%9C%80%E8%A6%81-undo-log"><span class="toc-number">1.3.16.1.</span> <span class="toc-text">为什么需要 undo log</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%B8%BA%E4%BB%80%E4%B9%88%E9%9C%80%E8%A6%81-Buffer-Pool"><span class="toc-number">1.3.16.2.</span> <span class="toc-text">为什么需要 Buffer Pool</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%B8%BA%E4%BB%80%E4%B9%88%E9%9C%80%E8%A6%81-redo-log"><span class="toc-number">1.3.16.3.</span> <span class="toc-text">为什么需要 redo log</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%B8%BA%E4%BB%80%E4%B9%88%E9%9C%80%E8%A6%81-binlog-%EF%BC%9F"><span class="toc-number">1.3.16.4.</span> <span class="toc-text">为什么需要 binlog ？</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%B8%BA%E4%BB%80%E4%B9%88%E9%9C%80%E8%A6%81%E4%B8%A4%E9%98%B6%E6%AE%B5%E6%8F%90%E4%BA%A4%EF%BC%9F"><span class="toc-number">1.3.16.5.</span> <span class="toc-text">为什么需要两阶段提交？</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#7-1-%E6%8F%AD%E5%BC%80-Buffer-Pool-%E7%9A%84%E9%9D%A2%E7%BA%B1"><span class="toc-number">1.3.17.</span> <span class="toc-text">7.1 揭开 Buffer Pool 的面纱</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Redis"><span class="toc-number">1.4.</span> <span class="toc-text">Redis</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#2-1-Redis-%E5%B8%B8%E8%A7%81%E9%9D%A2%E8%AF%95%E9%A2%98"><span class="toc-number">1.4.1.</span> <span class="toc-text">2.1 Redis 常见面试题</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E8%AE%A4%E8%AF%86Redis"><span class="toc-number">1.4.1.1.</span> <span class="toc-text">认识Redis</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Redis-%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84"><span class="toc-number">1.4.1.2.</span> <span class="toc-text">Redis 数据结构</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Redis-%E7%BA%BF%E7%A8%8B%E6%A8%A1%E5%9E%8B"><span class="toc-number">1.4.1.3.</span> <span class="toc-text">Redis 线程模型</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Redis-%E6%8C%81%E4%B9%85%E5%8C%96"><span class="toc-number">1.4.1.4.</span> <span class="toc-text">Redis 持久化</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Redis-%E9%9B%86%E7%BE%A4"><span class="toc-number">1.4.1.5.</span> <span class="toc-text">Redis 集群</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Redis-%E8%BF%87%E6%9C%9F%E5%88%A0%E9%99%A4%E4%B8%8E%E5%86%85%E5%AD%98%E6%B7%98%E6%B1%B0"><span class="toc-number">1.4.1.6.</span> <span class="toc-text">Redis 过期删除与内存淘汰</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Redis-%E7%BC%93%E5%AD%98%E8%AE%BE%E8%AE%A1"><span class="toc-number">1.4.1.7.</span> <span class="toc-text">Redis 缓存设计</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Redis-%E5%AE%9E%E6%88%98"><span class="toc-number">1.4.1.8.</span> <span class="toc-text">Redis 实战</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-1-Redis-%E5%B8%B8%E8%A7%81%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B%E5%92%8C%E5%BA%94%E7%94%A8%E5%9C%BA%E6%99%AF"><span class="toc-number">1.4.2.</span> <span class="toc-text">3.1 Redis 常见数据类型和应用场景</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#String"><span class="toc-number">1.4.2.1.</span> <span class="toc-text">String</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#List"><span class="toc-number">1.4.2.2.</span> <span class="toc-text">List</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Hash"><span class="toc-number">1.4.2.3.</span> <span class="toc-text">Hash</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Set"><span class="toc-number">1.4.2.4.</span> <span class="toc-text">Set</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Zset"><span class="toc-number">1.4.2.5.</span> <span class="toc-text">Zset</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#BitMap"><span class="toc-number">1.4.2.6.</span> <span class="toc-text">BitMap</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#HyperLogLog"><span class="toc-number">1.4.2.7.</span> <span class="toc-text">HyperLogLog</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#GEO"><span class="toc-number">1.4.2.8.</span> <span class="toc-text">GEO</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Stream"><span class="toc-number">1.4.2.9.</span> <span class="toc-text">Stream</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-2-Redis-%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%BB%8B%E7%BB%8D"><span class="toc-number">1.4.3.</span> <span class="toc-text">3.2 Redis 数据结构介绍</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-1-AOF-%E6%8C%81%E4%B9%85%E5%8C%96%E6%98%AF%E6%80%8E%E4%B9%88%E5%AE%9E%E7%8E%B0%E7%9A%84%EF%BC%9F"><span class="toc-number">1.4.4.</span> <span class="toc-text">4.1 AOF 持久化是怎么实现的？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-2-RDB-%E5%BF%AB%E7%85%A7%E6%98%AF%E6%80%8E%E4%B9%88%E5%AE%9E%E7%8E%B0%E7%9A%84%EF%BC%9F"><span class="toc-number">1.4.5.</span> <span class="toc-text">4.2 RDB 快照是怎么实现的？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-3-Redis-%E5%A4%A7-Key-%E5%AF%B9%E6%8C%81%E4%B9%85%E5%8C%96%E6%9C%89%E4%BB%80%E4%B9%88%E5%BD%B1%E5%93%8D%EF%BC%9F"><span class="toc-number">1.4.6.</span> <span class="toc-text">4.3 Redis 大 Key 对持久化有什么影响？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#5-1-Redis-%E8%BF%87%E6%9C%9F%E5%88%A0%E9%99%A4%E7%AD%96%E7%95%A5%E5%92%8C%E5%86%85%E5%AD%98%E6%B7%98%E6%B1%B0%E7%AD%96%E7%95%A5%E6%9C%89%E4%BB%80%E4%B9%88%E5%8C%BA%E5%88%AB%EF%BC%9F"><span class="toc-number">1.4.7.</span> <span class="toc-text">5.1 Redis 过期删除策略和内存淘汰策略有什么区别？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#6-1-%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6%E6%98%AF%E6%80%8E%E4%B9%88%E5%AE%9E%E7%8E%B0%E7%9A%84%EF%BC%9F"><span class="toc-number">1.4.8.</span> <span class="toc-text">6.1 主从复制是怎么实现的？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#6-2-%E4%B8%BA%E4%BB%80%E4%B9%88%E8%A6%81%E6%9C%89%E5%93%A8%E5%85%B5%EF%BC%9F"><span class="toc-number">1.4.9.</span> <span class="toc-text">6.2 为什么要有哨兵？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#7-1-%E4%BB%80%E4%B9%88%E6%98%AF%E7%BC%93%E5%AD%98%E9%9B%AA%E5%B4%A9%E3%80%81%E5%87%BB%E7%A9%BF%E3%80%81%E7%A9%BF%E9%80%8F%EF%BC%9F"><span class="toc-number">1.4.10.</span> <span class="toc-text">7.1 什么是缓存雪崩、击穿、穿透？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#7-2-%E6%95%B0%E6%8D%AE%E5%BA%93%E5%92%8C%E7%BC%93%E5%AD%98%E5%A6%82%E4%BD%95%E4%BF%9D%E8%AF%81%E4%B8%80%E8%87%B4%E6%80%A7%EF%BC%9F"><span class="toc-number">1.4.11.</span> <span class="toc-text">7.2 数据库和缓存如何保证一致性？</span></a></li></ol></li></ol></li></ol></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2022 - 2023 By 🎵张小佑♪</div></div></footer></div></div></div><div id="sidebar"><div id="sidebar-menus"><div class="avatar-img is-center"><img src="https://acallcf.oss-cn-qingdao.aliyuncs.com/images/1.jpg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="sidebar-site-data site-data is-center"><a href="/archives/" title="archive"><div class="headline">文章</div><div class="length-num">23</div></a><a href="/tags/" title="tag"><div class="headline">标签</div><div class="length-num">4</div></a><a href="/categories/" title="category"><div class="headline">分类</div><div class="length-num">2</div></a></div><div class="menus_items"><div class="menus_item"><a class="site-page faa-parent animated-hover" href="javascript:void(0);"><span> 文章</span></a><ul class="menus_item_child" style="left:-79px;"><li><a class="site-page child faa-parent animated-hover" href="/archives/"><i class="anzhiyufont anzhiyu-icon-box-archive faa-tada" style="font-size: 0.9em;"></i><span> 隧道</span></a></li><li><a class="site-page child faa-parent animated-hover" href="/categories/"><i class="anzhiyufont anzhiyu-icon-shapes faa-tada" style="font-size: 0.9em;"></i><span> 分类</span></a></li><li><a class="site-page child faa-parent animated-hover" href="/tags/"><i class="anzhiyufont anzhiyu-icon-tags faa-tada" style="font-size: 0.9em;"></i><span> 标签</span></a></li></ul></div><div class="menus_item"><a class="site-page faa-parent animated-hover" href="javascript:void(0);"><span> 友链</span></a><ul class="menus_item_child" style="left:17px;"><li><a class="site-page child faa-parent animated-hover" href="/comments/"><i class="anzhiyufont anzhiyu-icon-envelope faa-tada" style="font-size: 0.9em;"></i><span> 留言板</span></a></li></ul></div><div class="menus_item"><a class="site-page faa-parent animated-hover" href="javascript:void(0);"><span> 我的</span></a><ul class="menus_item_child" style="left:-79px;"><li><a class="site-page child faa-parent animated-hover" href="/music/"><i class="anzhiyufont anzhiyu-icon-music faa-tada" style="font-size: 0.9em;"></i><span> 音乐馆</span></a></li><li><a class="site-page child faa-parent animated-hover" href="/bangumis/"><i class="anzhiyufont anzhiyu-icon-bilibili faa-tada" style="font-size: 0.9em;"></i><span> 追番页</span></a></li><li><a class="site-page child faa-parent animated-hover" href="/album/"><i class="anzhiyufont anzhiyu-icon-images faa-tada" style="font-size: 0.9em;"></i><span> 相册集</span></a></li></ul></div><div class="menus_item"><a class="site-page faa-parent animated-hover" href="javascript:void(0);"><span> 关于</span></a><ul class="menus_item_child" style="left:-79px;"><li><a class="site-page child faa-parent animated-hover" href="/about/"><i class="anzhiyufont anzhiyu-icon-paper-plane faa-tada" style="font-size: 0.9em;"></i><span> 关于本人</span></a></li><li><a class="site-page child faa-parent animated-hover" href="/essay/"><i class="anzhiyufont anzhiyu-icon-lightbulb faa-tada" style="font-size: 0.9em;"></i><span> 闲言碎语</span></a></li><li><a class="site-page child faa-parent animated-hover" href="/equipment/"><i class="anzhiyufont anzhiyu-icon-dice-d20 faa-tada" style="font-size: 0.9em;"></i><span> 我的装备</span></a></li></ul></div></div></div></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="anzhiyufont anzhiyu-icon-book-open"></i></button><button id="translateLink" type="button" title="简繁转换">简</button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="anzhiyufont anzhiyu-icon-circle-half-stroke"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="anzhiyufont anzhiyu-icon-arrows-left-right"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="anzhiyufont anzhiyu-icon-gear"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="anzhiyufont anzhiyu-icon-list-ul"></i></button><button id="go-up" type="button" title="回到顶部"><i class="anzhiyufont anzhiyu-icon-arrow-up"></i></button></div></div><div id="nav-music"><a id="nav-music-hoverTips" onclick="anzhiyu.musicToggle()" accesskey="m">播放音乐</a><div id="console-music-bg"></div><meting-js id="8152976493" server="netease" type="playlist" mutex="true" preload="none" theme="var(--anzhiyu-main)" data-lrctype="0" order="random"></meting-js></div><div id="rightMenu"><div class="rightMenu-group rightMenu-small"><div class="rightMenu-item" id="menu-backward"><i class="anzhiyufont anzhiyu-icon-arrow-left"></i></div><div class="rightMenu-item" id="menu-forward"><i class="anzhiyufont anzhiyu-icon-arrow-right"></i></div><div class="rightMenu-item" id="menu-refresh"><i class="anzhiyufont anzhiyu-icon-arrow-rotate-right" style="font-size: 1rem;"></i></div><div class="rightMenu-item" id="menu-top"><i class="anzhiyufont anzhiyu-icon-arrow-up"></i></div></div><div class="rightMenu-group rightMenu-line rightMenuPlugin"><div class="rightMenu-item" id="menu-copytext"><i class="anzhiyufont anzhiyu-icon-copy"></i><span>复制选中文本</span></div><div class="rightMenu-item" id="menu-pastetext"><i class="anzhiyufont anzhiyu-icon-paste"></i><span>粘贴文本</span></div><a class="rightMenu-item" id="menu-commenttext"><i class="anzhiyufont anzhiyu-icon-comment-medical"></i><span>引用到评论</span></a><div class="rightMenu-item" id="menu-newwindow"><i class="anzhiyufont anzhiyu-icon-window-restore"></i><span>新窗口打开</span></div><div class="rightMenu-item" id="menu-copylink"><i class="anzhiyufont anzhiyu-icon-link"></i><span>复制链接地址</span></div><div class="rightMenu-item" id="menu-copyimg"><i class="anzhiyufont anzhiyu-icon-images"></i><span>复制此图片</span></div><div class="rightMenu-item" id="menu-downloadimg"><i class="anzhiyufont anzhiyu-icon-download"></i><span>下载此图片</span></div><div class="rightMenu-item" id="menu-newwindowimg"><i class="anzhiyufont anzhiyu-icon-window-restore"></i><span>新窗口打开图片</span></div><div class="rightMenu-item" id="menu-search"><i class="anzhiyufont anzhiyu-icon-magnifying-glass"></i><span>站内搜索</span></div><div class="rightMenu-item" id="menu-searchBaidu"><i class="anzhiyufont anzhiyu-icon-magnifying-glass"></i><span>百度搜索</span></div><div class="rightMenu-item" id="menu-music-toggle"><i class="anzhiyufont anzhiyu-icon-play"></i><span>播放音乐</span></div><div class="rightMenu-item" id="menu-music-back"><i class="anzhiyufont anzhiyu-icon-backward"></i><span>切换到上一首</span></div><div class="rightMenu-item" id="menu-music-forward"><i class="anzhiyufont anzhiyu-icon-forward"></i><span>切换到下一首</span></div><div class="rightMenu-item" id="menu-music-playlist" onclick="window.open(&quot;https://y.qq.com/n/ryqq/playlist/8802438608&quot;, &quot;_blank&quot;);" style="display: none;"><i class="anzhiyufont anzhiyu-icon-radio"></i><span>查看所有歌曲</span></div><div class="rightMenu-item" id="menu-music-copyMusicName"><i class="anzhiyufont anzhiyu-icon-copy"></i><span>复制歌名</span></div></div><div class="rightMenu-group rightMenu-line rightMenuOther"><a class="rightMenu-item menu-link" id="menu-randomPost"><i class="anzhiyufont anzhiyu-icon-shuffle"></i><span>随便逛逛</span></a><a class="rightMenu-item menu-link" href="/categories/"><i class="anzhiyufont anzhiyu-icon-cube"></i><span>博客分类</span></a><a class="rightMenu-item menu-link" href="/tags/"><i class="anzhiyufont anzhiyu-icon-tags"></i><span>文章标签</span></a></div><div class="rightMenu-group rightMenu-line rightMenuOther"><a class="rightMenu-item" id="menu-copy" href="javascript:void(0);"><i class="anzhiyufont anzhiyu-icon-copy"></i><span>复制地址</span></a><a class="rightMenu-item" id="menu-commentBarrage" href="javascript:void(0);"><i class="anzhiyufont anzhiyu-icon-message"></i><span class="menu-commentBarrage-text">关闭热评</span></a><a class="rightMenu-item" id="menu-darkmode" href="javascript:void(0);"><i class="anzhiyufont anzhiyu-icon-circle-half-stroke"></i><span class="menu-darkmode-text">深色模式</span></a><a class="rightMenu-item" id="menu-translate" href="javascript:void(0);"><i class="anzhiyufont anzhiyu-icon-language"></i><span>轉為繁體</span></a></div></div><div id="rightmenu-mask"></div><div id="he-plugin-simple"></div><script>var WIDGET = {
  "CONFIG": {
    "modules": "0124",
    "background": "2",
    "tmpColor": "FFFFFF",
    "tmpSize": "16",
    "cityColor": "FFFFFF",
    "citySize": "16",
    "aqiColor": "E8D87B",
    "aqiSize": "16",
    "weatherIconSize": "24",
    "alertIconSize": "18",
    "padding": "10px 10px 10px 10px",
    "shadow": "0",
    "language": "auto",
    "borderRadius": "20",
    "fixed": "true",
    "vertical": "top",
    "horizontal": "left",
    "left": "20",
    "top": "7.1",
    "key": "df245676fb434a0691ead1c63341cd94"
  }
}
</script><link rel="stylesheet" href="https://widget.qweather.net/simple/static/css/he-simple.css?v=1.4.0"/><script src="https://widget.qweather.net/simple/static/js/he-simple.js?v=1.4.0"></script><div><script src="https://npm.elemecdn.com/hexo-theme-anzhiyu@1.4.0/source/js/utils.js"></script><script src="https://npm.elemecdn.com/hexo-theme-anzhiyu@1.4.0/source/js/main.js"></script><script src="https://npm.elemecdn.com/hexo-theme-anzhiyu@1.4.0/source/js/tw_cn.js"></script><script src="https://npm.elemecdn.com/@fancyapps/ui@4.0.31/dist/fancybox.umd.js"></script><script src="https://npm.elemecdn.com/instant.page@5.1.1/instantpage.js" type="module"></script><script src="https://npm.elemecdn.com/node-snackbar@0.1.16/dist/snackbar.min.js"></script><script>function panguFn () {
  if (typeof pangu === 'object') pangu.autoSpacingPage()
  else {
    getScript('https://npm.elemecdn.com/pangu@4.0.7/dist/browser/pangu.min.js')
      .then(() => {
        pangu.autoSpacingPage()
      })
  }
}

function panguInit () {
  if (false){
    GLOBAL_CONFIG_SITE.isPost && panguFn()
  } else {
    panguFn()
  }
}

document.addEventListener('DOMContentLoaded', panguInit)</script><canvas id="universe"></canvas><script async src="https://npm.elemecdn.com/anzhiyu-theme-static@1.0.0/dark/dark.js"></script><script>// 消除控制台打印
var HoldLog = console.log;
console.log = function () {};
let now1 = new Date();
queueMicrotask(() => {
  const Log = function () {
    HoldLog.apply(console, arguments);
  }; //在恢复前输出日志
  const grt = new Date("09/01/2022 00:00:00"); //此处修改你的建站时间或者网站上线时间
  now1.setTime(now1.getTime() + 250);
  const days = (now1 - grt) / 1000 / 60 / 60 / 24;
  const dnum = Math.floor(days);
  const ascll = [
    `欢迎使用安知鱼!`,
    `生活明朗, 万物可爱`,
    `
        
       █████╗ ███╗   ██╗███████╗██╗  ██╗██╗██╗   ██╗██╗   ██╗
      ██╔══██╗████╗  ██║╚══███╔╝██║  ██║██║╚██╗ ██╔╝██║   ██║
      ███████║██╔██╗ ██║  ███╔╝ ███████║██║ ╚████╔╝ ██║   ██║
      ██╔══██║██║╚██╗██║ ███╔╝  ██╔══██║██║  ╚██╔╝  ██║   ██║
      ██║  ██║██║ ╚████║███████╗██║  ██║██║   ██║   ╚██████╔╝
      ╚═╝  ╚═╝╚═╝  ╚═══╝╚══════╝╚═╝  ╚═╝╚═╝   ╚═╝    ╚═════╝
        
        `,
    "已上线",
    dnum,
    "天",
    "©2022 By 安知鱼 1.4.0",
  ];
  const ascll2 = [`NCC2-036`, `调用前置摄像头拍照成功，识别为【小笨蛋】.`, `Photo captured: `, `🤪`];

  setTimeout(
    Log.bind(
      console,
      `\n%c${ascll[0]} %c ${ascll[1]} %c ${ascll[2]} %c${ascll[3]}%c ${ascll[4]}%c ${ascll[5]}\n\n%c ${ascll[6]}\n`,
      "color:#3b70fc",
      "",
      "color:#3b70fc",
      "color:#3b70fc",
      "",
      "color:#3b70fc",
      ""
    )
  );
  setTimeout(
    Log.bind(
      console,
      `%c ${ascll2[0]} %c ${ascll2[1]} %c \n${ascll2[2]} %c\n${ascll2[3]}\n`,
      "color:white; background-color:#4fd953",
      "",
      "",
      'background:url("https://npm.elemecdn.com/anzhiyu-blog@1.1.6/img/post/common/tinggge.gif") no-repeat;font-size:450%'
    )
  );

  setTimeout(Log.bind(console, "%c WELCOME %c 你好，小笨蛋.", "color:white; background-color:#4f90d9", ""));

  setTimeout(
    console.warn.bind(
      console,
      "%c ⚡ Powered by 安知鱼 %c 你正在访问 🎵张小佑♪ 的博客.",
      "color:white; background-color:#f0ad4e",
      ""
    )
  );

  setTimeout(Log.bind(console, "%c W23-12 %c 你已打开控制台.", "color:white; background-color:#4f90d9", ""));

  setTimeout(
    console.warn.bind(console, "%c S013-782 %c 你现在正处于监控中.", "color:white; background-color:#d9534f", "")
  );
});</script><script async src="/anzhiyu/random.js"></script><div class="js-pjax"><input type="hidden" name="page-type" id="page-type" value="post"></div><script async data-pjax src="https://npm.elemecdn.com/anzhiyu-theme-static@1.0.1/bubble/bubble.js"></script><script>var visitorMail = "visitor@anheyu.com";</script><script>//动态标题
let leaveTitle = '♪张小佑 - 分享思考与科技生活';
let backTitle = '♪张小佑 - 分享思考与科技生活';
let OriginTitile = document.title
let titleTime
document.addEventListener('visibilitychange', function () {
  if (document.hidden) {
    //离开当前页面时标签显示内容
    document.title = leaveTitle
    clearTimeout(titleTime)
  } else {
    //返回当前页面时标签显示内容
    document.title = backTitle + OriginTitile
    //两秒后变回正常标题
    titleTime = setTimeout(function () {
      document.title = OriginTitile
    }, 2000)
  }
})</script><script async data-pjax src="https://npm.elemecdn.com/anzhiyu-theme-static@1.0.0/waterfall/waterfall.js"></script><script src="https://lf3-cdn-tos.bytecdntp.com/cdn/expire-1-M/qrcodejs/1.0.0/qrcode.min.js"></script><script>// 初始化函数
let rm = {};

//禁止图片与超链接拖拽
let aElements = document.getElementsByTagName("a");
for (let i = 0; i < aElements.length; i++) {
  aElements[i].setAttribute("draggable", "false");
  let imgElements = aElements[i].getElementsByTagName("img");
  for (let j = 0; j < imgElements.length; j++) {
    imgElements[j].setAttribute("draggable", "false");
  }
}

// 显示菜单
rm.showRightMenu = function (isTrue, x = 0, y = 0) {
  console.info(x, y)
  let rightMenu = document.getElementById("rightMenu");
  rightMenu.style.top = x + "px";
  rightMenu.style.left = y + "px";
  if (isTrue) {
    rightMenu.style.display = "block";
    stopMaskScroll();
  } else {
    rightMenu.style.display = "none";
  }
};

// 隐藏菜单
rm.hideRightMenu = function () {
  rm.showRightMenu(false);
  let rightMenuMask = document.querySelector("#rightmenu-mask");
  rightMenuMask.style.display = "none";
};

// 尺寸
let rmWidth = document.getElementById("rightMenu").offsetWidth;
let rmHeight = document.getElementById("rightMenu").offsetHeight;

// 重新定义尺寸
rm.reloadrmSize = function () {
  rightMenu.style.visibility = "hidden";
  rightMenu.style.display = "block";
  // 获取宽度和高度
  rmWidth = document.getElementById("rightMenu").offsetWidth;
  rmHeight = document.getElementById("rightMenu").offsetHeight;
  rightMenu.style.visibility = "visible";
};

// 获取点击的href
let domhref = "";
let domImgSrc = "";
let globalEvent = null;

var oncontextmenuFunction = function (event) {
  if (document.body.clientWidth > 768) {
    let pageX = event.clientX + 10; //加10是为了防止显示时鼠标遮在菜单上
    let pageY = event.clientY;

    //其他额外菜单
    const $rightMenuOther = document.querySelector(".rightMenuOther");
    const $rightMenuPlugin = document.querySelector(".rightMenuPlugin");
    const $rightMenuCopyText = document.querySelector("#menu-copytext");
    const $rightMenuPasteText = document.querySelector("#menu-pastetext");
    const $rightMenuCommentText = document.querySelector("#menu-commenttext");
    const $rightMenuNewWindow = document.querySelector("#menu-newwindow");
    const $rightMenuNewWindowImg = document.querySelector("#menu-newwindowimg");
    const $rightMenuCopyLink = document.querySelector("#menu-copylink");
    const $rightMenuCopyImg = document.querySelector("#menu-copyimg");
    const $rightMenuDownloadImg = document.querySelector("#menu-downloadimg");
    const $rightMenuSearch = document.querySelector("#menu-search");
    const $rightMenuSearchBaidu = document.querySelector("#menu-searchBaidu");
    const $rightMenuMusicToggle = document.querySelector("#menu-music-toggle");
    const $rightMenuMusicBack = document.querySelector("#menu-music-back");
    const $rightMenuMusicForward = document.querySelector("#menu-music-forward");
    const $rightMenuMusicPlaylist = document.querySelector("#menu-music-playlist");
    const $rightMenuMusicCopyMusicName = document.querySelector("#menu-music-copyMusicName");

    let href = event.target.href;
    let imgsrc = event.target.currentSrc;

    // 判断模式 扩展模式为有事件
    let pluginMode = false;
    $rightMenuOther.style.display = "block";
    globalEvent = event;

    // 检查是否需要复制 是否有选中文本
    if (selectTextNow && window.getSelection()) {
      pluginMode = true;
      $rightMenuCopyText.style.display = "block";
      $rightMenuCommentText.style.display = "block";
      $rightMenuSearch.style.display = "block";
      $rightMenuSearchBaidu.style.display = "block";
    } else {
      $rightMenuCopyText.style.display = "none";
      $rightMenuCommentText.style.display = "none";
      $rightMenuSearchBaidu.style.display = "none";
      $rightMenuSearch.style.display = "none";
    }

    //检查是否右键点击了链接a标签
    if (href) {
      pluginMode = true;
      $rightMenuNewWindow.style.display = "block";
      $rightMenuCopyLink.style.display = "block";
      domhref = href;
    } else {
      $rightMenuNewWindow.style.display = "none";
      $rightMenuCopyLink.style.display = "none";
    }

    //检查是否需要复制图片
    if (imgsrc) {
      pluginMode = true;
      $rightMenuCopyImg.style.display = "block";
      $rightMenuDownloadImg.style.display = "block";
      $rightMenuNewWindowImg.style.display = "block";
      document.getElementById("rightMenu").style.width="12rem"
      domImgSrc = imgsrc;
    } else {
      $rightMenuCopyImg.style.display = "none";
      $rightMenuDownloadImg.style.display = "none";
      $rightMenuNewWindowImg.style.display = "none";
    }

    // 判断是否为输入框
    if (event.target.tagName.toLowerCase() === "input" || event.target.tagName.toLowerCase() === "textarea") {
      pluginMode = true;
      $rightMenuPasteText.style.display = "block";
    } else {
      $rightMenuPasteText.style.display = "none";
    }
    const navMusicEl = document.querySelector("#nav-music");
    //判断是否是音乐
    if (navMusicEl && navMusicEl.contains(event.target)) {
      pluginMode = true;
      $rightMenuMusicToggle.style.display = "block";
      $rightMenuMusicBack.style.display = "block";
      $rightMenuMusicForward.style.display = "block";
      $rightMenuMusicPlaylist.style.display = "block";
      $rightMenuMusicCopyMusicName.style.display = "block";
    } else {
      $rightMenuMusicToggle.style.display = "none";
      $rightMenuMusicBack.style.display = "none";
      $rightMenuMusicForward.style.display = "none";
      $rightMenuMusicPlaylist.style.display = "none";
      $rightMenuMusicCopyMusicName.style.display = "none";
    }

    // 如果不是扩展模式则隐藏扩展模块
    if (pluginMode) {
      $rightMenuOther.style.display = "none";
      $rightMenuPlugin.style.display = "block";
    } else {
      $rightMenuPlugin.style.display = "none";
    }

    rm.reloadrmSize();

    // 鼠标默认显示在鼠标右下方，当鼠标靠右或靠下时，将菜单显示在鼠标左方\上方
    if (pageX + rmWidth > window.innerWidth) {
      pageX -= rmWidth + 10;
    }
    if (pageY + rmHeight > window.innerHeight) {
      pageY -= pageY + rmHeight - window.innerHeight;
    }

    rm.showRightMenu(true, pageY, pageX);
    document.getElementById("rightmenu-mask").style.display = "flex";
    return false;
  }
};

// 监听右键初始化
window.oncontextmenu = oncontextmenuFunction

// 下载图片状态
rm.downloadimging = false;

// 复制图片到剪贴板
rm.writeClipImg = function (imgsrc) {
  console.log("按下复制");
  rm.hideRightMenu();
  anzhiyu.snackbarShow("正在下载中，请稍后", false, 10000);
  if (rm.downloadimging == false) {
    rm.downloadimging = true;
    setTimeout(function () {
      copyImage(imgsrc);
      anzhiyu.snackbarShow("复制成功！图片已添加盲水印，请遵守版权协议");
      rm.downloadimging = false;
    }, "10000");
  }
};

function imageToBlob(imageURL) {
  const img = new Image();
  const c = document.createElement("canvas");
  const ctx = c.getContext("2d");
  img.crossOrigin = "";
  img.src = imageURL;
  return new Promise(resolve => {
    img.onload = function () {
      c.width = this.naturalWidth;
      c.height = this.naturalHeight;
      ctx.drawImage(this, 0, 0);
      c.toBlob(
        blob => {
          // here the image is a blob
          resolve(blob);
        },
        "image/png",
        0.75
      );
    };
  });
}

async function copyImage(imageURL) {
  const blob = await imageToBlob(imageURL);
  const item = new ClipboardItem({ "image/png": blob });
  navigator.clipboard.write([item]);
}

rm.copyUrl = function (id) {
  const input = document.createElement("input"); // Create a new <input> element
  input.id = "copyVal"; // Set the id of the new element to "copyVal"
  document.body.appendChild(input); // Append the new element to the end of the <body> element
  
  const text = id;
  input.value = text;
  input.select();
  input.setSelectionRange(0, input.value.length);
  document.execCommand("copy");
  
  input.remove(); // Remove the <input> element from the DOM
};

function stopMaskScroll() {
  if (document.getElementById("rightmenu-mask")) {
    let xscroll = document.getElementById("rightmenu-mask");
    xscroll.addEventListener(
      "mousewheel",
      function (e) {
        //阻止浏览器默认方法
        rm.hideRightMenu();
        // e.preventDefault();
      },
      { passive: true }
    );
  }
  if (document.getElementById("rightMenu")) {
    let xscroll = document.getElementById("rightMenu");
    xscroll.addEventListener(
      "mousewheel",
      function (e) {
        //阻止浏览器默认方法
        rm.hideRightMenu();
        // e.preventDefault();
      },
      { passive: true }
    );
  }
}

rm.rightmenuCopyText = function (txt) {
  if (navigator.clipboard) {
    navigator.clipboard.writeText(txt);
  }
  rm.hideRightMenu();
};

rm.copyPageUrl = function (url) {
  if (!url) {
    url = window.location.href;
  }
  rm.copyUrl(url);
  anzhiyu.snackbarShow("复制本页链接地址成功", false, 2000);
  rm.hideRightMenu();
};

rm.sharePage = function () {
  var content = window.location.href;
  rm.copyUrl(url);
  anzhiyu.snackbarShow("复制本页链接地址成功", false, 2000);
  rm.hideRightMenu();
};

// 复制当前选中文本
var selectTextNow = "";
document.onmouseup = document.ondblclick = selceText;

function selceText() {
  var txt;
  if (document.selection) {
    txt = document.selection.createRange().text;
  } else {
    txt = window.getSelection().toString();
  }
  selectTextNow = txt !== "" ? txt : "";
}

// 读取剪切板
rm.readClipboard = function () {
  if (navigator.clipboard) {
    navigator.clipboard.readText().then(clipText => rm.insertAtCaret(globalEvent.target, clipText));
  }
};

// 粘贴文本到焦点
rm.insertAtCaret = function (elemt, value) {
  const startPos = elemt.selectionStart,
    endPos = elemt.selectionEnd;
  if (document.selection) {
    elemt.focus();
    var sel = document.selection.createRange();
    sel.text = value;
    elemt.focus();
  } else {
    if (startPos || startPos == "0") {
      var scrollTop = elemt.scrollTop;
      elemt.value = elemt.value.substring(0, startPos) + value + elemt.value.substring(endPos, elemt.value.length);
      elemt.focus();
      elemt.selectionStart = startPos + value.length;
      elemt.selectionEnd = startPos + value.length;
      elemt.scrollTop = scrollTop;
    } else {
      elemt.value += value;
      elemt.focus();
    }
  }
};

//粘贴文本
rm.pasteText = function () {
  const result = rm.readClipboard() || "";
  rm.hideRightMenu();
};

//引用到评论
rm.rightMenuCommentText = function (txt) {
  rm.hideRightMenu();
  const postCommentDom = document.getElementById("post-comment");
  var domTop = postCommentDom.offsetTop;
  window.scrollTo(0, domTop - 80);
  if (txt == "undefined" || txt == "null") txt = "好棒！";
  function setText() {
    setTimeout(() => {
      var input = document.getElementsByClassName("el-textarea__inner")[0];
      if (!input) setText();
      let evt = document.createEvent("HTMLEvents");
      evt.initEvent("input", true, true);
      let inputValue = replaceAll(txt, "\n", "\n> ");
      input.value = "> " + inputValue + "\n\n";
      input.dispatchEvent(evt);
      input.focus();
      input.setSelectionRange(-1, -1);
      if (document.getElementById("comment-tips")) {
        document.getElementById("comment-tips").classList.add("show");
      }
    }, 100);
  }
  setText();
};

//替换所有内容
function replaceAll(string, search, replace) {
  return string.split(search).join(replace);
}

// 百度搜索
rm.searchBaidu = function () {
  anzhiyu.snackbarShow("即将跳转到百度搜索", false, 2000);
  setTimeout(function () {
    window.open("https://www.baidu.com/s?wd=" + selectTextNow);
  }, "2000");
  rm.hideRightMenu();
};

//分享链接
rm.copyLink = function () {
  rm.rightmenuCopyText(domhref);
  anzhiyu.snackbarShow("已复制链接地址");
};

function addRightMenuClickEvent() {
  // 添加点击事件
  document.getElementById("menu-backward").addEventListener("click", function () {
  window.history.back();
    rm.hideRightMenu();
  });

  document.getElementById("menu-forward").addEventListener("click", function () {
    window.history.forward();
    rm.hideRightMenu();
  });

  document.getElementById("menu-refresh").addEventListener("click", function () {
    window.location.reload();
  });

  document.getElementById("menu-top").addEventListener("click", function () {
    anzhiyu.scrollToDest(0, 500);
    rm.hideRightMenu();
  });

  const menuLinks = document.querySelectorAll(".menu-link");
  menuLinks.forEach(function (link) {
    link.addEventListener("click", rm.hideRightMenu);
  });

  document.getElementById("menu-darkmode").addEventListener("click", anzhiyu.switchDarkMode);

  document.getElementById("menu-home") && document.getElementById("menu-home").addEventListener("click", function () {
    window.location.href = window.location.origin;
  });

  document.getElementById("menu-randomPost").addEventListener("click", function () {
    toRandomPost();
  });

  document.getElementById("menu-commentBarrage").addEventListener("click", anzhiyu.switchCommentBarrage);

  document.getElementById("rightmenu-mask").addEventListener("click", rm.hideRightMenu);

  document.getElementById("rightmenu-mask").addEventListener("contextmenu", function (event) {
    rm.hideRightMenu();
    event.preventDefault(); // Prevent the default context menu from appearing
  });

  document.getElementById("menu-copy").addEventListener("click", rm.copyPageUrl);

  document.getElementById("menu-pastetext").addEventListener("click", rm.pasteText);

  document.getElementById("menu-copytext").addEventListener("click", function () {
    rm.rightmenuCopyText(selectTextNow);
    anzhiyu.snackbarShow("复制成功，复制和转载请标注本文地址");
  });

  document.getElementById("menu-commenttext").addEventListener("click", function () {
    rm.rightMenuCommentText(selectTextNow);
  });

  document.getElementById("menu-newwindow").addEventListener("click", function () {
    window.open(domhref, "_blank");
    rm.hideRightMenu();
  });

  document.getElementById("menu-copylink").addEventListener("click", rm.copyLink);

  document.getElementById("menu-downloadimg").addEventListener("click", function () {
    anzhiyu.downloadImage(domImgSrc, "anzhiyu");
  });

  document.getElementById("menu-newwindowimg").addEventListener("click", function () {
    window.open(domImgSrc, "_blank");
    rm.hideRightMenu();
  });

  document.getElementById("menu-copyimg").addEventListener("click", function () {
    rm.writeClipImg(domImgSrc);
  });

  document.getElementById("menu-searchBaidu").addEventListener("click", rm.searchBaidu);

  //音乐
  document.getElementById("menu-music-toggle").addEventListener("click", anzhiyu.musicToggle);

  document.getElementById("menu-music-back").addEventListener("click", anzhiyu.musicSkipBack);

  document.getElementById("menu-music-forward").addEventListener("click", anzhiyu.musicSkipForward);

  document.getElementById("menu-music-copyMusicName").addEventListener("click", function () {
    rm.rightmenuCopyText(anzhiyu.musicGetName());
    anzhiyu.snackbarShow("复制歌曲名称成功", false, 3000);
  });

}

addRightMenuClickEvent();</script><script data-pjax>var themeColorMeta = document.querySelector('meta[name="theme-color"]');
var pageHeaderEl = document.getElementById("page-header");
var navMusicEl = document.getElementById("nav-music");
var consoleEl = document.getElementById("console");
// 已随机的歌曲
var selectRandomSong = [];
// 音乐默认声音大小
var musicVolume = 0.8;
// 是否切换了周杰伦音乐列表
var changeMusicListFlag = false;
// 当前默认播放列表
var defaultPlayMusicList = [];

document.getElementById("page-name").innerText = document.title.split(" | ♪张小佑")[0];
anzhiyu.initIndexEssay();
anzhiyu.changeTimeInEssay();
anzhiyu.removeBodyPaceClass();
anzhiyu.qrcodeCreate();
anzhiyu.changeTimeInAlbumDetail();
anzhiyu.reflashEssayWaterFall();
anzhiyu.sayhi();
anzhiyu.stopImgRightDrag();
anzhiyu.addNavBackgroundInit();
anzhiyu.setValueToBodyType();
anzhiyu.catalogActive();
anzhiyu.tagsPageActive();
anzhiyu.categoriesBarActive();
anzhiyu.topCategoriesBarScroll();
anzhiyu.switchRightClickMenuHotReview();
anzhiyu.getCustomPlayList();
anzhiyu.addEventListenerConsoleMusicList(false);
setTimeout(() => {
  if (typeof addFriendLinksInFooter === "function") {
    addFriendLinksInFooter();
  }
}, 200)</script><link rel="stylesheet" href="https://npm.elemecdn.com/anzhiyu-theme-static@1.1.4/icon/ali_iconfont_css.css"><link rel="stylesheet" href="https://npm.elemecdn.com/anzhiyu-theme-static@1.0.0/aplayer/APlayer.min.css" media="print" onload="this.media='all'"><script src="https://npm.elemecdn.com/anzhiyu-blog-static@1.0.1/js/APlayer.min.js"></script><script src="https://npm.elemecdn.com/hexo-anzhiyu-music@1.0.1/assets/js/Meting2.min.js"></script><script src="https://npm.elemecdn.com/pjax@0.2.8/pjax.min.js"></script><script>let pjaxSelectors = ["head > title","#config-diff","#body-wrap","#rightside-config-hide","#rightside-config-show",".js-pjax"]

var pjax = new Pjax({
  elements: 'a:not([target="_blank"])',
  selectors: pjaxSelectors,
  cacheBust: false,
  analytics: false,
  scrollRestoration: false
})

document.addEventListener('pjax:send', function () {
  // removeEventListener scroll 
  window.tocScrollFn && window.removeEventListener('scroll', window.tocScrollFn)
  window.scrollCollect && window.removeEventListener('scroll', scrollCollect)

  document.getElementById('rightside').style.cssText = "opacity: ''; transform: ''"
  
  if (window.aplayers) {
    for (let i = 0; i < window.aplayers.length; i++) {
      if (!window.aplayers[i].options.fixed) {
        window.aplayers[i].destroy()
      }
    }
  }

  typeof typed === 'object' && typed.destroy()

  //reset readmode
  const $bodyClassList = document.body.classList
  $bodyClassList.contains('read-mode') && $bodyClassList.remove('read-mode')
})

document.addEventListener('pjax:complete', function () {
  window.refreshFn()

  document.querySelectorAll('script[data-pjax]').forEach(item => {
    const newScript = document.createElement('script')
    const content = item.text || item.textContent || item.innerHTML || ""
    Array.from(item.attributes).forEach(attr => newScript.setAttribute(attr.name, attr.value))
    newScript.appendChild(document.createTextNode(content))
    item.parentNode.replaceChild(newScript, item)
  })

  GLOBAL_CONFIG.islazyload && window.lazyLoadInstance.update()

  typeof chatBtnFn === 'function' && chatBtnFn()
  typeof panguInit === 'function' && panguInit()

  // google analytics
  typeof gtag === 'function' && gtag('config', '', {'page_path': window.location.pathname});

  // baidu analytics
  typeof _hmt === 'object' && _hmt.push(['_trackPageview',window.location.pathname]);

  typeof loadMeting === 'function' && document.getElementsByClassName('aplayer').length && loadMeting()

  // prismjs
  typeof Prism === 'object' && Prism.highlightAll()
})

document.addEventListener('pjax:error', (e) => {
  if (e.request.status === 404) {
    pjax.loadUrl('/404.html')
  }
})</script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><script charset="UTF-8" src="https://npm.elemecdn.com/anzhiyu-theme-static@1.1.5/accesskey/accesskey.js"></script></div><script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body></html>