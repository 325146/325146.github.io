<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no"><title>2.极客笔记 | ♪张小佑</title><meta name="keywords" content="C++"><meta name="author" content="🎵张小佑♪"><meta name="copyright" content="🎵张小佑♪"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#f7f9fe"><meta name="mobile-web-app-capable" content="yes"><meta name="apple-touch-fullscreen" content="yes"><meta name="apple-mobile-web-app-title" content="2.极客笔记"><meta name="application-name" content="2.极客笔记"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-status-bar-style" content="#f7f9fe"><meta name="description" content="积极学习C++吧！">
<meta property="og:type" content="article">
<meta property="og:title" content="2.极客笔记">
<meta property="og:url" content="http://acall.love/2023/05/05/2.%E6%9E%81%E5%AE%A2%E4%B8%93%E6%A0%8F%E7%AC%94%E8%AE%B0/index.html">
<meta property="og:site_name" content="♪张小佑">
<meta property="og:description" content="积极学习C++吧！">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://acallcf.oss-cn-qingdao.aliyuncs.com/images/o5g6r7.webp">
<meta property="article:published_time" content="2023-05-04T16:00:00.000Z">
<meta property="article:modified_time" content="2023-05-04T16:00:00.000Z">
<meta property="article:author" content="🎵张小佑♪">
<meta property="article:tag" content="C++">
<meta property="article:tag" content="后端开发">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://acallcf.oss-cn-qingdao.aliyuncs.com/images/o5g6r7.webp"><link rel="shortcut icon" href="/img/favicon.ico"><link rel="canonical" href="http://acall.love/2023/05/05/2.%E6%9E%81%E5%AE%A2%E4%B8%93%E6%A0%8F%E7%AC%94%E8%AE%B0/"><link rel="preconnect" href="//npm.elemecdn.com"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><meta name="google-site-verification" content="xxx"/><meta name="baidu-site-verification" content="code-xxx"/><meta name="msvalidate.01" content="xxx"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://npm.elemecdn.com/node-snackbar@0.1.16/dist/snackbar.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://npm.elemecdn.com/@fancyapps/ui@4.0.31/dist/fancybox.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = { 
  root: '/',
  friends_vue_info: undefined,
  navMusic: true,
  changeMainColorPost: undefined,
  algolia: undefined,
  localSearch: undefined,
  translate: {"defaultEncoding":2,"translateDelay":0,"msgToTraditionalChinese":"繁","msgToSimplifiedChinese":"简","rightMenuMsgToTraditionalChinese":"转为繁体","rightMenuMsgToSimplifiedChinese":"转为简体"},
  noticeOutdate: {"limitDay":365,"position":"top","messagePrev":"It has been","messageNext":"days since the last update, the content of the article may be outdated."},
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":330},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '天',
  date_suffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: {"chs_to_cht":"你已切换为繁体","cht_to_chs":"你已切换为简体","day_to_night":"你已切换为深色模式","night_to_day":"你已切换为浅色模式","bgLight":"#3b70fc","bgDark":"#1f1f1f","position":"top-center"},
  source: {
    justifiedGallery: {
      js: 'https://npm.elemecdn.com/flickr-justified-gallery@2.1.2/dist/fjGallery.min.js',
      css: 'https://npm.elemecdn.com/flickr-justified-gallery@2.1.2/dist/fjGallery.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isAnchor: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: '2.极客笔记',
  isPost: true,
  isHome: false,
  isHighlightShrink: true,
  isToc: true,
  postUpdate: '2023-05-05 00:00:00'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
    win.getCSS = (url,id = false) => new Promise((resolve, reject) => {
      const link = document.createElement('link')
      link.rel = 'stylesheet'
      link.href = url
      if (id) link.id = id
      link.onerror = reject
      link.onload = link.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        link.onload = link.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(link)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#18171d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#f7f9fe')
        }
      }
      const t = saveToLocal.get('theme')
    
          const isDarkMode = window.matchMedia('(prefers-color-scheme: dark)').matches
          const isLightMode = window.matchMedia('(prefers-color-scheme: light)').matches
          const isNotSpecified = window.matchMedia('(prefers-color-scheme: no-preference)').matches
          const hasNoSupport = !isDarkMode && !isLightMode && !isNotSpecified

          if (t === undefined) {
            if (isLightMode) activateLightMode()
            else if (isDarkMode) activateDarkMode()
            else if (isNotSpecified || hasNoSupport) {
              const now = new Date()
              const hour = now.getHours()
              const isNight = hour <= 6 || hour >= 18
              isNight ? activateDarkMode() : activateLightMode()
            }
            window.matchMedia('(prefers-color-scheme: dark)').addListener(function (e) {
              if (saveToLocal.get('theme') === undefined) {
                e.matches ? activateDarkMode() : activateLightMode()
              }
            })
          } else if (t === 'light') activateLightMode()
          else activateDarkMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const detectApple = () => {
      if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
    })(window)</script><meta name="generator" content="Hexo 6.3.0"></head><body data-type="anzhiyu"><div id="web_bg"></div><div id="an_music_bg"></div><div id="loading-box" onclick="document.getElementById(&quot;loading-box&quot;).classList.add(&quot;loaded&quot;)"><div class="loading-bg"><img class="loading-img nolazyload" alt="加载头像" src="https://acallcf.oss-cn-qingdao.aliyuncs.com/images/1.jpg"/><div class="loading-image-dot"></div><div id="loading-percentage">0%</div></div></div><script>const loadingPercentage = document.getElementById("loading-percentage");
let loadingPercentageTimer = setInterval(function() {
  var progressBar = document.querySelector(".pace-progress");
  if (!progressBar) return
  var currentValue = progressBar.getAttribute("data-progress-text");
  if (currentValue !== loadingPercentage.textContent) {
    loadingPercentage.textContent = currentValue;
    if (currentValue === "100%") {
      clearInterval(loadingPercentageTimer);
    }
  }
}, 100);
const preloader = {
  endLoading: () => {
    document.body.style.overflow = 'auto';
    document.getElementById('loading-box').classList.add("loaded")
    Pace.restart()
  },
  initLoading: () => {
    document.body.style.overflow = '';
    document.getElementById('loading-box').classList.remove("loaded")
  }
}
window.addEventListener('load',()=> { preloader.endLoading() })

if (true) {
  document.addEventListener('pjax:send', () => { preloader.initLoading() })
  document.addEventListener('pjax:complete', () => { preloader.endLoading() })
}</script><link rel="stylesheet" href="https://npm.elemecdn.com/anzhiyu-theme-static@1.0.0/progress_bar/progress_bar.css"/><script async="async" src="https://npm.elemecdn.com/pace-js@1.2.4/pace.min.js" data-pace-options="{ &quot;restartOnRequestAfter&quot;:false,&quot;eventLag&quot;:false}"></script><div id="web_box"><div id="web_container"><div id="menu-mask"></div><div class="post" id="body-wrap"><header class="not-top-img" id="page-header"><nav id="nav"><div id="nav-group"><span id="blog_name"><div class="back-home-button"><i class="anzhiyufont anzhiyu-icon-grip-vertical"></i><div class="back-menu-list-groups"><div class="back-menu-list-group"><div class="back-menu-list-title">网页</div><div class="back-menu-list"><a class="back-menu-item" href="https://acall.love/" title="博客" target="_blank"><img class="back-menu-item-icon" src="/img/favicon.ico" alt="博客"/><span class="back-menu-item-text">博客</span></a></div></div><div class="back-menu-list-group"><div class="back-menu-list-title">项目</div><div class="back-menu-list"><a class="back-menu-item" href="https://image.anheyu.com/" title="安知鱼图床" target="_blank"><img class="back-menu-item-icon" src="https://image.anheyu.com/favicon.ico" alt="安知鱼图床"/><span class="back-menu-item-text">安知鱼图床</span></a></div></div></div></div><a id="site-name" href="/" accesskey="h"><div class="title">♪张小佑</div><i class="anzhiyufont anzhiyu-icon-house-chimney"></i></a></span><div class="mask-name-container"><div id="name-container"><a id="page-name" href="javascript:anzhiyu.scrollToDest(0, 500)">PAGE_NAME</a></div></div><div id="menus"><div class="menus_items"><div class="menus_item"><a class="site-page faa-parent animated-hover" href="javascript:void(0);"><span> 文章</span></a><ul class="menus_item_child" style="left:-79px;"><li><a class="site-page child faa-parent animated-hover" href="/archives/"><i class="anzhiyufont anzhiyu-icon-box-archive faa-tada" style="font-size: 0.9em;"></i><span> 隧道</span></a></li><li><a class="site-page child faa-parent animated-hover" href="/categories/"><i class="anzhiyufont anzhiyu-icon-shapes faa-tada" style="font-size: 0.9em;"></i><span> 分类</span></a></li><li><a class="site-page child faa-parent animated-hover" href="/tags/"><i class="anzhiyufont anzhiyu-icon-tags faa-tada" style="font-size: 0.9em;"></i><span> 标签</span></a></li></ul></div><div class="menus_item"><a class="site-page faa-parent animated-hover" href="javascript:void(0);"><span> 友链</span></a><ul class="menus_item_child" style="left:17px;"><li><a class="site-page child faa-parent animated-hover" href="/comments/"><i class="anzhiyufont anzhiyu-icon-envelope faa-tada" style="font-size: 0.9em;"></i><span> 留言板</span></a></li></ul></div><div class="menus_item"><a class="site-page faa-parent animated-hover" href="javascript:void(0);"><span> 我的</span></a><ul class="menus_item_child" style="left:-79px;"><li><a class="site-page child faa-parent animated-hover" href="/music/"><i class="anzhiyufont anzhiyu-icon-music faa-tada" style="font-size: 0.9em;"></i><span> 音乐馆</span></a></li><li><a class="site-page child faa-parent animated-hover" href="/bangumis/"><i class="anzhiyufont anzhiyu-icon-bilibili faa-tada" style="font-size: 0.9em;"></i><span> 追番页</span></a></li><li><a class="site-page child faa-parent animated-hover" href="/album/"><i class="anzhiyufont anzhiyu-icon-images faa-tada" style="font-size: 0.9em;"></i><span> 相册集</span></a></li></ul></div><div class="menus_item"><a class="site-page faa-parent animated-hover" href="javascript:void(0);"><span> 关于</span></a><ul class="menus_item_child" style="left:-79px;"><li><a class="site-page child faa-parent animated-hover" href="/about/"><i class="anzhiyufont anzhiyu-icon-paper-plane faa-tada" style="font-size: 0.9em;"></i><span> 关于本人</span></a></li><li><a class="site-page child faa-parent animated-hover" href="/essay/"><i class="anzhiyufont anzhiyu-icon-lightbulb faa-tada" style="font-size: 0.9em;"></i><span> 闲言碎语</span></a></li><li><a class="site-page child faa-parent animated-hover" href="/equipment/"><i class="anzhiyufont anzhiyu-icon-dice-d20 faa-tada" style="font-size: 0.9em;"></i><span> 我的装备</span></a></li></ul></div></div></div><div id="nav-right"><div class="nav-button only-home" id="travellings_button" title="随机前往一个开往项目网站"><a class="site-page" onclick="anzhiyu.totraveling()" title="随机前往一个开往项目网站" href="javascript:void(0);" rel="external nofollow" data-pjax-state="external"><i class="anzhiyufont anzhiyu-icon-train"></i></a></div><div class="nav-button" id="randomPost_button"><a class="site-page" onclick="toRandomPost()" title="随机前往一个文章" href="javascript:void(0);"><i class="anzhiyufont anzhiyu-icon-dice"></i></a></div><input id="center-console" type="checkbox"/><label class="widget" for="center-console" title="中控台" onclick="anzhiyu.switchConsole();"><i class="left"></i><i class="widget center"></i><i class="widget right"></i></label><div id="console"><div class="console-card-group-reward"><ul class="reward-all console-card"><li class="reward-item"><a href="https://acallcf.oss-cn-qingdao.aliyuncs.com/images/202307192211377.png" target="_blank"><img class="post-qr-code-img" alt="wechat" src="https://acallcf.oss-cn-qingdao.aliyuncs.com/images/202307192211377.png"/></a><div class="post-qr-code-desc">wechat</div></li><li class="reward-item"><a href="https://acallcf.oss-cn-qingdao.aliyuncs.com/images/202307192207910.png" target="_blank"><img class="post-qr-code-img" alt="alipayautoh" src="https://acallcf.oss-cn-qingdao.aliyuncs.com/images/202307192207910.png"/></a><div class="post-qr-code-desc">alipayautoh</div></li></ul></div><div class="console-card-group"><div class="console-card-group-left"><div class="console-card" id="card-newest-comments" onclick="anzhiyu.hideConsole()"><div class="card-content"><div class="author-content-item-tips">互动</div><span class="author-content-item-title"> <span>最新评论</span></span></div><div class="aside-list"><span>正在加载中...</span></div></div></div><div class="console-card-group-right"><div class="console-card tags" onclick="anzhiyu.hideConsole()"><div class="card-content"><div class="author-content-item-tips">兴趣点</div><span class="author-content-item-title">寻找你感兴趣的领域</span><div class="card-tags"><div class="item-headline"></div><div class="card-tag-cloud"><a href="/tags/C/" style="font-size: 1.05rem;">C++<sup>23</sup></a><a href="/tags/%E5%90%8E%E7%AB%AF%E5%BC%80%E5%8F%91/" style="font-size: 1.05rem;">后端开发<sup>22</sup></a><a href="/tags/%E9%9D%A2%E7%BB%8F/" style="font-size: 1.05rem;">面经<sup>1</sup></a><a href="/tags/%E9%9D%A2%E8%AF%95/" style="font-size: 1.05rem;">面试<sup>3</sup></a></div></div><hr/></div></div><div class="console-card history" onclick="anzhiyu.hideConsole()"><div class="item-headline"><i class="anzhiyufont anzhiyu-icon-box-archiv"></i><span>文章</span></div><div class="card-archives"><div class="item-headline"><i class="anzhiyufont anzhiyu-icon-archive"></i><span>归档</span></div><ul class="card-archive-list"><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2023/06/"><span class="card-archive-list-date">六月 2023</span><div class="card-archive-list-count-group"><span class="card-archive-list-count">3</span><span>篇</span></div></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2023/05/"><span class="card-archive-list-date">五月 2023</span><div class="card-archive-list-count-group"><span class="card-archive-list-count">5</span><span>篇</span></div></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2023/04/"><span class="card-archive-list-date">四月 2023</span><div class="card-archive-list-count-group"><span class="card-archive-list-count">2</span><span>篇</span></div></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2023/03/"><span class="card-archive-list-date">三月 2023</span><div class="card-archive-list-count-group"><span class="card-archive-list-count">1</span><span>篇</span></div></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2023/02/"><span class="card-archive-list-date">二月 2023</span><div class="card-archive-list-count-group"><span class="card-archive-list-count">5</span><span>篇</span></div></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2023/01/"><span class="card-archive-list-date">一月 2023</span><div class="card-archive-list-count-group"><span class="card-archive-list-count">7</span><span>篇</span></div></a></li></ul></div><hr/></div></div></div><div class="button-group"><div class="console-btn-item"><a class="darkmode_switchbutton" onclick="anzhiyu.switchDarkMode()" title="显示模式切换" href="javascript:void(0);"><i class="anzhiyufont anzhiyu-icon-moon"></i></a></div><div class="console-btn-item" id="consoleHideAside" onclick="anzhiyu.hideAsideBtn()" title="边栏显示控制"><a class="asideSwitch"><i class="anzhiyufont anzhiyu-icon-arrows-left-right"></i></a></div><div class="console-btn-item on" id="consoleCommentBarrage" onclick="anzhiyu.switchCommentBarrage()" title="热评开关"><a class="commentBarrage"><i class="anzhiyufont anzhiyu-icon-message"></i></a></div><div class="console-btn-item" id="consoleMusic" onclick="anzhiyu.musicToggle()" title="音乐开关"><a class="music-switch"><i class="anzhiyufont anzhiyu-icon-music"></i></a></div><div class="console-btn-item" id="consoleKeyboard" onclick="anzhiyu.keyboardToggle()" title="快捷键开关"><a class="keyboard-switch"><i class="anzhiyufont anzhiyu-icon-keyboard"></i></a></div></div><div class="console-mask" onclick="anzhiyu.hideConsole()" href="javascript:void(0);"></div></div><div class="nav-button" id="nav-totop"><a class="totopbtn" href="javascript:void(0);"><i class="anzhiyufont anzhiyu-icon-arrow-up"></i><span id="percent" onclick="anzhiyu.scrollToDest(0,500)">0</span></a></div><div id="toggle-menu"><a class="site-page" href="javascript:void(0);"><i class="anzhiyufont anzhiyu-icon-bars"></i></a></div></div></div></nav></header><main class="layout" id="content-inner"><div id="post"><div id="post-info"><div id="post-firstinfo"><div class="meta-firstline"><a class="post-meta-original">原创</a><span class="post-meta-categories"><span class="post-meta-separator"></span><i class="anzhiyufont anzhiyu-icon-inbox post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E5%A4%A7%E5%AD%A6%E7%94%9F%E6%B6%AF/">大学生涯</a></span><span class="article-meta tags"><a class="article-meta__tags" href="/tags/C/" tabindex="-1"> <span> <i class="anzhiyufont anzhiyu-icon-hashtag"></i>C++</span></a><a class="article-meta__tags" href="/tags/%E5%90%8E%E7%AB%AF%E5%BC%80%E5%8F%91/" tabindex="-1"> <span> <i class="anzhiyufont anzhiyu-icon-hashtag"></i>后端开发</span></a></span></div></div><h1 class="post-title">2.极客笔记</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="anzhiyufont anzhiyu-icon-calendar-days post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2023-05-04T16:00:00.000Z" title="发表于 2023-05-05 00:00:00">2023-05-05</time><span class="post-meta-separator"></span><i class="anzhiyufont anzhiyu-icon-history post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2023-05-04T16:00:00.000Z" title="更新于 2023-05-05 00:00:00">2023-05-05</time></span></div><div class="meta-secondline"><span class="post-meta-separator"></span><span class="post-meta-wordcount"><i class="anzhiyufont anzhiyu-icon-file-word post-meta-icon" title="文章字数"></i><span class="post-meta-label" title="文章字数">字数总计:</span><span class="word-count" title="文章字数">121.3k</span><span class="post-meta-separator"></span><i class="anzhiyufont anzhiyu-icon-clock post-meta-icon" title="阅读时长"></i><span class="post-meta-label" title="阅读时长">阅读时长:</span><span>370分钟</span></span><span class="post-meta-separator"></span><span class="post-meta-pv-cv" id="" data-flag-title="2.极客笔记"><i class="anzhiyufont anzhiyu-icon-fw-eye post-meta-icon"></i><span class="post-meta-label" title="阅读量">阅读量:</span><span id="busuanzi_value_page_pv"><i class="anzhiyufont anzhiyu-icon-spinner anzhiyu-spin"></i></span></span><span class="post-meta-separator">       </span><span class="post-meta-position" title="作者IP属地为郑州"><i class="anzhiyufont anzhiyu-icon-location-dot"></i>郑州</span></div></div></div><article class="post-content" id="article-container"><h2 id="极客专栏笔记"><a href="#极客专栏笔记" class="headerlink" title="极客专栏笔记"></a>极客专栏笔记</h2><h3 id="Redis核心技术与实战"><a href="#Redis核心技术与实战" class="headerlink" title="Redis核心技术与实战"></a>Redis核心技术与实战</h3><h4 id="开篇词-这样学Redis，才能技高一筹"><a href="#开篇词-这样学Redis，才能技高一筹" class="headerlink" title="开篇词 | 这样学Redis，才能技高一筹"></a>开篇词 | 这样学Redis，才能技高一筹</h4><ul>
<li><p>为了保证数据的可靠性，Redis 需要在磁盘上读写 AOF 和 RDB，但在高并发场景里，这就会直接带来两个新问题：一个是写 AOF 和RDB 会造成 Redis 性能抖动，另一个是 Redis 集群数据同步和实例恢复时，读 RDB 比较慢，限制了同步和恢复速度</p>
<ul>
<li>使用非易失内存 NVM，因为它既能保证高速的读写，又能快速持久化数据</li>
</ul>
</li>
<li><p>Redis常遇到的坑：</p>
<ul>
<li>CPU 使用上的“坑”，例如数据结构的复杂度、跨 CPU 核的访问；</li>
<li>内存使用上的“坑”，例如主从同步和 AOF 的内存竞争；</li>
<li>存储持久化上的“坑”，例如在 SSD 上做快照的性能抖动；</li>
<li>网络通信上的“坑”，例如多实例时的异常网络丢包</li>
</ul>
</li>
<li><p>Redis 知识全景图：</p>
<ul>
<li>“两大维度”就是指系统维度和应用维度</li>
<li>“三大主线”也就是指高性能、高可靠和高可扩展<ul>
<li>高性能主线，包括线程模型、数据结构、持久化、网络框架；</li>
<li>高可靠主线，包括主从复制、哨兵机制；</li>
<li>高可扩展主线，包括数据分片、负载均衡。</li>
</ul>
</li>
</ul>
</li>
<li><p>Redis 的问题画像图</p>
<img src="C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20220927224404140.png" alt="image-20220927224404140" style="zoom:67%;" /></li>
</ul>
<h4 id="02-数据结构：快速的Redis有哪些慢操作？"><a href="#02-数据结构：快速的Redis有哪些慢操作？" class="headerlink" title="02-数据结构：快速的Redis有哪些慢操作？"></a>02-数据结构：快速的Redis有哪些慢操作？</h4><ul>
<li>键和值⽤什么结构组织？为了实现从键到值的快速访问，Redis使⽤了⼀个哈希表来保存所有键值对。⼀个哈希表其实就是⼀个数组，数组的每个元素称为⼀个哈希桶。⼀个哈希表是由多个哈希桶组成的，每个哈希桶中保存了键值对数据。哈希桶中的entry元素中保存了*key和*value指针，分别指向了实际的键和值，这样⼀来，即使值是⼀个集合，也可以通过*value指针被查找到<ul>
<li>哈希表的最⼤好处很明显，就是可以⽤O(1)的时间复杂度来快速查找到键值对⸺只需要计算键的哈希值，就可以知道它所对应的哈希桶位置，然后就可以访问相应的entry元素</li>
<li>往Redis中写⼊⼤量数据后，就可能发现操作有时候会突然变慢了。这是因为⼀个潜在的⻛险点，哈希表的冲突问题和rehash可能带来的操作阻塞。如果哈希表⾥写⼊的数据越来越多，哈希冲突可能也会越来越多，这就会导致某些哈希冲突链过⻓，进⽽导致这个链上的元素查找耗时⻓，效率降低</li>
<li>Redis会对哈希表做rehash操作。rehash也就是增加现有的哈希桶数量，让逐渐增多的entry元素能在更多的桶之间分散保存，减少单个桶中的元素数量，从⽽减少单个桶中的冲突；为了使rehash操作更⾼效，Redis默认使⽤了两个全局哈希表：哈希表1和哈希表2。⼀开始刚插⼊数据时，默认使⽤哈希表1，此时的哈希表2并没有被分配空间。随着数据逐步增多，Redis开始执⾏rehash：<ul>
<li>给哈希表2分配更⼤的空间，例如是当前哈希表1⼤⼩的两倍；</li>
<li>把哈希表1中的数据重新映射并拷⻉到哈希表2中；</li>
<li>释放哈希表1的空间。</li>
</ul>
</li>
<li>第⼆步涉及⼤量的数据拷⻉，如果⼀次性把哈希表1中的数据都迁移完，会造成Redis线程阻塞，⽆法服务其他请求。此时，Redis就⽆法快速访问数据了；为了避免这个问题，Redis采⽤了渐进式rehash<ul>
<li>在第⼆步拷⻉数据时，Redis仍然正常处理客⼾端请求，每处理⼀个请求时，从哈希表1中的第⼀个索引位置开始，顺带着将这个索引位置上的所有entries拷⻉到哈希表2中；等处理下⼀个请求时，再顺带拷⻉哈希表1中的下⼀个索引位置的entries</li>
</ul>
</li>
</ul>
</li>
<li>集合数据操作效率：⼀个集合类型的值，第⼀步是通过全局哈希表找到对应的哈希桶位置，第⼆步是在集合中再增删改查<ul>
<li>⾸先，与集合的底层数据结构有关。例如，使⽤哈希表实现的集合，要⽐使⽤链表实现的集合访问效率更⾼。其次，操作效率和这些操作本⾝的执⾏特点有关，⽐如读写⼀个元素的操作要⽐读写所有元素的效率⾼。</li>
<li>集合类型的底层数据结构主要有5种：整数数组、双向链表、哈希表、压缩列表和跳表。<ul>
<li>整数数组和双向链表也很常⻅，它们的操作特征都是顺序读写，也就是通过数组下标或者链表的指针逐个元素访问，操作复杂度基本是O(N)，操作效率⽐较低；</li>
<li>压缩列表实际上类似于⼀个数组，数组中的每⼀个元素都对应保存⼀个数据。和数组不同的是，压缩列表在表头有三个字段zlbytes、zltail和zllen，分别表⽰列表⻓度、列表尾的偏移量和列表中的entry个数；压缩列表在表尾还有⼀个zlend，表⽰列表结束</li>
<li>有序链表只能逐⼀查找元素，导致操作起来⾮常缓慢，于是就出现了跳表。具体来说，跳表在链表的基础上，增加了多级索引，通过索引位置的⼏个跳转，实现数据的快速定位；数据量很⼤时，跳表的查找复杂度就是O(logN)</li>
</ul>
</li>
<li>集合类型的操作类型很多，有读写单个集合元素的，例如HGET、HSET，也有操作多个元素的，例如SADD，还有对整个集合进⾏遍历操作的，例如SMEMBERS<ul>
<li>单元素操作，是指每⼀种集合类型对单个数据实现的增删改查操作；这些操作的复杂度由集合采⽤的数据结构决定，例如，HGET、HSET和HDEL是对哈希表做操作，所以它们的复杂度都是O(1)；</li>
<li>范围操作，是指集合类型中的遍历操作，可以返回集合中的所有数据，⽐如Hash类型的HGETALL和Set类型的SMEMBERS，或者返回⼀个范围内的部分数据，⽐如List类型的LRANGE和ZSet类型的ZRANGE。这类操作的复杂度⼀般是O(N)，⽐较耗时，我们应该尽量避免</li>
<li>统计操作，是指集合类型对集合中所有元素个数的记录，例如LLEN和SCARD。这类操作复杂度只有O(1)，这是因为当集合类型采⽤压缩列表、双向链表、整数数组这些数据结构时，这些结构中专⻔记录了元素的个数统计，因此可以⾼效地完成相关操作</li>
<li>例外情况，是指某些数据结构的特殊记录，例如压缩列表和双向链表都会记录表头和表尾的偏移量。这样⼀来，对于List类型的LPOP、RPOP、LPUSH、RPUSH这四个操作来说，它们是在列表的头尾增删元素，这就可以通过偏移量直接定位，所以它们的复杂度也只有O(1)，可以实现快速操作</li>
</ul>
</li>
</ul>
</li>
</ul>
<h4 id="03-高性能IO模型：为什么单线程Redis能那么快？"><a href="#03-高性能IO模型：为什么单线程Redis能那么快？" class="headerlink" title="03-高性能IO模型：为什么单线程Redis能那么快？"></a>03-高性能IO模型：为什么单线程Redis能那么快？</h4><ul>
<li><p>Redis是单线程，主要是指Redis的⽹络IO和键值对读写是由⼀个线程来完成的，这也是Redis对外提供键值存储服务的主要流程。但Redis的其他功能，⽐如持久化、异步删除、集群数据同步等，其实是由额外的线程执⾏的</p>
</li>
<li><p>多线程的开销：系统中通常会存在被多线程同时访问的共享资源，⽐如⼀个共享的数据结构。当有多个线程要修改这个共享资源时，为了保证共享资源的正确性，就需要有额外的机制进⾏保证；并发访问控制一直是多线程开发中的一个难点问题，如果没有精细的设计，比如说，只是简单地采用一个粗粒度互斥锁，就会出现不理想的结果：即使增加了线程，大部分线程也在等待获取访问共享资源的互斥锁，并行变串行，系统吞吐率并没有随着线程的增加而增加；采用多线程开发一般会引入同步原语来保护共享资源的并发访问，这也会降低系统代码的易调试性和可维护性。为了避免这些问题，Redis 直接采用了单线程模式</p>
</li>
<li><p>单线程 Redis 为什么那么快？一方面，Redis 的大部分操作在内存上完成，再加上它采用了高效的数据结构，例如哈希表和跳表，这是它实现高性能的一个重要原因；另一方面，就是 Redis 采用了多路复用机制，使其在网络 IO 操作中能并发处理大量的客户端请求，实现高吞吐率</p>
<ul>
<li>网络 IO 操作中，有潜在的阻塞点，分别是 accept() 和 recv()。当 Redis监听到一个客户端有连接请求，但一直未能成功建立起连接时，会阻塞在 accept() 函数这里，导致其他客户端无法和 Redis 建立连接。类似的，当 Redis 通过 recv() 从一个客户端读取数据时，如果数据一直没有到达，Redis 也会一直阻塞在 recv()。</li>
<li>Socket 网络模型的非阻塞模式设置，主要体现在三个关键的函数调用上；在 socket 模型中，不同操作调用后会返回不同的套接字类型。socket() 方法会返回主动套接字，然后调用 listen() 方法，将主动套接字转化为监听套接字，此时，可以监听来自客户端的连接请求。最后，调用 accept() 方法接收到达的客户端连接，并返回已连接套接字</li>
<li>基于多路复用的高性能 I&#x2F;O 模型，该机制允许内核中，同时存在多个监听套接字和已连接套接字；为了在请求到达时能通知到 Redis 线程，select&#x2F;epoll 提供了基于事件的回调机制，即针对不同事件的发生，调用相应的处理函数</li>
</ul>
</li>
</ul>
<h4 id="04-AOF日志：宕机了，Redis如何避免数据丢失？"><a href="#04-AOF日志：宕机了，Redis如何避免数据丢失？" class="headerlink" title="04 | AOF日志：宕机了，Redis如何避免数据丢失？"></a>04 | AOF日志：宕机了，Redis如何避免数据丢失？</h4><ul>
<li><p>数据库的写前日志（Write Ahead Log, WAL）在实际写数据前，先把修改的数据记到日志文件中，以便故障时进行恢复。不过，AOF 日志正好相反，它是写后日志，Redis 是先执行命令，把数据写入内存，然后才记录日志</p>
<ul>
<li>传统数据库的日志，例如 redo log（重做日志），记录的是修改后的数据，而 AOF 里记录的是 Redis 收到的每一条命令，这些命令是以文本形式保存的。</li>
<li>为了避免额外的检查开销，Redis 在向 AOF 里面记录日志的时候，并不会先去对这些命令进行语法检查。所以，如果先记日志再执行命令的话，日志中就有可能记录了错误的命令，Redis 在使用日志恢复数据时，就可能会出错。</li>
<li>在命令执行后才记录日志，所以不会阻塞当前的写操作。</li>
</ul>
</li>
<li><p>AOF 两个潜在的风险</p>
<ul>
<li>如果刚执行完一个命令，还没有来得及记日志就宕机了，那么这个命令和相应的数据就有丢失的风险。</li>
<li>AOF 虽然避免了对当前命令的阻塞，但可能会给下一个操作带来阻塞风险。这是因为，AOF 日志也是在主线程中执行的，如果在把日志文件写入磁盘时，磁盘写压力大，就会导致写盘很慢，进而导致后续的操作也无法执行了</li>
</ul>
</li>
<li><p>三种写回策略：</p>
<ul>
<li>Always，同步写回：每个写命令执行完，立马同步地将日志写回磁盘；</li>
<li>Everysec，每秒写回：每个写命令执行完，只是先把日志写到 AOF 文件的内存缓冲区，每隔一秒把缓冲区中的内容写入磁盘；</li>
<li>No，操作系统控制的写回：每个写命令执行完，只是先把日志写到 AOF 文件的内存缓冲区，由操作系统决定何时将缓冲区内容写回磁盘。</li>
</ul>
</li>
<li><p>AOF 是以文件的形式在记录接收到的所有写命令。随着接收的写命令越来越多，AOF 文件会越来越大。要小心 AOF 文件过大带来的性能问题。主要在于以下三个方面：一是，文件系统本身对文件大小有限制，无法保存过大的文件；二是，如果文件太大，之后再往里面追加命令记录的话，效率也会变低；三是，如果发生宕机，AOF 中记录的命令要一个个被重新执行，用于故障恢复，如果日志文件太大，整个恢复过程就会非常缓慢，这就会影响到 Redis 的正常使用。</p>
</li>
<li><p>AOF 重写机制就是在重写时，Redis 根据数据库的现状创建一个新的 AOF 文件，也就是说，读取数据库中的所有键值对，然后对每一个键值对用一条命令记录它的写入</p>
<ul>
<li>和 AOF 日志由主线程写回不同，重写过程是由后台线程 bgrewriteaof 来完成的，这也是为了避免阻塞主线程，导致数据库性能下降；重写的过程总结为“一个拷贝，两处日志”</li>
<li>“一个拷贝”就是指，每次执行重写时，主线程 fork 出后台的 bgrewriteaof 子进程。此时，fork 会把主线程的内存拷贝一份给 bgrewriteaof 子进程，这里面就包含了数据库的最新数据。然后，bgrewriteaof 子进程就可以在不影响主线程的情况下，逐一把拷贝的数据写成操作，记入重写日志。</li>
<li>因为主线程未阻塞，仍然可以处理新来的操作。此时，如果有写操作，第一处日志就是指正在使用的 AOF 日志，Redis 会把这个操作写到它的缓冲区。这样一来，即使宕机了，这个 AOF 日志的操作仍然是齐全的，可以用于恢复。</li>
<li>而第二处日志，就是指新的 AOF 重写日志。这个操作也会被写到重写日志的缓冲区。这样，重写日志也不会丢失最新的操作。等到拷贝数据的所有操作记录重写完成后，重写日志记录的这些最新操作也会写入新的 AOF 文件，以保证数据库最新状态的记录。</li>
</ul>
</li>
<li><p>在“用日志”的过程中，也就是使用 AOF 进行故障恢复时，我们仍然需要把所有的操作记录都运行一遍。再加上 Redis 的单线程设计，这些命令操作只能一条一条按顺序执行，这个“重放”的过程就会很慢了</p>
</li>
</ul>
<h4 id="05-内存快照：宕机后，Redis如何实现快速恢复？"><a href="#05-内存快照：宕机后，Redis如何实现快速恢复？" class="headerlink" title="05 | 内存快照：宕机后，Redis如何实现快速恢复？"></a>05 | 内存快照：宕机后，Redis如何实现快速恢复？</h4><ul>
<li><p>所谓内存快照，就是指内存中的数据在某一个时刻的状态记录，对 Redis 来说，就是把某一时刻的状态以文件的形式写到磁盘上，即使宕机，快照文件也不会丢失，数据的可靠性也就得到了保证。这个快照文件就称为 RDB 文件，其中，RDB 就是 Redis DataBase 的缩写</p>
</li>
<li><p>和 AOF 相比，RDB 记录的是某一时刻的数据，并不是操作，所以，在做数据恢复时可以直接把 RDB 文件读入内存，很快地完成恢复</p>
</li>
<li><p>给哪些内存数据做快照？</p>
<ul>
<li>Redis 的数据都在内存中，为了提供所有数据的可靠性保证，它执行的是全量快照，把内存中的所有数据都记录到磁盘中，这样做的好处是，一次性记录了所有数据，一个都不少。全量数据越多，RDB 文件就越大，往磁盘上写数据的时间开销就越大；</li>
<li>RDB 文件的生成是否会阻塞主线程，这就关系到是否会降低 Redis 的性能。Redis 提供了两个命令来生成 RDB 文件，分别是 save 和 bgsave<ul>
<li>save：在主线程中执行，会导致阻塞；</li>
<li>bgsave：创建一个子进程，专门用于写入 RDB 文件，避免了主线程的阻塞，这也是Redis RDB 文件生成的默认配置。</li>
</ul>
</li>
<li>可以通过 bgsave 命令来执行全量快照，这既提供了数据的可靠性保证，也避免了对 Redis 的性能影响</li>
</ul>
</li>
<li><p>快照时数据能修改吗?</p>
<ul>
<li>如果快照执行期间数据不能被修改，是会有潜在问题的。在做快照的 20s 时间里，如果这 4GB 的数据都不能被修改，Redis 就不能处理对这些数据的写操作，那无疑就会给业务服务造成巨大的影响。<ul>
<li>避免阻塞和正常处理写操作并不是一回事。此时，主线程的确没有阻塞，可以正常接收请求，但是为了保证快照完整性，它只能处理读操作，因为不能修改正在执行快照的数据。</li>
</ul>
</li>
<li>Redis 就会借助操作系统提供的写时复制技术（Copy-On-Write, COW），在执行快照的同时，正常处理写操作<ul>
<li>bgsave 子进程是由主线程 fork 生成的，可以共享主线程的所有内存数据。bgsave 子进程运行后，开始读取主线程的内存数据，并把它们写入 RDB 文件</li>
<li>如果主线程要修改一块数据，这块数据就会被复制一份，生成该数据的副本。然后，bgsave 子进程会把这个副本数据写入 RDB 文件，而在这个过程中，主线程仍然可以直接修改原来的数据</li>
</ul>
</li>
</ul>
</li>
<li><p>可以每秒做一次快照吗？</p>
<ul>
<li>虽然 bgsave 执行时不阻塞主线程，但是如果频繁地执行全量快照，也会带来两方面的开销<ul>
<li>会给磁盘带来很大压力，多个快照竞争有限的磁盘带宽，前一个快照还没有做完，后一个又开始做了，容易造成恶性循环</li>
<li>bgsave 子进程需要通过 fork 操作从主线程创建出来。虽然，子进程在创建后不会再阻塞主线程，但是，fork 这个创建过程本身会阻塞主线程，而且主线程的内存越大，阻塞时间越长。如果频繁 fork 出 bgsave 子进程，这就会频繁阻塞主线程了</li>
</ul>
</li>
<li>可以做增量快照，所谓增量快照，就是指，做了一次全量快照后，后续的快照只对修改的数据进行快照记录，这样可以避免每次全量快照的开销，但是如果有 1 万个被修改的键值对，就需要有 1 万条额外的记录，额外空间开销比较大</li>
</ul>
</li>
<li><p><strong>混合使用 AOF 日志和内存快照的方法</strong>：内存快照以一定的频率执行，在两次快照之间，使用 AOF 日志记录这期间的所有命令操作，以较小的性能开销保证数据可靠性和性能</p>
</li>
<li><p>使用建议：</p>
<ul>
<li>数据不能丢失时，内存快照和 AOF 的混合使用是一个很好的选择；</li>
<li>如果允许分钟级别的数据丢失，可以只使用 RDB；</li>
<li>如果只用 AOF，优先使用 everysec 的配置选项，因为它在可靠性和性能之间取了一个平衡。</li>
</ul>
</li>
</ul>
<h4 id="06-数据同步：主从库如何实现数据一致？"><a href="#06-数据同步：主从库如何实现数据一致？" class="headerlink" title="06 | 数据同步：主从库如何实现数据一致？"></a>06 | 数据同步：主从库如何实现数据一致？</h4><ul>
<li><p>Redis 具有高可靠性其实有两层含义：一是数据尽量少丢失，二是服务尽量少中断。AOF 和 RDB 保证了前者，而对于后者，Redis 的做法就是增加副本冗余量，将一份数据同时保存在多个实例上。即使有一个实例出现了故障，需要过一段时间才能恢复，其他实例也可以对外提供服务，不会影响业务使用。</p>
<ul>
<li>这带来一个问题：这么多副本，它们之间的数据如何保持一致呢？数据读写操作可以发给所有的实例吗？</li>
</ul>
</li>
<li><p>实际上，Redis 提供了主从库模式，以保证数据副本的一致，主从库之间采用的是读写分离的方式</p>
<ul>
<li>读操作：主库、从库都可以接收；</li>
<li>写操作：首先到主库执行，然后，主库将写操作同步给从库</li>
</ul>
</li>
<li><p>为什么要采用读写分离的方式呢？</p>
<ul>
<li>如果不管是主库还是从库，都能接收客户端的写操作，一个直接的问题就是：如果客户端对同一个数据前后修改了三次，每一次的修改请求都发送到不同的实例上，在不同的实例上执行，这个数据在这三个实例上的副本就不一致了；非要保持这个数据在三个实例上一致，就要涉及到加锁、实例间协商是否完成修改等一系列操作，但这会带来巨额的开销，当然是不太能接受的。</li>
<li>而主从库模式一旦采用了读写分离，所有数据的修改只会在主库上进行，不用协调三个实例。主库有了最新的数据后，会同步给从库，这样，主从库的数据就是一致的</li>
</ul>
</li>
<li><p>主从库间如何进行第一次同步？</p>
<ul>
<li>启动多个 Redis 实例的时候，它们相互之间就可以通过 replicaof（Redis 5.0 之前使用 slaveof）命令形成主库和从库的关系，之后会按照三个阶段完成数据的第一次同步。</li>
<li>第一阶段是主从库间建立连接、协商同步的过程，主要是为全量复制做准备。在这一步，从库和主库建立起连接，并告诉主库即将进行同步，主库确认回复后，主从库间就可以开始同步了<ul>
<li>从库给主库发送 psync 命令，表示要进行数据同步，主库根据这个命令的参数来启动复制。psync 命令包含了主库的 runID 和复制进度 offset 两个参数。</li>
<li>主库收到 psync 命令后，会用 FULLRESYNC 响应命令带上两个参数：主库 runID 和主库目前的复制进度 offset，返回给从库。从库收到响应后，会记录下这两个参数。FULLRESYNC 响应表示第一次复制采用的全量复制，也就是说，主库会把当前所有的数据都复制给从库</li>
</ul>
</li>
<li>在第二阶段，主库将所有数据同步给从库。从库收到数据后，在本地完成数据加载。这个过程依赖于内存快照生成的 RDB 文件<ul>
<li>主库执行 bgsave 命令，生成 RDB 文件，接着将文件发给从库。从库接收到RDB 文件后，会先清空当前数据库，然后加载 RDB 文件。这是因为从库在通过 replicaof 命令开始和主库同步前，可能保存了其他数据。为了避免之前数据的影响，从库需要先把当前数据库清空。</li>
<li>在主库将数据同步给从库的过程中，主库不会被阻塞，仍然可以正常接收请求，但是这些请求中的写操作并没有记录到刚刚生成的 RDB 文件，为了保证主从库的数据一致性，主库会在内存中用专门的 replication buffer，记录RDB 文件生成后收到的所有写操作。</li>
</ul>
</li>
<li>第三个阶段，主库会把第二阶段执行过程中新收到的写命令，再发送给从库。具体的操作是，当主库完成 RDB 文件发送后，就会把此时 replication buffer 中的修改操作发给从库，从库再重新执行这些操作。</li>
</ul>
</li>
<li><p>主从级联模式分担全量复制时的主库压力</p>
<ul>
<li>一次全量复制中，对于主库来说，需要完成两个耗时的操作：生成 RDB 文件和传输 RDB 文件。如果从库数量很多，而且都要和主库进行全量复制的话，就会导致主库忙于 fork 子进程生成 RDB 文件，进行数据全量同步。fork 这个操作会阻塞主线程处理正常请求，从而导致主库响应应用程序的请求速度变慢</li>
<li>可以通过“主 - 从 - 从”模式将主库生成 RDB 和传输 RDB 的压力，以级联的方式分散到从库上</li>
<li>一旦主从库完成了全量复制，它们之间就会一直维护一个网络连接，主库会通过这个连接将后续陆续收到的命令操作再同步给从库，这个过程也称为基于长连接的命令传播，可以避免频繁建立连接的开销；不可忽视的是，这个过程中存在着风险点，最常见的就是网络断连或阻塞</li>
</ul>
</li>
<li><p>主从库间网络断了怎么办？</p>
<ul>
<li>从 Redis 2.8 开始，网络断了之后，主从库会采用增量复制的方式继续同步。当主从库断连后，主库会把断连期间收到的写操作命令，写入 replication buffer，同时也会把这些操作命令也写入 repl_backlog_buffer 这个缓冲区。<ul>
<li>repl_backlog_buffer 是一个环形缓冲区，主库会记录自己写到的位置，从库则会记录自己已经读到的位置。</li>
<li>从库在复制完写操作命令后，它在缓冲区中的读位置也开始逐步偏移刚才的起始位置，此时，从库已复制的偏移量 slave_repl_offset 也在不断增加</li>
<li>主从库的连接恢复之后，从库首先会给主库发送 psync 命令，并把自己当前的slave_repl_offset 发给主库，主库会判断自己的 master_repl_offset 和 slave_repl_offset之间的差距。</li>
</ul>
</li>
<li>在网络断连阶段，主库可能会收到新的写操作命令，所以，一般来说，master_repl_offset会大于 slave_repl_offset。此时，主库只用把 master_repl_offset 和 slave_repl_offset之间的命令操作同步给从库就行。</li>
<li>因为 repl_backlog_buffer 是一个环形缓冲区，所以在缓冲区写满后，主库会继续写入，此时，就会覆盖掉之前写入的操作。如果从库的读取速度比较慢，就有可能导致从库还未读取的操作被主库新写的操作覆盖了，这会导致主从库间的数据不一致</li>
<li>在实际应用中，考虑到可能存在一些突发的请求压力，我们通常需要把这个缓冲空间扩大一倍，即repl_backlog_size &#x3D; 缓冲空间大小 * 2，这也就是 repl_backlog_size 的最终值</li>
</ul>
</li>
<li><p>一个 Redis 实例的数据库不要太大，一个实例大小在几 GB 级别比较合适，这样可以减少 RDB 文件生成、传输和重新加载的开销</p>
</li>
</ul>
<h4 id="07-哨兵机制：主库挂了，如何不间断服务？"><a href="#07-哨兵机制：主库挂了，如何不间断服务？" class="headerlink" title="07 | 哨兵机制：主库挂了，如何不间断服务？"></a>07 | 哨兵机制：主库挂了，如何不间断服务？</h4><ul>
<li><p>如果主库发生故障了，那就直接会影响到从库的同步，因为从库没有相应的主库可以进行数据复制操作了，一旦有写操作请求了，按照主从库模式下的读写分离要求，需要由主库来完成写操作。此时，也没有实例可以来服务客户端的写操作请求。所以，如果主库挂了，我们就需要运行一个新主库，比如说把一个从库切换为主库，把它当成主库</p>
</li>
<li><p>在 Redis 主从集群中，哨兵机制是实现主从库自动切换的关键机制，它有效地解决了主从复制模式下故障转移的三个问题</p>
<ul>
<li>主库真的挂了吗？</li>
<li>该选择哪个从库作为主库？</li>
<li>怎么把新主库的相关信息通知给从库和客户端呢？</li>
</ul>
</li>
<li><p>哨兵机制的基本流程：</p>
<ul>
<li>哨兵其实就是一个运行在特殊模式下的 Redis 进程，主从库实例运行的同时，它也在运行。哨兵主要负责的就是三个任务：监控、选主（选择主库）和通知</li>
<li>监控是指哨兵进程在运行时，周期性地给所有的主从库发送 PING 命令，检测它们是否仍然在线运行。如果从库没有在规定时间内响应哨兵的 PING 命令，哨兵就会把它标记为“下线状态”；同样，如果主库也没有在规定时间内响应哨兵的 PING 命令，哨兵就会判定主库下线，然后开始自动切换主库的流程。</li>
<li>主库挂了以后，哨兵就需要从很多个从库里，按照一定的规则选择一个从库实例，把它作为新的主库。这一步完成后，现在的集群里就有了新主库。</li>
<li>在执行通知任务时，哨兵会把新主库的连接信息发给其他从库，让它们执行 replicaof 命令，和新主库建立连接，并进行数据复制。同时，哨兵会把新主库的连接信息通知给客户端，让它们把请求操作发到新主库上。</li>
<li>在监控和选主这两个任务中，哨兵需要做出两个决策：<ul>
<li>在监控任务中，哨兵需要判断主库是否处于下线状态</li>
<li>在选主任务中，哨兵也要决定选择哪个从库实例作为主库。</li>
</ul>
</li>
</ul>
</li>
<li><p>主观下线和客观下线</p>
<ul>
<li>哨兵进程会使用 PING 命令检测它自己和主、从库的网络连接情况，用来判断实例的状态。如果哨兵发现主库或从库对 PING 命令的响应超时了，那么，哨兵就会先把它标记为“主观下线”；<ul>
<li>如果检测的是从库，那么，哨兵简单地把它标记为“主观下线”就行了，因为从库的下线影响一般不太大，集群的对外服务不会间断。</li>
<li>如果检测的是主库，那么，哨兵还不能简单地把它标记为“主观下线”，开启主从切换。因为很有可能存在这么一个情况：那就是哨兵误判了，其实主库并没有故障。可是，一旦启动了主从切换，后续的选主和通知操作都会带来额外的计算和通信开销。误判一般会发生在集群网络压力较大、网络拥塞，或者是主库本身压力较大的情况</li>
</ul>
</li>
<li>哨兵机制通常会采用多实例组成的集群模式进行部署，这也被称为哨兵集群。引入多个哨兵实例一起来判断，就可以避免单个哨兵因为自身网络状况不好而误判；同时，多个哨兵的网络同时不稳定的概率较小，由它们一起做决策，误判率也能降低。</li>
<li>在判断主库是否下线时，不能由一个哨兵说了算，只有大多数的哨兵实例，都判断主库已经“主观下线”了，主库才会被标记为“客观下线”，这个叫法也是表明主库下线成为一个客观事实了。这个判断原则就是：少数服从多数。同时，这会进一步触发哨兵开始主从切换流程。</li>
<li>“客观下线”的标准就是，当有 N 个哨兵实例时，最好要有 N&#x2F;2 + 1 个实例判断主库为“主观下线”，才能最终判定主库为“客观下线”。这样一来，就可以减少误判的概率，也能避免误判带来的无谓的主从库切换</li>
</ul>
</li>
<li><p>如何选定新主库？</p>
<ul>
<li>在多个从库中，先按照一定的筛选条件，把不符合条件的从库去掉。然后，我们再按照一定的规则，给剩下的从库逐个打分，将得分最高的从库选为新主库</li>
<li>一般情况下，我们肯定要先保证所选的从库仍然在线运行。不过，在选主时从库正常在线，这只能表示从库的现状良好，并不代表它就是最适合做主库的; 所以，在选主时，除了要检查从库的当前在线状态，还要判断它之前的网络连接状态。如果从库总是和主库断连，而且断连次数超出了一定的阈值，这个从库的网络状况并不是太好，就可以把这个从库筛掉了。使用配置项 down-after-milliseconds * 10</li>
<li>分别按照三个规则依次进行三轮打分，这三个规则分别是从库优先级、从库复制进度以及从库 ID 号。只要在某一轮中，有从库得分最高，那么它就是主库了，选主过程到此结束。如果没有出现得分最高的从库，那么就继续进行下一轮。</li>
</ul>
</li>
</ul>
<h4 id="08-哨兵集群：哨兵挂了，主从库还能切换吗？"><a href="#08-哨兵集群：哨兵挂了，主从库还能切换吗？" class="headerlink" title="08 | 哨兵集群：哨兵挂了，主从库还能切换吗？"></a>08 | 哨兵集群：哨兵挂了，主从库还能切换吗？</h4><ul>
<li><p>一旦多个实例组成了哨兵集群，即使有哨兵实例出现故障挂掉了，其他哨兵还能继续协作完成主从库切换的工作，包括判定主库是不是处于下线状态，选择新主库，以及通知从库和客户端。在配置哨兵的信息时，只需设置主库的 IP 和端口，并没有配置其他哨兵的连接信息。</p>
</li>
<li><p>基于 pub&#x2F;sub 机制的哨兵集群组成</p>
<ul>
<li>哨兵实例之间可以相互发现，要归功于 Redis 提供的 pub&#x2F;sub 机制，也就是发布 &#x2F; 订阅机制。</li>
<li>哨兵只要和主库建立起了连接，就可以在主库上发布消息了，比如说发布它自己的连接信息（IP 和端口）。同时，它也可以从主库上订阅消息，获得其他哨兵发布的连接信息。当多个哨兵实例都在主库上做了发布和订阅操作后，它们之间就能知道彼此的 IP 地址和端口</li>
<li>除了哨兵实例，自己编写的应用程序也可以通过 Redis 进行消息的发布和订阅。所以，为了区分不同应用的消息，Redis 会以频道的形式，对这些消息进行分门别类的管理。所谓的频道，实际上就是消息的类别。当消息类别相同时，它们就属于同一个频道。反之，就属于不同的频道。只有订阅了同一个频道的应用，才能通过发布的消息进行信息交换</li>
<li>主从集群中，主库上有一个名为“_<em>sentinel</em>_:hello”的频道，不同哨兵就是通过它来相互发现，实现互相通信的。</li>
<li>哨兵除了彼此之间建立起连接形成集群外，还需要和从库建立连接。这是因为，在哨兵的监控任务中，它需要对主从库都进行心跳判断，而且在主从库切换完成后，它还需要通知从库，让它们和新主库进行同步。</li>
<li>哨兵是如何知道从库的 IP 地址和端口的呢？这是由哨兵向主库发送 INFO 命令来完成的。哨兵 2 给主库发送 INFO 命令，主库接受到这个命令后，就会把从库列表返回给哨兵。接着，哨兵就可以根据从库列表中的连接信息，和每个从库建立连接，并在这个连接上持续地对从库进行监控。哨兵 1和 3 可以通过相同的方法和从库建立连接</li>
</ul>
</li>
<li><p>基于 pub&#x2F;sub 机制的客户端事件通知</p>
<ul>
<li>哨兵不能只和主、从库连接。因为，主从库切换后，客户端也需要知道新主库的连接信息，才能向新主库发送请求操作。所以，哨兵还需要完成把新主库的信息告诉客户端这个任务。仍然可以依赖 pub&#x2F;sub 机制，来帮助我们完成哨兵和客户端间的信息同步。</li>
<li>从本质上说，哨兵就是一个运行在特定模式下的 Redis 实例，只不过它并不服务请求操作，只是完成监控、选主和通知的任务。所以，每个哨兵实例也提供 pub&#x2F;sub 机制，客户端可以从哨兵订阅消息。哨兵提供的消息订阅频道有很多，不同频道包含了主从库切换过程中的不同关键事件。</li>
<li>客户端读取哨兵的配置文件后，可以获得哨兵的地址和端口，和哨兵建立网络连接。然后，可以在客户端执行订阅命令，来获取不同的事件消息。</li>
<li>当哨兵把新主库选择出来后，客户端就会看到下面的 switch-master 事件。这个事件表示主库已经切换了，新主库的 IP 地址和端口信息已经有了。这个时候，客户端就可以用这里面的新主库地址和端口进行通信了。</li>
</ul>
</li>
<li><p>由哪个哨兵执行主从切换？</p>
<ul>
<li>确定由哪个哨兵执行主从切换的过程，和主库“客观下线”的判断过程类似，也是一个“投票仲裁”的过程</li>
<li>哨兵集群要判定主库“客观下线”，需要有一定数量的实例都认为该主库已经“主观下线”了；任何一个实例只要自身判断主库“主观下线”后，就会给其他实例发送 is-master-downby-addr 命令。接着，其他实例会根据自己和主库的连接情况，做出 Y 或 N 的响应，Y 相当于赞成票，N 相当于反对票。一个哨兵获得了仲裁所需的赞成票数后，就可以标记主库为“客观下线”。这个所需的赞成票数是通过哨兵配置文件中的 quorum 配置项设定的。</li>
<li>此时，这个哨兵就可以再给其他哨兵发送命令，表明希望由自己来执行主从切换，并让所有其他哨兵进行投票。这个投票过程称为“Leader 选举”。因为最终执行主从切换的哨兵称为 Leader，投票过程就是确定 Leader。</li>
<li>在投票过程中，任何一个想成为 Leader 的哨兵，要满足两个条件：第一，拿到半数以上的赞成票；第二，拿到的票数同时还需要大于等于哨兵配置文件中的 quorum 值。</li>
<li>需要注意的是，如果哨兵集群只有 2 个实例，此时，一个哨兵要想成为 Leader，必须获得2 票，而不是 1 票。所以，如果有个哨兵挂掉了，那么，此时的集群是无法进行主从库切<br>换的。因此，通常至少会配置 3 个哨兵实例。</li>
</ul>
</li>
<li><p>要保证所有哨兵实例的配置是一致的，尤其是主观下线的判断值 down-after-milliseconds。这个值在不同的哨兵实例上配置不一致，导致哨兵集群一直没有对有故障的主库形成共识，也就没有及时切换主库，最终的结果就是集群服务不稳定</p>
</li>
</ul>
<h4 id="09-切片集群：数据增多了，是该加内存还是加实例？"><a href="#09-切片集群：数据增多了，是该加内存还是加实例？" class="headerlink" title="09 | 切片集群：数据增多了，是该加内存还是加实例？"></a>09 | 切片集群：数据增多了，是该加内存还是加实例？</h4><ul>
<li>在使用 RDB 进行持久化时，Redis 会 fork 子进程来完成，fork 操作的用时和 Redis 的数据量是正相关的，而 fork 在执行时会阻塞主线程。数据量越大，fork 操作造成的主线程阻塞的时间越长。所以，在使用 RDB 对 25GB 的数据进行持久化时，数据量较大，后台运行的子进程在 fork 创建时阻塞了主线程，于是就导致Redis 响应变慢了。虽然组建切片集群比较麻烦，但是它可以保存大量数据，而且对Redis 主线程的阻塞影响较小。</li>
<li>切片集群，也叫分片集群，就是指启动多个 Redis 实例组成一个集群，然后按照一定的规则，把收到的数据划分成多份，每一份用一个实例来保存。如果把 25GB 的数据平均分成 5 份（当然，也可以不做均分），使用 5 个实例来保存，每个实例只需要保存 5GB 数据；那么，在切片集群中，实例在为 5GB 数据生成 RDB 时，数据量就小了很多，fork 子进程一般不会给主线程带来较长时间的阻塞。采用多个实例保存数据切片后，我们既能保存25GB 数据，又避免了 fork 子进程阻塞主线程而导致的响应突然变慢</li>
<li>如何保存更多数据？<ul>
<li>为了保存大量数据，使用了大内存云主机和切片集群两种方法。实际上，这两种方法分别对应着 Redis 应对数据量增多的两种方案：纵向扩展（scale up）和横向扩展（scale out）。</li>
<li>纵向扩展：升级单个 Redis 实例的资源配置，包括增加内存容量、增加磁盘容量、使用更高配置的 CPU。原来的实例内存是 8GB，硬盘是 50GB，纵向扩展后，内存增加到 24GB，磁盘增加到 150GB。<ul>
<li>纵向扩展的好处是，实施起来简单、直接。不过，这个方案也面临两个潜在的问题。</li>
<li>第一个问题是，当使用 RDB 对数据进行持久化时，如果数据量增加，需要的内存也会增加，主线程 fork 子进程时就可能会阻塞。不过，如果你不要求持久化保存 Redis 数据，那么，纵向扩展会是一个不错的选择。</li>
<li>第二个问题：纵向扩展会受到硬件和成本的限制。这很容易理解，毕竟，把内存从 32GB 扩展到 64GB 还算容易，但是，要想扩充到 1TB，就会面临硬件容量和成本上的限制了。</li>
</ul>
</li>
<li>横向扩展：横向增加当前 Redis 实例的个数，原来使用 1 个 8GB 内存、50GB 磁盘的实例，现在使用三个相同配置的实例；在面向百万、千万级别的用户规模时，横向扩展的 Redis 切片集群会是一个非常好的选择<ul>
<li>在只使用单个实例的时候，数据存在哪儿，客户端访问哪儿，都是非常明确的，但是，切片集群不可避免地涉及到多个实例的分布式管理问题</li>
</ul>
</li>
</ul>
</li>
<li>数据切片和实例的对应分布关系<ul>
<li>切片集群是一种保存大量数据的通用机制，这个机制可以有不同的实现方案。在Redis 3.0 之前，官方并没有针对切片集群提供具体的方案。从 3.0 开始，官方提供了一个名为 Redis Cluster 的方案，用于实现切片集群。Redis Cluster 方案中就规定了数据和实例的对应规则。</li>
<li>Redis Cluster 方案采用哈希槽（Hash Slot），来处理数据和实例之间的映射关系。在 Redis Cluster 方案中，一个切片集群共有 16384个哈希槽，这些哈希槽类似于数据分区，每个键值对都会根据它的 key，被映射到一个哈希槽中。<ul>
<li>具体的映射过程分为两大步：首先根据键值对的 key，按照 CRC16 算法计算一个 16 bit的值；然后，再用这个 16bit 值对 16384 取模，得到 0~16383 范围内的模数，每个模数代表一个相应编号的哈希槽</li>
<li>在部署 Redis Cluster 方案时，可以使用 cluster create 命令创建集群，此时，Redis会自动把这些槽平均分布在集群实例上。例如，如果集群中有 N 个实例，那么，每个实例上的槽个数为 16384&#x2F;N 个。也可以使用 cluster meet 命令手动建立实例间的连接，形成集群，再使用cluster addslots 命令，指定每个实例上的哈希槽个数。在手动分配哈希槽时，需要把 16384 个槽都分配完，否则Redis 集群无法正常工作。</li>
</ul>
</li>
</ul>
</li>
<li>客户端如何定位数据？<ul>
<li>在定位键值对数据时，它所处的哈希槽是可以通过计算得到的，这个计算可以在客户端发送请求时来执行。但是，要进一步定位到实例，还需要知道哈希槽分布在哪个实例上</li>
<li>客户端和集群实例建立连接后，实例就会把哈希槽的分配信息发给客户端。但是，在集群刚刚创建的时候，每个实例只知道自己被分配了哪些哈希槽，是不知道其他实例拥有的哈希槽信息的。Redis 实例会把自己的哈希槽信息发给和它相连接的其它实例，来完成哈希槽分配信息的扩散。当实例之间相互连接后，每个实例就有所有哈希槽的映射关系了。</li>
<li>客户端收到哈希槽信息后，会把哈希槽信息缓存在本地。当客户端请求键值对时，会先计算键所对应的哈希槽，然后就可以给相应的实例发送请求了。</li>
<li>在集群中，实例和哈希槽的对应关系并不是一成不变的，最常见的变化有两个：<ul>
<li>在集群中，实例有新增或删除，Redis 需要重新分配哈希槽；</li>
<li>为了负载均衡，Redis 需要把哈希槽在所有实例上重新分布一遍。</li>
</ul>
</li>
<li>Redis Cluster 方案提供了一种重定向机制，所谓的“重定向”，就是指，客户端给一个实例发送数据读写操作时，这个实例上并没有相应的数据，客户端要再给一个新实例发送操作命令。当客户端把一个键值对的操作请求发给一个实例时，如果这个实例上并没有这个键值对映射的哈希槽，那么，这个实例就会给客户端返回的 MOVED 命令响应结果，这个结果中就包含了新实例的访问地址</li>
<li>种迁移部分完成的情况下，客户端就会收到一条 ASK 报错信息，ASK 命令表示两层含义：第一，表明 Slot 数据还在迁移中；第二，ASK 命令把客户端所请求数据的最新实例地址返回给客户端。和 MOVED 命令不同，ASK 命令并不会更新客户端缓存的哈希槽分配信息。</li>
</ul>
</li>
</ul>
<h4 id="10-第1～9讲课后思考题答案及常见问题答疑"><a href="#10-第1～9讲课后思考题答案及常见问题答疑" class="headerlink" title="10 | 第1～9讲课后思考题答案及常见问题答疑"></a>10 | 第1～9讲课后思考题答案及常见问题答疑</h4><ul>
<li><p>和跟 Redis 相比，SimpleKV 还缺少什么？（Redis的优势）</p>
<ul>
<li>数据结构：缺乏广泛的数据结构支持，比如支持范围查询的 SkipList 和 Stream 等数据结构	</li>
<li>高可用：缺乏哨兵或者 master-slave 模式的高可用设计；</li>
<li>横向扩展：缺乏集群和分片功能；</li>
<li>内存安全性：缺乏内存过载时的 key 淘汰算法的支持；</li>
<li>内存利用率：没有充分对数据结构进行优化，提高内存利用率，例如使用压缩性的数据结构；</li>
<li>功能扩展：需要具备后续功能的拓展；</li>
<li>不具备事务性：无法保证多个操作的原子性。</li>
</ul>
</li>
<li><p>整数数组和压缩列表作为底层数据结构的优势是什么？</p>
<ul>
<li>整数数组和压缩列表的设计，充分体现了 Redis“又快又省”特点中的“省”，也就是节省内存空间。整数数组和压缩列表都是在内存中分配一块地址连续的空间，然后把集合中的元素一个接一个地放在这块空间内，非常紧凑。因为元素是挨个连续放置的，我们不用再通过额外的指针把元素串接起来，这就避免了额外指针带来的空间开销。</li>
<li>Redis 之所以采用不同的数据结构，其实是在性能和内存使用效率之间进行的平衡。</li>
</ul>
</li>
<li><p>Redis 基本 IO 模型中还有哪些潜在的性能瓶颈？</p>
<ul>
<li>在 Redis 基本 IO模型中，主要是主线程在执行操作，任何耗时的操作，例如 bigkey、全量返回等操作，都是潜在的性能瓶颈。</li>
</ul>
</li>
<li><p>AOF 重写过程中有没有其他潜在的阻塞风险？</p>
<ul>
<li>风险一：Redis 主线程 fork 创建 bgrewriteaof 子进程时，内核需要创建用于管理子进程的相关数据结构，这些数据结构在操作系统中通常叫作进程控制块（Process Control Block，简称为 PCB）。内核要把主线程的 PCB 内容拷贝给子进程。这个创建和拷贝过程由内核执行，是会阻塞主线程的。而且，在拷贝过程中，子进程要拷贝父进程的页表，这个过程的耗时和 Redis 实例的内存大小有关。如果 Redis 实例内存大，页表就会大，fork执行时间就会长，这就会给主线程带来阻塞风险。</li>
<li>风险二：bgrewriteaof 子进程会和主线程共享内存。当主线程收到新写或修改的操作时，主线程会申请新的内存空间，用来保存新写或修改的数据，如果操作的是 bigkey，也就是数据量大的集合类型数据，那么，主线程会因为申请大空间而面临阻塞风险。因为操作系统在分配内存空间时，有查找和锁的开销，这就会导致阻塞。</li>
</ul>
</li>
<li><p>AOF 重写为什么不共享使用 AOF 本身的日志？</p>
<ul>
<li>如果都用 AOF 日志的话，主线程要写，bgrewriteaof 子进程也要写，这两者会竞争文件系统的锁，这就会对 Redis 主线程的性能造成影响。</li>
</ul>
</li>
<li><p>使用一个 2 核 CPU、4GB 内存、500GB 磁盘的云主机运行 Redis，Redis 数据库的数据量大小差不多是 2GB。当时 Redis 主要以修改操作为主，写读比例差不多在 8:2 左右，也就是说，如果有 100 个请求，80 个请求执行的是修改操作。在这个场景下，用RDB 做持久化有什么风险吗？</p>
<ul>
<li>内存不足的风险：Redis fork 一个 bgsave 子进程进行 RDB 写入，如果主线程再接收到写操作，就会采用写时复制。写时复制需要给写操作的数据分配新的内存空间。本问题中写的比例为 80%，那么，在持久化过程中，为了保存 80% 写操作涉及的数据，写时复制机制会在实例内存中，为这些数据再分配新内存空间，分配的内存量相当于整个实例数据量<br>的 80%，大约是 1.6GB，这样一来，整个系统内存的使用量就接近饱和了。此时，如果实例还有大量的新 key 写入或 key 修改，云主机内存很快就会被吃光。如果云主机开启了Swap 机制，就会有一部分数据被换到磁盘上，当访问磁盘上的这部分数据时，性能会急剧下降。如果云主机没有开启 Swap，会直接触发 OOM，整个 Redis 实例会面临被系统<br>kill 掉的风险。</li>
<li>主线程和子进程竞争使用 CPU 的风险：生成 RDB 的子进程需要 CPU 核运行，主线程本身也需要 CPU 核运行，而且，如果 Redis 还启用了后台线程，此时，主线程、子进程和后台线程都会竞争 CPU 资源。由于云主机只有 2 核 CPU，这就会影响到主线程处理请求的速度。</li>
</ul>
</li>
<li><p>为什么主从库间的复制不使用 AOF？</p>
<ul>
<li>RDB 文件是二进制文件，无论是要把 RDB 写入磁盘，还是要通过网络传输 RDB，IO效率都比记录和传输 AOF 的高。</li>
<li>在从库端进行恢复时，用 RDB 的恢复效率要高于用 AOF。</li>
</ul>
</li>
<li><p>在主从切换过程中，客户端能否正常地进行请求操作呢？</p>
<ul>
<li>主从集群一般是采用读写分离模式，当主库故障后，客户端仍然可以把读请求发送给从库，让从库服务。但是，对于写请求操作，客户端就无法执行了。</li>
</ul>
</li>
<li><p>如果想要应用程序不感知服务的中断，还需要哨兵或客户端再做些什么吗？</p>
<ul>
<li>一方面，客户端需要能缓存应用发送的写请求。只要不是同步写操作（Redis 应用场景一般也没有同步写），写请求通常不会在应用程序的关键路径上，所以，客户端缓存写请求后，给应用程序返回一个确认就行。</li>
<li>另一方面，主从切换完成后，客户端要能和新主库重新建立连接，哨兵需要提供订阅频道，让客户端能够订阅到新主库的信息。同时，客户端也需要能主动和哨兵通信，询问新主库的信息</li>
</ul>
</li>
<li><p>5 个哨兵实例的集群，quorum 值设为 2。在运行过程中，如果有 3 个哨兵实例都发生故障了，此时，Redis 主库如果有故障，还能正确地判断主库“客观下线”吗？如果可以的话，还能进行主从库自动切换吗？</p>
<ul>
<li>因为判定主库“客观下线”的依据是，认为主库“主观下线”的哨兵个数要大于等于quorum 值，现在还剩 2 个哨兵实例，个数正好等于 quorum 值，所以还能正常判断主库是否处于“客观下线”状态。如果一个哨兵想要执行主从切换，就要获到半数以上的哨兵投票赞成，也就是至少需要 3 个哨兵投票赞成。但是，现在只有 2 个哨兵了，所以就无法进行主从切换了</li>
</ul>
</li>
<li><p>哨兵实例是不是越多越好呢？如果同时调大 down-after-milliseconds 值，对减少误判是不是也有好处？</p>
<ul>
<li>哨兵实例越多，误判率会越低，但是在判定主库下线和选举 Leader 时，实例需要拿到的赞成票数也越多，等待所有哨兵投完票的时间可能也会相应增加，主从库切换的时间也会变长，客户端容易堆积较多的请求操作，可能会导致客户端请求溢出，从而造成请求丢失。如果业务层对 Redis 的操作有响应时间要求，就可能会因为新主库一直没有选定，新操作<br>无法执行而发生超时报警。</li>
<li>调大 down-after-milliseconds 后，可能会导致这样的情况：主库实际已经发生故障了，但是哨兵过了很长时间才判断出来，这就会影响到 Redis 对业务的可用性。</li>
</ul>
</li>
<li><p>为什么 Redis 不直接用一个表，把键值对和实例的对应关系记录下来？</p>
<ul>
<li>如果使用表记录键值对和实例的对应关系，一旦键值对和实例的对应关系发生了变化（例如实例有增减或者数据重新分布），就要修改表。如果是单线程操作表，那么所有操作都要串行执行，性能慢；如果是多线程操作表，就涉及到加锁开销。此外，如果数据量非常大，使用表记录键值对和实例的对应关系，需要的额外存储空间也会增加。</li>
<li>基于哈希槽计算时，虽然也要记录哈希槽和实例的对应关系，但是哈希槽的个数要比键值对的个数少很多，无论是修改哈希槽和实例的对应关系，还是使用额外空间存储哈希槽和实例的对应关系，都比直接记录键值对和实例的关系的开销小得多</li>
</ul>
</li>
<li><p>rehash 的触发时机和渐进式执行机制</p>
<ul>
<li>Redis 什么时候做 rehash？<ul>
<li>Redis 会使用装载因子（load factor）来判断是否需要做 rehash。装载因子的计算方式是，哈希表中所有 entry 的个数除以哈希表的哈希桶个数。Redis 会根据装载因子的两种情况，来触发 rehash 操作：</li>
<li>装载因子≥1，同时，哈希表被允许进行 rehash；如果此时再有新的数据写入，哈希表就要使用链式哈希了，这会对查询性能产生影响。在进行 RDB 生成和 AOF 重写时，哈希表的 rehash 是被禁止的，这是为了避免对RDB 和 AOF 重写造成影响。如果此时，Redis 没有在生成 RDB 和重写 AOF，那么，就可以进行 rehash。否则的话，再有数据写入时，哈希表就要开始使用查询较慢的链式哈希了。</li>
<li>装载因子大于等于 5 时，就表明当前保存的数据量已经远远大于哈希桶的个数，哈希桶里会有大量的链式哈希存在，性能会受到严重影响，此时，就立马开始做 rehash。</li>
</ul>
</li>
<li>采用渐进式 hash 时，如果实例暂时没有收到新请求，是不是就不做 rehash 了？<ul>
<li>Redis 会执行定时任务，定时任务中就包含了 rehash 操作。所谓的定时任务，就是按照一定频率（例如每 100ms&#x2F; 次）执行的任务。</li>
<li>在 rehash 被触发后，即使没有收到新请求，Redis 也会定时执行一次 rehash 操作，而且，每次执行时长不会超过 1ms，以免对其他任务造成影响。</li>
</ul>
</li>
</ul>
</li>
<li><p>主线程、子进程和后台线程的联系与区别</p>
<ul>
<li>进程和线程的区别<ul>
<li>从操作系统的角度来看，进程一般是指资源分配单元，例如一个进程拥有自己的堆、栈、虚存空间（页表）、文件描述符等；而线程一般是指 CPU 进行调度和执行的实体。</li>
</ul>
</li>
<li>什么是主进程和主线程<ul>
<li>如果一个进程启动后，没有再创建额外的线程，那么，这样的进程一般称为主进程或主线程。</li>
<li>Redis 启动以后，本身就是一个进程，它会接收客户端发送的请求，并处理读写操作请求。而且，接收请求和处理请求操作是 Redis 的主要工作，Redis 没有再依赖于其他线程，所以，一般把完成这个主要工作的 edis 进程，称为主进程或主线程。</li>
<li>在主线程中，还可以使用 fork 创建子进程，或是使用 pthread_create 创建线程。</li>
</ul>
</li>
<li>Redis 中用 fork 创建的子进程有哪些<ul>
<li>创建 RDB 的后台子进程，同时由它负责在主从同步时传输 RDB 给从库；</li>
<li>通过无盘复制方式传输 RDB 的子进程；</li>
<li>bgrewriteaof 子进程</li>
</ul>
</li>
<li>从 4.0 版本开始，Redis 也开始使用pthread_create 创建线程，这些线程在创建后，一般会自行执行一些任务，例如执行异步删除任务。相对于完成主要工作的主线程来说，我们一般可以称这些线程为后台线程。</li>
</ul>
</li>
<li><p>写时复制的底层实现机制</p>
<ul>
<li>写时复制的效果：bgsave 子进程相当于复制了原始数据，而主线程仍然可以修改原来的数据</li>
<li>对 Redis 来说，主线程 fork 出 bgsave 子进程后，bgsave 子进程实际是复制了主线程的页表。这些页表中，就保存了在执行 bgsave 命令时，主线程的所有数据块在内存中的物理地址。这样一来，bgsave 子进程生成 RDB 时，就可以根据页表读取这些数据，再写入磁盘中。如果此时，主线程接收到了新写或修改操作，那么，主线程会使用写时复制机制。具体来说，写时复制就是指，主线程在有写操作时，才会把这个新写或修改后的数据写入到一个新的物理地址中，并修改自己的页表映射。</li>
</ul>
</li>
<li><p>replication buffer 和 repl_backlog_buffer 的区别</p>
<ul>
<li>replication buffer 是主从库在进行全量复制时，主库上用于和从库连接的客户端的 buffer，而 repl_backlog_buffer 是为了支持从库增量复制，主库上用于持续保存写操作的一块专用 buffer。</li>
<li>Redis 主从库在进行复制时，当主库要把全量复制期间的写操作命令发给从库时，主库会先创建一个客户端，用来连接从库，然后通过这个客户端，把写操作命令发给从库。在内存中，主库上的客户端就会对应一个 buffer，这个 buffer 就被称为 replication buffer。Redis 通过 client_buffer 配置项来控制这个 buffer 的大小。主库会给每个从库建立一个客户端，所以 replication buffer 不是共享的，而是每个从库都有一个对应的客户端。</li>
<li>repl_backlog_buffer 是一块专用 buffer，在 Redis 服务器启动后，开始一直接收写操作命令，这是所有从库共享的。主库和从库会各自记录自己的复制进度，所以，不同的从库在进行恢复时，会把自己的复制进度（slave_repl_offset）发给主库，主库就可以和它独立同步。</li>
</ul>
</li>
</ul>
<h4 id="11丨“万金油”的String，为什么不好用了？"><a href="#11丨“万金油”的String，为什么不好用了？" class="headerlink" title="11丨“万金油”的String，为什么不好用了？"></a>11丨“万金油”的String，为什么不好用了？</h4><ul>
<li><p>String 类型提供的“一个键对应一个值的数据”的保存形式，然而String 类型并不是适用于所有场合的，它有一个明显的短板，就是它保存数据时所消耗的内存空间较多；集合类型有非常节省内存空间的底层实现结构，但是，集合类型保存的数据模式，是一个键对应一系列值，并不适合直接保存单值的键值对。因此可以使用二级编码的方法，实现用集合类型保存单值键值对，Redis 实例的内存空间消耗明显下降了。</p>
</li>
<li><p>为什么 String 类型内存开销大？</p>
<ul>
<li><p>图片 ID 和图片存储对象 ID 都是 10 位数，我们可以用两个 8 字节的Long 类型表示这两个 ID。因为 8 字节的 Long 类型最大可以表示 2 的 64 次方的数值，所以肯定可以表示 10 位数。但是 String 类型却用了 64 字节，这是因为除了记录实际数据，String 类型还需要额外的内存空间记录数据长度、空间使用等信息，这些信息也叫作元数据。当实际保存的数据较小时，元数据的空间开销就显得比较大了，有点“喧宾夺主”的意思。</p>
</li>
<li><p>当保存 64 位有符号整数时，String 类型会把它保存为一个 8 字节的 Long 类型整数，这种保存方式通常也叫作 int 编码方式。但是，当保存的数据中包含字符时，String 类型就会用简单动态字符串（Simple Dynamic String，SDS）结构体来保存：</p>
<ul>
<li>buf：字节数组，保存实际数据。为了表示字节数组的结束，Redis 会自动在数组最后加一个“\0”，这就会额外占用 1 个字节的开销。</li>
<li>len：占 4 个字节，表示 buf 的已用长度。</li>
<li>alloc：也占个 4 字节，表示 buf 的实际分配长度，一般大于 len。</li>
</ul>
<p>在 SDS 中，buf 保存实际数据，而 len 和 alloc 本身其实是 SDS 结构体的额外开销。</p>
</li>
<li><p>另外，对于 String 类型来说，除了 SDS 的额外开销，还有一个来自于 RedisObject 结构体的开销：因为 Redis 的数据类型有很多，而且，不同数据类型都有些相同的元数据要记录（比如最后一次访问的时间、被引用的次数等），所以，Redis 会用一个 RedisObject 结构体来统一记录这些元数据，同时指向实际数据；一个 RedisObject 包含了 8 字节的元数据和一个 8 字节指针，这个指针再进一步指向具体数据类型的实际数据所在，例如指向 String 类型的 SDS 结构所在的内存地址</p>
</li>
<li><p>为了节省内存空间，Redis 还对 Long 类型整数和 SDS 的内存布局做了专门的设计。</p>
<ul>
<li>当保存的是 Long 类型整数时，RedisObject 中的指针就直接赋值为整数数据了，这样就不用额外的指针再指向整数了，节省了指针的空间开销</li>
<li>当保存的是字符串数据，并且字符串小于等于 44 字节时，RedisObject 中的元数据、指针和 SDS 是一块连续的内存区域，这样就可以避免内存碎片。这种布局方式也被称为 embstr 编码方式。</li>
<li>当字符串大于 44 字节时，SDS 的数据量就开始变多了，Redis 就不再把 SDS 和RedisObject 布局在一起了，而是会给 SDS 分配独立的空间，并用指针指向 SDS 结构。这种布局方式被称为 raw 编码模式。</li>
</ul>
<p>因为 10 位数的图片 ID 和图片存储对象 ID 是 Long 类型整数，所以可以直接用 int 编码的 RedisObject 保存。每个 int 编码的 RedisObject 元数据部分占 8 字节，指针部分被直接赋值为 8 字节的整数了。此时，每个 ID 会使用 16 字节，加起来一共是 32 字节</p>
</li>
<li><p>Redis 会使用一个全局哈希表保存所有键值对，哈希表的每一项是一个 dictEntry 的结构体，用来指向一个键值对。dictEntry 结构中有三个 8 字节的指针，分别指向 key、value 以及下一个 dictEntry，三个指针共 24 字节，然后由于Redis 使用的内存分配库 jemalloc 在分配内存时，会根据申请的字节数 N，找一个比 N 大，但是最接近 N 的2 的幂次数作为分配的空间，这样可以减少频繁分配的次数；所以，在刚刚说的场景里，dictEntry 结构就占用了 32 字节。</p>
</li>
</ul>
</li>
<li><p>用什么数据结构可以节省内存？</p>
<ul>
<li><p>Redis 有一种底层数据结构，叫压缩列表（ziplist），这是一种非常节省内存的结构。压缩列表的构成：表头有三个字段 zlbytes、zltail 和 zllen，分别表示列表长度、列表尾的偏移量，以及列表中的 entry 个数。压缩列表尾还有一个 lend，表示列表结束。压缩列表之所以能节省内存，就在于它是用一系列连续的 entry 保存数据。每个 entry 的元数据包括下面几部分</p>
<ul>
<li>prev_len，表示前一个 entry 的长度。</li>
<li>len：表示自身长度，4 字节；</li>
<li>encoding：表示编码方式，1 字节；</li>
<li>content：保存实际数据。</li>
</ul>
<p>这些 entry 会挨个儿放置在内存中，不需要再用额外的指针进行连接，这样就可以节省指针所占用的空间；每个 entry 保存一个图片存储对象 ID（8 字节），此时，每个 entry 的 prev_len 只需要1 个字节就行，因为每个 entry 的前一个 entry 长度都只有 8 字节，小于 254 字节；一个图片的存储对象 ID 所占用的内存大小是 14 字节（1+4+1+8&#x3D;14），实际分配 16 字节。</p>
</li>
<li><p>Redis 基于压缩列表实现了 List、Hash 和 Sorted Set 这样的集合类型，这样做的最大好处就是节省了 dictEntry 的开销。当你用 String 类型时，一个键值对就有一个 dictEntry，要用 32 字节空间。但采用集合类型时，一个 key 就对应一个集合的数据，能保存的数据多了很多，但也只用了一个 dictEntry，这样就节省了内存</p>
</li>
</ul>
</li>
<li><p>如何用集合类型保存单值的键值对？</p>
<ul>
<li><p>在保存单值的键值对时，可以采用基于 Hash 类型的二级编码方法。这里说的二级编码，就是把一个单值的数据拆分成两部分，前一部分作为 Hash 集合的 key，后一部分作为Hash 集合的 value，这样一来就可以把单值数据保存到 Hash 集合中了。</p>
</li>
<li><p>以图片 ID 1101000060 和图片存储对象 ID 3302000080 为例，我们可以把图片 ID 的前7 位（1101000）作为 Hash 类型的键，把图片 ID 的最后 3 位（060）和图片存储对象ID 分别作为 Hash 类型值中的 key 和 value。</p>
</li>
<li><p>Redis Hash 类型的两种底层实现结构，分别是压缩列表和哈希表。Hash类型设置了用压缩列表保存数据时的两个阈值，一旦超过了阈值，Hash 类型就会用哈希表来保存数据了。</p>
<ul>
<li>hash-max-ziplist-entries：表示用压缩列表保存时哈希集合中的最大元素个数。</li>
<li>hash-max-ziplist-value：表示用压缩列表保存时哈希集合中单个元素的最大长度</li>
</ul>
</li>
<li><p>如果我们往 Hash 集合中写入的元素个数超过了 hash-max-ziplist-entries，或者写入的单个元素大小超过了 hash-max-ziplist-value，Redis 就会自动把 Hash 类型的实现结构由压缩列表转为哈希表。为了能充分使用压缩列表的精简内存布局，我们一般要控制保存在 Hash 集合中的元素个数。所以，在刚才的二级编码中，我们只用图片 ID 最后 3 位作为 Hash 集合的 key，也就保证了 Hash 集合的元素个数不超过 1000，同时，我们把 hash-max-ziplist-entries 设置为 1000，这样一来，Hash 集合就可以一直使用压缩列表来节省内存空间了。</p>
</li>
</ul>
</li>
</ul>
<h4 id="12-有一亿个keys要统计，应该用哪种集合？"><a href="#12-有一亿个keys要统计，应该用哪种集合？" class="headerlink" title="12 | 有一亿个keys要统计，应该用哪种集合？"></a>12 | 有一亿个keys要统计，应该用哪种集合？</h4><ul>
<li><p>在 Web 和移动应用的业务场景中，我们经常需要保存这样一种信息：一个 key 对应了一个数据集合；Redis 集合类型的特点就是一个键对应一系列的数据，所以非常适合用来存取这些数据。但是，在这些场景中，除了记录信息，还需要对集合中的数据进行统计；通常情况下，面临的用户数量以及访问量都是巨大的，比如百万、千万级别的用户数量，或者千万级别、甚至亿级别的访问信息。所以，必须要选择能够非常高效地统计大量数据（例如亿级）的集合类型</p>
</li>
<li><p>聚合统计</p>
<ul>
<li>所谓的聚合统计，就是指统计多个集合元素的聚合结果，包括：统计多个集合的共有元素（交集统计）；把两个集合相比，统计其中一个集合独有的元素（差集统计）；统计多个集合的所有元素（并集统计）</li>
<li>需要对多个集合进行聚合计算时，Set 类型会是一个非常不错的选择。不过这里有一个潜在的风险：Set 的差集、并集和交集的计算复杂度较高，在数据量较大的情况下，如果直接执行这些计算，会导致 Redis 实例阻塞。</li>
<li>可以从主从集群中选择一个从库，让它专门负责聚合计算，或者是把数据读取到客户端，在客户端来完成聚合统计，这样就可以规避阻塞主库实例和其他从库实例的风险了</li>
</ul>
</li>
<li><p>排序统计</p>
<ul>
<li>在 Redis 常用的 4 个集合类型中（List、Hash、Set、Sorted Set），List 和 Sorted Set就属于有序集合；List 是按照元素进入 List 的顺序进行排序的，而 Sorted Set 可以根据元素的权重来排序，可以自己来决定每个元素的权重值。</li>
<li>在电商网站上提供最新评论列表的场景为例，网站一般会分页显示最新的评论列表，一旦涉及到分页操作，List 就可能会出现问题了。List 是通过元素在 List 中的位置来排序的，当有一个新元素插入时，原先的元素在 List 中的位置都后移了一位，比如说原来在第 1 位的元素现在排在了第 2 位。所以，对比新元素插入前后，List 相同位置上的元素就会发生变化，用LRANGE 读取时，就会读到旧元素。</li>
<li>和 List 相比，Sorted Set 就不存在这个问题，因为它是根据元素的实际权重来排序和获取数据的；Sorted Set 的 ZRANGEBYSCORE 命令就可以按权重排序后返回元素。这样的话，即使集合中的元素频繁更新，Sorted Set 也能通过 ZRANGEBYSCORE 命令准确地获取到按序排列的数据。</li>
<li>在面对需要展示最新列表、排行榜等场景时，如果数据更新频繁或者需要分页显示，建议优先考虑使用 Sorted Set。</li>
</ul>
</li>
<li><p>二值状态统计</p>
<ul>
<li>在签到统计时，每个用户一天的签到用 1 个 bit 位就能表示，一个月（假设是 31 天）的签到情况用 31 个 bit 位就可以，而一年的签到也只需要用 365 个 bit 位，根本不用太复杂的集合类型。这个时候就可以选择 Bitmap</li>
<li>Bitmap 本身是用 String 类型作为底层数据结构实现的一种统计二值状态的数据类型。String 类型是会保存为二进制的字节数组，所以，Redis 就把字节数组的每个 bit 位利用起来，用来表示一个元素的二值状态。可以把 Bitmap 看作是一个 bit 数组。</li>
<li>Bitmap 提供了 GETBIT&#x2F;SETBIT 操作，使用一个偏移值 offset 对 bit 数组的某一个 bit 位进行读和写。不过，需要注意的是，Bitmap 的偏移量是从 0 开始算的，也就是说 offset的最小值是 0。当使用 SETBIT 对一个 bit 位进行写操作时，这个 bit 位会被设置为 1。Bitmap 还提供了 BITCOUNT 操作，用来统计这个 bit 数组中所有“1”的个数。</li>
<li>在实际应用时，最好对 Bitmap 设置过期时间，让Redis 自动删除不再需要的签到记录，以节省内存开销。</li>
<li>如果只需要统计数据的二值状态，例如商品有没有、用户在不在等，就可以使用Bitmap，因为它只用一个 bit 位就能表示 0 或 1。在记录海量数据时，Bitmap 能够有效地节省内存空间。</li>
</ul>
</li>
<li><p>基数统计。</p>
<ul>
<li>基数统计就是指统计一个集合中不重复的元素个数。比如统计网页的 UV。网页 UV 的统计有个独特的地方，就是需要去重，一个用户一天内的多次访问只能算作一次。在 Redis 的集合类型中，Set 类型默认支持去重，所以看到有去重需求时，可能第一时间就会想到用 Set 类型。<ul>
<li>如果 page1 非常火爆，UV 达到了千万，这个时候，一个 Set 就要记录千万个用户ID。对于一个搞大促的电商网站而言，这样的页面可能有成千上万个，如果每个页面都用这样的一个 Set，就会消耗很大的内存空间</li>
</ul>
</li>
<li>也可以用 Hash 类型记录 UV，可以把用户 ID 作为 Hash 集合的 key，当用户访问页面时，就用 HSET 命令（用于设置 Hash 集合元素的值），对这个用户 ID 记录一个值“1”，表示一个独立访客；即使用户 1 多次访问页面，重复执行这个 HSET 命令，也只会把 user1 的值设置为 1，仍然只记为 1 个独立访客。当要统计 UV 时，可以用 HLEN 命令统计 Hash 集合中的所有元素个数；但是，和 Set 类型相似，当页面很多时，Hash 类型也会消耗很大的内存空间</li>
<li>HyperLogLog 是一种用于统计基数的数据集合类型，它的最大优势就在于，当集合元素数量非常多时，它计算基数所需的空间总是固定的，而且还很小。在 Redis 中，每个 HyperLogLog 只需要花费 12 KB 内存，就可以计算接近 2^64 个元素的基数<ul>
<li>在统计 UV 时，可以用 PFADD 命令（用于向 HyperLogLog 中添加新元素）把访问页面的每个用户都添加到 HyperLogLog 中。接下来，就可以用 PFCOUNT 命令直接获得 page1 的 UV 值了</li>
<li>HyperLogLog 的统计规则是基于概率完成的，所以它给出的统计结果是有一定误差的，标准误算率是 0.81%。需要精确统计结果的话，最好还是继续用 Set 或 Hash 类型。</li>
</ul>
</li>
</ul>
</li>
</ul>
<h4 id="13-GEO是什么？还可以定义新的数据类型吗？"><a href="#13-GEO是什么？还可以定义新的数据类型吗？" class="headerlink" title="13 | GEO是什么？还可以定义新的数据类型吗？"></a>13 | GEO是什么？还可以定义新的数据类型吗？</h4><ul>
<li><p>面向 LBS 应用的 GEO 数据类型</p>
<ul>
<li>基于位置信息服务（Location-Based Service，LBS）的应用访问的数据是和人或物关联的一组经纬度信息，而且要能查询相邻的经纬度范围，GEO 就非常适合应用在LBS 服务的场景中</li>
<li>GEO 的底层结构，在设计一个数据类型的底层结构时，我们首先需要知道，要处理的数据有什么访问特点<ul>
<li>一辆车（或一个用户）对应一组经纬度，并且随着车（或用户）的位置移动，相应的经纬度也会变化，这种数据记录模式属于一个 key（例如车 ID）对应一个 value（一组经纬度）。</li>
<li>Hash 集合类型可以快速存取一系列的 key 和 value，正好可以用来记录一系列车辆 ID 和经纬度的对应关系。同时，Hash 类型的 HSET 操作命令，会根据 key 来设置相应的 value 值，所以可以用它来快速地更新车辆变化的经纬度信息。</li>
<li>但问题是，对于一个 LBS 应用来说，除了记录经纬度信息，还需要根据用户的经纬度信息在车辆的 Hash 集合中进行范围查询。一旦涉及到范围查询，就意味着集合中的元素需要有序，但 Hash 类型的元素是无序的，显<br>然不能满足要求。</li>
<li>Sorted Set 类型也支持一个 key 对应一个 value 的记录模式，其中，key 就是 SortedSet 中的元素，而 value 则是元素的权重分数。更重要的是，Sorted Set 可以根据元素的权重分数排序，支持范围查询。这就能满足 LBS 服务中查找相邻位置的需求，实际上，GEO 类型的底层数据结构就是用 Sorted Set 来实现的</li>
<li>用 Sorted Set 来保存车辆的经纬度信息时，Sorted Set 的元素是车辆 ID，元素的权重分数是经纬度信息；Sorted Set 元素的权重分数是一个浮点数（float 类型），而一组经纬度包含的是经度和纬度两个值，是没法直接保存为一个浮点数的</li>
</ul>
</li>
<li>GeoHash 的编码方法<ul>
<li>基本原理就是“二分区间，区间编码”，当我们要对一组经纬度进行 GeoHash 编码时，要先对经度和纬度分别编码，然后再把经纬度各自的编码组合成一个最终编码（组合的规则是：最终编码值的偶数位上依次是经度的编码值，奇数位上依次是纬度的编码值）</li>
<li>使用 GeoHash 编码后，相当于把整个地理空间划分成了一个个方格，每个方格对应了 GeoHash 中的一个分区</li>
<li>有的编码值虽然在大小上接近，但实际对应的方格却距离比较远，为了避免查询不准确问题，可以同时查询给定经纬度所在的方格周围的 4 个或8 个方格</li>
</ul>
</li>
<li>如何操作 GEO 类型？<ul>
<li>经常会用到两个命令，分别是 GEOADD 和 GEORADIUS</li>
<li>GEOADD 命令：用于把一组经纬度信息和相对应的一个 ID 记录到 GEO 类型集合中；</li>
<li>GEORADIUS 命令：会根据输入的经纬度位置，查找以这个经纬度为中心的一定范围内的其他元素</li>
<li>还可以进一步限定返回的车辆信息。比如，可以使用 ASC 选项，让返回的车辆信息按照距离这个中心位置从近到远的方式来排序，以方便选择最近的车辆；还可以使用 COUNT 选项，指定返回的车辆信息的数量。</li>
</ul>
</li>
</ul>
</li>
<li><p>如何自定义数据类型？</p>
<ul>
<li>RedisObject 包括元数据和指针。其中，元数据的一个功能就是用来区分不同的数据类型，指针用来指向具体的数据类型的值</li>
<li>RedisObject 的内部组成包括了 type,、encoding,、lru 和 refcount 4 个元数据，以及 1个*ptr指针。<ul>
<li>type：表示值的类型，涵盖了五大基本类型；</li>
<li>encoding：是值的编码方式，用来表示 Redis 中实现各个基本类型的底层数据结构，例如 SDS、压缩列表、哈希表、跳表等；</li>
<li>lru：记录了这个对象最后一次被访问的时间，用于淘汰过期的键值对；</li>
<li>refcount：记录了对象的引用计数；</li>
<li>*ptr：是指向数据的指针。RedisObject 结构借助*ptr指针，就可以指向不同的数据类型</li>
</ul>
</li>
<li>开发一个新的数据类型<ul>
<li>定义新数据类型的底层结构；可以根据自己的需求，把 NewTypeObject 的底层结构定义为其他类型。例如，如果我们想要 NewTypeObject 的查询效率比链表高，就可以把它的底层结构设计成一颗 B+ 树</li>
<li>在 RedisObject 的 type 属性中，增加这个新类型的定义；这个定义是在 Redis 的 server.h 文件中</li>
<li>开发新类型的创建和释放函数；Redis 把数据类型的创建和释放函数都定义在了 object.c 文件中。在这个文件中增加 NewTypeObject 的创建函数 createNewTypeObject；对于释放函数来说，它是创建函数的反过程，是用 zfree 命令把新结构的内存空间释放掉</li>
<li>开发新类型的命令操作<ul>
<li>在 t_newtype.c 文件中增加命令操作的实现。</li>
<li>在 server.h 文件中，声明我们已经实现的命令，以便在 server.c 文件引用这个命令</li>
<li>在 server.c 文件中的 redisCommandTable 里面，把新增命令和实现函数关联起来。</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<h4 id="14-如何在Redis中保存时间序列数据？"><a href="#14-如何在Redis中保存时间序列数据？" class="headerlink" title="14 | 如何在Redis中保存时间序列数据？"></a>14 | 如何在Redis中保存时间序列数据？</h4><ul>
<li><p>时间序列数据的读写特点</p>
<ul>
<li>在实际应用中，时间序列数据通常是持续高并发写入的，例如，需要连续记录数万个设备的实时状态值。同时，时间序列数据的写入主要就是插入新数据，而不是更新一个已存在的数据，也就是说，一个时间序列数据被记录后通常就不会变了，因为它就代表了一个设备在某个时刻的状态值</li>
<li>这种数据的写入特点很简单，就是插入数据快，这就要求我们选择的数据类型，在进行数据插入时，复杂度要低，尽量不要阻塞</li>
<li>时间序列数据的“读”操作，既有对单条记录的查询（例如查询某个设备在某一个时刻的运行状态信息，对应的就是这个设备的一条记录），也有对某个时间范围内的数据的查询；还有一些更复杂的查询，比如对某个时间范围内的数据做聚合计算。用一个词概括时间序列数据的“读”，就是查询模式多</li>
<li>针对时间序列数据的“写要快”，Redis 的高性能写特性直接就可以满足；针对“查询模式多”，也就是要支持单点查询、范围查询和聚合计算，Redis 提供了保存时间序列数据的两种方案，分别可以基于 Hash 和 Sorted Set 实现，以及基于RedisTimeSeries 模块实现。</li>
</ul>
</li>
<li><p>基于 Hash 和 Sorted Set 保存时间序列数据</p>
<ul>
<li>Hash 和 Sorted Set 组合的方式有一个明显的好处：它们是 Redis 内在的数据类型，代码成熟和性能稳定。所以，基于这两个数据类型保存时间序列数据，系统稳定性是可以预期<ul>
<li>关于 Hash 类型它有一个特点是，可以实现对单键的快速查询。这就满足了时间序列数据的单键查询需求。可以把时间戳作为 Hash 集合的 key，把记录的设备状态值作为 Hash 集合的 value。当想要查询某个时间点或者是多个时间点上的温度数据时，直接使用 HGET 命令或者HMGET 命令，就可以分别获得 Hash 集合中的一个 key 和多个 key 的 value 值；但是，Hash 类型有个短板：它并不支持对数据进行范围查询。如果要对 Hash 类型进行范围查询的话，就需要扫描 Hash 集合中的所有数据，再把这些数据取回到客户端进行排序，然后，才能在客户端得到所查询范围内的数据。显然，查询效率很低</li>
<li>为了能同时支持按时间戳范围的查询，可以用 Sorted Set 来保存时间序列数据，因为它能够根据元素的权重分数来排序。可以把时间戳作为 Sorted Set 集合的元素分数，把时间点上记录的数据作为元素本身。</li>
</ul>
</li>
<li>同时使用 Hash 和 Sorted Set，可以满足单个时间点和一个时间范围内的数据查询需求了，但是又会面临一个新的问题：如何保证写入 Hash 和 Sorted Set 是一个原子性的操作呢？<ul>
<li>所谓“原子性的操作”，就是指我们执行多个写命令操作时（例如用 HSET 命令和 ZADD命令分别把数据写入 Hash 和 Sorted Set），这些命令操作要么全部完成，要么都不完成。</li>
<li>只有保证了写操作的原子性，才能保证同一个时间序列数据，在 Hash 和 Sorted Set 中，要么都保存了，要么都没保存。否则，就可能出现 Hash 集合中有时间序列数据，而Sorted Set 中没有，那么，在进行范围查询时，就没有办法满足查询需求了</li>
<li>Redis 用来实现简单的事务的MULTI 和 EXEC 命令。当多个命令及其参数本身无误时，MULTI 和 EXEC 命令可以保证执行这些命令时的原子性<ul>
<li>MULTI 命令：表示一系列原子性操作的开始。收到这个命令后，Redis 就知道，接下来再收到的命令需要放到一个内部队列中，后续一起执行，保证原子性。</li>
<li>EXEC 命令：表示一系列原子性操作的结束。一旦 Redis 收到了这个命令，就表示所有要保证原子性的命令操作都已经发送完成了。此时，Redis 开始执行刚才放到内部队列中的所有命令操作</li>
</ul>
</li>
</ul>
</li>
<li>如何对时间序列数据进行聚合计算？<ul>
<li>聚合计算一般被用来周期性地统计时间窗口内的数据汇总状态，在实时监控与预警等场景下会频繁执行</li>
<li>因为 Sorted Set 只支持范围查询，无法直接进行聚合计算，所以，只能先把时间范围内的数据取回到客户端，然后在客户端自行完成聚合计算。这个方法虽然能完成聚合计算，但是会带来一定的潜在风险，也就是大量数据在 Redis 实例和客户端间频繁传输，这会和其他操作命令竞争网络资源，导致其他操作变慢</li>
<li>为了避免客户端和 Redis 实例间频繁的大量数据传输，我们可以使用 RedisTimeSeries 来保存时间序列数据。RedisTimeSeries 支持直接在 Redis 实例上进行聚合计算。</li>
</ul>
</li>
<li>如果我们只需要进行单个时间点查询或是对某个时间范围查询的话，适合使用 Hash和 Sorted Set 的组合，它们都是 Redis 的内在数据结构，性能好，稳定性高。但是，如果我们需要进行大量的聚合计算，同时网络带宽条件不是太好时，Hash 和 Sorted Set 的组合就不太适合了。此时，使用 RedisTimeSeries 就更加合适一些。</li>
</ul>
</li>
<li><p>基于 RedisTimeSeries 模块保存时间序列数据</p>
<ul>
<li>RedisTimeSeries 是 Redis 的一个扩展模块。它专门面向时间序列数据提供了数据类型和访问接口，并且支持在 Redis 实例上直接对数据进行按时间范围的聚合计算。</li>
<li>因为 RedisTimeSeries 不属于 Redis 的内建功能模块，在使用时，我们需要先把它的源码单独编译成动态链接库 redistimeseries.so，再使用 loadmodule 命令进行加载</li>
<li>当用于时间序列数据存取时，RedisTimeSeries 的操作主要有 5 个：<ul>
<li>用 TS.CREATE 命令创建时间序列数据集合；需要设置时间序列数据集合的 key 和数据的过期时间，还可以为数据集合设置标签，来表示数据集合的属性。</li>
<li>用 TS.ADD 命令插入数据；往时间序列集合中插入数据，包括时间戳和具体的数值</li>
<li>用 TS.GET 命令读取最新数据；</li>
<li>用 TS.MGET 命令按标签过滤查询数据集合；</li>
<li>用 TS.RANGE 支持聚合计算的范围查询。同时用 AGGREGATION 参数指定要执行的聚合计算类型。</li>
</ul>
</li>
<li>与使用 Hash 和 Sorted Set 来保存时间序列数据相比，RedisTimeSeries 是专门为时间序列数据访问设计的扩展模块，能支持在 Redis 实例上直接进行聚合计算，以及按标签属性过滤查询数据集合，当我们需要频繁进行聚合计算，以及从大量集合中筛选出特定设备或用户的数据集合时，RedisTimeSeries 就可以发挥优势了</li>
<li>不过，RedisTimeSeries的底层数据结构使用了链表，它的范围查询的复杂度是 O(N) 级别的，同时，它的 TS.GET查询只能返回最新的数据，没有办法像第一种方案的 Hash 类型一样，可以返回任一时间点的数据</li>
</ul>
</li>
</ul>
<h4 id="15丨消息队列的考验：Redis有哪些解决方案？"><a href="#15丨消息队列的考验：Redis有哪些解决方案？" class="headerlink" title="15丨消息队列的考验：Redis有哪些解决方案？"></a>15丨消息队列的考验：Redis有哪些解决方案？</h4><ul>
<li><p>消息队列的消息存取需求</p>
<ul>
<li>在分布式系统中，当两个组件要基于消息队列进行通信时，一个组件会把要处理的数据以消息的形式传递给消息队列，然后，这个组件就可以继续执行其他操作了；远端的另一个组件从消息队列中把消息读取出来，再在本地进行处理。</li>
<li>一般把消息队列中发送消息的组件称为生产者（，把接收消息的组件称为消费者；在使用消息队列时，消费者可以异步读取生产者消息，然后再进行处理。这样一来，即使生产者发送消息的速度远远超过了消费者处理消息的速度，生产者已经发送的消息也可以缓存在消息队列中，避免阻塞生产者，这是消息队列作为分布式组件通信的一大优势</li>
<li>消息队列在存取消息时，必须要满足三个需求，分别是消息保序、处理重复的消息和保证消息可靠性<ul>
<li>消息保序：虽然消费者是异步处理消息，但是，消费者仍然需要按照生产者发送消息的顺序来处理消息，避免后发送的消息被先处理了。对于要求消息保序的场景来说，一旦出现这种消息被乱序处理的情况，就可能会导致业务逻辑被错误执行，从而给业务方造成损失。</li>
<li>重复消息处理：消费者从消息队列读取消息时，有时会因为网络堵塞而出现消息重传的情况。此时，消费者可能会收到多条重复的消息。对于重复的消息，消费者如果多次处理的话，就可能造成一个业务逻辑被多次执行，如果业务逻辑正好是要修改数据，那就会出现数据被多次修改的问题</li>
<li>消息可靠性保证：消费者在处理消息的时候，还可能出现因为故障或宕机导致消息没有处理完成的情况。此时，消息队列需要能提供消息可靠性的保证，也就是说，当消费者重启后，可以重新读取消息再次进行处理，否则，就会出现消息漏处理的问题</li>
</ul>
</li>
<li>这三大需求可以进一步转换为对消息队列的三大要求：消息数据有序存取，消息数据具有全局唯一编号，以及消息数据在消费完成后被删除。</li>
<li>Redis 的 List 和 Streams 两种数据类型，就可以满足消息队列的这三个需求。</li>
</ul>
</li>
<li><p>基于 List 的消息队列解决方案</p>
<ul>
<li>List 本身就是按先进先出的顺序对数据进行存取的，所以，如果使用 List 作为消息队列保存消息的话，就已经能满足消息保序的需求<ul>
<li>生产者可以使用 LPUSH 命令把要发送的消息依次写入 List，而消费者则可以使用 RPOP 命令，从 List 的另一端按照消息的写入顺序，依次读取消息并进行处理。</li>
<li>在消费者读取数据时，有一个潜在的性能风险点。在生产者往 List 中写入数据时，List 并不会主动地通知消费者有新消息写入，如果消费者想要及时处理消息，就需要在程序中不停地调用 RPOP 命令（比如使用一个 while(1) 循环）。如果有新消息写入，RPOP 命令就会返回结果，否则，RPOP 命令返回空值，再继续循环。<strong>即使没有新消息写入 List，消费者也要不停地调用 RPOP 命令</strong>，这就会导致消费者程序的 CPU 一直消耗在执行 RPOP 命令上，带来不必要的性能损失。</li>
<li>为了解决这个问题，Redis 提供了 BRPOP 命令。BRPOP 命令也称为阻塞式读取，客户端在没有读到队列数据时，自动阻塞，直到有新的数据写入队列，再开始读取新数据。和消费者程序自己不停地调用 RPOP 命令相比，这种方式能节省 CPU 开销。</li>
</ul>
</li>
<li>消费者程序本身能对重复消息进行判断。一方面，消息队列要能给每一个消息提供全局唯一的 ID 号；另一方面，消费者程序要把已经处理过的消息的 ID 号记录下来。<ul>
<li>当收到一条消息后，消费者程序就可以对比收到的消息 ID 和记录的已处理过的消息 ID，来判断当前收到的消息有没有经过处理。如果已经处理过，那么，消费者程序就不再进行处理了。这种处理特性也称为幂等性，幂等性就是指，对于同一条消息，消费者收到一次的处理结果和收到多次的处理结果是一致的。</li>
<li>List 本身是不会为每个消息生成 ID 号的，所以，消息的全局唯一 ID 号就需要生产者程序在发送消息前自行生成。生成之后，我们在用 LPUSH 命令把消息插入 List 时，需要在消息中包含这个全局唯一 ID。</li>
</ul>
</li>
<li>当消费者程序从 List 中读取一条消息后，List 就不会再留存这条消息了。所以，如果消费者程序在处理消息的过程出现了故障或宕机，就会导致消息没有处理完成，那么，消费者程序再次启动后，就没法再次从 List 中读取消息了。<ul>
<li>为了留存消息，List 类型提供了 BRPOPLPUSH 命令，这个命令的作用是让消费者程序从一个 List 中读取消息，同时，Redis 会把这个消息再插入到另一个 List（可以叫作备份List）留存。这样一来，如果消费者程序读了消息但没能正常处理，等它重启后，就可以从备份 List 中重新读取消息并进行处理了。</li>
</ul>
</li>
<li>在用 List 做消息队列时，还可能遇到过一个问题：生产者消息发送很快，而消费者处理消息的速度比较慢，这就导致 List 中的消息越积越多，给 Redis 的内存带来很大压力。<ul>
<li>希望启动多个消费者程序组成一个消费组，一起分担处理 List 中的消息。但是，List 类型并不支持消费组的实现。</li>
</ul>
</li>
</ul>
</li>
<li><p>基于 Streams 的消息队列解决方案</p>
<ul>
<li>Streams 是 Redis 专门为消息队列设计的数据类型，它提供了丰富的消息队列操作命令。<ul>
<li>XADD：插入消息，保证有序，可以自动生成全局唯一 ID；XADD 命令可以往消息队列中插入新消息，消息的格式是键 - 值对形式。对于插入的每一条消息，Streams 可以自动为其生成一个全局唯一的 ID。</li>
<li>XREAD：用于读取消息，可以按 ID 读取数据；<ul>
<li>XREAD 在读取消息时，可以指定一个消息 ID，并从这个消息 ID 的下一条消息开始进行读取。</li>
<li>消费者也可以在调用 XRAED 时设定 block 配置项，实现类似于 BRPOP 的阻塞读取操作。当消息队列中没有消息时，一旦设置了 block 配置项，XREAD 就会阻塞，阻塞的时长可以在 block 配置项进行设置</li>
</ul>
</li>
<li>XREADGROUP：按消费组形式读取消息；<ul>
<li>Streams 本身可以使用 XGROUP 创建消费组，创建消费组之后，Streams 可以使用XREADGROUP 命令让消费组内的消费者读取消息，</li>
</ul>
</li>
<li>XPENDING 和 XACK：XPENDING 命令可以用来查询每个消费组内所有消费者已读取但尚未确认的消息，而 XACK 命令用于向消息队列确认消息处理已完成</li>
</ul>
</li>
</ul>
</li>
<li><p>Redis 是一个非常轻量级的键值数据库，部署一个 Redis 实例就是启动一个进程，部署 Redis 集群，也就是部署多个 Redis 实例。而 Kafka、RabbitMQ 部署时，涉及额外的组件，例如 Kafka 的运行就需要再部署ZooKeeper。相比 Redis 来说，Kafka 和 RabbitMQ 一般被认为是重量级的消息队列。</p>
</li>
</ul>
<h4 id="16丨异步机制：如何避免单线程模型的阻塞？"><a href="#16丨异步机制：如何避免单线程模型的阻塞？" class="headerlink" title="16丨异步机制：如何避免单线程模型的阻塞？"></a>16丨异步机制：如何避免单线程模型的阻塞？</h4><ul>
<li><p>Redis 实例有哪些阻塞点？</p>
<ul>
<li>Redis 实例在运行时，要和许多对象进行交互，这些不同的交互就会涉及不同的操作<ul>
<li>客户端：网络 IO，键值对增删改查操作，数据库操作；</li>
<li>磁盘：生成 RDB 快照，记录 AOF 日志，AOF 日志重写；</li>
<li>主从节点：主库生成、传输 RDB 文件，从库接收 RDB 文件、清空数据库、加载 RDB文件；</li>
<li>切片集群实例：向其他实例传输哈希槽信息，数据迁移。</li>
</ul>
</li>
<li>和客户端交互时的阻塞点<ul>
<li>网络 IO 有时候会比较慢，但是 Redis 使用了 IO 多路复用机制，避免了主线程一直处在等待网络连接或请求到来的状态，所以，网络 IO 不是导致 Redis 阻塞的因素</li>
<li>键值对的增删改查操作是 Redis 和客户端交互的主要部分，也是 Redis 主线程执行的主要任务。所以，复杂度高的增删改查操作肯定会阻塞 Redis<ul>
<li>Redis 中涉及集合的操作复杂度通常为 O(N)，要在使用时重视起来，这些操作可以作为 Redis 的第一个阻塞点：集合全量查询和聚合操作。</li>
<li>删除操作的本质是要释放键值对占用的内存空间。释放内存只是第一步，为了更加高效地管理内存空间，在应用程序释放内存时，操作系统需要把释放掉的内存块插入一个空闲内存块的链表，以便后续进行管理和再分配。这个过程本身需要一定时间，而且会阻塞当前释放内存的应用程序，所以，如果一下子释放了大量内存，空闲内存块链表操作时间就会增加，相应地就会造成 Redis 主线程的阻塞。——bigkey 删除操作就是 Redis 的第二个阻塞点</li>
<li>在 Redis 的数据库级别操作中，清空数据库（例如 FLUSHDB 和 FLUSHALL 操作）必然也是一个潜在的阻塞风险，因为它涉及到删除和释放所有的键值对。所以，这就是 Redis 的第三个阻塞点：清空数据库</li>
</ul>
</li>
</ul>
</li>
<li>和磁盘交互时的阻塞点<ul>
<li>Redis 开发者早已认识到磁盘 IO 会带来阻塞，所以就把 Redis 进一步设计为采用子进程的方式生成 RDB 快照文件，以及执行 AOF 日志重写操作。这样一来，这两个操作由子进程负责执行，慢速的磁盘 IO 就不会阻塞主线程了。</li>
<li>Redis 直接记录 AOF 日志时，会根据不同的写回策略对数据做落盘保存。一个同步写磁盘的操作的耗时大约是 1～2ms，如果有大量的写操作需要记录在 AOF 日志中，并同步写回的话，就会阻塞主线程了。这就得到了 Redis 的第四个阻塞点了：AOF 日志同步写。</li>
</ul>
</li>
<li>主从节点交互时的阻塞点<ul>
<li>在主从集群中，主库需要生成 RDB 文件，并传输给从库。主库在复制的过程中，创建和传输 RDB 文件都是由子进程来完成的，不会阻塞主线程。但是，对于从库来说，它在接收了RDB 文件后，需要使用 FLUSHDB 命令清空当前数据库，这就正好撞上了第三个阻塞点</li>
<li>从库在清空当前数据库后，还需要把 RDB 文件加载到内存，这个过程的快慢和RDB 文件的大小密切相关，RDB 文件越大，加载过程越慢，所以，加载 RDB 文件就成为了 Redis 的第五个阻塞点</li>
</ul>
</li>
<li>切片集群实例交互时的阻塞点<ul>
<li>部署 Redis 切片集群时，每个 Redis 实例上分配的哈希槽信息需要在不同实例间进行传递，同时，当需要进行负载均衡或者有实例增删时，数据会在不同的实例间进行迁移。不过，哈希槽的信息量不大，而数据迁移是渐进式执行的，所以，一般来说，这两类操作对 Redis 主线程的阻塞风险不大。</li>
<li>不过，如果使用了 Redis Cluster 方案，而且同时正好迁移的是 bigkey 的话，就会造成主线程的阻塞，因为 Redis Cluster 使用了同步迁移。当没有 bigkey 时，切片集群的各实例在进行交互时不会阻塞主线程</li>
</ul>
</li>
</ul>
</li>
<li><p>哪些阻塞点可以异步执行？</p>
<ul>
<li>如果一个操作能被异步执行，就意味着，它并不是 Redis 主线程的关键路径上的操作：客户端把请求发送给 Redis 后，等着 Redis返回数据结果的操作。</li>
<li>对于 Redis 来说，读操作是典型的关键路径操作，因为客户端发送了读操作之后，就会等待读取的数据返回，以便进行后续的数据处理。而 Redis 的第一个阻塞点“集合全量查询和聚合操作”都涉及到了读操作，所以，它们是不能进行异步操作了。</li>
<li>删除操作并不需要给客户端返回具体的数据结果，所以不算是关键路径操作。第二个阻塞点“bigkey 删除”，和第三个阻塞点“清空数据库”，都是对数据做删除，并不在关键路径上。因此，可以使用后台子线程来异步执行删除操作。</li>
<li>第四个阻塞点“AOF 日志同步写”来说，为了保证数据可靠性，Redis 实例需要保证AOF 日志中的操作记录已经落盘，这个操作虽然需要实例等待，但它并不会返回具体的数据结果给实例。所以，也可以启动一个子线程来执行 AOF 日志的同步写，而不用让主线程等待 AOF 日志的写完成。</li>
<li>“从库加载 RDB 文件”这个阻塞点。从库要想对客户端提供数据存取服务，就必须把 RDB 文件加载完成。所以，这个操作也属于关键路径上的操作，必须让从库的主线程来执行</li>
<li>对于 Redis 的五大阻塞点来说，除了“集合全量查询和聚合操作”和“从库加载 RDB 文件”，其他三个阻塞点涉及的操作都不在关键路径上，所以，可以使用 Redis 的异步子线程机制来实现 bigkey 删除，清空数据库，以及 AOF 日志同步写。</li>
</ul>
</li>
<li><p>异步的子线程机制</p>
<ul>
<li>Redis 主线程启动后，会使用操作系统提供的 pthread_create 函数创建 3 个子线程，分别由它们负责 AOF 日志写操作、键值对删除以及文件关闭的异步执行</li>
<li>主线程通过一个链表形式的任务队列和子线程进行交互。当收到键值对删除和清空数据库的操作时，主线程会把这个操作封装成一个任务，放入到任务队列中，然后给客户端返回一个完成信息，表明删除已经完成<ul>
<li>但实际上，这个时候删除还没有执行，等到后台子线程从任务队列中读取任务后，才开始实际删除键值对，并释放相应的内存空间。因此，把这种异步删除也称为惰性删除（lazy free）。此时，删除或清空操作不会阻塞主线程，这就避免了对主线程的性能影响。</li>
</ul>
</li>
<li>和惰性删除类似，当 AOF 日志配置成 everysec 选项后，主线程会把 AOF 写日志操作封装成一个任务，也放到任务队列中。后台子线程读取任务后，开始自行写入 AOF 日志，这样主线程就不用一直等待 AOF 日志写完了。</li>
<li>异步的键值对删除和数据库清空操作是 Redis 4.0 后提供的功能，Redis 也提供了新的命令来执行这两个操作。<ul>
<li>键值对删除：当你的集合类型中有大量元素（例如有百万级别或千万级别元素）需要删除时，建议你使用 UNLINK 命令。</li>
<li>清空数据库：可以在 FLUSHDB 和 FLUSHALL 命令后加上 ASYNC 选项，这样就可以让后台子线程异步地清空数据库</li>
</ul>
</li>
</ul>
</li>
<li><p>无法使用异步操作来完成时的建议</p>
<ul>
<li>遇到 bigkey 删除时，先使用集合类型提供的 SCAN 命令读取数据，然后再进行删除。因为用 SCAN 命令可以每次只读取一部分数据并进行删除，这样可以避免一次性删除大量 key 给主线程带来的阻塞。</li>
<li>集合全量查询和聚合操作：可以使用 SCAN 命令，分批读取数据，再在客户端进行聚合计算；</li>
<li>从库加载 RDB 文件：把主库的数据量大小控制在 2~4GB 左右，以保证 RDB 文件能以较快的速度加载。</li>
</ul>
</li>
</ul>
<h4 id="17丨为什么CPU结构也会影响Redis的性能？"><a href="#17丨为什么CPU结构也会影响Redis的性能？" class="headerlink" title="17丨为什么CPU结构也会影响Redis的性能？"></a>17丨为什么CPU结构也会影响Redis的性能？</h4><ul>
<li><p>主流的 CPU 架构</p>
<ul>
<li>一个 CPU 处理器中一般有多个运行核心，我们把一个运行核心称为一个物理核，每个物理核都可以运行应用程序。每个物理核都拥有私有的一级缓存（Level 1 cache，简称 L1 cache），包括一级指令缓存和一级数据缓存，以及私有的二级缓存（Level 2 cache，简称 L2 cache）。<ul>
<li>物理核的私有缓存其实是指缓存空间只能被当前的这个物理核使用，其他的物理核无法对这个核的缓存空间进行数据存取。</li>
<li>因为 L1 和 L2 缓存是每个物理核私有的，所以，当数据或指令保存在 L1、L2 缓存时，物理核访问它们的延迟不超过 10 纳秒，速度非常快。那么，如果 Redis 把要运行的指令或存取的数据保存在 L1 和 L2 缓存的话，就能高速地访问这些指令和数据</li>
<li>这些 L1 和 L2 缓存的大小受限于处理器的制造技术，一般只有 KB 级别，存不下太多的数据。如果 L1、L2 缓存中没有所需的数据，应用程序就需要访问内存来获取数据。而应用程序的访存延迟一般在百纳秒级别，是访问 L1、L2 缓存的延迟的近 10 倍，不可避免地会对性能造成影响。</li>
</ul>
</li>
<li>不同的物理核还会共享一个共同的三级缓存（Level 3 cache，简称为 L3 cache）。L3 缓存能够使用的存储资源比较多，所以一般比较大，能达到几 MB 到几十 MB，这就能让应用程序缓存更多的数据。当 L1、L2 缓存中没有数据缓存时，可以访问 L3，尽可能避免访问内存。</li>
<li>现在主流的 CPU 处理器中，每个物理核通常都会运行两个超线程，也叫作逻辑核。同一个物理核的逻辑核会共享使用 L1、L2 缓存。在主流的服务器上，一个 CPU 处理器会有 10 到 20 多个物理核。同时，为了提升服务器的处理能力，服务器上通常还会有多个 CPU 处理器（也称为多 CPU Socket），每个处理器有自己的物理核（包括 L1、L2 缓存），L3 缓存，以及连接的内存，同时，不同处理器间通过总线连接。在多 CPU 架构上，应用程序可以在不同的处理器上运行。</li>
<li>如果应用程序先在一个 Socket 上运行，并且把数据保存到了内存，然后被调度到另一个 Socket 上运行，此时，应用程序再进行内存访问时，就需要访问之前 Socket 上连接的内存，这种访问属于远端内存访问。和访问 Socket 直接连接的内存相比，远端内存访问会增加应用程序的延迟。<ul>
<li>在多 CPU 架构下，一个应用程序访问所在 Socket 的本地内存和访问远端内存的延迟并不一致，所以，我们也把这个架构称为非统一内存访问架构（Non-Uniform Memory Access，NUMA 架构）。</li>
</ul>
</li>
</ul>
</li>
<li><p>CPU 多核对 Redis 性能的影响</p>
<ul>
<li>在一个 CPU 核上运行时，应用程序需要记录自身使用的软硬件资源信息（例如栈指针、CPU 核的寄存器值等），这些信息称为运行时信息。同时，应用程序访问最频繁的指令和数据还会被缓存到 L1、L2 缓存上，以便提升执行速度。</li>
<li>在多核 CPU 的场景下，一旦应用程序需要在一个新的 CPU 核上运行，那么，运行时信息就需要重新加载到新的 CPU 核上。而且，新的 CPU 核的 L1、L2 缓存也需要重新加载数据和指令，这会导致程序的运行时间增加。</li>
<li>在多核 CPU 环境下对 Redis 性能进行调优的案例<ul>
<li>项目需求是要对 Redis 的 99% 尾延迟进行优化，要求 GET 尾延迟小于 300微秒，PUT 尾延迟小于 500 微秒</li>
<li>把所有请求的处理延迟从小到大排个序，99% 的请求延迟小于的值就是 99% 尾延迟。比如说，有 1000 个请求，假设按请求延迟从小到大排序后，第 991 个请求的延迟实测值是 1ms，而前 990 个请求的延迟都小于 1ms，所以，这里的 99% 尾延迟就是 1ms。</li>
<li>仔细检测了 Redis 实例运行时的服务器 CPU 的状态指标值，这才发现，CPU的 context switch 次数比较多。context switch 是指线程的上下文切换，这里的上下文就是线程的运行时信息。在 CPU 多核的环境中，一个线程先在一个 CPU 核上运行，之后又切换到另一个 CPU 核上运行，这时就会发生 context switch。</li>
<li>当 context switch 发生后，Redis 主线程的运行时信息需要被重新加载到另一个 CPU 核上，而且，此时，另一个 CPU 核上的 L1、L2 缓存中，并没有 Redis 实例之前运行时频繁访问的指令和数据，所以，这些指令和数据都需要重新从 L3 缓存，甚至是内存中加载。这个重新加载的过程是需要花费一定时间的。而且，Redis 实例需要等待这个重新加载的过程完成后，才能开始处理请求，所以，这也会导致一些请求的处理时间增加。</li>
<li>如果在 CPU 多核场景下，Redis 实例被频繁调度到不同 CPU 核上运行的话，那么，对Redis 实例的请求处理时间影响就更大了。每调度一次，一些请求就会受到运行时信息、指令和数据重新加载过程的影响，这就会导致某些请求的延迟明显高于其他请求。</li>
<li>要避免 Redis 总是在不同 CPU 核上来回调度执行。于是，我们尝试着把 Redis实例和 CPU 核绑定了，让一个 Redis 实例固定运行在一个 CPU 核上，可以使用taskset 命令把一个程序绑定在一个核上运行。</li>
</ul>
</li>
</ul>
</li>
<li><p>CPU 的 NUMA 架构对 Redis 性能的影响</p>
<ul>
<li>在实际应用 Redis 时，为了提升 Redis 的网络性能，把操作系统的网络中断处理程序和 CPU 核绑定。这个做法可以避免网络中断处理程序在不同核上来回调度执行，的确能有效提升 Redis 的网络处理性能。</li>
<li>但是，网络中断程序是要和 Redis 实例进行网络数据交互的，一旦把网络中断程序绑核后，就需要注意 Redis 实例是绑在哪个核上了，这会关系到 Redis 访问网络数据的效率高低。</li>
<li>Redis 实例和网络中断程序的数据交互：网络中断处理程序从网卡硬件中读取数据，并把数据写入到操作系统内核维护的一块内存缓冲区。内核会通过 epoll 机制触发事件，通知 Redis 实例，Redis 实例再把数据从内核的内存缓冲区拷贝到自己的内存空间</li>
<li>在 CPU 的 NUMA 架构下，当网络中断处理程序、Redis 实例分别和 CPU 核绑定后，就会有一个潜在的风险：如果网络中断处理程序和 Redis 实例各自所绑的 CPU 核不在同一个 CPU Socket 上，那么，Redis 实例读取网络数据时，就需要跨 CPU Socket 访问内存，这个过程会花费较多时间</li>
<li>为了避免 Redis 跨 CPU Socket 访问网络数据，我们最好把网络中断程序和 Redis实例绑在同一个 CPU Socket 上，这样一来，Redis 实例就可以直接从本地内存读取网络数据</li>
<li>在 CPU 的 NUMA 架构下，对 CPU 核的编号规则，并不是先把一个 CPU Socket 中的所有逻辑核编完，再对下一个 CPU Socket 中的逻辑核编码，而是先给每个 CPU Socket 中每个物理核的第一个逻辑核依次编号，再给每个 CPU Socket 中的物理核的第二个逻辑核依次编号。</li>
</ul>
</li>
<li><p>绑核的风险和解决方案</p>
<ul>
<li>把 Redis 实例绑到一个 CPU 逻辑核上时，就会导致子进程、后台线程和 Redis 主线程竞争 CPU 资源，一旦子进程或后台线程占用 CPU 时，主线程就会被阻塞，导致Redis 请求延迟增加。</li>
<li>两种解决方案，分别是一个 Redis 实例对应绑一个物理核和优化 Redis 源码。<ul>
<li>一个 Redis 实例对应绑一个物理核：在给 Redis 实例绑核时，我们不要把一个实例和一个逻辑核绑定，而要和一个物理核绑定，也就是说，把一个物理核的 2 个逻辑核都用上；和只绑一个逻辑核相比，把 Redis 实例和物理核绑定，可以让主线程、子进程、后台线程共享使用 2 个逻辑核，可以在一定程度上缓解 CPU 资源竞争</li>
<li>优化 Redis 源码：修改 Redis 源码，把子进程和后台线程绑到不同的 CPU 核上。既可以实现 Redis 实例绑核，避免切换核带来的性能影响，还可以让子进程、后台线程和主线程不在同一个核上运行，避免了它们之间的 CPU 资源竞争。相比使用 taskset 绑核来说，这个方案可以进一步降低绑核的风险</li>
</ul>
</li>
</ul>
</li>
</ul>
<h4 id="18丨波动的响应延迟：如何应对变慢的Redis？（上）"><a href="#18丨波动的响应延迟：如何应对变慢的Redis？（上）" class="headerlink" title="18丨波动的响应延迟：如何应对变慢的Redis？（上）"></a>18丨波动的响应延迟：如何应对变慢的Redis？（上）</h4><ul>
<li><p>应用服务器（App Server）要完成一个事务性操作，包括在 MySQL 上执行一个写事务，在 Redis 上插入一个标记位，并通过一个第三方服务给用户发送一条完成消息。</p>
<ul>
<li>这三个操作都需要保证事务原子性，所以，如果此时 Redis 的延迟增加，就会拖累 App Server 端整个事务的执行。这个事务一直完成不了，又会导致 MySQL 上写事务占用的资源无法释放，进而导致访问 MySQL 的其他请求被阻塞。很明显，Redis 变慢会带来严重的连锁反应。</li>
</ul>
</li>
<li><p>Redis 真的变慢了吗？</p>
<ul>
<li>一个最直接的方法，就是查看 Redis 的响应延迟。<ul>
<li>Redis 延迟很低，但是在某些时刻，有些 Redis 实例会出现很高的响应延迟，甚至能达到几秒到十几秒，不过持续时间不长，这也叫延迟“毛刺”</li>
<li>看 Redis 延迟的绝对值，但是，在不同的软硬件环境下，Redis 本身的绝对性能并不相同。</li>
</ul>
</li>
<li>第二个方法是基于当前环境下的 Redis 基线性能做判断。<ul>
<li>所谓的基线性能就是一个系统在低压力、无干扰下的基本性能，这个性能只由当前的软硬件配置决定。</li>
<li>可以把它和Redis 运行时的延迟结合起来，再进一步判断 Redis 性能是否变慢了。把运行时延迟和基线性能进行对比，如果观察到的 Redis 运行时延迟是其基线性能的 2 倍及以上，就可以认定 Redis 变慢了。</li>
<li>判断基线性能这一点，对于在虚拟化环境下运行的 Redis 来说，非常重要。这是因为，在虚拟化环境（例如虚拟机或容器）中，由于增加了虚拟化软件层，与物理机相比，虚拟机或容器本身就会引入一定的性能开销，所以基线性能会高一些</li>
</ul>
</li>
<li>如果想了解网络对 Redis 性能的影响，一个简单的方法是用 iPerf 这样的工具，测量从Redis 客户端到服务器端的网络延迟。</li>
</ul>
</li>
<li><p>如何应对 Redis 变慢？</p>
<ul>
<li>Redis 自身的操作特性、文件系统和操作系统，它们是影响 Redis 性能的三大要素。</li>
</ul>
</li>
<li><p>Redis 自身操作特性的影响</p>
<ul>
<li><p>Redis 提供的键值对命令操作对延迟性能的影响</p>
</li>
<li><p>慢查询命令，发现 Redis 性能变慢时，可以通过 Redis 日志，或者是 latency monitor 工具，查询变慢的请求，根据请求对应的具体命令以及官方文档，确认下是否采用了复杂度高的慢查询命令。如果的确有大量的慢查询命令，有两种处理方式：</p>
<ul>
<li>用其他高效命令代替。比如说，如果你需要返回一个 SET 中的所有成员时，不要使用SMEMBERS 命令，而是要使用 SSCAN 多次迭代返回，避免一次返回大量数据，造成线程阻塞。</li>
<li>当需要执行排序、交集、并集操作时，可以在客户端完成，而不要用 SORT、SUNION、SINTER 这些命令，以免拖慢 Redis 实例。</li>
</ul>
<p>还有一个比较容易忽略的慢查询命令，就是 KEYS。它用于返回和输入模式匹配的所有key，KEYS 命令需要遍历存储的键值对，所以操作延时高。一般不被建议用于生产环境中</p>
</li>
<li><p>过期 key 操作，过期 key 的自动删除机制。它是 Redis 用来回收内存空间的常用机制，应用广泛，本身就会引起 Redis 操作阻塞，导致性能变慢</p>
<ul>
<li><p>Redis 键值对的 key 可以设置过期时间，具体的算法如下：</p>
<p>采样 CTIVE_EXPIRE_CYCLE_LOOKUPS_PER_LOOP 个数的 key，并将其中过期的key 全部删除；</p>
<p>如果超过 25% 的 key 过期了，则重复删除的过程，直到过期 key 的比例降至 25% 以下。</p>
</li>
<li><p>删除操作是阻塞的（Redis 4.0 后可以用异步线程机制来减少阻塞影响）。所以，一旦该条件触发，Redis 的线程就会一直执行删除，这样一来，就没办法正常服务其他的键值操作了，就会进一步引起其他键值操作的延迟增加，Redis 就会变慢。</p>
</li>
<li><p>频繁使用带有相同时间参数的 EXPIREAT 命令设置过期 key，这就会导致，在同一秒内有大量的 key 同时过期。</p>
</li>
<li><p>可以在EXPIREAT 和 EXPIRE 的过期时间参数上，加上一个一定大小范围内的随机数，这样，既保证了 key 在一个邻近时间范围内被删除，又避免了同时过期造成的压力。</p>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<h4 id="19丨波动的响应延迟：如何应对变慢的Redis？（下）"><a href="#19丨波动的响应延迟：如何应对变慢的Redis？（下）" class="headerlink" title="19丨波动的响应延迟：如何应对变慢的Redis？（下）"></a>19丨波动的响应延迟：如何应对变慢的Redis？（下）</h4><ul>
<li><p>Redis 会持久化保存数据到磁盘，这个过程要依赖文件系统来完成，所以，文件系统将数据写回磁盘的机制，会直接影响到 Redis 持久化的效率。而且，在持久化的过程中，Redis也还在接收其他请求，持久化的效率高低又会影响到 Redis 处理请求的性能</p>
</li>
<li><p>Redis 是内存数据库，内存操作非常频繁，所以，操作系统的内存机制会直接影响到 Redis 的处理效率。比如说，如果 Redis 的内存不够用了，操作系统会启动 swap机制，这就会直接拖慢 Redis。</p>
</li>
<li><p>文件系统：AOF 模式</p>
<ul>
<li><p>为了保证数据可靠性，Redis 会采用 AOF 日志或 RDB 快照。其中，AOF日志提供了三种日志写回策略：no、everysec、always。这三种写回策略依赖文件系统的两个系统调用完成，也就是 write 和 fsync。</p>
<ul>
<li>write 只要把日志记录写到内核缓冲区，就可以返回了，并不需要等待日志实际写回到磁盘；</li>
<li>而 fsync 需要把日志记录写回到磁盘后才能返回，时间较长</li>
</ul>
</li>
<li><p>当写回策略配置为 everysec 和 always 时，Redis 需要调用 fsync 把日志写回磁盘。但是，这两种写回策略的具体执行情况还不太一样。</p>
<ul>
<li>在使用 everysec 时，Redis 允许丢失一秒的操作记录，所以，Redis 主线程并不需要确保每个操作记录日志都写回磁盘。而且，fsync 的执行时间很长，如果是在 Redis 主线程中执行 fsync，就容易阻塞主线程。所以，当写回策略配置为 everysec 时，Redis 会使用后台的子线程异步完成 fsync 的操作。</li>
<li>而对于 always 策略来说，Redis 需要确保每个操作记录日志都写回磁盘，如果用后台子线程异步完成，主线程就无法及时地知道每个操作是否已经完成了，这就不符合 always 策略的要求了。所以，always 策略并不使用后台子线程来执行。</li>
</ul>
</li>
<li><p>在使用 AOF 日志时，为了避免日志文件不断增大，Redis 会执行 AOF 重写，生成体量缩小的新的 AOF 日志文件。AOF 重写本身需要的时间很长，也容易阻塞 Redis 主线程，所以，Redis 使用子进程来进行 AOF 重写</p>
<ul>
<li>这里有一个潜在的风险点：AOF 重写会对磁盘进行大量 IO 操作，同时，fsync 又需要等到数据写到磁盘后才能返回，所以，当 AOF 重写的压力比较大时，就会导致 fsync 被阻塞。虽然 fsync 是由后台子线程负责执行的，但是，主线程会监控 fsync 的执行进度。</li>
<li>当主线程使用后台子线程执行了一次 fsync，需要再次把新接收的操作记录写回磁盘时，如果主线程发现上一次的 fsync 还没有执行完，那么它就会阻塞。所以，如果后台子线程执行的 fsync 频繁阻塞的话（比如 AOF 重写占用了大量的磁盘 IO 带宽），主线程也会阻塞，导致 Redis 性能变慢。</li>
</ul>
</li>
<li><p>由于 fsync 后台子线程和 AOF 重写子进程的存在，主IO 线程一般不会被阻塞。但是，如果在重写日志时，AOF 重写子进程的写入量比较大，fsync 线程也会被阻塞，进而阻塞主线程，导致延迟增加。</p>
</li>
<li><p>可以检查下 Redis 配置文件中的 appendfsync 配置项，该配置项的取值表明了Redis 实例使用的是哪种 AOF 日志写回策略</p>
<ul>
<li>如果 AOF 写回策略使用了 everysec 或 always 配置，请先确认下业务方对数据可靠性的要求，明确是否需要每一秒或每一个操作都记日志。有的业务方不了解 Redis AOF 机制，很可能就直接使用数据可靠性最高等级的 always 配置了。其实，在有些场景中（例如Redis 用于缓存），数据丢了还可以从后端数据库中获取，并不需要很高的数据可靠性。</li>
<li>如果业务应用对延迟非常敏感，但同时允许一定量的数据丢失，那么，可以把配置项 no-appendfsync-<br>on-rewrite 设置为 yes，这个配置项设置为 yes 时，表示在 AOF 重写时，不进行 fsync 操作。也就是说，Redis 实例把写命令写到内存后，不调用后台线程进行 fsync 操作，就可以直接返回了。当然，如果此时实例发生宕机，就会导致数据丢失。反之，如果这个配置项设置为 no（也是默认配置），在 AOF 重写时，Redis 实例仍然会调用后台线程进行 fsync 操作，这就会给实例带来阻塞。</li>
</ul>
</li>
<li><p>如果的确需要高性能，同时也需要高可靠数据保证，建议考虑采用高速的固态硬盘作为 AOF 日志的写入设备。高速固态盘的带宽和并发度比传统的机械硬盘的要高出 10 倍及以上。在 AOF 重写和fsync 后台线程同时执行时，固态硬盘可以提供较为充足的磁盘 IO 资源，让 AOF 重写和fsync 后台线程的磁盘 IO 资源竞争减少，从而降低对 Redis 的性能影响</p>
</li>
</ul>
</li>
<li><p>操作系统：swap</p>
<ul>
<li>内存 swap 是操作系统里将内存数据在内存和磁盘间来回换入和换出的机制，涉及到磁盘的读写，所以，一旦触发 swap，无论是被换入数据的进程，还是被换出数据的进程，其性能都会受到慢速磁盘读写的影响。</li>
<li>Redis 是内存数据库，内存使用量大，如果没有控制好内存的使用量，或者和其他内存需求大的应用一起运行了，就可能受到 swap 的影响，而导致性能变慢。<ul>
<li>正常情况下，Redis 的操作是直接通过访问内存就能完成，一旦 swap 被触发了，Redis 的请求操作需要等到磁盘数据读写完成才行。而且，和AOF 日志文件读写使用 fsync 线程不同，swap 触发后影响的是 Redis 主 IO 线程，这会极大地增加 Redis 的响应时间。</li>
</ul>
</li>
<li>什么时候会触发 swap 呢？触发 swap 的原因主要是物理机器内存不足，对于 Redis 而言，有两种常见的情况：<ul>
<li>Redis 实例自身使用了大量的内存，导致物理机器的可用内存不足；</li>
<li>和 Redis 实例在同一台机器上运行的其他进程，在进行大量的文件读写操作。文件读写本身会占用系统内存，这会导致分配给 Redis 实例的内存量变少，进而触发 Redis 发生swap。</li>
</ul>
</li>
<li>解决思路：增加机器的内存或者使用 Redis 集群。</li>
</ul>
</li>
<li><p>操作系统：内存大页</p>
<ul>
<li>除了内存 swap，还有一个和内存相关的因素，即内存大页机制（Transparent Huge Page, THP），也会影响 Redis 性能。该机制支持 2MB 大小的内存页分配，而常规的内存页分配是按 4KB 的粒度来执行的。</li>
<li>虽然内存大页可以给 Redis 带来内存分配方面的收益，但是，不要忘了，Redis 为了提供数据可靠性保证，需要将数据做持久化保存。这个写入过程由额外的线程执行，所以，此时，Redis 主线程仍然可以接收客户端写请求。客户端的写请求可能会修改正在进行持久化的数据。在这一过程中，Redis 就会采用写时复制机制，也就是说，一旦有数据要被修改，Redis 并不会直接修改内存中的数据，而是将这些数据拷贝一份，然后再进行修改。</li>
<li>如果采用了内存大页，那么，即使客户端请求只修改 100B 的数据，Redis 也需要拷贝2MB 的大页。相反，如果是常规内存页机制，只用拷贝 4KB。两者相比，你可以看到，当客户端请求修改或新写入数据较多时，内存大页机制将导致大量的拷贝，这就会影响Redis 正常的访存操作，最终导致性能变慢。</li>
<li>在实际生产环境中部署时，我建议你不要使用内存大页机制，操作也很简单 echo never &#x2F;sys&#x2F;kernel&#x2F;mm&#x2F;transparent_hugepage&#x2F;enabled 即可</li>
</ul>
</li>
</ul>
<h4 id="20-删除数据后，为什么内存占用率还是很高？"><a href="#20-删除数据后，为什么内存占用率还是很高？" class="headerlink" title="20 | 删除数据后，为什么内存占用率还是很高？"></a>20 | 删除数据后，为什么内存占用率还是很高？</h4><ul>
<li><p>当数据删除后，Redis 释放的内存空间会由内存分配器管理，并不会立即返回给操作系统。所以，操作系统仍然会记录着给 Redis 分配了大量内存。这往往会伴随一个潜在的风险点：Redis 释放的内存空间可能并不是连续的，那么这些不连续的内存空间很有可能处于一种闲置的状态。这就会导致一个问题：虽然有<br>空闲空间，Redis 却无法用来保存数据，不仅会减少 Redis 能够实际保存的数据量，还会降低 Redis 运行机器的成本回报率。</p>
</li>
<li><p>什么是内存碎片？</p>
<ul>
<li>虽然操作系统的剩余内存空间总量足够，但是，应用申请的是一块连续地址空间的 N 字节，但在剩余的内存空间中，没有大小为 N 字节的连续空间了，那么，这些剩余空间就是内存碎片</li>
</ul>
</li>
<li><p>内存碎片是如何形成的？</p>
<ul>
<li>内因：内存分配器的分配策略<ul>
<li>内存分配器的分配策略就决定了操作系统无法做到“按需分配”。这是因为，内存分配器一般是按固定大小来分配内存，而不是完全按照应用程序申请的内存空间大小给程序分配。</li>
<li>Redis 可以使用 libc、jemalloc、tcmalloc 多种内存分配器来分配内存，默认使用jemalloc。jemalloc 的分配策略之一，是按照一系列固定的大小划分内存空间，例如 8 字节、16 字节、32 字节、48 字节，…, 2KB、4KB、8KB 等。当程序申请的内存最接近某个固定值时，jemalloc 会给它分配相应大小的空间。这样的分配方式本身是为了减少分配次数。</li>
<li>但是，如果 Redis 每次向分配器申请的内存空间大小不一样，这种分配方式就会有形成碎片的风险，而这正好来源于 Redis 的外因了。</li>
</ul>
</li>
<li>外因：键值对大小不一样和删改操作<ul>
<li>Redis 通常作为共用的缓存系统或键值数据库对外提供服务，所以，不同业务应用的数据都可能保存在 Redis 中，这就会带来不同大小的键值对。这样一来，Redis 申请内存空间分配时，本身就会有大小不一的空间需求。内存分配器只能按固定大小分配内存，所以，分配的内存空间一般都会比申请的空间大一些，不会完全一致，这本身就会造成一定的碎片，降低内存空间存储效率。</li>
<li>第二个外因是，这些键值对会被修改和删除，这会导致空间的扩容和释放。具体来说，一方面，如果修改后的键值对变大或变小了，就需要占用额外的空间或者释放不用的空间。另一方面，删除的键值对就不再需要内存空间了，此时，就会把空间释放出来，形成空闲空间。</li>
</ul>
</li>
</ul>
</li>
<li><p>如何判断是否有内存碎片？</p>
<ul>
<li>Redis 是内存数据库，内存利用率的高低直接关系到 Redis 运行效率的高低。为了让用户能监控到实时的内存使用情况，Redis 自身提供了 INFO 命令，可以用来查询内存使用的详细信息<ul>
<li>有一个 mem_fragmentation_ratio 的指标，它表示的就是 Redis 当前的内存碎片率，是两个指标used_memory_rss 和 used_memory 相除的结果。used_memory_rss 是操作系统实际分配给 Redis 的物理内存空间，里面就包含了碎片；而 used_memory 是 Redis 为了保存数据实际申请使用的空间。</li>
</ul>
</li>
<li>mem_fragmentation_ratio 大于 1 但小于 1.5。这种情况是合理的。毕竟，内因的内存分配器是一定要使用的，分配策略都是通用的，不会轻易修改；而外因由 Redis 负载决定，也无法限制。所以，存在内存碎片也是正常的。</li>
<li>mem_fragmentation_ratio 大于 1.5 。这表明内存碎片率已经超过了 50%。一般情况下，这个时候，就需要采取一些措施来降低内存碎片率了。</li>
</ul>
</li>
<li><p>如何清理内存碎片？</p>
<ul>
<li>Redis 发生内存碎片后，一个“简单粗暴”的方法就是重启 Redis 实例，重启 Redis 会带来两个后果：<ul>
<li>如果 Redis 中的数据没有持久化，那么，数据就会丢失；</li>
<li>即使 Redis 数据持久化了，还需要通过 AOF 或 RDB 进行恢复，恢复时长取决于AOF 或 RDB 的大小，如果只有一个 Redis 实例，恢复阶段无法提供服务。</li>
</ul>
</li>
<li>从 4.0-RC3 版本以后，Redis 自身提供了一种内存碎片自动清理的方法，内存碎片清理，简单来说，就是“搬家让位，合并空间”。当有数据把一块连续的内存空间分割成好几块不连续的空间时，操作系统就会把数据拷贝到别处。此时，数据拷贝需要能把这些数据原来占用的空间都空出来，把原本不连续的内存空间变成连续的空间。否则，如果数据拷贝后，并没有形成连续的内存空间，这就不能算是清理了。</li>
<li>碎片清理是有代价的，操作系统需要把多份数据拷贝到新位置，把原有空间释放出来，这会带来时间开销。因为 Redis 是单线程，在数据拷贝时，Redis 只能等着，这就导致 Redis 无法及时处理请求，性能就会降低。而且，有的时候，数据拷贝还需要注意顺序，这种对顺序性的要求，会进一步增加 Redis 的等待时间，导致性能降低。</li>
<li>Redis 专门为自动内存碎片清理功机制设置的参数，可以通过设置参数，来控制碎片清理的开始和结束时机，以及占用的 CPU 比例，从而减少碎片清理对 Redis 本身请求处理的性能影响。Redis 需要启用自动内存碎片清理，可以把 activedefrag 配置项设置为 yes，具体什么时候清理，会受到下面这两个参数的控制。这两个参数分别设置了触发内存清理的一个条件，如果同时满足这两个条件，就开始清理。在清理的过程中，只要有一个条件不满足了，就停止自动清理。<ul>
<li>active-defrag-ignore-bytes 100mb：表示内存碎片的字节数达到 100MB 时，开始清理；</li>
<li>active-defrag-threshold-lower 10：表示内存碎片空间占操作系统分配给 Redis 的总空间比例达到 10% 时，开始清理。</li>
</ul>
</li>
<li>为了尽可能减少碎片清理对 Redis 正常请求处理的影响，自动内存碎片清理功能在执行时，还会监控清理操作占用的 CPU 时间，而且还设置了两个参数，分别用于控制清理操作占用的 CPU 时间比例的上、下限，既保证清理工作能正常进行，又避免了降低 Redis 性能。这两个参数具体如下：<ul>
<li>active-defrag-cycle-min 25： 表示自动清理过程所用 CPU 时间的比例不低于25%，保证清理能正常开展；</li>
<li>active-defrag-cycle-max 75：表示自动清理过程所用 CPU 时间的比例不高于75%，一旦超过，就停止清理，从而避免在清理时，大量的内存拷贝阻塞 Redis，导致响应延迟升高。</li>
</ul>
</li>
</ul>
</li>
</ul>
<h4 id="21丨缓冲区：一个可能引发“惨案”的地方"><a href="#21丨缓冲区：一个可能引发“惨案”的地方" class="headerlink" title="21丨缓冲区：一个可能引发“惨案”的地方"></a>21丨缓冲区：一个可能引发“惨案”的地方</h4><ul>
<li><p>缓冲区的功能其实很简单，主要就是用一块内存空间来暂时存放命令数据，以免出现因为数据和命令的处理速度慢于发送速度而导致的数据丢失和性能问题。但因为缓冲区的内存空间有限，如果往里面写入数据的速度持续地大于从里面读取数据的速度，就会导致缓冲区需要越来越多的内存来暂存数据。当缓冲区占用的内存超出了设定的上限阈值时，就会出现缓冲区溢出。如果发生了溢出，就会丢数据了。</p>
<ul>
<li>如果不给缓冲区的大小设置上限，随着累积的数据越来越多，缓冲区占用内存空间越来越大，一旦耗尽了 Redis 实例所在机器的可用内存，就会导致 Redis 实例崩溃</li>
<li>缓冲区是用来避免请求或数据丢失的惨案的，但也只有用对了，才能真正起到“避免”的作用。</li>
<li>Redis 是典型的 client-server 架构，所有的操作命令都需要通过客户端发送给服务器端。所以，缓冲区在 Redis 中的一个主要应用场景，就是在客户端和服务器端之间进行通信时，用来暂存客户端发送的命令数据，或者是服务器端返回给客户端的数据结果。此外，缓冲区的另一个主要应用场景，是在主从节点间进行数据同步时，用来暂存主节点接收的写命令和数据。</li>
</ul>
</li>
<li><p>客户端输入和输出缓冲区</p>
<ul>
<li>为了避免客户端和服务器端的请求发送和处理速度不匹配，服务器端给每个连接的客户端都设置了一个输入缓冲区和输出缓冲区，称之为客户端输入缓冲区和输出缓冲区。</li>
<li>输入缓冲区会先把客户端发送过来的命令暂存起来，Redis 主线程再从输入缓冲区中读取命令，进行处理。当 Redis 主线程处理完数据后，会把结果写入到输出缓冲区，再通过输出缓冲区返回给客户端</li>
</ul>
</li>
<li><p>如何应对输入缓冲区溢出？</p>
<ul>
<li>输入缓冲区就是用来暂存客户端发送的请求命令的，所以可能导致溢出的情况主要是下面两种：<ul>
<li>写入了 bigkey，比如一下子写入了多个百万级别的集合类型数据；</li>
<li>服务器端处理请求的速度过慢，例如，Redis 主线程出现了间歇性阻塞，无法及时处理正常发送的请求，导致客户端发送的请求在缓冲区越积越多。</li>
</ul>
</li>
<li>如何查看输入缓冲区的内存使用情况<ul>
<li>要查看和服务器端相连的每个客户端对输入缓冲区的使用情况，可以使用 CLIENT LIST 命令，CLIENT 命令返回的信息虽然很多，但只需要重点关注两类信息就可以了。一类是与服务器端连接的客户端的信息。这个案例展示的是一个客户端的输入缓冲区情况，如果有多个客户端，输出结果中的 addr 会显示不同客户端的 IP 和端口号。另一类是与输入缓冲区相关的三个参数：<ul>
<li>cmd，表示客户端最新执行的命令。</li>
<li>qbuf，表示输入缓冲区已经使用的大小。</li>
<li>qbuf-free，表示输入缓冲区尚未使用的大小。qbuf 和 qbuf-free 的总和就是，Redis 服务器端当前为已连接的这个客户端分配的缓冲区总大小</li>
</ul>
</li>
<li>如果 qbuf 很大，而同时 qbuf-free 很小，就要引起注意了，因为这时候输入缓冲区已经占用了很多内存，而且没有什么空闲空间了。此时，客户端再写入大量命令的话，就会引起客户端输入缓冲区溢出，Redis 的处理办法就是把客户端连接关闭，结果就是业务程序无法进行数据存取了。</li>
<li>通常情况下，Redis 服务器端不止服务一个客户端，当多个客户端连接占用的内存总量，超过了 Redis 的 maxmemory 配置项时（例如 4GB），就会触发 Redis 进行数据淘汰。一旦数据被淘汰出 Redis，再要访问这部分数据，就需要去后端数据库读取，这就降低了业务应用的访问性能。此外，更糟糕的是，如果使用多个客户端，导致 Redis 内存占用过大，也会导致内存溢出（out-of-memory）问题，进而会引起 Redis 崩溃，给业务应用造成严重影响。</li>
</ul>
</li>
<li>如何避免输入缓冲区溢出<ul>
<li>可以从两个角度去考虑如何避免，一是把缓冲区调大，二是从数据命令的发送和处理速度入手。</li>
<li>Redis 的客户端输入缓冲区大小的上限阈值，在代码中就设定为了 1GB。也就是说，Redis服务器端允许为每个客户端最多暂存 1GB 的命令和数据。1GB 的大小，对于一般的生产环境已经是比较合适的了。一方面，这个大小对于处理绝大部分客户端的请求已经够用了；另一方面，如果再大的话，Redis 就有可能因为客户端占用了过多的内存资源而崩溃，所以，Redis 并没有提供参数让我们调节客户端输入缓冲区的大小</li>
<li>只能从数据命令的发送和处理速度入手，也就是避免客户端写入 bigkey，以及避免 Redis 主线程阻塞。</li>
</ul>
</li>
</ul>
</li>
<li><p>如何应对输出缓冲区溢出？</p>
<ul>
<li>Redis 的输出缓冲区暂存的是 Redis 主线程要返回给客户端的数据。一般来说，主线程返回给客户端的数据，既有简单且大小固定的 OK 响应（例如，执行 SET 命令）或报错信息，也有大小不固定的、包含具体数据的执行结果（例如，执行 HGET 命令）。</li>
<li>Redis 为每个客户端设置的输出缓冲区也包括两部分：一部分，是一个大小为 16KB的固定缓冲空间，用来暂存 OK 响应和出错信息；另一部分，是一个可以动态增加的缓冲空间，用来暂存大小可变的响应结果。</li>
<li>什么情况下会发生输出缓冲区溢出呢？<ul>
<li>服务器端返回 bigkey 的大量结果；bigkey 原本就会占用大量的内存空间，所以服务器端返回的结果包含 bigkey，必然会影响输出缓冲区</li>
<li>执行了 MONITOR 命令；</li>
<li>缓冲区大小设置得不合理。</li>
</ul>
</li>
<li>MONITOR 命令是用来监测 Redis 执行的。执行这个命令之后，就会持续输出监测到的各个命令操作，MONITOR 的输出结果会持续占用输出缓冲区，并越<br>占越多，最后的结果就是发生溢出。所以，MONITOR 命令主要用在调试环境中，不要在线上生产环境中持续使用 MONITOR。当然，如果在线上环境中偶尔使用 MONITOR 检查 Redis 的命令执行情况，是没问题的。</li>
<li>和输入缓冲区不同，可以通过 client output-<br>buffer-limit 配置项，来设置缓冲区的大小。具体设置的内容包括两方面：<ul>
<li>设置缓冲区大小的上限阈值；</li>
<li>设置输出缓冲区持续写入数据的数量上限阈值，和持续写入数据的时间的上限阈值。</li>
</ul>
</li>
<li>对于和 Redis 实例进行交互的应用程序来说，主要使用两类客户端和 Redis 服务器端交互，分别是常规和 Redis 服务器端进行读写命令交互的普通客户端，以及订阅了 Redis 频道的订阅客户端。此外，在 Redis 主从集群中，主节点上也有一类客户端（从节点客户端）用来和从节点进行数据同步</li>
<li>通常把普通客户端的缓冲区大小限制，以及持续写入量限制、持续写入时间限制都设置为 0，也就是不做限制</li>
<li>对于订阅客户端来说，一旦订阅的 Redis 频道有消息了，服务器端都会通过输出缓冲区把消息发给客户端。所以，订阅客户端和服务器间的消息发送方式，不属于阻塞式发送。不过，如果频道消息较多的话，也会占用较多的输出缓冲区空间。因此，会给订阅客户端设置缓冲区大小限制、缓冲区持续写入量限制，以及持续写入时间限制</li>
</ul>
</li>
<li><p>主从集群中的缓冲区</p>
<ul>
<li>主从集群间的数据复制包括全量复制和增量复制两种。全量复制是同步所有数据，而增量复制只会把主从库网络断连期间主库收到的命令，同步给从库。无论在哪种形式的复制中，为了保证主从节点的数据一致，都会用到缓冲区</li>
<li>复制缓冲区的溢出问题<ul>
<li>在全量复制过程中，主节点在向从节点传输 RDB 文件的同时，会继续接收客户端发送的写命令请求。这些写命令就会先保存在复制缓冲区中，等 RDB 文件传输完成后，再发送给从节点去执行。主节点上会为每个从节点都维护一个复制缓冲区，来保证主从节点间的数据同步。如果在全量复制时，从节点接收和加载 RDB 较慢，同时主节点接收到了大量的写命令，写命令在复制缓冲区中就会越积越多，最终导致溢出</li>
<li>主节点上的复制缓冲区，本质上也是一个用于和从节点连接的客户端（称之为从节点客户端），使用的输出缓冲区。复制缓冲区一旦发生溢出，主节点也会直接关闭和从节点进行复制操作的连接，导致全量复制失败</li>
<li>如何避免复制缓冲区发生溢出呢？<ul>
<li>一方面，可以控制主节点保存的数据量大小。按通常的使用经验，我们会把主节点的数据量控制在 2~4GB，这样可以让全量同步执行得更快些，避免复制缓冲区累积过多命令。</li>
<li>另一方面，可以使用 client-output-buffer-limit 配置项，来设置合理的复制缓冲区大小。设置的依据，就是主节点的数据量大小、主节点的写负载压力和主节点本身的内存大小。</li>
</ul>
</li>
<li>主节点上复制缓冲区的内存开销，会是每个从节点客户端输出缓冲区占用内存的总和。如果集群中的从节点数非常多的话，主节点的内存开销就会非常大。所以，我们还必须得控制和主节点连接的从节点个数，不要使用大规模的主从集群。</li>
</ul>
</li>
<li>复制积压缓冲区的溢出问题<ul>
<li>增量复制时使用的缓冲区，这个缓冲区称为复制积压缓冲区(repl_backlog_buffer);主节点在把接收到的写命令同步给从节点时，同时会把这些写命令写入复制积压缓冲区。一旦从节点发生网络闪断，再次和主节点恢复连接后，从节点就会从复制积压缓冲区中，读取断连期间主节点接收到的写命令，进而进行增量同步</li>
<li>复制积压缓冲区是一个大小有限的环形缓冲区。当主节点把复制积压缓冲区写满后，会覆盖缓冲区中的旧命令数据。如果从节点还没有同步这些旧命令数据，就会造成主从节点间重新开始执行全量复制。</li>
<li>为了应对复制积压缓冲区的溢出问题，我们可以调整复制积压缓冲区的大小，也就是设置 repl_backlog_size 这个参数的值</li>
</ul>
</li>
</ul>
</li>
</ul>
<h4 id="22丨第11～21讲课后思考题答案及常见问题答疑"><a href="#22丨第11～21讲课后思考题答案及常见问题答疑" class="headerlink" title="22丨第11～21讲课后思考题答案及常见问题答疑"></a>22丨第11～21讲课后思考题答案及常见问题答疑</h4><ul>
<li><p>除了 String 类型和 Hash 类型，还有什么类型适合图片吗？</p>
<ul>
<li>除了 String 和 Hash，还可以使用 Sorted Set 类型进行保存。Sorted Set 的元素有 member 值和 score 值，可以像 Hash 那样，使用二级编码进行保存。具体做法是，把图片 ID 的前 7 位作为 Sorted Set 的 key，把图片 ID 的后 3 位作为 member 值，图片存储对象 ID 作为 score 值。</li>
<li>Sorted Set 中元素较少时，Redis 会使用压缩列表进行存储，可以节省内存空间。不过，和 Hash 不一样，Sorted Set 插入数据时，需要按 score 值的大小排序。当底层结构是压缩列表时，Sorted Set 的插入性能就比不上 Hash。所以，Sorted Set 类型虽然可以用来保存，但并不是最优选项</li>
</ul>
</li>
<li><p>在用 Sorted Set 保存时间序列数据时，如果把时间戳作为 score，把实际的数据作为 member，这样保存数据有没有潜在的风险？另外，如果你是 Redis 的开发维护者，你会把聚合计算也设计为 Sorted Set 的一个内在功能吗？</p>
<ul>
<li>Sorted Set 和 Set 一样，都会对集合中的元素进行去重，也就是说，如果往集合中插入的 member 值，和之前已经存在的 member 值一样，那么，原来 member 的score 就会被新写入的 member 的 score 覆盖。相同 member 的值，在 Sorted Set 中只会保留一个。</li>
<li>对于时间序列数据来说，这种去重的特性是会带来数据丢失风险的。毕竟，某一时间段内的多个时间序列数据的值可能是相同的。如果我们往 Sorted Set 中写入的数据是在不同时刻产生的，但是写入的时刻不同，Sorted Set 中只会保存一份最近时刻的数据。这样一来，其他时刻的数据就都没有保存下来。</li>
<li>关于是否把聚合计算作为 Sorted Set 的内在功能，考虑到 Redis 的读写功能是由单线程执行，在进行数据读写时，本身就会消耗较多的 CPU 资源，如果再在 Sorted Set 中实现聚合计算，就会进一步增加 CPU 的资源消耗，影响到 Redis 的正常数据读取。所以，除非对 Redis 的线程模型做修改，比如说在 Redis 中使用额外的线程池做聚合计算，否则，不会把聚合计算作为 Redis 的内在功能实现的。</li>
</ul>
</li>
<li><p>如果一个生产者发送给消息队列的消息，需要被多个消费者进行读取和处理（例如，一个消息是一条从业务系统采集的数据，既要被消费者 1 读取并进行实时计算，也要被消费者 2 读取并留存到分布式文件系统 HDFS 中，以便后续进行历史查询），你会使用Redis 的什么数据类型来解决这个问题呢？</p>
<ul>
<li>可以使用 Streams 数据类型的消费组，同时消费生产者的数据；但是，有个地方需要注意，如果只是使用一个消费组的话，消费组内的多个消费者在消费消息时是互斥的，换句话说，在一个消费组内，一个消息只能被一个消费者消费。我们希望消息既要被消费者 1 读取，也要被消费者 2 读取，是一个多消费者的需求。所以，如果使用消费组模式，需要让消费者 1 和消费者 2 属于不同的消费组，这样它们就能同时消费了。</li>
<li>Redis 基于字典和链表数据结构，实现了发布和订阅功能，这个功能可以实现一个消息被多个消费者消费使用，可以满足问题中的场景需求。</li>
</ul>
</li>
<li><p>Redis 的写操作（例如 SET、HSET、SADD 等）是在关键路径上吗？</p>
<ul>
<li>Redis 本身是内存数据库，所以，写操作都需要在内存上完成执行后才能返回，这就意味着，如果这些写操作处理的是大数据集，例如 1 万个数据，那么，主线程需要等这1 万个数据都写完，才能继续执行后面的命令。所以说，Redis 的写操作也是在关键路径上的。</li>
<li>把面向内存和面向磁盘的写操作区分开。当一个写操作需要把数据写到磁盘时，一般来说，写操作只要把数据写到操作系统的内核缓冲区就行。不过，如果执行了同步写操作，那就必须要等到数据写回磁盘。所以，面向磁盘的写操作一般不会在关键路径上。</li>
<li>根据写操作命令的返回值来决定是否在关键路径上，如果返回值是 OK，或者客户端不关心是否写成功，那么，此时的写操作就不算在关键路径上。这个思路不错，不过，需要注意的是，客户端经常会阻塞等待发送的命令返回结果，在上<br>一个命令还没有返回结果前，客户端会一直等待，直到返回结果后，才会发送下一个命令。此时，即使我们不关心返回结果，客户端也要等到写操作执行完成才行。所以，在不关心写操作返回结果的场景下，可以对 Redis 客户端做异步改造。具体点说，就是使用异步线程发送这些不关心返回结果的命令，而不是在 Redis 客户端中等待这些命令的结果</li>
</ul>
</li>
<li><p>在一台有两个 CPU Socket（每个 Socket 8 个物理核）的服务器上，我们部署了一个有着 8 个实例的 Redis 切片集群（8 个实例都为主节点，没有主备关系），现在有两个方案：</p>
<ul>
<li>在同一个 CPU Socket 上运行 8 个实例，并和 8 个 CPU 核绑定；</li>
<li>在两个 CPU Socket 上各运行 4 个实例，并和相应 Socket 上的核绑定</li>
</ul>
<p>如果不考虑网络数据读取的影响，你会选择哪个方案呢？</p>
<ul>
<li>建议使用第二个方案，主要有两方面的原因。<ul>
<li>同一个 CPU Socket 上的进程，会共享 L3 缓存。如果把 8 个实例都部署在同一个Socket 上，它们会竞争 L3 缓存，这就会导致它们的 L3 缓存命中率降低，影响访问性<br>能。</li>
<li>同一个 CPU Socket 上的进程，会使用同一个 Socket 上的内存空间。8 个实例共享同一个 Socket 上的内存空间，肯定会竞争内存资源。如果有实例保存的数据量大，其他实例能用到的内存空间可能就不够了，此时，其他实例就会跨 Socket 申请内存，进而造成跨 Socket 访问内存，造成实例的性能降低</li>
</ul>
</li>
<li>在切片集群中，不同实例间通过网络进行消息通信和数据迁移，并不会使用共享内存空间进行跨实例的数据访问。所以，即使把不同的实例部署到不同的 Socket 上，它们之间也不会发生跨 Socket 内存的访问，不会受跨 Socket 内存访问的负面影响。</li>
</ul>
</li>
<li><p>在 Redis 中，还有哪些命令可以代替 KEYS 命令，实现对键值对的 key 的模糊查询呢？这些命令的复杂度会导致 Redis 变慢吗？</p>
<ul>
<li>Redis 提供的 SCAN 命令，以及针对集合类型数据提供的 SSCAN、HSCAN 等，可以根据执行时设定的数量参数，返回指定数量的数据，这就可以避免像 KEYS 命令一样同时返回所有匹配的数据，不会导致 Redis 变慢</li>
</ul>
</li>
<li><p>你遇到过 Redis 变慢的情况吗？如果有的话，你是怎么解决的呢？</p>
<ul>
<li>使用复杂度过高的命令或一次查询全量数据；</li>
<li>操作 bigkey；</li>
<li>大量 key 集中过期；</li>
<li>内存达到 maxmemory；</li>
<li>客户端使用短连接和 Redis 相连；</li>
<li>当 Redis 实例的数据量大时，无论是生成 RDB，还是 AOF 重写，都会导致 fork 耗时严重；</li>
<li>AOF 的写回策略为 always，导致每个操作都要同步刷回磁盘；</li>
<li>Redis 实例运行机器的内存不足，导致 swap 发生，Redis 需要到 swap 分区读取数据；</li>
<li>进程绑定 CPU 不合理；</li>
<li>Redis 实例运行机器上开启了透明内存大页机制；</li>
<li>网卡压力过大。</li>
</ul>
</li>
<li><p>如果mem_fragmentation_ratio 小于 1，Redis 的内存使用是什么情况呢？会对 Redis 的性能和内存空间利用率造成什么影响呢？</p>
<ul>
<li>如果 mem_fragmentation_ratio 小于 1，就表明，操作系统分配给 Redis 的内存空间已经小于 Redis 所申请的空间大小了，此时，运行 Redis 实例的服务器上的内存已经不够用了，可能已经发生 swap 了。这样一来，Redis 的读写性能也会受到影响，因为Redis 实例需要在磁盘上的 swap 分区中读写数据，速度较慢。</li>
</ul>
</li>
<li><p>在和 Redis 实例交互时，应用程序中使用的客户端需要使用缓冲区吗？如果使用的话，对 Redis 的性能和内存使用会有影响吗？</p>
<ul>
<li>应用程序中使用的 Redis 客户端，需要把要发送的请求暂存在缓冲区。这有两方面的好处。</li>
<li>一方面，可以在客户端控制发送速率，避免把过多的请求一下子全部发到 Redis 实例，导致实例因压力过大而性能下降。不过，客户端缓冲区不会太大，所以，对 Redis 实例的内存使用没有什么影响。</li>
<li>另一方面，在应用 Redis 主从集群时，主从节点进行故障切换是需要一定时间的，此时，主节点无法服务外来请求。如果客户端有缓冲区暂存请求，那么，客户端仍然可以正常接收业务应用的请求，这就可以避免直接给应用返回无法服务的错误。</li>
</ul>
</li>
<li><p>如何使用慢查询日志和 latency monitor 排查执行慢的操作？</p>
<ul>
<li>Redis 的慢查询日志记录了执行时间超过一定阈值的命令操作。当发现 Redis 响应变慢、请求延迟增加时，就可以在慢查询日志中进行查找，确定究竟是哪些命令执行时间很长。在使用慢查询日志前，需要设置两个参数。<ul>
<li>slowlog-log-slower-than：这个参数表示，慢查询日志对执行时间大于多少微秒的命令进行记录。</li>
<li>slowlog-max-len：这个参数表示，慢查询日志最多能记录多少条命令记录。慢查询日志的底层实现是一个具有预定大小的先进先出队列，一旦记录的命令数量超过了队列长度，最先记录的命令操作就会被删除。这个值默认是 128。但是，如果慢查询命令较多的话，日志里就存不下了；如果这个值太大了，又会占用一定的内存空间。所以，一般建议设置为 1000 左右，这样既可以多记录些慢查询命令，方便排查，也可以避免内存开销。</li>
</ul>
</li>
<li>设置好参数后，慢查询日志就会把执行时间超过 slowlog-log-slower-than 阈值的命令操作记录在日志中。可以使用 SLOWLOG GET 命令，来查看慢查询日志中记录的命令操作</li>
<li>有了慢查询日志后，就可以快速确认，究竟是哪些命令的执行时间比较长，然后可以反馈给业务部门，让业务开发人员避免在应用 Redis 的过程中使用这些命令，或是减少操作的数据量，从而降低命令的执行复杂度。</li>
<li>除了慢查询日志以外，Redis 从 2.8.13 版本开始，还提供了 latency monitor 监控工具，这个工具可以用来监控 Redis 运行过程中的峰值延迟情况。和慢查询日志的设置相类似，要使用 latency monitor，首先要设置命令执行时长的阈值。当一个命令的实际执行时长超过该阈值时，就会被 latency monitor 监控到;设置好了 latency monitor 的参数后，我们可以使用 latency latest 命令，查看最新和最大的超过阈值的延迟情况</li>
</ul>
</li>
<li><p>如何排查 Redis 的 bigkey？</p>
<ul>
<li>Redis 可以在执行 redis-cli 命令时带上–bigkeys 选项，进而对整个数据库中的键值对大小情况进行统计分析，比如说，统计每种数据类型的键值对个数以及平均大小。这个命令执行后，会输出每种数据类型中最大的 bigkey 的信息，对于 String 类型来说，会输出最大 bigkey 的字节长度，对于集合类型来说，会输出最大 bigkey 的元素个数</li>
<li>不过，在使用–bigkeys 选项时，有一个地方需要注意一下。这个工具是通过扫描数据库来查找 bigkey 的，所以，在执行的过程中，会对 Redis 实例的性能产生影响。如果在使用主从集群，建议在从节点上执行该命令。因为主节点上执行时，会阻塞主节点。如果没有从节点，两个小建议：<ul>
<li>第一个建议是，在 Redis 实例业务压力的低峰阶段进行扫描查询，以免影响到实例的正常运行；</li>
<li>第二个建议是，可以使用 -i 参数控制扫描间隔，避免长时间扫描降低 Redis 实例的性能。</li>
</ul>
</li>
<li>使用 Redis 自带的–bigkeys 选项排查 bigkey，有两个不足的地方<ul>
<li>这个方法只能返回每种类型中最大的那个 bigkey，无法得到大小排在前 N 位的bigkey；</li>
<li>对于集合类型来说，这个方法只统计集合元素个数的多少，而不是实际占用的内存量。但是，一个集合中的元素个数多，并不一定占用的内存就多。因为，有可能每个元素占用的内存很小，这样的话，即使元素个数有很多，总内存开销也不大。</li>
</ul>
</li>
<li>如果想统计每个数据类型中占用内存最多的前 N 个 bigkey，可以自己开发一个程序，来进行统计。基本的开发思路：使用 SCAN 命令对数据库扫描，然后用 TYPE 命令获取返回的每一个 key 的类型。接下来，对于 String 类型，可以直接使用 STRLEN 命令获取字符串的长度，也就是占用的内存空间字节数。对于集合类型来说，有两种方法可以获得它占用的内存大小。<ul>
<li>如果能够预先从业务层知道集合元素的平均大小，那么，可以使用命令获取集合元素的个数，然后乘以集合元素的平均大小，这样就能获得集合占用的内存大小</li>
<li>如果不能提前知道写入集合的元素大小，可以使用 MEMORY USAGE 命令（需要 Redis 4.0 及以上版本），查询一个键值对占用的内存空间</li>
</ul>
</li>
</ul>
</li>
</ul>
<h4 id="23丨旁路缓存：Redis是如何工作的？"><a href="#23丨旁路缓存：Redis是如何工作的？" class="headerlink" title="23丨旁路缓存：Redis是如何工作的？"></a>23丨旁路缓存：Redis是如何工作的？</h4><ul>
<li>缓存的特征<ul>
<li>一个系统中的不同层之间的访问速度不一样，所以才需要缓存，这样就可以把一些需要频繁访问的数据放在缓存中，以加快它们的访问速度</li>
<li>计算机系统中，默认有两种缓存：<ul>
<li>CPU 里面的末级缓存，即 LLC，用来缓存内存中的数据，避免每次从内存中存取数据；</li>
<li>内存中的高速页缓存，即 page cache，用来缓存磁盘中的数据，避免每次从磁盘中存取数据。</li>
</ul>
</li>
<li>跟内存相比，LLC 的访问速度更快，而跟磁盘相比，内存的访问是更快的。可以看出来缓存的第一个特征：<strong>在一个层次化的系统中，缓存一定是一个快速子系统，数据存在缓存中时，能避免每次从慢速子系统中存取数据</strong>。对应到互联网应用来说，Redis 就是快速子系统，而数据库就是慢速子系统了。</li>
<li>LLC 的大小是 MB 级别，page cache 的大小是 GB级别，而磁盘的大小是 TB 级别。这包含了缓存的第二个特征：<strong>缓存系统的容量大小总是小于后端慢速系统的，不可能把所有数据都放在缓存系统中。</strong>它表明，缓存的容量终究是有限的，缓存中的数据量也是有限的，肯定是没法时刻都满足访问需求的。所以，缓存和后端慢速系统之间，必然存在数据写回和再读取的交互过程。简单来说，缓存中的数据需要按一定规则淘汰出去，写回后端系统，而新的数据又要从后端系统中读取进来，写入缓存。<ul>
<li>Redis 本身是支持按一定规则淘汰数据的，相当于实现了缓存的数据淘汰，其实，这也是 Redis 适合用作缓存的一个重要原因。</li>
</ul>
</li>
</ul>
</li>
<li>Redis 缓存处理请求的两种情况<ul>
<li>把 Redis 用作缓存时，会把 Redis 部署在数据库的前端，业务应用在访问数据时，会先查询 Redis 中是否保存了相应的数据。此时，根据数据是否存在缓存中，会有两种情况。</li>
<li>缓存命中：Redis 中有相应数据，就直接读取 Redis，性能非常快。</li>
<li>缓存缺失：Redis 中没有保存相应数据，就从后端数据库中读取数据，性能就会变慢。而且，一旦发生缓存缺失，为了让后续请求能从缓存中读取到数据，需要把缺失的数据写入 Redis，这个过程叫作缓存更新</li>
<li>使用 Redis 缓存时，我们基本有三个操作：<ul>
<li>应用读取数据时，需要先读取 Redis；</li>
<li>发生缓存缺失时，需要从数据库读取数据；</li>
<li>发生缓存缺失时，还需要更新缓存。</li>
</ul>
</li>
</ul>
</li>
<li>Redis 作为旁路缓存的使用操作<ul>
<li>Redis 是一个独立的系统软件，和业务应用程序是两个软件，部署了 Redis 实例后，它只会被动地等待客户端发送请求，然后再进行处理。所以，如果应用程序想要使用Redis 缓存，就要在程序中增加相应的缓存操作代码。所以，也把 Redis 称为旁路缓存，也就是说，读取缓存、读取数据库和更新缓存的操作都需要在应用程序中来完成。</li>
<li>使用 Redis 缓存时，具体来说，需要在应用程序中增加三方面的代码：<ul>
<li>当应用程序需要读取数据时，需要在代码中显式调用 Redis 的 GET 操作接口，进行查询；</li>
<li>如果缓存缺失了，应用程序需要再和数据库连接，从数据库中读取数据；</li>
<li>当缓存中的数据需要更新时，也需要在应用程序中显式地调用 SET 操作接口，把更新的数据写入缓存。</li>
</ul>
</li>
<li>在使用 Redis 缓存时，有一个地方就需要注意了：因为需要新增程序代码来使用缓存，所以，Redis 并不适用于那些无法获得源码的应用，例如一些很早之前开发的应用程序，它们的源码已经没有再维护了，或者是第三方供应商开发的应用，没有提供源码，所以就没有办法在这些应用中进行缓存操作。</li>
<li>在使用旁路缓存时，需要在应用程序中增加操作代码，增加了使用 Redis 缓存的额外工作量，但是，也正因为 Redis 是旁路缓存，是一个独立的系统，我们可以单独对 Redis缓存进行扩容或性能优化。而且，只要保持操作接口不变，在应用程序中增加的代码就不用再修改了。</li>
</ul>
</li>
<li>Redis 缓存的两种类型：只读缓存和读写缓存。只读缓存能加速读请求，而读写缓存可以同时加速读写请求。而且，读写缓存又有两种数据写回策略，可以根据业务需求，在保证性能和保证数据可靠性之间进行选择<ul>
<li>当 Redis 用作只读缓存时，应用要读取数据的话，会先调用 Redis GET 接口，查询数据是否存在。而所有的数据写请求，会直接发往后端的数据库，在数据库中增删改。对于删改的数据来说，如果 Redis 已经缓存了相应的数据，应用需要把这些缓存的数据删除，Redis中就没有这些数据了。<ul>
<li>当应用再次读取这些数据时，会发生缓存缺失，应用会把这些数据从数据库中读出来，并写到缓存中。这样一来，这些数据后续再被读取时，就可以直接从缓存中获取了，能起到加速访问的效果</li>
<li>只读缓存直接在数据库中更新数据的好处是，所有最新的数据都在数据库中，而数据库是提供数据可靠性保障的，这些数据不会有丢失的风险。当需要缓存图片、短视频这些用户只读的数据时，就可以使用只读缓存这个类型了。</li>
</ul>
</li>
<li>对于读写缓存来说，除了读请求会发送到缓存进行处理（直接在缓存中查询数据是否存在)，所有的写请求也会发送到缓存，在缓存中直接对数据进行增删改操作。此时，得益于Redis 的高性能访问特性，数据的增删改操作可以在缓存中快速完成，处理结果也会快速返回给业务应用，这就可以提升业务应用的响应速度。<ul>
<li>和只读缓存不一样的是，在使用读写缓存时，最新的数据是在 Redis 中，而 Redis是内存数据库，一旦出现掉电或宕机，内存中的数据就会丢失。这也就是说，应用的最新数据可能会丢失，给应用业务带来风险。</li>
<li>根据业务应用对数据可靠性和缓存性能的不同要求有同步直写和异步写回两种策略。其中，同步直写策略优先保证数据可靠性，而异步写回策略优先提供快速响应。</li>
<li>同步直写是指，写请求发给缓存的同时，也会发给后端数据库进行处理，等到缓存和数据库都写完数据，才给客户端返回。这样，即使缓存宕机或发生故障，最新的数据仍然保存在数据库中，这就提供了数据可靠性保证。不过，同步直写会降低缓存的访问性能。这是因为缓存中处理写请求的速度是很快的，而数据库处理写请求的速度较慢。即使缓存很快地处理了写请求，也需要等待数据库处理完所有的写请求，才能给应用返回结果，这就增加了缓存的响应延迟。</li>
<li>异步写回策略，则是优先考虑了响应延迟。此时，所有写请求都先在缓存中处理。等到这些增改的数据要被从缓存中淘汰出来时，缓存将它们写回后端数据库。这样一来，处理这些数据的操作是在缓存中进行的，很快就能完成。只不过，如果发生了掉电，而它们还没有被写回数据库，就会有丢失的风险了</li>
</ul>
</li>
<li>关于是选择只读缓存，还是读写缓存，主要看我们对写请求是否有加速的需求。<ul>
<li>如果需要对写请求进行加速，选择读写缓存；</li>
<li>如果写请求很少，或者是只需要提升读请求的响应速度的话，选择只读缓存。</li>
</ul>
</li>
</ul>
</li>
</ul>
<h4 id="24丨替换策略：缓存满了怎么办？"><a href="#24丨替换策略：缓存满了怎么办？" class="headerlink" title="24丨替换策略：缓存满了怎么办？"></a>24丨替换策略：缓存满了怎么办？</h4><ul>
<li>为了保证较高的性价比，缓存的空间容量必然要小于后端数据库的数据总量。不过，内存大小毕竟有限，随着要缓存的数据量越来越大，有限的缓存空间不可避免地会被写满；解决这个问题就涉及到缓存系统的一个重要机制，即缓存数据的淘汰机制。简单来说，数据淘汰机制包括两步：第一，根据一定的策略，筛选出对应用访问来说“不重要”的数据；第二，将这些数据从缓存中删除，为新来的数据腾出空间</li>
<li>设置多大的缓存容量合适？<ul>
<li>实际应用中的数据访问是具有局部性的。“八二原理”，有 20% 的数据贡献了 80% 的访问了，而剩余的数据虽然体量很大，但只贡献了 20% 的访问量。这 80% 的数据在访问量上就形成了一条长长的尾巴，也称为“长尾效应”。如果按照“八二原理”来设置缓存空间容量，也就是把缓存空间容量设置为总数据量的 20% 的话，就有可能拦截到 80% 的访问</li>
<li>用户的个性化需求越来越多，在一个业务应用中，不同用户访问的内容可能差别很大，所以，用户请求的数据和它们贡献的访问量比例，不再具备长尾效应中的“八二原理”分布特征了。也就是说，20% 的数据可能贡献不了 80% 的访问，而剩余的 80% 数据反而贡献了更多的访问量，称之为重尾效应。</li>
<li>正是因为 20% 的数据不一定能贡献 80% 的访问量，我们不能简单地按照“总数据量的20%”来设置缓存最大空间容量。这个容量规划不能一概而论，是需要结合应用数据实际访问特征和成本开销来综合考虑的。</li>
<li>系统的设计选择是一个权衡的过程：大容量缓存是能带来性能加速的收益，但是成本也会更高，而小容量缓存不一定就起不到加速访问的效果。一般来说，建议把缓存容量设置为总数据量的 15% 到 30%，兼顾访问性能和内存空间开销。</li>
</ul>
</li>
<li>Redis 缓存有哪些淘汰策略？<ul>
<li>Redis 4.0 之前一共实现了 6 种内存淘汰策略，在 4.0 之后，又增加了 2 种策略。可以按照是否会进行数据淘汰把它们分成两类：<ul>
<li>不进行数据淘汰的策略，只有 noeviction 这一种。</li>
<li>会进行淘汰的 7 种其他策略。可以再进一步根据淘汰候选数据集的范围把它们分成两类：<ul>
<li>在设置了过期时间的数据中进行淘汰，包括 volatile-random、volatile-ttl、volatile-lru<br>、volatile-lfu（Redis 4.0 后新增）四种。</li>
<li>在所有数据范围内进行淘汰，包括 allkeys-lru、allkeys-random、allkeys-lfu（Redis 4.0 后新增）三种。</li>
</ul>
</li>
</ul>
</li>
<li>默认情况下，Redis 在使用的内存空间超过 maxmemory 值时，并不会淘汰数据，也就是设定的 noeviction 策略。对应到 Redis 缓存，也就是指，一旦缓存被写满了，再有写请求来时，Redis 不再提供服务，而是直接返回错误。Redis 用作缓存时，实际的数据集通常都是大于缓存容量的，总会有新的数据要写入缓存，这个策略本身不淘汰数据，也就不会腾出新的缓存空间，我们不把它用在 Redis 缓存中。</li>
<li>volatile-random、volatile-ttl、volatile-lru 和 volatile-lfu 这四种淘汰策略。它们筛选的候选数据范围，被限制在已经设置了过期时间的键值对上。即使缓存没有写满，这些数据如果过期了，也会被删除。使用 EXPIRE 命令对一批键值对设置了过期时间后，无论是这些键值对的过期时间是快到了，还是 Redis 的内存使用量达到了 maxmemory 阈值，Redis 都会进一步按照 这四种策略的具体筛选规则进行淘汰。<ul>
<li>volatile-ttl 在筛选时，会针对设置了过期时间的键值对，根据过期时间的先后进行删除，越早过期的越先被删除。</li>
<li>volatile-random 就像它的名称一样，在设置了过期时间的键值对中，进行随机删除。</li>
<li>volatile-lru 会使用 LRU 算法筛选设置了过期时间的键值对。</li>
<li>volatile-lfu 会使用 LFU 算法选择设置了过期时间的键值对。</li>
</ul>
</li>
<li>相对于 volatile-ttl、volatile-random、volatile-lru、volatile-lfu 这四种策略淘汰的是设置了过期时间的数据，allkeys-lru、allkeys-random、allkeys-lfu 这三种淘汰策略的备选淘汰数据范围，就扩大到了所有键值对，无论这些键值对是否设置了过期时间。它们筛选数据进行淘汰的规则是：<ul>
<li>allkeys-random 策略，从所有键值对中随机选择并删除数据；</li>
<li>allkeys-lru 策略，使用 LRU 算法在所有数据中进行筛选。</li>
<li>allkeys-lfu 策略，使用 LFU 算法在所有数据中进行筛选。</li>
</ul>
</li>
<li>LRU 算法的全称是 Least Recently Used，从名字上就可以看出，这是按照最近最少使用的原则来筛选数据，最不常用的数据会被筛选出来，而最近频繁使用的数据会留在缓存中。LRU 会把所有的数据组织成一个链表，链表的头和尾分别表示MRU 端和 LRU 端，分别代表最近最常使用的数据和最近最不常用的数据。<ul>
<li>不过，LRU 算法在实际实现时，需要用链表管理所有的缓存数据，这会带来额外的空间开销。而且，当有数据被访问时，需要在链表上把该数据移动到 MRU 端，如果有大量数据被访问，就会带来很多链表移动操作，会很耗时，进而会降低 Redis 缓存性能。</li>
<li>在 Redis 中，LRU 算法被做了简化，以减轻数据淘汰对缓存性能的影响。具体来说，Redis 默认会记录每个数据的最近一次访问的时间戳。然后，Redis 在决定淘汰的数据时，第一次会随机选出N 个数据，把它们作为一个候选集合。接下来，Redis 会比较这 N 个数据的 lru 字段，把lru 字段值最小的数据从缓存中淘汰出去;Redis 提供了一个配置参数 maxmemory-samples，这个参数就是 Redis 选出的数据个数N</li>
<li>当需要再次淘汰数据时，Redis 需要挑选数据进入第一次淘汰时创建的候选集合。这儿的挑选标准是：能进入候选集合的数据的 lru 字段值必须小于候选集合中最小的 lru 值。当有新数据进入候选数据集后，如果候选数据集中的数据个数达到了 maxmemorysamples，Redis 就把候选数据集中 lru 字段值最小的数据淘汰出去。</li>
</ul>
</li>
<li>优先使用 allkeys-lru 策略。这样，可以充分利用 LRU 这一经典缓存算法的优势，把最近最常访问的数据留在缓存中，提升应用的访问性能。如果你的业务数据中有明显的冷热数据区分，我建议你使用 allkeys-lru 策略。</li>
<li>如果业务应用中的数据访问频率相差不大，没有明显的冷热数据区分，建议使用allkeys-random 策略，随机选择淘汰的数据就行。</li>
<li>如果业务中有置顶的需求，比如置顶新闻、置顶视频，那么，可以使用 volatile-lru策略，同时不给这些置顶数据设置过期时间。这样一来，这些需要置顶的数据一直不会被删除，而其他数据会在过期时根据 LRU 规则进行筛选。</li>
</ul>
</li>
<li>如何处理被淘汰的数据？<ul>
<li>一般来说，一旦被淘汰的数据选定后，如果这个数据是干净数据，那么就直接删除；如果这个数据是脏数据，需要把它写回数据库<ul>
<li>干净数据和脏数据的区别就在于，和最初从后端数据库里读取时的值相比，有没有被修改过。干净数据一直没有被修改，所以后端数据库里的数据也是最新值。在替换时，它可以被直接删除。而脏数据就是曾经被修改过的，已经和后端数据库中保存的数据不一致了。此时，如果不把脏数据写回到数据库中，这个数据的最新值就丢失了，就会影响应用的正常使用</li>
</ul>
</li>
<li>不过，对于 Redis 来说，它决定了被淘汰的数据后，会把它们删除。即使淘汰的数据是脏数据，Redis 也不会把它们写回数据库。所以，我们在使用 Redis 缓存时，如果数据被修改了，需要在数据修改时就将它写回数据库。否则，这个脏数据被淘汰时，会被 Redis 删除，而数据库里也没有最新的数据了。</li>
</ul>
</li>
</ul>
<h4 id="25丨缓存异常（上）：如何解决缓存和数据库的数据不一致问题？"><a href="#25丨缓存异常（上）：如何解决缓存和数据库的数据不一致问题？" class="headerlink" title="25丨缓存异常（上）：如何解决缓存和数据库的数据不一致问题？"></a>25丨缓存异常（上）：如何解决缓存和数据库的数据不一致问题？</h4><ul>
<li><p>缓存和数据库的数据不一致是如何发生的？</p>
<ul>
<li><p>“数据的一致性”具体是啥意思。其实，这里的“一致性”包含了两种情况：</p>
<ul>
<li>缓存中有数据，那么，缓存的数据值需要和数据库中的值相同；</li>
<li>缓存中本身没有数据，那么，数据库中的值必须是最新值</li>
</ul>
<p>不符合这两种情况的，就属于缓存和数据库的数据不一致问题了。</p>
</li>
<li><p>对于读写缓存来说，如果要对数据进行增删改，就需要在缓存中进行，同时还要根据采取的写回策略，决定是否同步写回到数据库中。</p>
<ul>
<li>同步直写策略：写缓存时，也同步写数据库，缓存和数据库中的数据一致；</li>
<li>异步写回策略：写缓存时不同步写数据库，等到数据从缓存中淘汰时，再写回数据库。使用这种策略时，如果数据还没有写回数据库，缓存就发生了故障，那么，此时，数据库就没有最新的数据了</li>
<li>对于读写缓存来说，要想保证缓存和数据库中的数据一致，就要采用同步直写策略。不过，需要注意的是，如果采用这种策略，就需要同时更新缓存和数据库。所以，要在业务应用中使用事务机制，来保证缓存和数据库的更新具有原子性，也就是说，两者要不一起更新，要不都不更新，返回错误信息，进行重试。否则就无法实现同步直写。</li>
<li>在有些场景下，对数据一致性的要求可能不是那么高，比如说缓存的是电商商品的非关键属性或者短视频的创建或修改时间等，那么，我们可以使用异步写回策略。</li>
</ul>
</li>
<li><p>对于只读缓存来说，如果有数据新增，会直接写入数据库；而有数据删改时，就需要把只读缓存中的数据标记为无效。这样一来，应用后续再访问这些增删改的数据时，因为缓存中没有相应的数据，就会发生缓存缺失。此时，应用再从数据库中把数据读入缓存，这样后续再访问数据时，就能够直接从缓存中读取了。</p>
<ul>
<li>新增数据：数据会直接写到数据库中，不用对缓存做任何操作，此时，缓存中本身就没有新增数据，而数据库中是最新值，所以此时缓存和数据库的数据是一致的。</li>
<li>删改数据：如果发生删改操作，应用既要更新数据库，也要在缓存中删除数据。这两个操作如果无法保证原子性，也就是说，要不都完成，要不都没完成，此时，就会出现数据不一致问题<ul>
<li>假设应用先删除缓存，再更新数据库，如果缓存删除成功，但是数据库更新失败，那么，应用再访问数据时，缓存中没有数据，就会发生缓存缺失。然后，应用再访问数据库，但是数据库中的值为旧值，应用就访问到旧值</li>
<li>如果应用先完成了数据库的更新，但是，在删除缓存时失败了，那么，数据库中的值是新值，而缓存中的是旧值，这肯定是不一致的。这个时候，如果有其他的并发请求来访问数据，按照正常的缓存访问流程，就会先在缓存中查询，但此时，就会读到旧值了</li>
<li>在更新数据库和删除缓存值的过程中，无论这两个操作的执行顺序谁先谁后，只要有一个操作失败了，就会导致客户端读取到旧值</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li><p>如何解决数据不一致问题？</p>
<ul>
<li>重试机制：可以把要删除的缓存值或者是要更新的数据库值暂存到消息队列中（例如使用Kafka 消息队列）。当应用没有能够成功地删除缓存值或者是更新数据库值时，可以从消息队列中重新读取这些值，然后再次进行删除或更新<ul>
<li>如果能够成功地删除或更新，就要把这些值从消息队列中去除，以免重复操作，此时也可以保证数据库和缓存的数据一致了。否则的话，还需要再次进行重试。如果重试超过的一定次数，还是没有成功，就需要向业务层发送报错信息了</li>
</ul>
</li>
<li>即使更新数据库和删除缓存值第一次执行时都没有失败，当有大量并发请求时，应用还是有可能读到不一致的数据<ul>
<li><strong>先删除缓存，再更新数据库</strong>：可使用“延迟双删“，在线程 A 更新完数据库值以后，可以让它先 sleep 一小段时间，再进行一次缓存删除操作</li>
<li><strong>先更新数据库值，再删除缓存值：</strong>如果线程 A 删除了数据库中的值，但还没来得及删除缓存值，线程 B 就开始读取数据了，那么此时，线程 B 查询缓存时，发现缓存命中，就会直接从缓存中读取旧值。不过，在这种情况下，如果其他线程并发读缓存的请求不多，那么，就不会有很多请求读取到旧值。而且，线程 A 一般也会很快删除缓存值，这样一来，其他线程再次读取时，就会发生缓存缺失，进而从数据库中读取最新值。所以，这种情况对业务的影响较小。</li>
</ul>
</li>
</ul>
</li>
<li><p>在大多数业务场景下，会把 Redis 作为只读缓存使用。针对只读缓存来说，我们既可以先删除缓存值再更新数据库，也可以先更新数据库再删除缓存。建议是，优先使用先更新数据库再删除缓存的方法，原因主要有两个：</p>
<ul>
<li>先删除缓存值再更新数据库，有可能导致请求因缓存缺失而访问数据库，给数据库带来压力；</li>
<li>如果业务应用中读取数据库和写缓存的时间不好估算，那么，延迟双删中的等待时间就不好设置。</li>
<li>当使用先更新数据库再删除缓存时，也有个地方需要注意，如果业务层要求必须读取一致的数据，那么，我们就需要在更新数据库时，先在 Redis 缓存客户端暂存并发读请求，等数据库更新完、缓存值删除后，再读取数据，从而保证数据一致性。</li>
</ul>
</li>
</ul>
<h4 id="26丨缓存异常（下）：如何解决缓存雪崩、击穿、穿透难题？"><a href="#26丨缓存异常（下）：如何解决缓存雪崩、击穿、穿透难题？" class="headerlink" title="26丨缓存异常（下）：如何解决缓存雪崩、击穿、穿透难题？"></a>26丨缓存异常（下）：如何解决缓存雪崩、击穿、穿透难题？</h4><ul>
<li><p>缓存雪崩</p>
<ul>
<li>缓存雪崩是指大量的应用请求无法在 Redis 缓存中进行处理，紧接着，应用将大量请求发送到数据库层，导致数据库层的压力激增。</li>
<li>第一个原因是：缓存中有大量数据同时过期，导致大量请求无法得到处理。当数据保存在缓存中，并且设置了过期时间时，如果在某一个时刻，大量数据同时过期，此时，应用再访问这些数据的话，就会发生缓存缺失。紧接着，应用就会把请求发送给数据库，从数据库中读取数据。如果应用的并发请求量很大，那么数据库的压力也就很大，这会进一步影响到数据库的其他正常业务请求处理<ul>
<li>可以避免给大量的数据设置相同的过期时间。如果业务层的确要求有些数据同时失效，可以在用 EXPIRE 命令给每个数据设置过期时间时，给这些数据的过期时间增加一个较小的随机数</li>
<li>还可以通过服务降级，来应对缓存雪崩。发生缓存雪崩时，针对不同的数据采取不同的处理方式。<ul>
<li>当业务应用访问的是非核心数据（例如电商商品属性）时，暂时停止从缓存中查询这些数据，而是直接返回预定义信息、空值或是错误信息；</li>
<li>当业务应用访问的是核心数据（例如电商商品库存）时，仍然允许查询缓存，如果缓存缺失，也可以继续通过数据库读取</li>
</ul>
</li>
</ul>
</li>
<li>除了大量数据同时失效会导致缓存雪崩，还有一种情况也会发生缓存雪崩，那就是，Redis缓存实例发生故障宕机了，无法处理请求，这就会导致大量请求一下子积压到数据库层，从而发生缓存雪崩。<ul>
<li>一个 Redis 实例可以支持数万级别的请求处理吞吐量，而单个数据库可能只能支持数千级别的请求处理吞吐量，它们两个的处理能力可能相差了近十倍。由于缓存雪崩，Redis 缓存失效，所以，数据库就可能要承受近十倍的请求压力，从而因为压力过大而崩溃</li>
<li>针对这种情况，可以在业务系统中实现服务熔断或请求限流机制。<ul>
<li>服务熔断，是指在发生缓存雪崩时，为了防止引发连锁的数据库雪崩，甚至是整个系统的崩溃，暂停业务应用对缓存系统的接口访问。再具体点说，就是业务应用调用缓存接口时，缓存客户端并不把请求发给 Redis 缓存实例，而是直接返回，等到 Redis 缓存实例重新恢复服务后，再允许应用请求发送到缓存系统。</li>
<li>在业务系统运行时，可以监测 Redis 缓存所在机器和数据库所在机器的负载指标，例如每秒请求数、CPU 利用率、内存利用率等。如果发现 Redis 缓存实例宕机了，而数据库所在机器的负载压力突然增加（例如每秒请求数激增），此时，就发生缓存雪崩了。大量请求被发送到数据库进行处理。可以启动服务熔断机制，暂停业务应用对缓存服务的访问，从而降低对数据库的访问压力</li>
<li>请求限流就是指，在业务系统的请求入口前端控制每秒进入系统的请求数，避免过多的请求被发送到数据库。一旦发生了缓存雪崩，数据库的每秒请求数突然增加到每秒 1 万个，此时就可以启动请求限流机制，在请求入口前端只允许每秒进入系统的请求数为 1000 个，再多的请求就会在入口前端被直接拒绝服务</li>
<li>使用服务熔断或是请求限流机制，来应对 Redis 实例宕机导致的缓存雪崩问题，是属于“事后诸葛亮”，也就是已经发生缓存雪崩了，使用这两个机制，来降低雪崩对数据库和整个业务系统的影响。</li>
</ul>
</li>
<li>另外一个建议是：通过主从节点的方式构建 Redis 缓存高可靠集群。如果 Redis 缓存的主节点故障宕机了，从节点还可以切换成为主节点，继续提供缓存服务，避免了由于缓存实例宕机而导致的缓存雪崩问题。</li>
</ul>
</li>
</ul>
</li>
<li><p>缓存击穿</p>
<ul>
<li>缓存击穿是指，针对某个访问非常频繁的热点数据的请求，无法在缓存中进行处理，紧接着，访问该数据的大量请求，一下子都发送到了后端数据库，导致了数据库压力激增，会影响数据库处理其他请求。缓存击穿的情况，经常发生在热点数据过期失效时</li>
<li>解决方法也比较直接，对于访问特别频繁的热点数据，就不设置过期时间了。这样一来，对热点数据的访问请求，都可以在缓存中进行处理，而 Redis 数万级别的高吞吐量可以很好地应对大量的并发请求访问。</li>
</ul>
</li>
<li><p>缓存穿透</p>
<ul>
<li>缓存穿透是指要访问的数据既不在 Redis 缓存中，也不在数据库中，导致请求在访问缓存时，发生缓存缺失，再去访问数据库时，发现数据库中也没有要访问的数据。此时，应用也无法从数据库中读取数据再写入缓存，来服务后续请求，这样一来，缓存也就成了“摆设”，如果应用持续有大量请求访问数据，就会同时给缓存和数据库带来巨大压力</li>
<li>缓存穿透一般来说会发生在两种情况<ul>
<li>业务层误操作：缓存中的数据和数据库中的数据被误删除了，所以缓存和数据库中都没有数据；</li>
<li>恶意攻击：专门访问数据库中没有的数据。</li>
</ul>
</li>
<li>为了避免缓存穿透的影响，有三种应对方案。<ul>
<li>第一种方案是<strong>缓存空值或缺省值</strong>。一旦发生缓存穿透，就可以针对查询的数据，在 Redis 中缓存一个空值或是和业务层协商确定的缺省值避免了把大量请求发送给数据库处理，保持了数据库的正常运行</li>
<li>第二种方案是，使用<strong>布隆过滤器快速判断数据是否存在</strong>，避免从数据库中查询数据是否存在，减轻数据库压力<ul>
<li>布隆过滤器由一个初值都为 0 的 bit 数组和 N 个哈希函数组成，可以用来快速判断某个数据是否存在</li>
<li>布隆过滤器会通过三个操作完成标记：首先，使用 N 个哈希函数，分别计算这个数据的哈希值，得到 N 个哈希值。然后，把这 N 个哈希值对 bit 数组的长度取模，得到每个哈希值在数组中的对应位置。最后，把对应位置的 bit 位设置为 1，这就完成了在布隆过滤器中标记数据的操作。</li>
<li>数据不存在（例如，数据库里没有写入数据），也就没有用布隆过滤器标记过数据，那么，bit 数组对应 bit 位的值仍然为 0；只要这 N 个 bit 值有一个不为 1，这就表明布隆过滤器没有对该数据做过标记</li>
</ul>
</li>
<li>最后一种方案是，在请求入口的前端进行请求检测。缓存穿透的一个原因是有大量的恶意请求访问不存在的数据，所以，一个有效的应对方案是在请求入口前端，对业务系统接收到的请求进行合法性检测，把恶意的请求（例如请求参数不合理、请求参数是非法值、请求字段不存在）直接过滤掉，不让它们访问后端缓存和数据库</li>
</ul>
</li>
</ul>
</li>
<li><p>服务熔断、服务降级、请求限流这些方法都是属于“有损”方案，在保证数据库和整体系统稳定的同时，会对业务应用带来负面影响。例如使用服务降级时，有部分数据的请求就只能得到错误返回信息，无法正常处理。如果使用了服务熔断，那么，整个缓存系统的服务都被暂停了，影响的业务范围更大。而使用了请求限流机制后，整个业务系统的吞吐率会降低，能并发处理的用户请求会减少，会影响到用户体验。尽量使用预防式方案：</p>
<ul>
<li>针对缓存雪崩，合理地设置数据过期时间，以及搭建高可靠缓存集群；</li>
<li>针对缓存击穿，在缓存访问非常频繁的热点数据时，不要设置过期时间；</li>
<li>针对缓存穿透，提前在入口前端实现恶意请求检测，或者规范数据库的数据删除操作，避免误删除</li>
</ul>
</li>
</ul>
<h4 id="27丨缓存被污染了，该怎么办？"><a href="#27丨缓存被污染了，该怎么办？" class="headerlink" title="27丨缓存被污染了，该怎么办？"></a>27丨缓存被污染了，该怎么办？</h4><ul>
<li><p>什么是缓存污染呢？</p>
<ul>
<li>在一些场景下，有些数据被访问的次数非常少，甚至只会被访问一次。当这些数据服务完访问请求后，如果还继续留存在缓存中的话，就只会白白占用缓存空间。这种情况，就是缓存污染。</li>
<li>当缓存污染不严重时，只有少量数据占据缓存空间，此时，对缓存系统的影响不大。但是，缓存污染一旦变得严重后，就会有大量不再访问的数据滞留在缓存中。如果这时数据占满了缓存空间，我们再往缓存中写入新数据时，就需要先把这些数据逐步淘汰出缓存，这就会引入额外的操作时间开销，进而会影响应用的性能</li>
</ul>
</li>
<li><p>如何解决缓存污染问题？</p>
<ul>
<li>得把不会再被访问的数据筛选出来并淘汰掉。这样就不用等到缓存被写满以后，再逐一淘汰旧数据之后，才能写入新数据了。而哪些数据能留存在缓存中，是由缓存的淘汰策略决定的。</li>
<li>volatile-random 和 allkeys-random 这两种策略。它们都是采用随机挑选数据的方式，来筛选即将被淘汰的数据;既然是随机挑选，那么 Redis 就不会根据数据的访问情况来筛选数据。如果被淘汰的数据又被访问了，就会发生缓存缺失。也就是说，应用需要到后端数据库中访问这些数据，降低了应用的请求响应速度。所以，volatile-random 和 allkeys-random 策略，在避免缓存污染这个问题上的效果非常有限</li>
<li>volatile-ttl 针对的是设置了过期时间的数据，把这些数据中剩余存活时间最短的筛选出来并淘汰掉。虽然 volatile-ttl 策略不再是随机选择淘汰数据了，但是剩余存活时间并不能直接反映数据再次访问的情况。所以，按照 volatile-ttl 策略淘汰数据，和按随机方式淘汰数据类似，也可能出现数据被淘汰后，被再次访问导致的缓存缺失问题。<ul>
<li>一种例外的情况：业务应用在给数据设置过期时间的时候，就明确知道数据被再次访问的情况，并根据访问情况设置过期时间。此时，Redis 按照数据的剩余最短存活时间进行筛选，是可以把不会再被访问的数据筛选出来的，进而避免缓存污染</li>
</ul>
</li>
</ul>
</li>
<li><p>LRU 缓存策略</p>
<ul>
<li>如果一个数据刚刚被访问，那么这个数据肯定是热数据，还会被再次访问。按照这个核心思想，Redis 中的 LRU 策略，会在每个数据对应的 RedisObject 结构体中设置一个 lru 字段，用来记录数据的访问时间戳。在进行数据淘汰时，LRU 策略会在候选数据集中淘汰掉 lru 字段值最小的数据（也就是访问时间最久的数据）。</li>
<li>在数据被频繁访问的业务场景中，LRU 策略的确能有效留存访问时间最近的数据。而且，因为留存的这些数据还会被再次访问，所以又可以提升业务应用的访问速度</li>
<li>但是，也正是因为只看数据的访问时间，使用 LRU 策略在处理扫描式单次查询操作时，无法解决缓存污染。所谓的扫描式单次查询操作，就是指应用对大量的数据进行一次全体读取，每个数据都会被读取，而且只会被读取一次。此时，因为这些被查询的数据刚刚被访问过，所以 lru 字段值都很大</li>
<li>在使用 LRU 策略淘汰数据时，这些数据会留存在缓存中很长一段时间，造成缓存污染。如果查询的数据量很大，这些数据占满了缓存空间，却又不会服务新的缓存请求，此时，再有新数据要写入缓存的话，还是需要先把这些旧数据替换出缓存才行，这会影响缓存的性能。</li>
</ul>
</li>
<li><p>LFU 缓存策略的优化</p>
<ul>
<li>LFU 缓存策略是在 LRU 策略基础上，为每个数据增加了一个计数器，来统计这个数据的访问次数。当使用 LFU 策略筛选淘汰数据时，首先会根据数据的访问次数进行筛选，把访问次数最低的数据淘汰出缓存。如果两个数据的访问次数相同，LFU 策略再比较这两个数据的访问时效性，把距离上一次访问时间更久的数据淘汰出缓存。</li>
<li>和那些被频繁访问的数据相比，扫描式单次查询的数据因为不会被再次访问，所以它们的访问次数不会再增加。因此，LFU 策略会优先把这些访问次数低的数据淘汰出缓存。这样一来，LFU 策略就可以避免这些数据对缓存造成污染</li>
<li>Redis 在实现 LFU 策略的时候，只是把原来 24bit 大小的 lru 字段，又进一步拆分成了两部分。<ul>
<li>ldt 值：lru 字段的前 16bit，表示数据的访问时间戳；</li>
<li>counter 值：lru 字段的后 8bit，表示数据的访问次数</li>
</ul>
</li>
<li>当 LFU 策略筛选数据时，Redis 会在候选集合中，根据数据 lru 字段的后 8bit选择访问次数最少的数据进行淘汰。当访问次数相同时，再根据 lru 字段的前 16bit 值大小，选择访问时间最久远的数据进行淘汰。</li>
<li>Redis 只使用了 8bit 记录数据的访问次数，而 8bit 记录的最大值是255，在实现 LFU 策略时，Redis 并没有采用数据每被访问一次，就给对应的 counter 值加 1 的计数规则，而是采用了一个更优化的计数规则。<ul>
<li>每当数据被访问一次时，首先，用计数器当前的值乘以配置项 lfu_log_factor 再加 1，再取其倒数，得到一个 p 值；然后，把这个 p 值和一个取值范围在（0，1）间的随机数 r 值比大小，只有 p 值大于 r 值时，计数器才加 1。</li>
<li>正是因为使用了非线性递增的计数器方法，即使缓存数据的访问次数成千上万，LFU 策略也可以有效地区分不同的访问次数，从而进行合理的数据筛选</li>
</ul>
</li>
<li>在一些场景下，有些数据在短时间内被大量访问后就不会再被访问了。那么再按照访问次数来筛选的话，这些数据会被留存在缓存中，但不会提升缓存命中率。为此，Redis 在实现 LFU 策略时，还设计了一个 counter值的衰减机制。<ul>
<li>LFU 策略使用衰减因子配置项 lfu_decay_time 来控制访问次数的衰减。LFU 策略会计算当前时间和数据最近一次访问时间的差值，并把这个差值换算成以分钟为单位。然后，LFU 策略再把这个差值除以 lfu_decay_time 值，所得的结果就是数据 counter 要衰减的值。</li>
</ul>
</li>
</ul>
</li>
<li><p>在实际业务应用中，LRU 和 LFU 两个策略都有应用。LRU 和 LFU 两个策略关注的数据访问特征各有侧重，LRU 策略更加关注数据的时效性，而 LFU 策略更加关注数据的访问频次。通常情况下，实际应用的负载具有较好的时间局部性，所以 LRU 策略的应用会更加广泛。但是，在扫描式查询的应用场景中，LFU 策略就可以很好地应对缓存污染问题了，建议优先使用</p>
<ul>
<li>如果业务应用中有短时高频访问的数据，除了 LFU 策略本身会对数据的访问次数进行自动衰减以外，再给个小建议：可以优先使用 volatile-lfu 策略，并根据这些数据的访问时限设置它们的过期时间，以免它们留存在缓存中造成污染</li>
</ul>
</li>
<li><p>总结：如何解决缓存污染的问题，分析数据淘汰策略是否可能避免污染，重点介绍LRU测框和LFU策略，LFU策略是针对LRU无法处理大量只访问一次的数据造成的污染问题，引入了频次进行淘汰，且采用非线性增长的计数器（因为lfu的频次记录字段仅占8bit）</p>
</li>
</ul>
<h4 id="28丨Pika如何基于SSD实现大容量Redis？"><a href="#28丨Pika如何基于SSD实现大容量Redis？" class="headerlink" title="28丨Pika如何基于SSD实现大容量Redis？"></a>28丨Pika如何基于SSD实现大容量Redis？</h4><ul>
<li><p>在应用 Redis 时，随着业务数据的增加（比如说电商业务中，随着用户规模和商品数量的增加），就需要 Redis 能保存更多的数据。</p>
<ul>
<li>可能会想到使用 Redis 切片集群，把数据分散保存到多个实例上。但是这样做的话，会有一个问题，如果要保存的数据总量很大，但是每个实例保存的数据量较小的话，就会导致集群的实例规模增加，这会让集群的运维管理变得复杂，增加开销</li>
<li>可以通过增加 Redis 单实例的内存容量，形成大内存实例，每个实例可以保存更多的数据，这样一来，在保存相同的数据总量时，所需要的大内存实例的个数就会减少，就可以节省开销，但这也并不是完美的方案：基于大内存的大容量实例在实例恢复、主从同步过程中会引起一系列潜在问题，例如恢复时间增长、主从切换开销大、缓冲区易溢出。</li>
<li>可以基于 SSD 来实现大容量的 Redis 实例，360 公司 DBA 和基础架构组联合开发的 Pika 键值数据库，正好实现了这一需求。</li>
<li>Pika 在刚开始设计的时候，就有两个目标：一是，单实例可以保存大容量数据，同时避免了实例恢复和主从同步时的潜在问题；二是，和 Redis 数据类型保持兼容，可以支持使用<br>Redis 的应用平滑地迁移到 Pika 上。所以，如果一直在使用 Redis，并且想使用 SSD来扩展单实例容量，Pika 就是一个很好的选择。</li>
</ul>
</li>
<li><p>大内存 Redis 实例的潜在问题</p>
<ul>
<li>内存快照 RDB 受到的影响。内存大小和内存快照 RDB 的关系是非常直接的：实例内存容量大，RDB 文件也会相应增大，那么，RDB 文件生成时的 fork 时长就会增加，这就会导致 Redis 实例阻塞。而且，RDB 文件增大后，使用 RDB 进行恢复的时长也会增加，会导致 Redis 较长时间无法对外提供服务。</li>
<li>主从节点间的同步的第一步就是要做全量同步。全量同步是主节点生成 RDB 文件，并传给从节点，从节点再进行加载。试想一下，如果 RDB 文件很大，肯定会导致全量同步的时长增加，效率不高，而且还可能会导致复制缓冲区溢出。一旦缓冲区溢出了，主从节点间就会又开始全量同步，影响业务应用的正常使用。如果我们增加复制缓冲区的容量，这又会消耗宝贵的内存资源。</li>
<li>如果主库发生了故障，进行主从切换后，其他从库都需要和新主库进行一次全量同步。如果 RDB 文件很大，也会导致主从切换的过程耗时增加，同样会影响业务的可用性。</li>
</ul>
</li>
<li><p>Pika 的整体架构</p>
<ul>
<li>Pika 键值数据库的整体架构中包括了五部分，分别是网络框架、Pika 线程模块、Nemo 存储模块、RocksDB 和 binlog 机制</li>
<li>网络框架主要负责底层网络请求的接收和发送。Pika 的网络框架是对操作系统底层的网络函数进行了封装。Pika 在进行网络通信时，可以直接调用网络框架封装好的函数。</li>
<li>Pika 线程模块采用了多线程模型来具体处理客户端请求，包括一个请求分发线程（DispatchThread）、一组工作线程（WorkerThread）以及一个线程池（ThreadPool）。<ul>
<li>请求分发线程专门监听网络端口，一旦接收到客户端的连接请求后，就和客户端建立连接，并把连接交由工作线程处理。工作线程负责接收客户端连接上发送的具体命令请求，并把命令请求封装成 Task，再交给线程池中的线程，由这些线程进行实际的数据存取处理</li>
<li>在实际应用 Pika 的时候，可以通过增加工作线程数和线程池中的线程数，来提升Pika 的请求处理吞吐率，进而满足业务层对数据处理性能的需求。</li>
</ul>
</li>
<li>Nemo 模块很容易理解，它实现了 Pika 和 Redis 的数据类型兼容。这样一来，当我们把Redis 服务迁移到 Pika 时，不用修改业务应用中操作 Redis 的代码，而且还可以继续应用运维 Redis 的经验，这使得 Pika 的学习成本就较低。</li>
<li>RocksDB 提供的基于 SSD 保存数据的功能。它使得 Pika 可以不用大容量的内存，就能保存更多数据，还避免了使用内存快照。</li>
<li>Pika 使用 binlog 机制记录写命令，用于主从节点的命令同步，避免了刚刚所说的大内存实例在主从同步过程中的潜在问题。</li>
</ul>
</li>
<li><p>Pika 如何基于 SSD 保存更多数据？</p>
<ul>
<li>为了把数据保存到 SSD，Pika 使用了业界广泛应用的持久化键值数据库RocksDB。</li>
<li>RocksDB 写入数据的基本流程：当 Pika 需要保存数据时，RocksDB 会使用两小块内存空间（Memtable1 和Memtable2）来交替缓存写入的数据。Memtable 的大小可以设置，一个 Memtable 的大小一般为几 MB 或几十 MB。当有数据要写入 RocksDB 时，RocksDB 会先把数据写入<br>到 Memtable1。等到 Memtable1 写满后，RocksDB 再把数据以文件的形式，快速写入底层的 SSD。同时，RocksDB 会使用 Memtable2 来代替 Memtable1，缓存新写入的数据。等到 Memtable1 的数据都写入 SSD 了，RocksDB 会在 Memtable2 写满后，再用Memtable1 缓存新写入的数据。</li>
<li>RocksDB 会先用 Memtable 缓存数据，再将数据快速写入SSD，即使数据量再大，所有数据也都能保存到 SSD 中。而且，Memtable 本身容量不大，即使 RocksDB 使用了两个 Memtable，也不会占用过多的内存，这样一来，Pika 在保存大容量数据时，也不用占据太大的内存空间</li>
<li>当 Pika 需要读取数据的时候，RocksDB 会先在 Memtable 中查询是否有要读取的数据。这是因为，最新的数据都是先写入到 Memtable 中的。如果 Memtable 中没有要读取的<br>数据，RocksDB 会再查询保存在 SSD 上的数据文件</li>
<li>当使用大内存实例保存大量数据时，Redis 会面临 RDB 生成和恢复的效率问题，以及主从同步时的效率和缓冲区溢出问题。 Pika 保存大量数据时不会面临相同的问题了<ul>
<li>一方面，Pika 基于 RocksDB 保存了数据文件，直接读取数据文件就能恢复，不需要再通过内存快照进行恢复了。而且，Pika 从库在进行全量同步时，可以直接从主库拷贝数据文件，不需要使用内存快照，这样一来，Pika 就避免了大内存快照生成效率低的问题。</li>
<li>另一方面，Pika 使用了 binlog 机制实现增量命令同步，既节省了内存，还避免了缓冲区溢出的问题。binlog 是保存在 SSD 上的文件，Pika 接收到写命令后，在把数据写入Memtable 时，也会把命令操作写到 binlog 文件中。和 Redis 类似，当全量同步结束后，从库会从 binlog 中把尚未同步的命令读取过来，这样就可以和主库的数据保持一致。当进行增量同步时，从库也是把自己已经复制的偏移量发给主库，主库把尚未同步的命令发给从库，来保持主从库的数据一致。</li>
<li>和 Redis 使用缓冲区相比，使用 binlog 好处是非常明显的：binlog 是保存在 SSD上的文件，文件大小不像缓冲区，会受到内存容量的较多限制。而且，当 binlog 文件增大后，还可以通过轮替操作，生成新的 binlog 文件，再把旧的 binlog 文件独立保存。这样一来，即使 Pika 实例保存了大量的数据，在同步过程中也不会出现缓冲区溢出的问题了。</li>
</ul>
</li>
</ul>
</li>
<li><p>Pika 如何实现 Redis 数据类型兼容？</p>
<ul>
<li><p>Pika 的底层存储使用了 RocksDB 来保存数据，但是，RocksDB 只提供了单值的键值对类型，RocksDB 键值对中的值就是单个值，而 Redis 键值对中的值还可以是集合类型。</p>
<ul>
<li>对于 Redis 的 String 类型来说，它本身就是单值的键值对，直接用 RocksDB 保存就行。但是对于集合类型来说，就无法直接把集合保存为单值的键值对，而是需要进行转换操作。</li>
</ul>
</li>
<li><p>为了保持和 Redis 的兼容性，Pika 的 Nemo 模块就负责把 Redis 的集合类型转换成单值的键值对。可以把 Redis 的集合类型分成两类：</p>
<ul>
<li>一类是 List 和 Set 类型，它们的集合中也只有单值；</li>
<li>另一类是 Hash 和 Sorted Set 类型，它们的集合中的元素是成对的，其中，Hash 集合元素是 field-value 类型，而 Sorted Set 集合元素是 member-score 类型</li>
</ul>
<p>Nemo 模块通过转换操作，把这 4 种集合类型的元素表示为单值的键值对</p>
</li>
<li><p>在 Pika 中，List 集合的 key 被嵌入到了单值键值对的键当中，用 key 字段表示；而 List 集合的元素值，则被嵌入到单值键值对的值当中，用 value 字段表示。因为 List 集合中的元素是有序的，所以，Nemo 模块还在单值键值对的 key 后面增加了 sequence 字段，表示当前元素在 List 中的顺序，同时，还在 value 的前面增加了previous sequence 和 next sequence 这两个字段，分别表示当前元素的前一个元素和后一个元素。</p>
<ul>
<li>此外，在单值键值对的 key 前面，Nemo 模块还增加了一个值“l”，表示当前数据是 List类型，以及增加了一个 1 字节的 size 字段，表示 List 集合 key 的大小。在单值键值对的value 后面，Nemo 模块还增加了 version 和 ttl 字段，分别表示当前数据的版本号和剩余存活时间（用来支持过期 key 功能）</li>
</ul>
</li>
<li><p>Set 集合的 key 和元素 member 值，都被嵌入到了 Pika 单值键值对的键当中，分别用key 和 member 字段表示。同时，和 List 集合类似，单值键值对的 key 前面有值“s”，用来表示数据是 Set 类型，同时还有 size 字段，用来表示 key 的大小。Pika 单值键值对的值只保存了数据的版本信息和剩余存活时间</p>
</li>
<li><p>对于 Hash 类型来说，Hash 集合的 key 被嵌入到单值键值对的键当中，用 key 字段表示，而 Hash 集合元素的 field 也被嵌入到单值键值对的键当中，紧接着 key 字段，用field 字段表示。Hash 集合元素的 value 则是嵌入到单值键值对的值当中，并且也带有版本信息和剩余存活时间</p>
</li>
<li><p>对于 Sorted Set 类型来说，该类型是需要能够按照集合元素的 score 值排序的，而RocksDB 只支持按照单值键值对的键来排序。所以，Nemo 模块在转换数据时，就把Sorted Set 集合 key、元素的 score 和 member 值都嵌入到了单值键值对的键当中，此时，单值键值对中的值只保存了数据的版本信息和剩余存活时间</p>
</li>
<li><p>采用了上面的转换方式之后，Pika 不仅能兼容支持 Redis 的数据类型，而且还保留了这些数据类型的特征，例如 List 的元素保序、Sorted Set 的元素按 score 排序。</p>
</li>
</ul>
</li>
<li><p>Pika 的其他优势与不足</p>
<ul>
<li>跟 Redis 相比，Pika 最大的特点就是使用了 SSD 来保存数据，这个特点能带来的最直接好处就是，Pika 单实例能保存更多的数据了，实现了实例数据扩容。除此之外，Pika 使用 SSD 来保存数据，还有额外的两个优势。<ul>
<li>实例重启快。Pika 的数据在写入数据库时，是会保存到 SSD 上的。当 Pika 实例重启时，可以直接从 SSD 上的数据文件中读取数据，不需要像 Redis 一样，从 RDB 文件全部重新加载数据或是从 AOF 文件中全部回放操作，这极大地提高了 Pika 实例的重启速度，可以快速处理业务应用请求。</li>
<li>主从库重新执行全量同步的风险低。Pika 通过 binlog 机制实现写命令的增量同步，不再受内存缓冲区大小的限制，所以，即使在数据量很大导致主从库同步耗时很长的情况下，Pika 也不用担心缓冲区溢出而触发的主从库重新全量同步</li>
</ul>
</li>
<li>虽然它保持了 Redis 操作接口，也能实现数据库扩容，但是，当把数据保存到 SSD 上后，会降低数据的访问性能。这是因为，数据操作毕竟不能在内存中直接执行了，而是要在底层的 SSD 中进行存取，这肯定会影响，Pika 的性能。而且还需要把 binlog 机制记录的写命令同步到 SSD 上，这会降低 Pika 的写性能。<ul>
<li>不过，Pika 的多线程模型，可以同时使用多个线程进行数据读写，这在一定程度上弥补了从 SSD 存取数据造成的性能损失。当然也可以使用高配的 SSD 来提升访问性能，进而减少读写 SSD 对 Pika 性能的影响。</li>
</ul>
</li>
</ul>
</li>
<li><p>总结：基于SSD给Redis单实例扩容的技术方案Pika，既支持Redis操作接口，又支持保存大容量的数据，Pika是单值键值对类型，针对Redis的各种数据类型通过Nemo模块进行转换；其实例重启快，且执行全量同步的风险低（通过binlog机制实现写命令的增量同步，不再受内存缓冲区的大小限制）但是其读写性能还是要弱于Redis的，可以通过增加线程数量提高Pika的并发请求处理能力</p>
</li>
</ul>
<h4 id="29丨无锁的原子操作：Redis如何应对并发访问？"><a href="#29丨无锁的原子操作：Redis如何应对并发访问？" class="headerlink" title="29丨无锁的原子操作：Redis如何应对并发访问？"></a>29丨无锁的原子操作：Redis如何应对并发访问？</h4><ul>
<li><p>为了保证并发访问的正确性，Redis 提供了两种方法，分别是加锁和原子操作。</p>
<ul>
<li>加锁是一种常用的方法，在读取数据前，客户端需要先获得锁，否则就无法进行操作。当一个客户端获得锁后，就会一直持有这把锁，直到客户端完成数据更新，才释放这把锁。其实这里会有两个问题：<ul>
<li>一个是，如果加锁操作多，会降低系统的并发访问性能；</li>
<li>第二个是，Redis 客户端要加锁时，需要用到分布式锁，而分布式锁实现复杂，需要用额外的存储系统来提供加解锁操作</li>
</ul>
</li>
<li>原子操作是另一种提供并发访问控制的方法。原子操作是指执行过程保持原子性的操作，而且原子操作执行时并不需要再加锁，实现了无锁操作。这样一来，既能保证并发控制，还能减少对系统并发性能的影响</li>
</ul>
</li>
<li><p>并发访问中需要对什么进行控制？</p>
<ul>
<li><p>并发访问控制，是指对多个客户端访问操作同一份数据的过程进行控制，以保证任何一个客户端发送的操作在 Redis 实例上执行时具有互斥性。例如，客户端 A 的访问操作在执行时，客户端 B 的操作不能执行，需要等到 A 的操作结束后，才能执行</p>
</li>
<li><p>并发访问控制对应的操作主要是数据修改操作。当客户端需要修改数据时，基本流程分成两步：</p>
<ul>
<li>客户端先把数据读取到本地，在本地进行修改；</li>
<li>客户端修改完数据后，再写回 Redis。</li>
</ul>
<p>把这个流程叫做“读取 - 修改 - 写回”操作（Read-Modify-Write，简称为 RMW 操作）。当有多个客户端对同一份数据执行 RMW 操作的话，就需要让 RMW 操作涉及的代码以原子性方式执行。访问同一份数据的 RMW 操作代码，就叫做临界区代码。</p>
</li>
<li><p>当有多个客户端并发执行临界区代码时，就会存在一些潜在问题</p>
<ul>
<li>临界区代码中的客户端读取数据、更新数据、再写回数据涉及了三个操作，而这三个操作在执行时并不具有互斥性，多个客户端基于相同的初始值进行修改，而不是基于前一个客户端修改后的值再修改</li>
</ul>
</li>
<li><p>为了保证数据并发修改的正确性，可以用锁把并行操作变成串行操作，串行操作就具有互斥性。一个客户端持有锁后，其他客户端只能等到锁释放，才能拿锁再进行修改</p>
<ul>
<li>虽然加锁保证了互斥性，但是加锁也会导致系统并发性能降低。</li>
<li>和加锁类似，原子操作也能实现并发控制，但是原子操作对系统并发性能的影响较小</li>
</ul>
</li>
</ul>
</li>
<li><p>Redis 的两种原子操作方法</p>
<ul>
<li>把多个操作在 Redis 中实现成一个操作，也就是单命令操作；<ul>
<li>Redis 是使用单线程来串行处理客户端的请求操作命令的，所以，当 Redis 执行某个命令操作时，其他命令是无法执行的，这相当于命令操作是互斥执行的。当然，Redis 的快照生成、AOF 重写这些操作，可以使用后台线程或者是子进程执行，也就是和主线程的操作并行执行。不过，这些操作只是读取数据，不会修改数据，所以，我们并不需要对它们做并发控制。</li>
<li>虽然 Redis 的单个命令操作可以原子性地执行，但是在实际应用中，数据修改时可能包含多个操作，至少包括读数据、数据增减、写回数据三个操作，这显然就不是单个命令操作了</li>
<li>Redis 提供了 INCR&#x2F;DECR 命令，把这三个操作转变为一个原子操作了。INCR&#x2F;DECR 命令可以对数据进行增值 &#x2F; 减值操作，而且它们本身就是单个命令操作，Redis 在执行它们时，本身就具有互斥性</li>
<li>如果要执行的操作不是简单地增减数据，而是有更加复杂的判断逻辑或者是其他操作，那么，Redis 的单命令操作已经无法保证多个操作的互斥执行</li>
</ul>
</li>
<li>把多个操作写到一个 Lua 脚本中，以原子性方式执行单个 Lua 脚本。<ul>
<li>Redis 会把整个 Lua 脚本作为一个整体执行，在执行的过程中不会被其他命令打断，从而保证了 Lua 脚本中操作的原子性。如果我们有多个操作要执行，但是又无法用INCR&#x2F;DECR 这种命令操作来实现，就可以把这些要执行的操作编写到一个 Lua 脚本中。然后，我们可以使用 Redis 的 EVAL 命令来执行脚本。这样一来，这些操作在执行时就具有了互斥性。</li>
<li>如果把很多操作都放在 Lua 脚本中原子执行，会导致 Redis 执行脚本的时间增加，同样也会降低 Redis 的并发性能。所以，在编写 Lua脚本时，要避免把不需要做并发控制的操作写入脚本中。</li>
</ul>
</li>
</ul>
</li>
<li><p>第29讲，Redis如何应对并发访问：并发控制其实就是保证临界代码区的互斥执行，保证数据正确，通常通过加锁和原子操作实现；但是加锁回降低并发访问性能，而且分布式锁的实现复杂，需要使用额外的存储系统进行加解锁操作；redis提供两种原子操作的方法实现：</p>
<ul>
<li>单命令操作：Redis内部提供的一种原子操作，例如INCR&#x2F;DECR，但是其适用范围较小，如果需要进行判断等操作或者不是简单的增减时就不适用了</li>
<li>Lua脚本：<code>--eval lua.script keys, args</code> 可以执行多个操作，绕开了单命令操作的限制，但是把很多操作都放到Lua脚本中执行的话会导致其执行时间增加，降低redis的并发性能，要避免把不需要并发控制的操作写入脚本中</li>
</ul>
</li>
<li><p>第30讲，使用Redis实现分布式锁：</p>
<ul>
<li>分布式锁和单机上的锁的区别在于需要使用一个共享存储系统来维护一个锁变量，而redis本身就是一个共享的存储系统，其中也需要保证锁操作的原子性和锁的可靠性；</li>
<li>对于单redis实现的分布式锁，关于锁的原子性的保证可以利用redis中的单命令操作和lua脚本，使用SET操作（SET NX EX&#x2F;PX）对锁变量设定一个包含过期时间和唯一客户端标识的锁变量，然后使用lua脚本针对客户端身份进行验证然后解锁操作；</li>
<li>为了保证分布式锁的高可靠性，可以基于多个Redis节点实现分布式锁，采用Redlock的算法，总共有三个步骤：1.客户端获取当前时间；2.客户端按顺序向N个redis实例执行加锁操作；3.一旦完成了和所有redis的加锁操作，计算整个加锁过程的总耗时；如果客户端从超过半数的redis实例上获得了锁并且总耗时没有超过锁的有效时间，则重新计算该锁的有效时间，如果来不及完成共享数据的操作了则释放锁，以免出现还没有完成操作，锁就过期了的情况；否则成功获取锁进行操作。</li>
</ul>
</li>
<li><p>第31讲，Redis能否实现ACID属性</p>
<ul>
<li>ACID属性：原子性（一个事务多个操作必须都完成）、一致性（数据库中的数据在事务执行前后是一致的）、隔离性（数据库在执行一个事务时，其他操作无法存取到当前事务正在访问的数据）、持久性（数据的修改要被持久化保存下来）</li>
<li>Redis通过MULTI显示的表示一个事务的开启，然后讲要执行的具体操作发送给服务器（redis实例只是将其暂存到一个命令队列里面，不会立即执行），最后通过EXEC命令提交事务，执行命令队列里的所有命令</li>
<li>Redis的事务机制能否保证原子性要考虑三个情况：对于在执行EXEC命令客户端的操作命令本身就有错误的情况，redis会拒绝所有提交的命令操作，从而保证原子性；对于事务操作入队时命令和操作的数据类型不匹配但是redis实例没有检测出错误的情况，redis会执行剩余的正确命令，从而导致原子性失效；对于在执行EXEC命令时，redis实例发生故障而导致事务执行失败，如果开启了AOF日志则可以使用redis-check-aof检测AOF日志文件，可以把这个已完成的事务从AOF文件中去除，从而保证原子性</li>
<li>对于一致性，redis事务机制是可以保证的，而隔离性再使用WATCH机制的情况下也是可以保证的，但是redis不管采用什么持久化模式都无法保证持久性（但是本身是内存数据库，持久性并不是必须的属性）</li>
</ul>
</li>
<li><p>第32讲，Redis主从同步时可能出现的3个问题：</p>
<ul>
<li>主从数据不一致：这是由于主从库间的命令是异步进行的，主要是因为主从库网络可能有传输延迟或者从库收到了命令但是此时被阻塞需要等待当前命令执行结束；解决方法首先是需要保证主从库网络连接良好（硬件环境配置），然后可以开发一个外部程序监控主从服务器之间的复制进度，相差较大则移除此库的连接信息，复制进度又赶上后再加回来</li>
<li>读到过期数据：redis采用了两种策略删除过期数据，惰性删除策略和定期删除策略，这两个策略都是删除部分的过期数据，那么留存的过期数据就可能被访问到，一是由于配置过低（3.2以上会直接返回空值），二是由于过期命令直接的延迟导致过期时间延长（使用EXPIREAT命令解决）</li>
<li>不合理配置导致服务器挂掉：protected-mode需要设定为no然后利用bind配置项设定其他可以访问实例的哨兵IP地址；cluster-node-timeout设置了redis cluster中实例响应心跳的超时时间，需要调大些</li>
</ul>
</li>
<li><p>第33讲，主从切换时可能遇到的脑裂问题，脑裂问题是指在主从集群中同时有两个主库都能接受写请求，可能会导致数据的丢失</p>
<ul>
<li>分析数据丢失的原因：首先确认是不是数据同步出现了问题，最常见的原因就是主库的数据还没有同步到从库，结果主库发生了故障，等从库升级为主库后，未同步的数据就丢失了，这一步可以通过比较master_repl_offset 和 slave_repl_offset 的差值进行确定；然后判断排查客户端的操作日志，看是否发生了脑裂现象，即在主从切换后的一段时间内，有一个客户端仍然在和原主库通信，并没有和升级的新主库进行交互，最后排查出是主库发生了假故障</li>
<li>脑裂发生的主要原因是原主库发生了假故障，一般是由于与主库部署在同一台服务器上的其他程序临时占用了大量资源，导致主库资源使用受限，或者主库自身遇到了阻塞的情况，比如处理bigkey或者内存swap，短时间无法响应心跳；因此哨兵机制判断主库失活进行主从切换，主从切换后，从库一旦升级为新主库，哨兵就会让原主库执行 slave of 命令，和新主库重新进行全量同步，而在全量同步执行的最后阶段，原主库需要清空本地的数据，这就使得数据丢失了</li>
<li>为了应对脑裂，可以在主从集群部署时，通过合理地配置参数 min-slaves-to-write（主库能进行数据同步的最少从库数量） 和 min-slaves-max-lag（主从库间进行数据复制时，从库给主库发送ACK 消息的最大延迟），来预防脑裂的发生：主库连接的从库中至少有 N 个从库，和主库进行数据复制时的 ACK 消息延迟不能超过 T 秒，否则，主库就不会再接收客户端的请求</li>
</ul>
</li>
<li><p>第34讲，课后习题及常见问题答疑：</p>
<ul>
<li>Redis 的只读缓存和使用直写策略的读写缓存，都会把数据同步写到后端数据库中，你觉得它们有什么区别吗？<ul>
<li>主要的区别在于，当有缓存数据被修改时，在只读缓存中，业务应用会直接修改数据库，并把缓存中的数据标记为无效；而在读写缓存中，业务应用需要同时修改缓存和数据库。</li>
</ul>
</li>
<li>Redis 缓存在处理脏数据时，不仅会修改数据，还会把它写回数据库，Redis 缓存对应哪一种或哪几种模式？<ul>
<li>如果在使用 Redis 缓存时，需要把脏数据写回数据库，这就意味着，Redis 中缓存的数据可以直接被修改，这就对应了读写缓存模式。更进一步分析的话，脏数据是在被替换出缓存时写回后端数据库的，这就对应了带有异步写回策略的读写缓存模式</li>
</ul>
</li>
<li>在只读缓存中对数据进行删改时，需要在缓存中删除相应的缓存值。如果在这个过程中，不是删除缓存值，而是直接更新缓存的值，你觉得和删除缓存值相比，直接更新缓存值有什么好处和不足吗？<ul>
<li>直接在缓存中更新缓存值，等到下次数据再被访问时，业务应用可以直接从缓存中读取数据，这是它的一大好处。</li>
<li>不足之处在于，当有数据更新操作时，要保证缓存和数据库中的数据是一致的，这就可以采用我在第 25 讲中介绍的重试或延时双删方法。不过，这样就需要在业务应用中增加额外代码，有一定的开销。</li>
</ul>
</li>
<li>在讲到缓存雪崩时，我可以采用服务熔断、服务降级、请求限流三种方法来应对，这三个方法可以用来应对缓存穿透问题吗？<ul>
<li>缓存穿透这个问题的本质是查询了 Redis 和数据库中没有的数据，而服务熔断、服务降级和请求限流的方法，本质上是为了解决 Redis 实例没有起到缓存层作用的问题，缓存雪崩和缓存击穿都属于这类问题。</li>
<li>在缓存穿透的场景下，业务应用是要从 Redis 和数据库中读取不存在的数据，此时，如果没有人工介入，Redis 是无法发挥缓存作用的。</li>
<li>一个可行的办法就是事前拦截，不让这种查询 Redis 和数据库中都没有的数据的请求发送到数据库层。使用布隆过滤器也是一个方法，布隆过滤器在判别数据不存在时，是不会误判的，而且判断速度非常快，一旦判断数据不存在，就立即给客户端返回结果。使用布隆过滤器的好处是既降低了对 Redis 的查询压力，也避免了对数据库的无效访问。</li>
</ul>
</li>
<li>使用了 LFU 策略后，缓存还会被污染吗？<ul>
<li><p>在一些极端情况下，LFU 策略使用的计数器可能会在短时间内达到一个很大值，而计数器的衰减配置项设置得较大，导致计数器值衰减很慢，在这种情况下，数据就可能在缓存中长期驻留。例如，一个数据在短时间内被高频访问，即使我们使用了 LFU 策略，这个数据也有可能滞留在缓存中，造成污染。</p>
</li>
<li><p>使用 SSD 作为内存容量的扩展可以增加 Redis 实例的数据保存量，可以使用机械硬盘来作为实例容量扩展吗？有什么好处或不足吗</p>
<ul>
<li>从容量维度来看，机械硬盘的性价比更高</li>
<li>从性能角度来看，机械硬盘（例如 SAS 盘）的延迟大约在 3<del>5ms，而企业级 SSD 的读延迟大约是 60</del>80us，写延迟在 20us。缓存的负载特征一般是小粒度数据、高并发请求，要求访问延迟低。所以，如果使用机械硬盘作为 Pika 底层存储设备的话，缓存的访问性能就会降低。</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<p>​<br>​        - Redis 在执行 Lua 脚本时，是可以保证原子性的，在 Lua 脚本例子（lua.script）中，是否需要把读取客户端 ip 的访问次数，也就是 GET(ip)，以及判断访问次数是否超过 20 的判断逻辑，也加到 Lua 脚本中吗<br>​          - 在这个例子中，要保证原子性的操作有三个，分别是 INCR、判断访问次数是否为 1和设置过期时间。而对于获取 IP 以及判断访问次数是否超过 20 这两个操作来说，它们只是读操作，即使客户端有多个线程并发执行这两个操作，也不会改变任何值，所以并不需要保证原子性，也就不用把它们放到 Lua 脚本中了</p>
<p>​<br>​        - 可以使用 SET 命令带上 NX 和 EX&#x2F;PX 选项进行加锁操作，那么是否可以用SETNX + EXPIRE来实现加锁操作呢？<br>​          - SETNX 和 EXPIRE 两个命令虽然分别完成了对锁变量进行原子判断和值设置，以及设置锁变量的过期时间的操作，但是这两个操作一起执行时，并没有保证原子性。如果在执行了 SETNX 命令后，客户端发生了故障，但锁变量还没有设置过期时间，就无法在实例上释放了，这就会导致别的客户端无法执行加锁操作。所以，不能使用这个方法进行加锁。</p>
<p>​<br>​        - 在执行事务时，如果 Redis 实例发生故障，而 Redis 使用的是 RDB 机制，那么，<br>​          事务的原子性还能得到保证吗？<br>​          - 当 Redis 采用 RDB 机制保证数据可靠性时，Redis 会按照一定的周期执行内存快照。一个事务在执行过程中，事务操作对数据所做的修改并不会实时地记录到 RDB 中，而且，Redis 也不会创建 RDB 快照。我们可以根据故障发生的时机以及 RDB 是否生成，分成三种情况来讨论事务的原子性保证。<br>​          - 假设事务在执行到一半时，实例发生了故障，在这种情况下，上一次 RDB 快照中不会包含事务所做的修改，而下一次 RDB 快照还没有执行。所以，实例恢复后，事务修改的数据会丢失，事务的原子性能得到保证。<br>​          - 假设事务执行完成后，RDB 快照已经生成了，如果实例发生了故障，事务修改的数据可以从 RDB 中恢复，事务的原子性也就得到了保证。<br>​          - 假设事务执行已经完成，但是 RDB 快照还没有生成，如果实例发生了故障，那么，事务修改的数据就会全部丢失，也就谈不上原子性了。</p>
<p>​<br>​        - 在主从集群中，把 slave-read-only 设置为 no，让从库也能直接删除数据，以此来避免读到过期数据，这个方法好吗？<br>​          - 主从复制中的增删改操作都需要在主库执行，即使从库能做删除，也不要在从库删除，否则会导致数据不一致<br>​          - 第一种情况是，由于网络延迟导致从库没有及时收到 expire 命令，从库按照原定的过期时间删除了过期 key，这就导致主从数据不一致了；第二种情况是，主从库的时钟不同步，导致主从库删除时间不一致。</p>
<p>​<br>​        - 假设将 min-slaves-to-write 设置为 1，min-slaves-max-lag 设置为 15s，哨兵的 down-after-milliseconds 设置为 10s，哨兵主从切换需要 5s，而主库因为某些原因<br>​          卡住了 12s。此时，还会发生脑裂吗？主从切换完成后，数据会丢失吗？<br>​          - 主库卡住了 12s，超过了哨兵的 down-after-milliseconds 10s 阈值，所以，哨兵会把主库判断为客观下线，开始进行主从切换。因为主从切换需要 5s，在主从切换过程中，原主库恢复正常。min-slaves-max-lag 设置的是 15s，而原主库在卡住 12s 后就恢复正常了，所以没有被禁止接收请求，客户端在原主库恢复后，又可以发送请求给原主库。一旦在主从切换之后有新主库上线，就会出现脑裂。如果原主库在恢复正常后到降级为从库前的这段时间内，接收了写操作请求，那么，这些数据就会丢失了</p>
<p>​<br>​        - 如何理解把 Redis 称为旁路缓存？<br>​          - 业务应用在使用 Redis 缓存时，需要在业务代码中显式地增加缓存的操作逻辑<br>​          - 和旁路缓存相对应的计算机系统中的 CPU 缓存和 pagecache。这两种缓存默认就在应用程序访问内存和磁盘的路径上，应用程序都能直接使用这两种缓存</p>
<pre><code>- 使用 Redis 缓存时，应该用哪种模式？
  - 通用的缓存模式有三种：只读缓存模式、采用同步直写策略的读写缓存模式、采用异步写回策略的读写缓存模式。
    - 一般情况下，我们会把 Redis 缓存用作只读缓存。只读缓存涉及的操作，包括查询缓存、缓存缺失时读数据库和回填，数据更新时删除缓存数据，这些操作都可以加到业务应用中。而且，当数据更新时，缓存直接删除数据，缓存和数据库的数据一致性较为容易保证。
    - 有时我们也会把 Redis 用作读写缓存，同时采用同步直写策略。在这种情况下，缓存涉及的操作也都可以加到业务应用中。而且，和只读缓存相比有一个好处，就是数据修改后的最新值可以直接从缓存中读取。
    - 对于采用异步写回策略的读写缓存模式来说，缓存系统需要能在脏数据被淘汰时，自行把数据写回数据库，但是，Redis 是无法实现这一点的，所以使用 Redis 缓存时，并不采用这个模式。
</code></pre>
<ul>
<li><p>第35讲，Redis 的切片集群使用多个实例保存数据，能够很好地应对大数据量的场景，Redis 切片集群的 Codis 方案介绍，Codis 集群包含 codis server、codis proxy、Zookeeper、codis dashboard 和 codis fe 这四大类组件</p>
<ul>
<li><p>codis proxy 和 codis server 负责处理数据读写请求，其中，codis proxy 和客户端连<br>接，接收请求，并转发请求给 codis server，而 codis server 负责具体处理请求。</p>
</li>
<li><p>codis dashboard 和 codis fe 负责集群管理，其中，codis dashboard 执行管理操作，而 codis fe 提供 Web 管理界面。</p>
</li>
<li><p>Zookeeper 集群负责保存集群的所有元数据信息，包括路由表、proxy 实例信息等。这里，有个地方需要你注意，除了使用 Zookeeper，Codis 还可以使用 etcd 或本地文件系统保存元数据信息。</p>
</li>
<li><p>Codis 的关键技术原理：</p>
<ul>
<li>数据如何在集群里分布？在 Codis 集群中，一个数据应该保存在哪个 codis server 上，这是通过逻辑槽（Slot）映射来完成的，数据 key 和 Slot 的映射关系是客户端在读写数据前直接通过 CRC32 计算得到的，而 Slot和 codis server 的映射关系是通过分配完成的，称为数据路由表（简称路由表）codis dashboard 上进行分配传递给codis proxy同时保存在本地Zookeeper中。在数据分布的实现方法上，Codis 和 Redis Cluster 很相似，都采用了 key 映射到 Slot、Slot 再分配到实例上的机制，但是一旦数据位置发生变化（例如有实例增减），路由表被修改了，codis dashbaord 就会把修改后的路由表发送给 codis proxy，从而根据最新的路由信息转发请求；而Redis Cluster 中，数据路由表是通过每个实例相互间的通信传递的，最后会在每个实例上保存一份，如果实例数量较多的话，就会消耗较多的集群网络资源</li>
<li>集群扩容和数据迁移如何进行?：Codis 集群扩容包括了两方面：增加 codis server 和增加 codis proxy。增加 codis server，这个过程主要涉及到两步操作：启动新的 codis server，将它加入集群；把部分数据迁移到新的 server（包括选择、发送、删除，可分为同步迁移和异步迁移（异步迁移的数据会被设置为只读从而保证数据一致性；对于 bigkey，异步迁移采用了拆分指令的方式进行迁移，设定临时过期时间））</li>
<li>集群客户端需要重新开发吗?：Redis 单实例在使用切片集群时，有些功能是和单实例不一样的，比如集群中的数据迁移操作，迁移过程中，数据访问请求可能要被重定向，所以，客户端需要增加和集群功能相关的命令操作的支持。Codis 使用 codis proxy 直接和客户端连接，codis proxy 是和单实例客户端兼容的。而和集群相关的管理工作（例如请求转发、数据迁移等），都由 codis proxy、codis dashboard 这些组件来完成，不需要客户端参与</li>
<li>怎么保证集群可靠性？：codis server 其实就是 Redis 实例，只不过增加了和集群操作相关的命令，Codis 就使用主从集群来保证 codis server 的可靠性；在 Codis 集群设计时，proxy 上的信息源头都是来自 Zookeeper（例如路由表）。而Zookeeper 集群使用多个实例来保存数据，只要有超过半数的 Zookeeper 实例可以正常工作， Zookeeper 集群就可以提供服务，也可以保证这些数据的可靠性；当 codis proxy 发生故障后，直接重启 proxy 就行。重启后的 proxy，可以通过 codis dashboard 从Zookeeper 集群上获取路由表，然后，就可以接收客户端请求进行转发了</li>
</ul>
</li>
<li><p>切片集群方案选择建议：</p>
<ul>
<li>从稳定性和成熟度来看，Codis 应用得比较早，在业界已经有了成熟的生产部署</li>
<li>从业务应用客户端兼容性来看，连接单实例的客户端可以直接连接 codis proxy，而原本连接单实例的客户端要想连接 Redis Cluster 的话，就需要开发新功能</li>
<li>从使用 Redis 新命令和新特性来看，Codis 并不支持 Redis 后续的开源版本中的新增命令和数据类型，也并没有实现开源 Redis 版本的所有命令</li>
<li>从数据迁移性能维度来看，Codis 能支持异步迁移，异步迁移对集群处理正常请求的性能影响要比使用同步迁移的小</li>
</ul>
</li>
</ul>
</li>
<li><p>第36讲，Redis 在秒杀场景中的具体应用。秒杀场景有 2 个负载特征，分别是瞬时高并发请求和读多写少。Redis 良好的高并发处理能力，以及高效的键值对读写特性，正好可以满足秒杀场景的需求。</p>
<ul>
<li>秒杀场景包含了多个环节，可以分成秒杀前、秒杀中和秒杀后三个阶段，每个阶段的请求处理需求并不相同，Redis 并不能支撑秒杀场景的每一个环节</li>
<li>秒杀场景的负载特征对支撑系统的要求：<ul>
<li>第一个特征是瞬时并发访问量非常高。一般数据库每秒只能支撑千级别的并发请求，而 Redis 的并发处理能力（每秒处理请求数）能达到万级别，甚至更高。所以，当有大量并发请求涌入秒杀系统时，我们就需要使用 Redis 先拦截大部分请求，避免大量请求直接发送给数据库，把数据库压垮</li>
<li>第二个特征是读多写少，而且读操作是简单的查询操作。</li>
</ul>
</li>
<li><strong>Redis 可以在秒杀场景的哪些环节发挥作用</strong>？<ul>
<li>一般是在秒杀活动中使用Redis：可分为三个操作，库存查验、库存扣减和订单处理。因为每个秒杀请求都会查询库存，而请求只有查到有库存余量后，后续的库存扣减和订单处理才会被执行。所以，这个阶段中最大的并发压力都在库存查验操作上</li>
<li>为了支撑大量高并发的库存查验请求，需要在这个环节使用 Redis 保存库存量，这样一来，请求可以直接从 Redis 中读取库存并进行查验</li>
<li>订单处理可以在数据库中执行（请求压力已经不大了，数据库可以支撑这些订单处理请求），但库存扣减操作，不能交给后端数据库处理，如果把库存扣减的操作放到数据库执行，会带来两个问题：<ul>
<li>额外的开销。Redis 中保存了库存量，而库存量的最新值又是数据库在维护，所以数据库更新后，还需要和 Redis 进行同步，这个过程增加了额外的操作逻辑，也带来了额外的开销。</li>
<li>下单量超过实际库存量，出现超售。由于数据库的处理速度较慢，不能及时更新库存余量，这就会导致大量库存查验的请求读取到旧的库存值，并进行下单。此时，就会出现下单数量大于实际的库存量，导致出现超售，这就不符合业务层的要求了</li>
</ul>
</li>
</ul>
</li>
<li><strong>Redis 的哪些方法可以支撑秒杀场景</strong>？秒杀场景对 Redis 操作的根本要求有两个：<ul>
<li><strong>支持高并发</strong>。Redis 本身高速处理请求的特性就可以支持高并发，也可以使用切片集群，用不同的实例保存不同商品的库存，这样就避免使用单个实例导致所有的秒杀请求都集中在一个实例上的问题</li>
<li><strong>保证库存查验和库存扣减原子性执行</strong>。针对这条要求可以使用 Redis 的原子操作或是分布式锁这两个功能特性来支撑；库存查验和库存扣减这两个操作要保证一起执行，一个直接的方法就是使用使用 Lua 脚本原子性地执行这两个操作；还有另一种方法，就是使用分布式锁来保证多个客户端能互斥执行这两个操作，具体做法是，先让客户端向 Redis 申请分布式锁，只有拿到锁的客户端才能执行库存查验和库存扣减，这样一来，客户端在争抢分布式锁时，大部分秒杀请求本身就会因为抢不到锁而被拦截；可以使用切片集群中的不同实例来分别保存分布式锁和商品库存信息。使用这种保存方式后，秒杀请求会首先访问保存分布式锁的实例，可以减轻保存库存信息的实例的压力</li>
</ul>
</li>
<li>在秒杀场景中，可以通过前端 CDN 和浏览器缓存拦截大量秒杀前的请求。在实际秒杀活动进行时，库存查验和库存扣减是承受巨大并发请求压力的两个操作，同时，这两个操作的执行需要保证原子性。Redis 的原子操作、分布式锁这两个功能特性可以有效地来支撑秒杀场景的需求。</li>
<li>秒杀系统是一个系统性工程，Redis 实现了对库存查验和扣减这个环节的支撑，除此之外，还有 4 个环节需要处理好：<ul>
<li>前端静态页面的设计。秒杀页面上能静态化处理的页面元素，都要尽量静态化，这样可以充分利用 CDN 或浏览器缓存服务秒杀开始前的请求。</li>
<li>请求拦截和流控。在秒杀系统的接入层，对恶意请求进行拦截，避免对系统的恶意攻击，例如使用黑名单禁止恶意 IP 进行访问。如果 Redis 实例的访问压力过大，为了避免实例崩溃，也需要在接入层进行限流，控制进入秒杀系统的请求数量。</li>
<li>库存信息过期时间处理。Redis 中保存的库存信息其实是数据库的缓存，为了避免缓存击穿问题，不要给库存信息设置过期时间。</li>
<li>数据库订单异常处理。如果数据库没能成功处理订单，可以增加订单重试功能，保证订单最终能被成功处理。</li>
</ul>
</li>
<li>秒杀活动带来的请求流量巨大，需要把秒杀商品的库存信息用单独的实例保存，而不要和日常业务系统的数据保存在同一个实例上，这样可以避免干扰业务系统正常运行</li>
</ul>
</li>
<li><p>第37讲，在切片集群中，数据会按照一定的分布规则分散到不同的实例上保存，容易导致一个问题：数据倾斜；数据倾斜的两种情况：数据量倾斜和数据访问倾斜</p>
<ul>
<li><p>造成数据量倾斜的原因主要有三个：</p>
<ol>
<li><p>数据中有 bigkey，导致某个实例的数据量增加；</p>
<p>一个根本的应对方法是，我们在业务层生成数据时，要尽量避免把过多的数据保存在同一个键值对中；如果 bigkey 正好是集合类型，还有一个方法，就是把 bigkey 拆分成很多个小的集合类型数据，分散保存在不同的实例上</p>
</li>
<li><p>Slot 手工分配不均，导致某个或某些实例上有大量数据；</p>
<p>可以通过运维规范，在分配之前就要避免把过多的 Slot 分配到同一个实例。如果是已经分配好 Slot 的集群，可以先查看 Slot 和实例的具体分配关系，从而判断是否有过多的 Slot 集中到了同一个实例。如果有的话，使用迁移命令将部分 Slot迁移到其它实例，从而避免数据倾斜</p>
</li>
<li><p>使用了 Hash Tag，导致数据集中到某些实例上；</p>
<p>Hash Tag 是指加在键值对 key 中的一对花括号{}；使用 Hash Tag 的好处是，如果不同 key 的 Hash Tag 内容都是一样的，那么，这些 key对应的数据会被映射到同一个 Slot 中，同时会被分配到同一个实例上。如果使用 Hash Tag 进行切片的数据会带来较大的访问压力，就优先考虑避<br>免数据倾斜，最好不要使用 Hash Tag 进行数据切片</p>
</li>
</ol>
</li>
<li><p>数据访问倾斜的主要原因就是有热点数据存在，导致大量访问请求集中到了热点数据所在的实例上；通常来说，热点数据以服务读操作为主，在这种情况下，我们可以采用热点数据多副本的方法来应对，具体做法是，把热点数据复制多份，在每一个数据副本的 key 中增加一个随机前缀，让它和其它副本数据不会被映射到同一个 Slot 中</p>
</li>
<li><p>热点数据多副本方法只能针对只读的热点数据。如果热点数据是有读有写的话，就不适合采用多副本方法了，因为要保证多副本间的数据一致性，会带来额外的开销</p>
</li>
<li><p>关于集群的实例资源配置：在构建切片集群时，尽量使用大小配置相同的实例（例如实例内存配置保持相同），这样可以避免因实例资源不均衡而在不同实例上分配不同数量的 Slot</p>
</li>
</ul>
</li>
<li><p>第38讲，Redis Cluster 实例间以 Gossip 协议进行通信的机制以及限制其规模的主要因素</p>
<ul>
<li>为什么要限定集群规模呢？：实例间的通信开销会随着实例规模增加而增大，在集群超过一定规模时（比如 800 节点），集群吞吐量反而会下降</li>
<li>Redis Cluster 运行时，各实例间需要通过 PING、PONG 消息进行信息交换，这些心跳消息包含了当前实例和部分其它实例的状态信息，以及 Slot 分配信息。这种通信机制有助于 RedisCluster 中的所有实例都拥有完整的集群状态信息；这个规则就是 Gossip 协议：<ul>
<li>按照一定的频率，从集群中随机挑选一些实例，把 PING 消息发送给挑选出来的实例，用来检测这些实例是否在线，并交换彼此的状态信息</li>
<li>一个实例在接收到 PING 消息后，会给发送 PING 消息的实例，发送一个 PONG 消息。PONG 消息包含的内容和 PING 消息一样</li>
<li>PING 消息的大小大约是 12KB，每个实例发送了PING 消息后，还会收到返回的 PONG 消息，两个消息加起来有 24KB；如果实例正常处理的单个请求只有几 KB的话，那么，实例为了维护集群状态一致传输的 PING&#x2F;PONG 消息，就要比单个业务请求大了。随着集群规模增加，这些心跳消息的数量也会越多，会占据一部分集群的网络通信带宽，进而会降低集群服务正常客户端请求的吞吐量。</li>
</ul>
</li>
<li>随着集群规模的增加，实例间的通信量也会增加。如果盲目地对 Redis Cluster进行扩容，就可能会遇到集群性能变慢的情况。这是因为，集群中大规模的实例间心跳消息会挤占集群处理正常请求的带宽。而且，有些实例可能因为网络拥塞导致无法及时收到PONG 消息，每个实例在运行时会周期性地（每秒 10 次）检测是否有这种情况发生，一旦发生，就会立即给这些 PONG 消息超时的实例发送心跳消息。集群规模越大，网络拥塞的概率就越高，相应的，PONG 消息超时的发生概率就越高，这就会导致集群中有大量的心跳消息，影响集群服务正常请求。</li>
<li>为了避免过多的心跳消息挤占集群带宽，可以调大 cluster-node-timeout 值，比如说调大到 20 秒或 25 秒；但也不要调得太大，否则，如果实例真的发生了故障，我们就需要等待对应时长后，才能检测出这个故障，这又会导致实际的故障恢复时间被延长，会影响到集群服务的正常使用；可以在调整 cluster-node-timeout 值的前后，使用 tcpdump 命令抓取实例发送心跳信息网络包的情况</li>
</ul>
</li>
<li><p>第39讲，Redis 6.0 的新特性介绍</p>
<ul>
<li>面向网络处理的多 IO 线程可以提高网络请求处理的速度，而客户端缓存可以让应用直接在客户端本地读取数据，这两个特性可以提升 Redis 的性能<ul>
<li>随着网络硬件的性能提升，Redis 的性能瓶颈有时会出现在网络 IO 的处理上，单个主线程处理网络请求的速度跟不上底层网络硬件的速度，Redis采用多个 IO 线程来处理网络请求，提高网络请求处理的并行度</li>
<li>Redis 的多 IO 线程只是用来处理网络请求的，对于读写命令，Redis 仍然使用单线程来处理。这是因为Redis 处理请求时网络处理经常是瓶颈，通过多个 IO 线程并行处理网络操作，可以提升实例的整体处理性能。而继续使用单线程执行命令操作，就不用为了保证 Lua 脚本、事务的原子性，额外开发多线程互斥机制了</li>
</ul>
</li>
<li>主线程和 IO 线程具体是怎么协作完成请求处理的：<ul>
<li>首先，主线程负责接收建立连接请求。当有客户端请求和实例建立 Socket 连接时，主线程会创建和客户端的连接，并把 Socket 放入全局等待队列中。紧接着，主线程通过轮询方法把 Socket 连接分配给 IO 线程</li>
<li>主线程一旦把 Socket 分配给 IO 线程，就会进入阻塞状态，等待 IO 线程完成客户端请求读取和解析</li>
<li>等到 IO 线程解析完请求，主线程还是会以单线程的方式执行这些命令操作</li>
<li>IO 线程回写 Socket 和主线程清空全局队列：和 IO 线程读取和解析请求一样，IO 线程回写 Socket 时，也是有多个线程在并发执行，所以回写 Socket 的速度也很快。等到 IO 线程回写 Socket 完毕，主线程会清空全局队列，等待客户端的后续请求</li>
</ul>
</li>
<li><strong>实现服务端协助的客户端缓存</strong>：业务应用中的 Redis 客户端就可以把读取的数据缓存在业务应用本地，应用就可以直接在本地快速读取数据，不过会面临一个问题：如果数据被修改了或是失效了，如何通知客户端对缓存的数据做失效处理？<ul>
<li>第一种模式是普通模式。在这个模式下，实例会在服务端记录客户端读取过的 key，并监测 key 是否有修改。一旦 key 的值发生变化，服务端会给客户端发送 invalidate 消息（只会报告一次），通知客户端缓存失效了</li>
<li>第二种模式是广播模式。在这个模式下，服务端会给客户端广播所有 key 的失效情况，不过，这样做了之后，如果 key 被频繁修改，服务端会发送大量的失效广播消息，这就会消耗大量的网络带宽资源</li>
<li>在实际应用时，会让客户端注册希望跟踪的 key 的前缀，当带有注册前缀的key 被修改时，服务端会把失效消息广播给所有注册的客户端。和普通模式不同，在广播模式下，即使客户端还没有读取过 key，但只要它注册了要跟踪的 key，服务端都会把key 失效消息通知给这个客户端</li>
<li>普通模式和广播模式，需要客户端使用 RESP 3 协议，对于使用 RESP 2 协议的客户端来说，就需要使用另一种模式，也就是重定向模式（redirect），需要执行订阅命令，专门订阅用于发送失效消息的频道，再使用另外一个客户端，执行 CLIENT TRACKING命令，设置服务端将失效消息转发给使用RESP 2协议的客户端</li>
</ul>
</li>
<li>细粒度权限控制让 Redis 可以按照命令粒度控制不同用户的访问权限，加强了 Redis 的安全保护，6.0 版本支持创建不同用户来使用 Redis，还支持以用户为粒度设置命令操作的访问权限</li>
<li>RESP 3 协议则增强客户端的功能，可以让应用更加方便地使用 Redis 的不同数据类型<ul>
<li>在 RESP 2 中，客户端和服务器端的通信内容都是以字节数组形式进行编码的，客户端需要根据操作的命令或是据类型自行对传输的数据进行解码，增加了客户端开发复杂度</li>
<li>而 RESP 3 直接支持多种数据类型的区分编码（直接通过不同的开头字符，区分不同的数据类型），包括空值、浮点数、布尔值、有序的字典集合、无序的集合等</li>
</ul>
</li>
</ul>
</li>
</ul>
<h4 id=""><a href="#" class="headerlink" title=""></a></h4><h4 id="期中测试题"><a href="#期中测试题" class="headerlink" title="期中测试题"></a>期中测试题</h4><ul>
<li><p>Redis 在接收多个网络客户端发送的请求操作时，如果有一个客户端和 Redis 的网络连接断开了，Redis 会一直等待该客户端恢复连接吗？为什么？</p>
<ul>
<li>Redis 不会等待客户端恢复连接。</li>
<li>原因是，Redis 的网络连接是由操作系统进行处理的，操作系统内核负责监听网络连接套接字上的连接请求或数据请求，而 Redis 采用了 IO 多路复用机制 epoll，不会阻塞在某一个特定的套接字上。epoll 机制监测到套接字上有请求到达时，就会触发相应的事件，并把事件放到一个队列中，Redis 就会对这个事件队列中的事件进行处理。这样一来，Redis 只用查看和处理事件队列，就可以了。当客户端网络连接断开或恢复时，操作系统会进行处理，并且在客户端能再次发送请求时，把接收到的请求以事件形式通知 Redis。</li>
</ul>
</li>
<li><p>Redis 的主从集群可以提升数据可靠性，主节点在和从节点进行数据同步时，会使用两个缓冲区：复制缓冲区和复制积压缓冲区。这两个缓冲区的作用各是什么？会对 Redis 主从同步产生什么影响吗？</p>
<ul>
<li>复制缓冲区作用：主节点开始和一个从节点进行全量同步时，会为从节点创建一个输出缓冲区，这个缓冲区就是复制缓冲区。当主节点向从节点发送 RDB 文件时，如果又接收到了写命令操作，就会把它们暂存在复制缓冲区中。等 RDB 文件传输完成，并且在从节点加载完成后，主节点再把复制缓冲区中的写命令发给从节点，进行同步。</li>
<li>对主从同步的影响：如果主库传输 RDB 文件以及从库加载 RDB 文件耗时长，同时主库接收的写命令操作较多，就会导致复制缓冲区被写满而溢出。一旦溢出，主库就会关闭和从库的网络连接，重新开始全量同步。所以，我们可以通过调整 client-output-buffer-limitslave 这个配置项，来增加复制缓冲区的大小，以免复制缓冲区溢出。</li>
<li>复制积压缓冲区作用：主节点和从节点进行常规同步时，会把写命令也暂存在复制积压缓冲区中。如果从节点和主节点间发生了网络断连，等从节点再次连接后，可以从复制积压缓冲区中同步尚未复制的命令操作。</li>
<li>对主从同步的影响：如果从节点和主节点间的网络断连时间过长，复制积压缓冲区可能被新写入的命令覆盖。此时，从节点就没有办法和主节点进行增量复制了，而是只能进行全量复制。针对这个问题，应对的方法是调大复制积压缓冲区的大小</li>
</ul>
</li>
<li><p>假设在业务场景中，我们有 20GB 的短视频属性信息（包括短视频 ID、短视频基本信息，例如短视频作者、创建时间等）要持久化保存，并且线上负载以读为主，需要能快速查询到这些短视频信息</p>
<p>首先，你会用 Redis 的什么数据类型来保存数据？如果我们只用单个实例来运行的话，你会采用什么样的持久化方案来保证数据的可靠性？</p>
<p>另外，如果不使用单实例运行，我们有两个备选方案：一个是用两台 32GB 内存的云主机来运行主从两个 Redis 实例；另一个是用 10 台 8GB 的云主机来运行 Redis Cluster，每两台云主机分别运行一个 Redis 实例主库和从库，分别保存 4GB 数据，你会用哪种方案呢</p>
<ul>
<li>Redis 的 Hash 类型属于典型的集合类型，可以保存 key-value 形式的数据。而且，当Hash 类型中保存较多数据时，它的底层是由哈希表实现的。哈希表的存取复杂度是O(1)，所以可以实现快速访问。在这道题中，短视频属性信息属于典型 key-value 形式，所以，我们可以使用 Hash 类型保存短视频信息。具体来说，就是将一个短视频 ID 作为Hash 集合的 key，将短视频的其他属性信息作为 Hash 集合内部的键值对，例如“作者”:“实际姓名”，“创建时间”:“实际时间”。这样既满足了保存数据的需求，也可以利用 Hash 快速查询的特点，快速查到相应的信息。</li>
<li>Redis 的 AOF 日志会记录客户端发送给实例的每一次写操作命令，在 Redis 实例恢复时，可以通过重新运行 AOF 文件中的命令，实现恢复数据的目的。在这道题的业务场景中，负载以读为主，因此，写命令不会太多，AOF 日志文件的体量不会太大，即使实例故障了，也可以快速完成恢复。所以，当使用单实例运行时，我们可以使用 AOF 日志来做持久化方案。</li>
<li>关于使用多实例的运行方案：两种方案各有优势<ul>
<li>方案一优势：可以节省云主机数量和成本。虽然主从节点进行第一次全量同步时，RDB 文件较大，耗时会长些，但是因为写请求少，所以复制缓冲区的压力不大。不足：如果网络环境不好，需要频繁地进行全量同步的话，这种方案的优势就小了，每次全量同步时的 RDB 生成和传输压力都很大。</li>
<li>方案二优势：每个实例只用保存 4GB 数据，和从库同步时的压力较小。而且，这种方案的可扩展性更好，如果有新增数据，可以更好地应对。不足：需要较多的云主机，运维和资源成本较高。</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="MySQL45讲"><a href="#MySQL45讲" class="headerlink" title="MySQL45讲"></a>MySQL45讲</h3><h4 id="01-基础架构：一条SQL查询语句是如何执行的？"><a href="#01-基础架构：一条SQL查询语句是如何执行的？" class="headerlink" title="01 | 基础架构：一条SQL查询语句是如何执行的？"></a>01 | 基础架构：一条SQL查询语句是如何执行的？</h4><ul>
<li>MySQL 可以分为 Server 层和存储引擎层两部分，不同的存储引擎共用一个Server 层，也就是从连接器到执行器的部分<ul>
<li>Server 层包括连接器、查询缓存、分析器、优化器、执行器等，涵盖 MySQL 的大多数核心服务功能，以及所有的内置函数（如日期、时间、数学和加密函数等），所有跨存储引擎的功能都在这一层实现，比如存储过程、触发器、视图等</li>
<li>存储引擎层负责数据的存储和提取。其架构模式是插件式的，支持 InnoDB、MyISAM、Memory 等多个存储引擎</li>
</ul>
</li>
<li><strong>连接器：</strong>负责跟客户端建立连接、获取权限、维持和管理连接；<ul>
<li>一个用户成功建立连接后，即使用管理员账号对这个用户的权限做了修改，也不会影响已经存在连接的权限。修改完成后，只有再新建的连接才会使用新的权限设置</li>
<li>建立连接的过程通常是比较复杂的，所以建议你在使用中要尽量减少建立连接的动作，也就是尽量使用长连接；如果长连接累积下来，可能导致内存占用太大，被系统强行杀掉（OOM），从现象看就是 MySQL 异常重启了，两个解决方法：<ul>
<li>定期断开长连接。使用一段时间，或者程序里面判断执行过一个占用内存的大查询后，断开连接，之后要查询再重连</li>
<li>每次执行一个比较大的操作后，通过执行mysql_reset_connection 来重新初始化连接资源</li>
</ul>
</li>
</ul>
</li>
<li><strong>查询缓存：</strong>MySQL 拿到一个查询请求后，会先到查询缓存看看，之前是不是执行过这条语句。之前执行过的语句及其结果可能会以 key-value 对的形式，被直接缓存在内存中，如果能够直接在这个缓存中找到 key，那么这个value 就会被直接返回给客户端<ul>
<li>查询缓存往往弊大于利：查询缓存的失效非常频繁，只要有对一个表的更新，这个表上所有的查询缓存都会被清空</li>
<li>MySQL 也提供了这种“按需使用”的方式。你可以将参数 query_cache_type 设置成 DEMAND</li>
<li>MySQL 8.0 版本直接将查询缓存的整块功能删掉了，也就是说 8.0 开始彻底没有这个功能</li>
</ul>
</li>
<li><strong>分析器</strong>：对 SQL 语句做解析，<strong>分析器先会做“词法分析”，然后做“语法分析”</strong></li>
<li><strong>优化器：</strong>优化器是在表里面有多个索引的时候，<strong>决定使用哪个索引</strong>；或者在一个语句有多表关联（join）的时候，决定各个表的连接顺序；优化器阶段完成后，这个语句的执行方案就确定下来了，然后进入执行器阶段</li>
<li><strong>执行器：</strong>开始执行的时候，要<strong>先判断一下对这个表 T 有没有执行查询的权限</strong>；在有些场景下，执行器调用一次，在引擎内部则扫描了多行，因此引擎扫描行数跟rows_examined 并不是完全相同的</li>
</ul>
<h4 id="02-日志系统：一条SQL更新语句是如何执行的？"><a href="#02-日志系统：一条SQL更新语句是如何执行的？" class="headerlink" title="02 | 日志系统：一条SQL更新语句是如何执行的？"></a>02 | 日志系统：一条SQL更新语句是如何执行的？</h4><ul>
<li><p>查询语句的那一套流程，更新语句也是同样会走一遍。</p>
<ul>
<li>执行语句前要先连接数据库，这是连接器的工作。</li>
<li>在一个表上有更新的时候，跟这个表有关的查询缓存会失效，所以这条语句就会把表 T 上所有缓存结果都清空。这也就是我们一般不建议使用查询缓存的原因。</li>
<li>接下来，分析器会通过词法和语法解析知道这是一条更新语句。优化器决定要使用 ID 这个索引。然后，执行器负责具体执行，找到这一行，然后更新。</li>
<li>与查询流程不一样的是，更新流程还涉及两个重要的日志模块：redo log（重做日志）和 binlog（归档日志）。</li>
</ul>
</li>
<li><p>重要的日志模块：redo log</p>
<ul>
<li>MySQL 如果每一次的更新操作都需要写进磁盘，然后磁盘也<br>要找到对应的那条记录，然后再更新，整个过程 IO 成本、查找成本都很高。为了解决这个问题，MySQL 的设计者就用了类似酒店掌柜粉板的思路来提升更新效率；而粉板和账本配合的整个过程，其实就是 MySQL 里经常说到的 WAL 技术，WAL 的全称是 Write-Ahead Logging，它的关键点就是先写日志，再写磁盘，也就是先写粉板，等不忙的时候再写账本。</li>
<li>具体来说，当有一条记录需要更新的时候，InnoDB 引擎就会先把记录写到 redo log（粉板）里面，并更新内存，这个时候更新就算完成了。同时，InnoDB 引擎会在适当的时候，将这个操作记录更新到磁盘里面，而这个更新往往是在系统比较空闲的时候做，这就像打烊以后掌柜做的事。</li>
<li>InnoDB 的 redo log 是固定大小的，比如可以配置为一组 4 个文件，每个文件的大小是 1GB，那么这块“粉板”总共就可以记录 4GB 的操作。从头开始写，写到末尾就又回到开头循环写；write pos 是当前记录的位置，一边写一边后移，checkpoint 是当前要擦除的位置，也是往后推移并且循环的，擦除记录前要把记录更新到数据文件。write pos 和 checkpoint 之间的是“粉板”上还空着的部分，可以用来记录新的操作。如果 write pos 追上 checkpoint，表示“粉板”满了，这时候不能再执行新的更新，得停下来先擦掉一些记录，把 checkpoint 推进一下。</li>
<li>redo log 用于保证 crash-safe 能力。innodb_flush_log_at_trx_commit 这个参数设置成1 的时候，表示每次事务的 redo log 都直接持久化到磁盘。这个参数建议设置成 1，这样可以保证 MySQL 异常重启之后数据不丢失。</li>
</ul>
</li>
<li><p>重要的日志模块：binlog</p>
<ul>
<li>粉板 redo log 是 InnoDB 引擎特有的日志，而 Server 层也有自己的日志，称为binlog（归档日志）。</li>
<li>最开始 MySQL 里并没有 InnoDB 引擎。MySQL 自带的引擎是 MyISAM，但是MyISAM 没有 crash-safe 的能力，binlog 日志只能用于归档。而 InnoDB 是另一个公司以插件形式引入 MySQL 的，既然只依靠 binlog 是没有 crash-safe 能力的，所以 InnoDB使用另外一套日志系统——也就是 redo log 来实现 crash-safe 能力</li>
<li>两种日志有以下三点不同：<ol>
<li>redo log 是 InnoDB 引擎特有的；binlog 是 MySQL 的 Server 层实现的，所有引擎都可以使用。</li>
<li>redo log 是物理日志，记录的是“在某个数据页上做了什么修改”；binlog 是逻辑日志，记录的是这个语句的原始逻辑，比如“给 ID&#x3D;2 这一行的 c 字段加 1 ”。</li>
<li>redo log 是循环写的，空间固定会用完；binlog 是可以追加写入的。“追加写”是指binlog 文件写到一定大小后会切换到下一个，并不会覆盖以前的日志</li>
</ol>
</li>
<li>sync_binlog 这个参数设置成 1 的时候，表示每次事务的 binlog 都持久化到磁盘。这个参数也建议你设置成 1，这样可以保证 MySQL 异常重启之后 binlog 不丢失。</li>
</ul>
</li>
<li><p>执行器和 InnoDB 引擎在执行一个简单的update 语句时的内部流程。</p>
<ol>
<li>执行器先找引擎取 ID&#x3D;2 这一行。ID 是主键，引擎直接用树搜索找到这一行。如果ID&#x3D;2 这一行所在的数据页本来就在内存中，就直接返回给执行器；否则，需要先从磁盘读入内存，然后再返回。</li>
<li>执行器拿到引擎给的行数据，把这个值加上 1，比如原来是 N，现在就是 N+1，得到新的一行数据，再调用引擎接口写入这行新数据。</li>
<li>引擎将这行新数据更新到内存中，同时将这个更新操作记录到 redo log 里面，此时redo log 处于 prepare 状态。然后告知执行器执行完成了，随时可以提交事务。</li>
<li>执行器生成这个操作的 binlog，并把 binlog 写入磁盘。</li>
<li>执行器调用引擎的提交事务接口，引擎把刚刚写入的 redo log 改成提交（commit）状态，更新完成。</li>
</ol>
</li>
<li><p><strong>为什么必须有“两阶段提交”呢？这是为了让两份日志之间的逻辑一致</strong></p>
<ul>
<li><p>由于 redo log 和 binlog 是两个独立的逻辑，如果不用两阶段提交，要么就是先写完 redolog 再写 binlog，或者采用反过来的顺序。</p>
</li>
<li><p><strong>先写 redo log 后写 binlog</strong>。假设在 redo log 写完，binlog 还没有写完的时候，MySQL 进程异常重启。由于我们前面说过的，redo log 写完之后，系统即使崩溃，仍然能够把数据恢复回来，所以恢复后这一行 c 的值是 1。但是由于 binlog 没写完就 crash 了，这时候 binlog 里面就没有记录这个语句。因此，之后备份日志的时候，存起来的 binlog 里面就没有这条语句。如果需要用这个 binlog 来恢复临时库的话，由于这个语句的 binlog 丢失，这个临时库就会少了这一次更新，恢复出来的这一行 c 的值就是 0，与原库的值不同。</p>
</li>
<li><p>先写 binlog 后写 redo log。如果在 binlog 写完之后 crash，由于 redo log 还没写，崩溃恢复以后这个事务无效，所以这一行 c 的值是 0。但是 binlog 里面已经记录了“把c 从 0 改成 1”这个日志。所以，在之后用 binlog 来恢复的时候就多了一个事务出来，恢复出来的这一行 c 的值就是 1，与原库的值不同。</p>
</li>
<li><p>如果不使用“两阶段提交”，那么数据库的状态就有可能和用它的日志恢复出来的库的状态不一致。不只是误操作后需要用这个过程来恢复数据。当你需要扩容的时候，也就是需要再多搭建一些备库来增加系统的读能力的时候，现在常见的做法也是用全量备份加上应用binlog 来实现的，这个“不一致”就会导致你的线上出现主从数据库不一致的情况</p>
</li>
</ul>
</li>
</ul>
<h4 id="03-事务隔离：为什么你改了我还看不见？"><a href="#03-事务隔离：为什么你改了我还看不见？" class="headerlink" title="03 | 事务隔离：为什么你改了我还看不见？"></a>03 | 事务隔离：为什么你改了我还看不见？</h4><ul>
<li><p>简单来说，事务就是要保证一组数据库操作，要么全部成功，要么全部失败。在 MySQL中，事务支持是在引擎层实现的。你现在知道，MySQL 是一个支持多引擎的系统，但并不是所有的引擎都支持事务。比如 MySQL 原生的 MyISAM 引擎就不支持事务，这也是MyISAM 被 InnoDB 取代的重要原因之一。提到事务，你肯定会想到 ACID（Atomicity、Consistency、Isolation、Durability，即原子性、一致性、隔离性、持久性）</p>
</li>
<li><p>隔离性与隔离级别</p>
<ul>
<li>当数据库上有多个事务同时执行的时候，就可能出现脏读（dirty read）、不可重复读（non-repeatable read）、幻读（phantom read）的问题，为了解决这些问题，就有了“隔离级别”的概念。</li>
<li>隔离得越严实，效率就会越低。因此很多时候，我们都要在二者之间寻找一个平衡点。SQL 标准的事务隔离级别包括：读未提交（read uncommitted）、读提交（read committed）、可重复读（repeatable read）和串行化（serializable ）<ul>
<li>读未提交是指，一个事务还没提交时，它做的变更就能被别的事务看到。</li>
<li>读提交是指，一个事务提交之后，它做的变更才会被其他事务看到。</li>
<li>可重复读是指，一个事务执行过程中看到的数据，总是跟这个事务在启动时看到的数据是一致的。当然在可重复读隔离级别下，未提交变更对其他事务也是不可见的。</li>
<li>串行化，顾名思义是对于同一行记录，“写”会加“写锁”，“读”会加“读锁”。当出现读写锁冲突的时候，后访问的事务必须等前一个事务执行完成，才能继续执行。</li>
</ul>
</li>
<li>在实现上，数据库里面会创建一个视图，访问的时候以视图的逻辑结果为准。在“可重复读”隔离级别下，这个视图是在事务启动时创建的，整个事务存在期间都用这个视图。在“读提交”隔离级别下，这个视图是在每个 SQL 语句开始执行的时候创建的。这里需要注意的是，“读未提交”隔离级别下直接返回记录上的最新值，没有视图概念；而“串行化”隔离级别下直接用加锁的方式来避免并行访问。在不同的隔离级别下，数据库行为是有所不同的。</li>
</ul>
</li>
<li><p>事务隔离的实现</p>
<ul>
<li>在 MySQL 中，实际上每条记录在更新的时候都会同时记录一条回滚操作。记录上的最新值，通过回滚操作，都可以得到前一个状态的值；同一条记录在系统中可以存在多个版本，就是数据库的多版本并发控制（MVCC）。</li>
<li>系统会判断，当没有事务再需要用到这些回滚日志时，回滚日志会被删除。什么时候才不需要了呢？就是当系统里没有比这个回滚日志更早的 read-view 的时候</li>
<li>长事务意味着系统里面会存在很老的事务视图。由于这些事务随时可能访问数据库里面的任何数据，所以这个事务提交之前，数据库里面它可能用到的回滚记录都必须保留，这就会导致大量占用存储空间。在 MySQL 5.5 及以前的版本，回滚日志是跟数据字典一起放在 ibdata 文件里的，即使长事务最终提交，回滚段被清理，文件也不会变小。我见过数据只有 20GB，而回滚段有200GB 的库。最终只好为了清理回滚段，重建整个库</li>
</ul>
</li>
<li><p>事务的启动方式</p>
<ul>
<li>显式启动事务语句， begin 或 start transaction。配套的提交语句是 commit，回滚语句是 rollback。</li>
<li>set autocommit&#x3D;0，这个命令会将这个线程的自动提交关掉。意味着如果你只执行一个 select 语句，这个事务就启动了，而且并不会自动提交。这个事务持续存在直到你主动执行 commit 或 rollback 语句，或者断开连接。</li>
<li>在 autocommit 为 1 的情况下，用 begin 显式启动的事务，如果执行 commit 则提交事务。如果执行 commit work and chain，则是提交事务并自动启动下一个事务，这样也省去了再次执行 begin 语句的开销。同时带来的好处是从程序开发的角度明确地知道每个语句是否处于事务中。</li>
<li>可以在 information_schema 库的 innodb_trx 这个表中查询长事务</li>
</ul>
</li>
</ul>
<h4 id="04-深入浅出索引（上）"><a href="#04-深入浅出索引（上）" class="headerlink" title="04 | 深入浅出索引（上）"></a>04 | 深入浅出索引（上）</h4><ul>
<li>索引的出现其实就是为了提高数据查询的效率，就像书的目录一样。对于数据库的表而言，索引其实就是它的“目录”。索引的出现是为了提高查询效率，但是实现索引的方式却有很多种</li>
<li>索引的常见模型<ul>
<li>哈希表是一种以键 - 值（key-value）存储数据的结构，我们只要输入待查找的值即 key，就可以找到其对应的值即 Value。哈希的思路很简单，把值放在数组里，用一个哈希函数把key 换算成一个确定的位置，然后把 value 放在数组的这个位置。不可避免地，多个 key 值经过哈希函数的换算，会出现同一个值的情况。处理这种情况的一种方法是，拉出一个链表。哈希表这种结构适用于只有等值查询的场景，比如 Memcached 及其他一些NoSQL 引擎。</li>
<li>有序数组在等值查询和范围查询场景中的性能就都非常优秀。同时很显然，这个索引结构支持范围查询。如果仅仅看查询效率，有序数组就是最好的数据结构了。但是，在需要更新数据的时候就麻烦了，往中间插入一个记录就必须得挪动后面所有的记录，成本太高。有序数组索引只适用于静态存储引擎</li>
<li>二叉搜索树的特点是：每个节点的左儿子小于父节点，父节点又小于右儿子。当然为了维持 O(log(N)) 的查询复杂度，你就需要保持这棵树是平衡二叉树。为了做这个保证，更新的时间复杂度也是 O(log(N))。二叉树是搜索效率最高的，但是实际上大多数的数据库存储却并不使用二叉树。其原因是，索引不止存在内存中，还要写到磁盘上，为了让一个查询尽量少地读磁盘，就必须让查询过程访问尽量少的数据块。那么，我们就不应该使用二叉树，而是要使用“N 叉”树。这里，“N 叉”树中的“N”取决于数据块的大小。N 叉树由于在读写上的性能优点，以及适配磁盘的访问模式，已经被广泛应用在数据库引擎中了。</li>
</ul>
</li>
<li>InnoDB 的索引模型<ul>
<li>在 InnoDB 中，表都是根据主键顺序以索引的形式存放的，这种存储方式的表称为索引组织表。又因为前面我们提到的，InnoDB 使用了 B+ 树索引模型，所以数据都是存储在 B+树中的。</li>
<li>每一个索引在 InnoDB 里面对应一棵 B+ 树。根据叶子节点的内容，索引类型分为主键索引和非主键索引。<ul>
<li>主键索引的叶子节点存的是整行数据。在 InnoDB 里，主键索引也被称为聚簇索引（clustered index）。</li>
<li>非主键索引的叶子节点内容是主键的值。在 InnoDB 里，非主键索引也被称为二级索引（secondary index）。</li>
</ul>
</li>
<li>基于非主键索引的查询需要多扫描一棵索引树。因此，我们在应用中应该尽量使用主键查询。</li>
</ul>
</li>
<li>索引维护<ul>
<li>B+ 树为了维护索引有序性，在插入新值的时候需要做必要的维护。</li>
<li>除了性能外，页分裂操作还影响数据页的利用率。原本放在一个页的数据，现在分到两个页中，整体空间利用率降低大约 50%。当然有分裂就有合并。当相邻两个页由于删除了数据，利用率很低之后，会将数据页做合并。合并的过程，可以认为是分裂过程的逆过程</li>
<li>自增主键是指自增列上定义的主键，在建表语句中一般是这么定义的： NOT NULL PRIMARY KEY AUTO_INCREMENT。自增主键的插入数据模式，每次插入一条新记录，都是追加操作，都不涉及到挪动其他记录，也不会触发叶子节点的分裂</li>
<li>除了考虑性能外，我们还可以从存储空间的角度来看。假设你的表中确实有一个唯一字段，比如字符串类型的身份证号，那应该用身份证号做主键，还是用自增字段做主键呢？主键长度越小，普通索引的叶子节点就越小，普通索引占用的空间也就越小。所以，从性能和存储空间方面考量，自增主键往往是更合理的选择。</li>
</ul>
</li>
</ul>
<h4 id="05-深入浅出索引（下）"><a href="#05-深入浅出索引（下）" class="headerlink" title="05 | 深入浅出索引（下）"></a>05 | 深入浅出索引（下）</h4><ul>
<li>如果查询结果所需要的数据只在主键索引上有，那么不得不回到主键索引树搜索，也即回表；而如果查询的值已经在索引树上了，那么可以直接提供查询结果，不需要回表，称为覆盖索引；由于覆盖索引可以减少树的搜索次数，显著提升查询性能，所以使用覆盖索引是一个常用的性能优化手段。</li>
<li>B+ 树这种索引结构，可以利用索引的“最左前缀”，来定位记录。不只是索引的全部定义，只要满足最左前缀，就可以利用索引来加速检索。这个最左前缀可以是联合索引的最左 N 个字段，也可以是字符串索引的最左 M 个字符。</li>
<li><strong>在建立联合索引的时候，如何安排索引内的字段顺序。</strong>评估标准是，索引的复用能力。因为可以支持最左前缀，所以当已经有了 (a,b)这个联合索引后，一般就不需要单独在 a 上建立索引了。因此，第一原则是，如果通过调整顺序，可以少维护一个索引，那么这个顺序往往就是需要优先考虑采用的。</li>
<li>MySQL 5.6 引入的索引下推优化（index condition pushdown)， 可以在索引遍历过程中，对索引中包含的字段先做判断，直接过滤掉不满足条件的记录，减少回表次数</li>
</ul>
<h4 id="06-全局锁和表锁-：给表加个字段怎么有这么多阻碍？"><a href="#06-全局锁和表锁-：给表加个字段怎么有这么多阻碍？" class="headerlink" title="06 | 全局锁和表锁 ：给表加个字段怎么有这么多阻碍？"></a>06 | 全局锁和表锁 ：给表加个字段怎么有这么多阻碍？</h4><ul>
<li><p>根据加锁的范围，MySQL 里面的锁大致可以分成全局锁、表级锁和行锁三类</p>
</li>
<li><p>全局锁就是对整个数据库实例加锁。MySQL 提供了一个加全局读锁的方法，命令是 Flush tables with read lock (FTWRL)。当需要让整个库处于只读状态的时候，可以使用这个命令，之后其他线程的以下语句会被阻塞：数据更新语句（数据的增删改）、数据定义语句（包括建表、修改表结构等）和更新类事务的提交语句。</p>
<ul>
<li>全局锁的典型使用场景是，做全库逻辑备份。也就是把整库每个表都 select 出来存成文本。但是让整库都只读，听上去就很危险：<ul>
<li>如果你在主库上备份，那么在备份期间都不能执行更新，业务基本上就得停摆；</li>
<li>如果你在从库上备份，那么备份期间从库不能执行主库同步过来的 binlog，会导致主从延迟。</li>
</ul>
</li>
<li>不加锁的话，备份系统备份的得到的库不是一个逻辑时间点，这个视图是逻辑不一致的。官方自带的逻辑备份工具是 mysqldump。当 mysqldump 使用参数–single-transaction<br>的时候，导数据之前就会启动一个事务，来确保拿到一致性视图。而由于 MVCC 的支持，这个过程中数据是可以正常更新的。<ul>
<li>一致性读是好，但前提是引擎要支持这个隔离级别。比如，对于 MyISAM 这种不支持事务的引擎，如果备份过程中有更新，总是只能取到最新的数据，那么就破坏了备份的一致性。这时就需要使用FTWRL 命令了</li>
<li>single-transaction 方法只适用于所有的表使用事务引擎的库。如果有的表使用了不支持事务的引擎，那么备份就只能通过 FTWRL 方法。</li>
</ul>
</li>
<li>既然要全库只读，为什么不使用 set global readonly&#x3D;true 的方式呢<ul>
<li>在有些系统中，readonly 的值会被用来做其他逻辑，比如用来判断一个库是主库还是备库。因此，修改 global 变量的方式影响面更大。</li>
<li>在异常处理机制上有差异。如果执行 FTWRL 命令之后由于客户端发生异常断开，那么 MySQL 会自动释放这个全局锁，整个库回到可以正常更新的状态。而将整个库设置为 readonly 之后，如果客户端发生异常，则数据库就会一直保持 readonly 状态，这样会导致整个库长时间处于不可写状态，风险较高。</li>
</ul>
</li>
</ul>
</li>
<li><p>MySQL 里面表级别的锁有两种：一种是表锁，一种是元数据锁（meta data lock，MDL)。</p>
<ul>
<li>表锁的语法是 lock tables … read&#x2F;write。与 FTWRL 类似，可以用 unlock tables 主动释放锁，也可以在客户端断开的时候自动释放。需要注意，lock tables 语法除了会限制别的线程的读写外，也限定了本线程接下来的操作对象。<ul>
<li>在还没有出现更细粒度的锁的时候，表锁是最常用的处理并发的方式。而对于 InnoDB 这种支持行锁的引擎，一般不使用 lock tables 命令来控制并发，毕竟锁住整个表的影响面还是太大</li>
</ul>
</li>
<li>MDL 不需要显式使用，在访问一个表的时候会被自动加上。MDL 的作用是，保证读写的正确性；当对一个表做增删改查操作的时候，加 MDL读锁；当要对表做结构变更操作的时候，加 MDL 写锁。<ul>
<li>读锁之间不互斥，因此你可以有多个线程同时对一张表增删改查。</li>
<li>读写锁之间、写锁之间是互斥的，用来保证变更表结构操作的安全性。因此，如果有两个线程要同时给一个表加字段，其中一个要等另一个执行完才能开始执行。</li>
</ul>
</li>
<li>给一个表加字段，或者修改字段，或者加索引，需要扫描全表的数据。在对大表操作的时候，肯定会特别小心，以免对线上服务造成影响。而实际上，即使是小表，操作不慎也会出问题。事务中的 MDL 锁，在语句执行开始时申请，但是语句结束后并不会马上释放，而会等到整个事务提交后再释放。如何安全地给小表加字段？<ul>
<li>首先要解决长事务，事务不提交，就会一直占着 MDL 锁。在 MySQL 的information_schema 库的 innodb_trx 表中，可以查到当前执行中的事务。如果要做DDL 变更的表刚好有长事务在执行，要考虑先暂停 DDL，或者 kill 掉这个长事务</li>
<li>如果要变更的表是一个热点表，虽然数据量不大，但是上面的请求很频繁，而不得不加个字段，该怎么做呢？<ul>
<li>比较理想的机制是，在 alter table语句里面设定等待时间，如果在这个指定的等待时间里面能够拿到 MDL 写锁最好，拿不到也不要阻塞后面的业务语句，先放弃。之后开发人员或者 DBA 再通过重试命令重复这个过程。</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<h4 id="07丨行锁功过：怎么减少行锁对性能的影响？"><a href="#07丨行锁功过：怎么减少行锁对性能的影响？" class="headerlink" title="07丨行锁功过：怎么减少行锁对性能的影响？"></a>07丨行锁功过：怎么减少行锁对性能的影响？</h4><ul>
<li>在 InnoDB 事务中，行锁是在需要的时候才加上的，但并不是不需要了就立刻释放，而是要等到事务结束时才释放。这个就是两阶段锁协议<ul>
<li>如果事务中需要锁多个行，要把最可能造成锁冲突、最可能影响并发度的锁尽量往后放，最大程度地减少了事务之间的锁等待，提升并发度</li>
</ul>
</li>
<li>当并发系统中不同线程出现循环资源依赖，涉及的线程都在等待别的线程释放资源时，就会导致这几个线程都进入无限等待的状态，称为死锁；当出现死锁以后，有两种策略：<ul>
<li>一种策略是，直接进入等待，直到超时。这个超时时间可以通过参数innodb_lock_wait_timeout 来设置。</li>
<li>另一种策略是，发起死锁检测，发现死锁后，主动回滚死锁链条中的某一个事务，让其他事务得以继续执行。将参数 innodb_deadlock_detect 设置为 on，表示开启这个逻辑</li>
<li>在 InnoDB 中，innodb_lock_wait_timeout 的默认值是 50s，意味着如果采用第一个策略，当出现死锁以后，第一个被锁住的线程要过 50s 才会超时退出，然后其他线程才有可能继续执行。对于在线服务来说，这个等待时间往往是无法接受的。但是，又不可能直接把这个时间设置成一个很小的值，比如 1s。这样当出现死锁的时候，确实很快就可以解开，但如果不是死锁，而是简单的锁等待呢？所以，正常情况下我们还是要采用第二种策略</li>
<li>主动死锁检测在发生死锁的时候，是能够快速发现并进行处理的，但是它也是有额外负担的；每个新来的被堵住的线程，都要判断会不会由于自己的加入导致了死锁，这是一个时间复杂度是 O(n) 的操作；假设有 1000 个并发线程要同时更新同一行，那么死锁检测操作就是100 万这个量级的。虽然最终检测的结果是没有死锁，但是这期间要消耗大量的 CPU 资源。因此就会看到 CPU 利用率很高，但是每秒却执行不了几个事务</li>
</ul>
</li>
<li>怎么解决由这种热点行更新导致的性能问题呢？<ul>
<li>一种头痛医头的方法，就是如果你能确保这个业务一定不会出现死锁，可以临时把死锁检测关掉。但是这种操作本身带有一定的风险，因为业务设计的时候一般不会把死锁当做一个严重错误，毕竟出现死锁了，就回滚，然后通过业务重试一般就没问题了，这是业务无损的。而关掉死锁检测意味着可能会出现大量的超时，这是业务有损的。</li>
<li>另一个思路是控制并发度。如果并发能够控制住，比如同一行同时最多只有 10 个线程在更新，那么死锁检测的成本很低，就不会出现这个问题。这个并发控制要做在数据库服务端。如果你有中间件，可以考虑在中间件实现；也可以做在 MySQL 里面。基本思路就是，对于相同行的更新，在进入引擎之前排队。这样在 InnoDB 内部就不会有大量的死锁检测工作了。</li>
</ul>
</li>
</ul>
<h4 id="08丨事务到底是隔离的还是不隔离的？"><a href="#08丨事务到底是隔离的还是不隔离的？" class="headerlink" title="08丨事务到底是隔离的还是不隔离的？"></a>08丨事务到底是隔离的还是不隔离的？</h4><ul>
<li><p>在 MySQL 里，有两个“视图”的概念：</p>
<ul>
<li>一个是 view。它是一个用查询语句定义的虚拟表，在调用的时候执行查询语句并生成结果。创建视图的语法是 create view … ，而它的查询方法与表一样。</li>
<li>另一个是 InnoDB 在实现 MVCC 时用到的一致性读视图，即 consistent read view，用于支持 RC（Read Committed，读提交）和 RR（Repeatable Read，可重复读）隔离级别的实现。</li>
</ul>
</li>
<li><p>“快照”在 MVCC 里是怎么工作的？</p>
<ul>
<li>在可重复读隔离级别下，事务在启动的时候就“拍了个快照”。注意，这个快照是基于整库的。</li>
<li>InnoDB 里面每个事务有一个唯一的事务 ID，叫作 transaction id。它是在事务开始的时候向 InnoDB 的事务系统申请的，是按申请顺序严格递增的。而每行数据也都是有多个版本的。每次事务更新数据的时候，都会生成一个新的数据版本，并且把 transaction id 赋值给这个数据版本的事务 ID，记为 row trx_id。同时，旧的数据版本要保留，并且在新的数据版本中，能够有信息可以直接拿到它。也就是说，数据表中的一行记录，其实可能有多个版本 (row)，每个版本有自己的 row trx_id。</li>
<li>按照可重复读的定义，一个事务启动的时候，能够看到所有已经提交的事务结果。但是之后，这个事务执行期间，其他事务的更新对它不可见；因此，一个事务只需要在启动的时候声明说，“以我启动的时刻为准，如果一个数据版本是在我启动之前生成的，就认；如果是我启动以后才生成的，我就不认，我必须要找到它的上一个版本”。当然，如果“上一个版本”也不可见，那就得继续往前找。还有，如果是这个事务自己更新的数据，它自己还是要认的。</li>
<li>在实现上， InnoDB 为每个事务构造了一个数组，用来保存这个事务启动瞬间，当前正在“活跃”的所有事务 ID。“活跃”指的就是，启动了但还没提交；数组里面事务 ID 的最小值记为低水位，当前系统里面已经创建过的事务 ID 的最大值加 1记为高水位。这个视图数组和高水位，就组成了当前事务的一致性视图（read-view）。而数据版本的可见性规则，就是基于数据的 row trx_id 和这个一致性视图的对比结果得到的。</li>
<li>对于当前事务的启动瞬间来说，一个数据版本的 row trx_id，有以下几种可能：<ul>
<li>如果落在低水位之前，表示这个版本是已提交的事务或者是当前事务自己生成的，这个数据是可见的；</li>
<li>如果落在高水位之后，表示这个版本是由将来启动的事务生成的，是肯定不可见的；</li>
<li>如果落在低水位和高水位之间，那就包括两种情况<ul>
<li>若 row trx_id 在数组中，表示这个版本是由还没提交的事务生成的，不可见；</li>
<li>若 row trx_id 不在数组中，表示这个版本是已经提交了的事务生成的，可见。</li>
</ul>
</li>
</ul>
</li>
<li>InnoDB 利用了“所有数据都有多个版本”的这个特性，实现了“秒级创建快照”的能力。</li>
<li>一个数据版本，对于一个事务视图来说，除了自己的更新总是可见以外，有三种情况：<ol>
<li>版本未提交，不可见；</li>
<li>版本已提交，但是是在视图创建后提交的，不可见；</li>
<li>版本已提交，而且是在视图创建前提交的，可见</li>
</ol>
</li>
</ul>
</li>
<li><p>更新数据都是先读后写的，而这个读，只能读当前的值，称为“当前读”（current read）。除了 update 语句外，select 语句如果加锁，也是当前读。</p>
</li>
<li><p>事务的可重复读的能力是怎么实现的？</p>
<ul>
<li>可重复读的核心就是一致性读（consistent read）；而事务更新数据的时候，只能用当前读。如果当前的记录的行锁被其他事务占用的话，就需要进入锁等待。</li>
<li>读提交的逻辑和可重复读的逻辑类似，它们最主要的区别是：<ul>
<li>在可重复读隔离级别下，只需要在事务开始的时候创建一致性视图，之后事务里的其他查询都共用这个一致性视图；</li>
<li>在读提交隔离级别下，每一个语句执行前都会重新算出一个新的视图。</li>
</ul>
</li>
</ul>
</li>
</ul>
<h4 id="09-普通索引和唯一索引，应该怎么选择？"><a href="#09-普通索引和唯一索引，应该怎么选择？" class="headerlink" title="09 | 普通索引和唯一索引，应该怎么选择？"></a>09 | 普通索引和唯一索引，应该怎么选择？</h4><ul>
<li><p>普通索引和唯一索引对查询语句性能的影响</p>
<ul>
<li>假设，执行查询的语句是 select id from T where k&#x3D;5。这个查询语句在索引树上查找的过程，先是通过 B+ 树从树根开始，按层搜索到叶子节点，然后可以认为数据页内部通过二分法来定位记录</li>
<li>对于普通索引来说，查找到满足条件的第一个记录后，需要查找下一个记录，直到碰到第一个不满足 k&#x3D;5 条件的记录。</li>
<li>对于唯一索引来说，由于索引定义了唯一性，查找到第一个满足条件的记录后，就会停止继续检索。</li>
<li>这个不同带来的性能差距微乎其微，InnoDB 的数据是按数据页为单位来读写的。当需要读一条记录的时候，并不是将这个记录本身从磁盘读出来，而是以页为单位，将其整体读入内存。在InnoDB 中，每个数据页的大小默认是 16KB<ul>
<li>因为引擎是按页读写的，所以说，当找到 k&#x3D;5 的记录的时候，它所在的数据页就都在内存里了。那么，对于普通索引来说，要多做的那一次“查找和判断下一条记录”的操作，就只需要一次指针寻找和一次计算。</li>
<li>如果 k&#x3D;5 这个记录刚好是这个数据页的最后一个记录，那么要取下一个记录，必须读取下一个数据页，这个操作会稍微复杂一些。出现这种情况的概率会很低。所以，计算平均性能差异时，仍可以认为这个操作成本对于现在的CPU 来说可以忽略不计。</li>
</ul>
</li>
</ul>
</li>
<li><p>change buffer</p>
<ul>
<li>当需要更新一个数据页时，如果数据页在内存中就直接更新，而如果这个数据页还没有在内存中的话，在不影响数据一致性的前提下，InooDB 会将这些更新操作缓存在 change buffer 中，这样就不需要从磁盘中读入这个数据页了。在下次查询需要访问这个数据页的时候，将数据页读入内存，然后执行 change buffer 中与这个页有关的操作。通过这种方式就能保证这个数据逻辑的正确性。</li>
<li>虽然名字叫作 change buffer，实际上它是可以持久化的数据。也就是说，change buffer 在内存中有拷贝，也会被写入到磁盘上</li>
<li>将 change buffer 中的操作应用到原数据页，得到最新结果的过程称为 merge。除了访问这个数据页会触发 merge 外，系统有后台线程会定期 merge。在数据库正常关闭（shutdown）的过程中，也会执行 merge 操作</li>
<li>如果能够将更新操作先记录在 change buffer，减少读磁盘，语句的执行速度会得到明显的提升。而且，数据读入内存是需要占用 buffer pool 的，所以这种方式还能够避免占用内存，提高内存利用率</li>
<li>什么条件下可以使用 change buffer 呢？<ul>
<li>对于唯一索引来说，所有的更新操作都要先判断这个操作是否违反唯一性约束。比如，要插入 (4,400) 这个记录，就要先判断现在表中是否已经存在 k&#x3D;4 的记录，而这必须要将数据页读入内存才能判断。如果都已经读入到内存了，那直接更新内存会更快，就没必要使用<br>change buffer 了。因此，唯一索引的更新就不能使用 change buffer，实际上也只有普通索引可以使用</li>
</ul>
</li>
<li>change buffer 用的是 buffer pool 里的内存，因此不能无限增大。change buffer 的大小，可以通过参数 innodb_change_buffer_max_size 来动态设置。这个参数设置为 50 的时候，表示 change buffer 的大小最多只能占用 buffer pool 的 50%。</li>
</ul>
</li>
<li><p>普通索引和唯一索引对更新语句性能的影响</p>
<ul>
<li>如果要在这张表中插入一个新记录 (4,400) 的话，InnoDB 的处理流程是怎样的</li>
<li>第一种情况是，这个记录要更新的目标页在内存中。<ul>
<li>对于唯一索引来说，找到 3 和 5 之间的位置，判断到没有冲突，插入这个值，语句执行结束；</li>
<li>对于普通索引来说，找到 3 和 5 之间的位置，插入这个值，语句执行结束</li>
<li>普通索引和唯一索引对更新语句性能影响的差别，只是一个判断，只会耗费微小的 CPU 时间。</li>
</ul>
</li>
<li>第二种情况是，这个记录要更新的目标页不在内存中<ul>
<li>对于唯一索引来说，需要将数据页读入内存，判断到没有冲突，插入这个值，语句执行结束；</li>
<li>对于普通索引来说，则是将更新记录在 change buffer，语句执行就结束了。</li>
<li>将数据从磁盘读入内存涉及随机 IO 的访问，是数据库里面成本最高的操作之一。change buffer 因为减少了随机磁盘访问，所以对更新性能的提升是会很明显的。</li>
</ul>
</li>
</ul>
</li>
<li><p>普通索引的所有场景，使用 change buffer 都可以起到加速作用吗？</p>
<ul>
<li>因为 merge 的时候是真正进行数据更新的时刻，而 change buffer 的主要目的就是将记录的变更动作缓存下来，所以在一个数据页做 merge 之前，change buffer 记录的变更越多（也就是这个页面上要更新的次数越多），收益就越大。</li>
<li>因此，对于写多读少的业务来说，页面在写完以后马上被访问到的概率比较小，此时change buffer 的使用效果最好。这种业务模型常见的就是账单类、日志类的系统</li>
<li>假设一个业务的更新模式是写入之后马上会做查询，那么即使满足了条件，将更新先记录在 change buffer，但之后由于马上要访问这个数据页，会立即触发 merge 过程。这样随机访问 IO 的次数不会减少，反而增加了 change buffer 的维护代价。所以，对于这种业务模式来说，change buffer 反而起到了副作用。</li>
</ul>
</li>
<li><p>索引选择和实践</p>
<ul>
<li>这两类索引在查询能力上是没差别的，主要考虑的是对更新性能的影响。建议尽量选择普通索引</li>
<li>如果所有的更新后面，都马上伴随着对这个记录的查询，那么应该关闭 change buffer。而在其他情况下，change buffer 都能提升更新性能。普通索引和 change buffer 的配合使用，对于数据量大的表的更新优化还是很明显的。</li>
</ul>
</li>
<li><p>change buffer 和 redo log</p>
<ul>
<li>insert into t(id,k) values(id1,k1),(id2,k2);假设当前 k 索引树的状态，查找到位置后，k1 所在的数据页在内存 (InnoDB buffer pool) 中，k2 所在的数据页不在内存中。</li>
<li>这条更新语句涉及了四个部分：内存、redo log（ib_log_fileX）、 数据表空间（t.ibd）、系统表空间（ibdata1）。</li>
<li>这条更新语句做了如下的操作：<ul>
<li>Page 1 在内存中，直接更新内存；</li>
<li>Page 2 没有在内存中，就在内存的 change buffer 区域，记录下“我要往 Page 2 插入一行”这个信息</li>
<li>将上述两个动作记入 redo log 中</li>
</ul>
</li>
<li>执行这条更新语句的成本很低，就是写了两处内存，然后写了一处磁盘（两次操作合在一起写了一次磁盘），而且还是顺序写的。</li>
<li>WAL 之后如果读数据，是不是一定要读盘，是不是一定要从 redo log 里面把数据更新以后才可以返回？其实是不用的。虽然磁盘上还是之前的数据，但是这里直接从内存返回结果，结果是正确的。</li>
<li>要读 Page 2 的时候，需要把 Page 2 从磁盘读入内存中，然后应用 change buffer 里面的操作日志，生成一个正确的版本并返回结果。直到需要读 Page 2 的时候，这个数据页才会被读入内存。</li>
<li>简单地对比这两个机制在提升更新性能上的收益的话，redo log 主要节省的是随机写磁盘的 IO 消耗（转成顺序写），而 change buffer 主要节省的则是随机读磁盘的 IO 消耗。</li>
</ul>
</li>
<li><p>“业务代码已经保证不会写入重复数据”的情况下，讨论性能问题。如果业务不能保证，或者业务就是要求数据库来做约束，那么没得选，必须创建唯一索引。</p>
</li>
</ul>
<h4 id="10丨MySQL为什么有时候会选错索引？"><a href="#10丨MySQL为什么有时候会选错索引？" class="headerlink" title="10丨MySQL为什么有时候会选错索引？"></a>10丨MySQL为什么有时候会选错索引？</h4><ul>
<li><p>优化器的逻辑</p>
<ul>
<li>选择索引是优化器的工作。而优化器选择索引的目的，是找到一个最优的执行方案，并用最小的代价去执行语句。在数据库里面，扫描行数是影响执行代价的因素之一。扫描的行数越少，意味着访问磁盘数据的次数越少，消耗的 CPU 资源越少，扫描行数并不是唯一的判断标准，优化器还会结合是否使用临时表、是否排序等因素进行综合判断。</li>
<li>扫描行数是怎么判断的？MySQL 在真正开始执行语句之前，并不能精确地知道满足这个条件的记录有多少条，而只能根据统计信息来估算记录数。这个统计信息就是索引的“区分度”。显然，一个索引上不同的值越多，这个索引的区分度就越好。而一个索引上不同的值的个数，称之为“基数” （cardinality）。也就是说，这个基数越大，索引的区分度越好。可以使用 show index 方法，看到一个索引的基数。</li>
<li>MySQL 是怎样得到索引的基数的呢？MySQL 使用采样统计，因为把整张表取出来一行行统计，虽然可以得到精确的结果，但是代价太高了，所以只能选择“采样统计”。采样统计的时候，InnoDB 默认会选择 N 个数据页，统计这些页面上的不同值，得到一个平均值，然后乘以这个索引的页面数，就得到了这个索引的基数；而数据表是会持续更新的，索引统计信息也不会固定不变。所以，当变更的数据行数超过1&#x2F;M 的时候，会自动触发重新做一次索引统计。</li>
<li>在 MySQL 中，有两种存储索引统计的方式，可以通过设置参数 innodb_stats_persistent的值来选择：<ul>
<li>设置为 on 的时候，表示统计信息会持久化存储。这时，默认的 N 是 20，M 是 10。</li>
<li>设置为 off 的时候，表示统计信息只存储在内存中。这时，默认的 N 是 8，M 是 16。</li>
</ul>
</li>
<li>索引统计只是一个输入，对于一个具体的语句来说，优化器还要判断，执行这个语句本身要扫描多少行。使用普通索引需要把回表的代价算进去，MySQL 选错索引，这件事儿还得归咎到没能准确地判断出扫描行数。<ul>
<li>既然是统计信息不对，那就修正。analyze table t 命令，可以用来重新统计索引信息</li>
</ul>
</li>
</ul>
</li>
<li><p>原本可以执行得很快的 SQL 语句，执行速度却比预期的慢很多，应该怎么办呢？</p>
<ul>
<li>一种方法是，采用 force index 强行选择一个索引。如果 force index 指定的索引在候选索引列表中，就直接选择这个索引，不再评估其他索引的执行代价。<ul>
<li>使用 force index 最主要的问题还是变更的及时性。因为选错索引的情况还是比较少出现的，所以开发的时候通常不会先写上 force index。而是等到线上出现问题的时候，才会再去修改 SQL 语句、加上 force index。但是修改之后还要测试和发布，对于生产系统来说，这个过程不够敏捷。</li>
</ul>
</li>
<li>第二种方法就是，可以考虑修改语句，引导 MySQL 使用期望的索引。根据数据特征诱导了一下优化器，也不具备通用性</li>
<li>第三种方法是，在有些场景下，可以新建一个更合适的索引，来提供给优化器做选择，或删掉误用的索引</li>
</ul>
</li>
</ul>
<h4 id="11丨怎么给字符串字段加索引？"><a href="#11丨怎么给字符串字段加索引？" class="headerlink" title="11丨怎么给字符串字段加索引？"></a>11丨怎么给字符串字段加索引？</h4><ul>
<li><p>使用前缀索引，定义好长度，就可以做到既节省空间，又不用额外增加太多的查询成本</p>
<ul>
<li>在建立索引时关注的是区分度，区分度越高越好。因为区分度越高，意味着重复的键值越少。因此，可以通过统计索引上有多少个不同的值来判断要使用多长的前缀。</li>
</ul>
</li>
<li><p>前缀索引对覆盖索引的影响</p>
<ul>
<li>虽然 index2 已经包含了所有的信息，但 InnoDB 还是要回到 id 索引再查一下，因为系统并不确定前缀索引的定义是<br>否截断了完整信息</li>
<li>使用前缀索引就用不上覆盖索引对查询性能的优化了</li>
</ul>
</li>
<li><p>遇到前缀的区分度不够好的情况时，我们要怎么办呢？</p>
<ul>
<li><p>第一种方式是使用倒序存储</p>
</li>
<li><p>第二种方式是使用 hash 字段。可以在表上再创建一个整数字段，来保存身份证的校验码，同时在这个字段上创建索引</p>
<ul>
<li>每次插入新记录的时候，都同时用 crc32() 这个函数得到校验码填到这个新字段。由于校验码可能存在冲突，也就是说两个不同的身份证号通过 crc32() 函数得到的结果可能是相同的，所以查询语句 where 部分要判断 id_card 的值是否精确相同。</li>
</ul>
</li>
<li><p>使用倒序存储和使用 hash 字段这两种方法的异同点。</p>
<ul>
<li><p>相同点是，都不支持范围查询。倒序存储的字段上创建的索引是按照倒序字符串的方式排序的，已经没有办法利用索引方式查出身份证号码在 [ID_X, ID_Y] 的所有市民了。同样地，hash 字段的方式也只能支持等值查询。</p>
</li>
<li><p>区别，主要体现在以下三个方面：</p>
<ol>
<li><p>从占用的额外空间来看，倒序存储方式在主键索引上，不会消耗额外的存储空间，而hash 字段方法需要增加一个字段。当然，倒序存储方式使用 4 个字节的前缀长度应该是不够的，如果再长一点，这个消耗跟额外这个 hash 字段也差不多抵消了。</p>
</li>
<li><p>在 CPU 消耗方面，倒序方式每次写和读的时候，都需要额外调用一次 reverse 函数，而hash 字段的方式需要额外调用一次 crc32() 函数。如果只从这两个函数的计算复杂度来看的话，reverse 函数额外消耗的 CPU 资源会更小些。</p>
</li>
<li><p>从查询效率上看，使用 hash 字段方式的查询性能相对更稳定一些。因为 crc32 算出来的值虽然有冲突的概率，但是概率非常小，可以认为每次查询的平均扫描行数接近 1。而倒序存储方式毕竟还是用的前缀索引的方式，也就是说还是会增加扫描行数。</p>
</li>
</ol>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<h4 id="12-为什么我的MySQL会“抖”一下？"><a href="#12-为什么我的MySQL会“抖”一下？" class="headerlink" title="12 | 为什么我的MySQL会“抖”一下？"></a>12 | 为什么我的MySQL会“抖”一下？</h4><ul>
<li><p>你的 SQL 语句为什么变“慢”了</p>
<ul>
<li><p>WAL 机制:InnoDB 在处理更新语句的时候，只做了写日志这一个磁盘操作，这个日志叫作 redo log（重做日志），在更新内存写完 redo log 后，就返回给客户端，本次更新成功。</p>
</li>
<li><p>当内存数据页跟磁盘数据页内容不一致的时候，我们称这个内存页为“脏页”。内存数据写入到磁盘后，内存和磁盘上的数据页的内容就一致了，称为“干净页”。不论是脏页还是干净页，都在内存中</p>
</li>
<li><p>平时执行很快的更新操作，其实就是在写内存和日志，而 MySQL 偶尔“抖”一下的那个瞬间，可能就是在刷脏页（flush）。</p>
</li>
<li><p>什么情况会引发数据库的 flush 过程呢？</p>
<ul>
<li>InnoDB 的 redo log 写满了。这时候系统会停止所有更新操作，把 checkpoint 往前推进（需要将两个点之间的日志对应的所有脏页都 flush到磁盘上），redo log 留出空间可以继续写</li>
<li>系统内存不足。当需要新的内存页，而内存不够用的时候，就要淘汰一些数据页，空出内存给别的数据页使用。如果淘汰的是“脏页”，就要先将脏页写到磁盘。如果刷脏页一定会写盘，就保证了每个数据页有两种状态：<ul>
<li>一种是内存里存在，内存里就肯定是正确的结果，直接返回；</li>
<li>另一种是内存里没有数据，就可以肯定数据文件上是正确的结果，读入内存后返回。这样的效率最高</li>
</ul>
</li>
<li>MySQL 认为系统“空闲”的时候。合理地安排时间，即使是“生意好”的时候，也要见缝插针地找时间，只要有机会就刷一点“脏页”。</li>
<li>MySQL 正常关闭的情况。这时候，MySQL 会把内存的脏页都flush 到磁盘上，这样下次 MySQL 启动的时候，就可以直接从磁盘上读数据，启动速度会很快。</li>
</ul>
</li>
<li><p>第一种是“redo log 写满了，要 flush 脏页”，这种情况是 InnoDB 要尽量避免的。因为出现这种情况的时候，整个系统就不能再接受更新了，所有的更新都必须堵住</p>
</li>
<li><p>第二种是“内存不够用了，要先将脏页写到磁盘”，这种情况其实是常态。InnoDB 用缓冲池（buffer pool）管理内存，缓冲池中的内存页有三种状态：</p>
<ul>
<li>第一种是，还没有使用的；</li>
<li>第二种是，使用了并且是干净页；</li>
<li>第三种是，使用了并且是脏页。</li>
</ul>
<p>而当要读入的数据页没有在内存的时候，就必须到缓冲池中申请一个数据页。这时候只能把最久不使用的数据页从内存中淘汰掉：如果要淘汰的是一个干净页，就直接释放出来复用；但如果是脏页呢，就必须将脏页先刷到磁盘，变成干净页后才能复用</p>
</li>
<li><p>刷脏页虽然是常态，但是出现以下这两种情况，都是会明显影响性能的：</p>
<ul>
<li>一个查询要淘汰的脏页个数太多，会导致查询的响应时间明显变长；</li>
<li>日志写满，更新全部堵住，写性能跌为 0，这种情况对敏感业务来说，是不能接受的。</li>
</ul>
</li>
</ul>
</li>
<li><p>InnoDB 刷脏页的控制策略</p>
<ul>
<li>首先，要正确地告诉 InnoDB 所在主机的 IO 能力，这样 InnoDB 才能知道需要全力刷脏页的时候，可以刷多快。<ul>
<li>这就要用到 innodb_io_capacity 这个参数了，它会告诉 InnoDB 你的磁盘能力。这个值建议你设置成磁盘的 IOPS</li>
</ul>
</li>
<li>InnoDB 的刷盘速度就是要参考这两个因素：一个是脏页比例，一个是 redo log 写盘速度。InnoDB 会根据这两个因素先单独算出两个数字。<ul>
<li>参数 innodb_max_dirty_pages_pct 是脏页比例上限，默认值是 75%。InnoDB 会根据当前的脏页比例（假设为 M），算出一个范围在 0 到 100 之间的数字，F1(M)</li>
<li>InnoDB 每次写入的日志都有一个序号，当前写入的序号跟 checkpoint 对应的序号之间的差值，假设为 N。InnoDB 会根据这个 N 算出一个范围在 0 到 100 之间的数字，这个计算公式可以记为 F2(N)。</li>
<li>根据上述算得的 F1(M) 和 F2(N) 两个值，取其中较大的值记为 R，之后引擎就可以按照 innodb_io_capacity 定义的能力乘以 R% 来控制刷脏页的速度。</li>
</ul>
</li>
</ul>
</li>
<li><p>InnoDB 会在后台刷脏页，而刷脏页的过程是要将内存页写入磁盘。所以，无论是查询语句在需要内存的时候可能要求淘汰一个脏页，还是由于刷脏页的逻辑会占用 IO 资源并可能影响到了更新语句，都可能是造成从业务端感知到MySQL“抖”了一下的原因</p>
<ul>
<li>要尽量避免这种情况，就要合理地设置 innodb_io_capacity 的值，并且平时要多关注脏页比例，不要让它经常接近 75%。</li>
<li>脏页比例是通过Innodb_buffer_pool_pages_dirty&#x2F;Innodb_buffer_pool_pages_total 得到的</li>
<li>一旦一个查询请求需要在执行过程中先 flush 掉一个脏页时，这个查询就可能要比平时慢了。而 MySQL 中的一个机制，可能让你的查询会更慢：在准备刷一个脏页的时候，如果这个数据页旁边的数据页刚好是脏页，就会把这个“邻居”也带着一起刷掉；而且这个把“邻居”拖下水的逻辑还可以继续蔓延，也就是对于每个邻居数据页，如果跟它相邻的数据页也还是脏页的话，也会被放到一起刷。<ul>
<li>在 InnoDB 中，innodb_flush_neighbors 参数就是用来控制这个行为的，值为 1 的时候会有上述的“连坐”机制，值为 0 时表示不找邻居，自己刷自己的。</li>
<li>使用的是 SSD 这类 IOPS 比较高的设备的话，就建议你把innodb_flush_neighbors 的值设置成 0。因为这时候 IOPS 往往不是瓶颈，而“只刷自己”，就能更快地执行完必要的刷脏页操作，减少 SQL 语句响应时间。</li>
</ul>
</li>
</ul>
</li>
<li><p>总结：</p>
<ul>
<li>为什么MySQL会抖一下：这很可能是因为正在进行flush刷脏页的操作，介绍了刷脏页操作的执行时机，控制刷脏页的方法（考虑脏页比例和redolog写入速度）和监控方式，会携带“邻居”刷表</li>
</ul>
</li>
</ul>
<h4 id="13丨为什么表数据删掉一半，表文件大小不变？"><a href="#13丨为什么表数据删掉一半，表文件大小不变？" class="headerlink" title="13丨为什么表数据删掉一半，表文件大小不变？"></a>13丨为什么表数据删掉一半，表文件大小不变？</h4><ul>
<li><p>参数 innodb_file_per_table</p>
<ul>
<li>表数据既可以存在共享表空间里，也可以是单独的文件。这个行为是由参数innodb_file_per_table 控制的<ul>
<li>这个参数设置为 OFF 表示的是，表的数据放在系统共享表空间，也就是跟数据字典放在一起；</li>
<li>这个参数设置为 ON 表示的是，每个 InnoDB 表数据存储在一个以 .ibd 为后缀的文件中。</li>
</ul>
</li>
<li>将 innodb_file_per_table 设置为 ON，是推荐做法；因为，一个表单独存储为一个文件更容易管理，而且在你不需要这个表的时候，通过 drop table 命令，系统就会直接删除这个文件。而如果是放在共享表空间中，即使表删掉了，空间也是不会回收的。</li>
</ul>
</li>
<li><p>数据删除流程</p>
<ul>
<li>InnoDB 的数据是按页存储的，那么如果删掉了一个数据页上的所有记录，会怎么样？<ul>
<li>整个数据页就可以被复用，但是，数据页的复用跟记录的复用是不同的。</li>
<li>记录的复用，只限于符合范围条件的数据。当整个页从 B+ 树里面摘掉以后，可以复用到任何位置。如果相邻的两个数据页利用率都很小，系统就会把这两个页上的数据合到其中一个页上，另外一个数据页就被标记为可复用。</li>
</ul>
</li>
<li>delete 命令其实只是把记录的位置，或者数据页标记为了“可复用”，但磁盘文件的大小是不会变的。也就是说，通过 delete 命令是不能回收表空间的。这些可以复用，而没有被使用的空间，看起来就像是“空洞”。</li>
<li>实际上，不止是删除数据会造成空洞，插入数据也会。如果数据是按照索引递增顺序插入的，那么索引是紧凑的。但如果数据是随机插入的，就可能造成索引的数据页分裂。另外，更新索引上的值，可以理解为删除一个旧的值，再插入一个新值。不难理解，这也是会造成空洞的。</li>
<li>经过大量增删改的表，都是可能是存在空洞的。所以，如果能够把这些空洞去掉，就能达到收缩表空间的目的。</li>
</ul>
</li>
<li><p>重建表</p>
<ul>
<li><p>如果现在有一个表 A，需要做空间收缩，为了把表中存在的空洞去掉；可以新建一个与表 A 结构相同的表 B，然后按照主键 ID 递增的顺序，把数据一行一行地从表 A 里读出来再插入到表 B；由于表 B 是新建的表，所以表 A 主键索引上的空洞，在表 B 中就都不存在了。显然地，表B 的主键索引更紧凑，数据页的利用率也更高。如果我们把表 B 作为临时表，数据从表 A导入表 B 的操作完成后，用表 B 替换 A，从效果上看，就起到了收缩表 A 空间的作用。</p>
</li>
<li><p>可以使用 alter table A engine&#x3D;InnoDB 命令来重建表。区别只是这个临时表 B 不需要自己创建，MySQL 会自动完成转存数据、交换表名、删除旧表的操作。</p>
</li>
<li><p>花时间最多的步骤是往临时表插入数据的过程，如果在这个过程中，有新的数据要写入到表 A 的话，就会造成数据丢失。因此，在整个 DDL 过程中，表 A 中不能有更新。也就是说，这个 DDL 不是 Online 的。MySQL 5.6 版本开始引入的 Online DDL，对这个操作流程做了优化</p>
</li>
<li><p>引入了 Online DDL 之后，重建表的流程：</p>
<ul>
<li>建立一个临时文件，扫描表 A 主键的所有数据页；</li>
<li>用数据页中表 A 的记录生成 B+ 树，存储到临时文件中；</li>
<li>生成临时文件的过程中，将所有对 A 的操作记录在一个日志文件（row log）中</li>
<li>临时文件生成后，将日志文件中的操作应用到临时文件，得到一个逻辑数据上与表 A 相同的数据文件</li>
<li>用临时文件替换表 A 的数据文件。</li>
</ul>
<p>由于日志文件记录和重放操作这个功能的存在，这个方案在重建表的过程中，允许对表 A 做增删改操作。</p>
</li>
<li><p>对于一个大表来说，Online DDL 最耗时的过程就是拷贝数据到临时表的过程，这个步骤的执行期间可以接受增删改操作。所以，相对于整个 DDL 过程来说，锁的时间非常短。对业务来说，就可以认为是 Online 的</p>
</li>
<li><p>需要补充说明的是，上述的这些重建方法都会扫描原表数据和构建临时文件。对于很大的表来说，这个操作是很消耗 IO 和 CPU 资源的。因此，如果是线上服务，要很小心地控制操作时间。</p>
</li>
</ul>
</li>
<li><p>Online 和 inplace</p>
<ul>
<li>整个 DDL 过程都在 InnoDB 内部完成。对于 server 层来说，没有把数据挪动到临时表，是一个“原地”操作，这就是“inplace”名称的来源。</li>
<li>DDL 过程如果是 Online 的，就一定是 inplace 的；</li>
<li>反过来未必，也就是说 inplace 的 DDL，有可能不是 Online 的。截止到 MySQL 8.0，添加全文索引（FULLTEXT index）和空间索引 (SPATIAL index) 就属于这种情况。</li>
</ul>
</li>
<li><p>optimize table、analyze table 和 alter table 这三种方式重建表的区别</p>
<ul>
<li>从 MySQL 5.6 版本开始，alter table t engine &#x3D; InnoDB（也就是 recreate）默认的就是上面的流程了；</li>
<li>analyze table t 其实不是重建表，只是对表的索引信息做重新统计，没有修改数据，这个过程中加了 MDL 读锁；</li>
<li>optimize table t 等于 recreate+analyze。</li>
</ul>
</li>
<li><p>总结</p>
<ul>
<li>delete表后表空间并不会缩小，而是变成一个“可复用”的状态，需要使用alter table进行重建表才可以实现“空洞填充”，为了支持online DDL，需要在进行重建表的过程中记录row log，这个操作是由innodb实现的，然后再对重建后的表进行增加增删改操作；注意online DDL其实是很耗费IO和CPU资源的</li>
</ul>
</li>
</ul>
<h4 id="14丨count这么慢，我该怎么办？"><a href="#14丨count这么慢，我该怎么办？" class="headerlink" title="14丨count这么慢，我该怎么办？"></a>14丨count这么慢，我该怎么办？</h4><ul>
<li><p>count(*) 的实现方式</p>
<ul>
<li>在不同的 MySQL 引擎中，count(*) 有不同的实现方式<ul>
<li>MyISAM 引擎把一个表的总行数存在了磁盘上，因此执行 count(*) 的时候会直接返回这个数，效率很高；</li>
<li>InnoDB 引擎就麻烦了，它执行 count(*)的时候，需要把数据一行一行地从引擎里面读出来，然后累积计数。</li>
<li>讨论的是没有过滤条件的 count(*)，如果加了where 条件的话，MyISAM 表也是不能返回得这么快的。</li>
</ul>
</li>
<li>为什么 InnoDB 不跟 MyISAM 一样，也把数字存起来呢？<ul>
<li>即使是在同一个时刻的多个查询，由于多版本并发控制（MVCC）的原因，InnoDB 表“应该返回多少行”也是不确定的。</li>
<li>这和 InnoDB 的事务设计有关系，可重复读是它默认的隔离级别，在代码上就是通过多版本并发控制，也就是 MVCC 来实现的。每一行记录都要判断自己是否对这个会话可见，因此对于 count(*) 请求来说，InnoDB 只好把数据一行一行地读出依次判断，可见的行才能够用于计算“基于这个查询”的表的总行数。</li>
<li>InnoDB 是索引组织表，主键索引树的叶子节点是数据，而普通索引树的叶子节点是主键值。所以，普通索引树比主键索引树小很多。对于 count(*) 这样的操作，遍历哪个索引树得到的结果逻辑上都是一样的。因此，MySQL 优化器会找到最小的那棵树来遍历。在保证逻辑正确的前提下，尽量减少扫描的数据量，是数据库系统设计的通用法则之一。</li>
</ul>
</li>
<li>show table status 命令的话，就会发现这个命令的输出结果里面也有一个TABLE_ROWS 用于显示这个表当前有多少行，这个命令执行挺快的，那这个TABLE_ROWS 能代替 count(*) 吗？<ul>
<li>TABLE_ROWS 就是从这个采样估算得来的，因此它也很不准。官方文档说误差可能达到 40% 到 50%。所以，show table status 命令显示的行数也不能直接使用。</li>
</ul>
</li>
</ul>
</li>
<li><p>用缓存系统保存计数</p>
<ul>
<li>对于更新很频繁的库来说，可能会第一时间想到，用缓存系统来支持。可以用一个 Redis 服务来保存这个表的总行数。这个表每被插入一行 Redis 计数就加1，每被删除一行 Redis 计数就减 1。</li>
<li>缓存系统可能会丢失更新。Redis 的数据不能永久地留在内存里，所以会找一个地方把这个值定期地持久化存储起来。但即使这样，仍然可能丢失更新。试想如果刚刚在数据表中插入了一行，Redis 中保存的值也加了 1，然后 Redis 异常重启了，重启后你要从存储 redis 数据的地方把这个值读回来，而刚刚加 1 的这个计数操作却丢失了。</li>
<li>Redis 异常重启以后，到数据库里面单独执行一次count(*) 获取真实的行数，再把这个值写回到 Redis 里就可以了。异常重启毕竟不是经常出现的情况，这一次全表扫描的成本，还是可以接受的。但实际上，将计数保存在缓存系统中的方式，还不只是丢失更新的问题。即使 Redis 正常工作，这个值还是逻辑上不精确的。在并发系统里面，是无法精确控制不同线程的执行时刻的</li>
</ul>
</li>
<li><p>在数据库保存计数</p>
<ul>
<li>用缓存系统保存计数有丢失数据和计数不精确的问题。那么，如果把这个计数直接放到数据库里单独的一张计数表 C 中，又会怎么样呢？</li>
<li>这解决了崩溃丢失的问题，InnoDB 是支持崩溃恢复不丢数据的。</li>
<li>由于 InnoDB 要支持事务，从而导致 InnoDB 表不能把count(*) 直接存起来，然后查询的时候直接返回形成的。可以就利用“事务”这个特性，解决计数不精确的问题。</li>
</ul>
</li>
<li><p>不同的 count 用法</p>
<ul>
<li>在 select count(?) from t 这样的查询语句里面，count(*)、count(主键 id)、count(字段) 和 count(1) 等不同用法的性能，有哪些差别</li>
<li>count() 的语义。count() 是一个聚合函数，对于返回的结果集，一行行地判断，如果 count 函数的参数不是 NULL，累计值就加 1，否则不加。最后返回累计值。</li>
<li>count(*)、count(主键 id) 和 count(1) 都表示返回满足条件的结果集的总行数；而count(字段），则表示返回满足条件的数据行里面，参数“字段”不为 NULL 的总个数</li>
<li>对于 count(主键 id) 来说，InnoDB 引擎会遍历整张表，把每一行的 id 值都取出来，返回给 server 层。server 层拿到 id 后，判断是不可能为空的，就按行累加。</li>
<li>对于 count(1) 来说，InnoDB 引擎遍历整张表，但不取值。server 层对于返回的每一行，放一个数字“1”进去，判断是不可能为空的，按行累加。</li>
<li>对于 count(字段) 来说：<ul>
<li>如果这个“字段”是定义为 not null 的话，一行行地从记录里面读出这个字段，判断不能为 null，按行累加；</li>
<li>如果这个“字段”定义允许为 null，那么执行的时候，判断到有可能是 null，还要把值取出来再判断一下，不是 null 才累加。</li>
</ul>
</li>
<li>但是 count(*) 是例外，并不会把全部字段取出来，而是专门做了优化，不取值。count(*)肯定不是 null，按行累加。</li>
<li>按照效率排序的话，count(字段)&lt;count(主键 id)&lt;count(1)≈count(*)，建议，尽量使用 count(*)。</li>
</ul>
</li>
<li><p>总结：MySQL获得行数的几种方法，对于innodb引擎，count(*) 约等于 count(1) &gt; count(主键id) &gt; count(字段)；使用redis辅助计数无法保证和MySQL表中的计数统一，这是因为不支持分布式事务，无法拿到精确一致的视图，额外使用一个计数表进行计数可保证</p>
</li>
</ul>
<h4 id="15丨答疑文章（一）：日志和索引相关问题"><a href="#15丨答疑文章（一）：日志和索引相关问题" class="headerlink" title="15丨答疑文章（一）：日志和索引相关问题"></a>15丨答疑文章（一）：日志和索引相关问题</h4><ul>
<li><p>在两阶段提交的不同瞬间，MySQL 如果发生异常重启，是怎么保证数据完整性的？</p>
<ul>
<li><p>两个“commit”的概念</p>
<ul>
<li>“commit 语句”，是指 MySQL 语法中，用于提交一个事务的命令。一般跟begin&#x2F;start transaction 配对使用。</li>
<li>“commit 步骤”，指的是事务提交过程中的一个小步骤，也是最后一步。当这个步骤执行完成后，这个事务就提交完成了。</li>
<li>“commit 语句”执行的时候，会包含“commit 步骤”。</li>
</ul>
</li>
<li><p>如果在写入 redo log 处于 prepare 阶段之后、写 binlog 之前，发生了崩溃（crash），由于此时 binlog 还没写，redo log 也还没提交，所以崩溃恢复的时候，这个事务会回滚。这时候，binlog 还没写，所以也不会传到备库</p>
</li>
<li><p>binlog 写完，redo log 还没 commit前发生 crash，那崩溃恢复的时候 MySQL 会怎么处理？</p>
<ul>
<li>如果 redo log 里面的事务是完整的，也就是已经有了 commit 标识，则直接提交；</li>
<li>如果 redo log 里面的事务只有完整的 prepare，则判断对应的事务 binlog 是否存在并完整：<br>a. 如果是，则提交事务；<br>b. 否则，回滚事务。</li>
</ul>
</li>
<li><p>追问1：MySQL 怎么知道 binlog 是完整的?</p>
<ul>
<li>一个事务的 binlog 是有完整格式的：</li>
<li>statement 格式的 binlog，最后会有 COMMIT；</li>
<li>row 格式的 binlog，最后会有一个 XID event。</li>
<li>在 MySQL 5.6.2 版本以后，还引入了 binlog-checksum 参数，用来验证 binlog内容的正确性。对于 binlog 日志由于磁盘原因，可能会在日志中间出错的情况，MySQL可以通过校验 checksum 的结果来发现。所以，MySQL 还是有办法验证事务 binlog 的完整性的</li>
</ul>
</li>
<li><p>追问 2：redo log 和 binlog 是怎么关联起来的?</p>
<ul>
<li>它们有一个共同的数据字段，叫 XID。崩溃恢复的时候，会按顺序扫描 redo log：</li>
<li>如果碰到既有 prepare、又有 commit 的 redo log，就直接提交；</li>
<li>如果碰到只有 parepare、而没有 commit 的 redo log，就拿着 XID 去 binlog 找对应的事务</li>
</ul>
</li>
<li><p>追问 3：处于 prepare 阶段的 redo log 加上完整 binlog，重启就能恢复，MySQL 为什么要这么设计?</p>
<ul>
<li>binlog 写完以后 MySQL 发生崩溃，这时候 binlog 已经写入了，之后就会被从库（或者用这个 binlog 恢复出来的库）使用。所以，在主库上也要提交这个事务。采用这个策略，主库和备库的数据就保证了一致性</li>
</ul>
</li>
<li><p>追问 4：如果这样的话，为什么还要两阶段提交呢？干脆先 redo log 写完，再写 binlog。崩溃恢复的时候，必须得两个日志都完整才可以。是不是一样的逻辑？</p>
<ul>
<li>其实，两阶段提交是经典的分布式系统问题，并不是 MySQL 独有的。</li>
<li>如果必须要举一个场景，来说明这么做的必要性的话，那就是事务的持久性问题。对于 InnoDB 引擎来说，如果 redo log 提交完成了，事务就不能回滚（如果这还允许回滚，就可能覆盖掉别的事务的更新）。而如果 redo log 直接提交，然后 binlog 写入的时候失败，InnoDB 又回滚不了，数据和 binlog 日志又不一致了。</li>
<li>两阶段提交就是为了给所有人一个机会，当每个人都说“我 ok”的时候，再一起提交。</li>
</ul>
</li>
<li><p>追问 5：不引入两个日志，也就没有两阶段提交的必要了。只用 binlog 来支持崩溃恢复，又能支持归档，不就可以了？</p>
<ul>
<li>如果说历史原因的话，那就是 InnoDB 并不是 MySQL 的原生存储引擎。MySQL 的原生引擎是 MyISAM，设计之初就有没有支持崩溃恢复。InnoDB 在作为 MySQL 的插件加入 MySQL 引擎家族之前，就已经是一个提供了崩溃恢复和事务支持的引擎了。InnoDB 接入了 MySQL 后，发现既然 binlog 没有崩溃恢复的能力，那就用 InnoDB 原有的 redo log 好了。</li>
<li>如果说实现上的原因的话，就有很多了。就按照问题中说的，只用 binlog 来实现崩溃恢复的流程，这样的流程下，binlog 还是不能支持崩溃恢复的。说一个不支持的点吧：binlog 没有能力恢复“数据页”。InnoDB 引擎使用的是 WAL 技术，执行事务的时候，写完内存和日志，事务就算完成了。如果之后崩溃，要依赖于日志来恢复数据页。</li>
</ul>
</li>
<li><p>追问 6：那能不能反过来，只用 redo log，不要 binlog？</p>
<ul>
<li>如果只从崩溃恢复的角度来讲是可以的。你可以把 binlog 关掉，这样就没有两阶段提交了，但系统依然是 crash-safe 的。</li>
<li>binlog 有着 redo log 无法替代的功能。</li>
<li>一个是归档。redo log 是循环写，写到末尾是要回到开头继续写的。这样历史日志没法保留，redo log 也就起不到归档的作用。</li>
<li>一个就是 MySQL 系统依赖于 binlog。binlog 作为 MySQL 一开始就有的功能，被用在了很多地方。其中，MySQL 系统高可用的基础，就是 binlog 复制。</li>
<li>还有很多公司有异构系统（比如一些数据分析系统），这些系统就靠消费 MySQL 的binlog 来更新自己的数据。关掉 binlog 的话，这些下游系统就没法输入了。</li>
<li>总之，由于现在包括 MySQL 高可用在内的很多系统机制都依赖于 binlog，所以“鸠占鹊巢”redo log 还做不到</li>
</ul>
</li>
<li><p>追问 7：redo log 一般设置多大？</p>
<ul>
<li>redo log 太小的话，会导致很快就被写满，然后不得不强行刷 redo log，这样WAL 机制的能力就发挥不出来了。所以，如果是现在常见的几个 TB 的磁盘的话，就不要太小气了，直接将 redo log 设置为4 个文件、每个文件 1GB 吧。</li>
</ul>
</li>
<li><p>追问 8：正常运行中的实例，数据写入后的最终落盘，是从 redo log 更新过来的还是从 buffer pool 更新过来的呢？</p>
<ul>
<li>实际上，redo log 并没有记录数据页的完整数据，所以它并没有能力自己去更新磁盘数据页，也就不存在“数据最终落盘，是由 redo log 更新过去”的情况</li>
<li>如果是正常运行的实例的话，数据页被修改以后，跟磁盘的数据页不一致，称为脏页。最终数据落盘，就是把内存中的数据页写盘。这个过程，甚至与 redo log 毫无关系。</li>
<li>在崩溃恢复场景中，InnoDB 如果判断到一个数据页可能在崩溃恢复的时候丢失了更新，就会将它读到内存，然后让 redo log 更新内存内容。更新完成后，内存页变成脏页，就回到了第一种情况的状态。</li>
</ul>
</li>
<li><p>追问 9：redo log buffer 是什么？是先修改内存，还是先写 redo log文件？</p>
<ul>
<li>在一个事务的更新过程中，日志是要写多次的。假如一个事务要往两个表中插入记录，插入数据的过程中，生成的日志都得先保存起来，但又不能在还没 commit 的时候就直接写到 redo log 文件里。</li>
<li>redo log buffer 就是一块内存，用来先存 redo 日志的。也就是说，在执行第一个insert 的时候，数据的内存被修改了，redo log buffer 也写入了日志。</li>
<li>但是，真正把日志写到 redo log 文件（文件名是 ib_logfile+ 数字），是在执行 commit语句的时候做的。</li>
<li>单独执行一个更新语句的时候，InnoDB 会自己启动一个事务，在语句执行完成的时候提交。过程跟上面是一样的，只不过是“压缩”到了一个语句里面完成。</li>
</ul>
</li>
</ul>
</li>
<li><p>总结：答疑文章，一个事务的binlog是有完整格式的，redolog和binlog通过一个共同的数据字段XID关联起来，处于prepare阶段的redolog + 完整的binlog可以实现重启恢复；两阶段提交是为了给两个log都一个机会，保证数据一致性；redolog并没有记录数据页的完整数据，所以没有自己去更新数据页，最终数据的落盘是讲脏页刷盘，<strong>redolog是用于操作内存内容将其变成脏页</strong></p>
</li>
</ul>
<h4 id="16丨“orderby”是怎么工作的？"><a href="#16丨“orderby”是怎么工作的？" class="headerlink" title="16丨“orderby”是怎么工作的？"></a>16丨“orderby”是怎么工作的？</h4><p>以 select city,name,age from t where city&#x3D;’杭州’ order by name limit 1000 ; 为例子进行分析</p>
<ul>
<li><p>全字段排序</p>
<ul>
<li><p>explain 命令Extra 这个字段中的“Using filesort”表示的就是需要排序，MySQL 会给每个线程分配一块内存用于排序，称为 sort_buffer。</p>
</li>
<li><p>通常情况下，这个语句执行流程如下 ：</p>
<ol>
<li><p>初始化 sort_buffer，确定放入 name、city、age 这三个字段；</p>
</li>
<li><p>从索引 city 找到第一个满足 city&#x3D;’杭州’条件的主键 id</p>
</li>
<li><p>到主键 id 索引取出整行，取 name、city、age 三个字段的值，存入 sort_buffer 中；</p>
</li>
<li><p>从索引 city 取下一个记录的主键 id；</p>
</li>
<li><p>重复步骤 3、4 直到 city 的值不满足查询条件为止；</p>
</li>
<li><p>对 sort_buffer 中的数据按照字段 name 做快速排序；</p>
</li>
<li><p>按照排序结果取前 1000 行返回给客户端</p>
</li>
</ol>
<p>暂且把这个排序过程，称为全字段排序</p>
</li>
<li><p>“按 name 排序”这个动作，可能在内存中完成，也可能需要使用外部排序，这取决于排序所需的内存和参数 sort_buffer_size。</p>
<ul>
<li>sort_buffer_size，就是 MySQL 为排序开辟的内存（sort_buffer）的大小。如果要排序的数据量小于 sort_buffer_size，排序就在内存中完成。但如果排序数据量太大，内存放不下，则不得不利用磁盘临时文件辅助排序。</li>
<li>通过查看 OPTIMIZER_TRACE 的结果来确认的，可以从number_of_tmp_files 中看到是否使用了临时文件，其表示的是，排序过程中使用的临时文件数</li>
<li>内存放不下时，就需要使用外部排序，外部排序一般使用归并排序算法。可以这么简单理解，MySQL 将需要排序的数据分成若干份，每一份单独排序后存在这些临时文件中。然后把这若干个有序文件再合并成一个有序的大文件</li>
<li>如果 sort_buffer_size 超过了需要排序的数据量的大小，number_of_tmp_files 就是 0，表示排序可以直接在内存中完成。否则就需要放在临时文件中排序。sort_buffer_size 越小，需要分成的份数越多，number_of_tmp_files 的值就越大。</li>
</ul>
</li>
</ul>
</li>
<li><p>rowid 排序</p>
<ul>
<li><p>在上面这个算法过程里面，只对原表的数据读了一遍，剩下的操作都是在 sort_buffer 和临时文件中执行的。但这个算法有一个问题，就是如果查询要返回的字段很多的话，那么sort_buffer 里面要放的字段数太多，这样内存里能够同时放下的行数很少，要分成很多个临时文件，排序的性能会很差，如果单行很大，这个方法效率不够好。</p>
</li>
<li><p>来修改一个参数，让 MySQL 采用另外一种算法。max_length_for_sort_data，是 MySQL 中专门控制用于排序的行数据的长度的一个参数。它的意思是，如果单行的长度超过这个值，MySQL 就认为单行太大，要换一个算法。</p>
</li>
<li><p>新的算法放入 sort_buffer 的字段，只有要排序的列（即 name 字段）和主键 id。但这时，排序的结果就因为少了 city 和 age 字段的值，不能直接返回了，整个执行流程就<br>变成如下所示的样子：</p>
<ol>
<li>初始化 sort_buffer，确定放入两个字段，即 name 和 id；</li>
<li>从索引 city 找到第一个满足 city&#x3D;’杭州’条件的主键 id</li>
<li>到主键 id 索引取出整行，取 name、id 这两个字段，存入 sort_buffer 中；</li>
<li>从索引 city 取下一个记录的主键 id；</li>
<li>重复步骤 3、4 直到不满足 city&#x3D;’杭州’条件为止</li>
<li>对 sort_buffer 中的数据按照字段 name 进行排序；</li>
<li>遍历排序结果，取前 1000 行，并按照 id 的值回到原表中取出 city、name 和 age 三个字段返回给客户端。</li>
</ol>
<p>称为 rowid 排序。rowid 排序多访问了一次表 t 的主键索引，就是步骤 7</p>
</li>
<li><p>从 OPTIMIZER_TRACE 的结果中，能看到另外两个信息变了</p>
<ul>
<li>sort_mode 变成了 &lt;sort_key, rowid&gt;，表示参与排序的只有 name 和 id 这两个字段。</li>
<li>number_of_tmp_files 变成 10 了，是因为这时候参与排序的行数虽然仍然是 4000 行，但是每一行都变小了，因此需要排序的总数据量就变小了，需要的临时文件也相应地变少了。</li>
</ul>
</li>
</ul>
</li>
<li><p>全字段排序 VS rowid 排序</p>
<ul>
<li>如果 MySQL 实在是担心排序内存太小，会影响排序效率，才会采用 rowid 排序算法，这样排序过程中一次可以排序更多行，但是需要再回到原表去取数据。</li>
<li>如果 MySQL 认为内存足够大，会优先选择全字段排序，把需要的字段都放到 sort_buffer中，这样排序后就会直接从内存里面返回查询结果了，不用再回到原表去取数据。</li>
<li>体现了 MySQL 的一个设计思想：如果内存够，就要多利用内存，尽量减少磁盘访问。对于 InnoDB 表来说，rowid 排序会要求回表多造成磁盘读，因此不会被优先选择。</li>
<li>MySQL 做排序是一个成本比较高的操作；是不是所有的 order by 都需要排序操作呢？如果不排序就能得到正确的结果，那对系统的消耗会小很多，语句的执行时间也会变得更短。<ul>
<li>MySQL 之所以需要生成临时表，并且在临时表上做排序操作，其原因是原来的数据都是无序的。如果能够保证从 city 这个索引上取出来的行，天然就是按照 name 递增排序的话，是不是就可以不用再排序了呢？</li>
<li>可以在这个市民表上创建一个 city 和 name 的联合索引</li>
</ul>
</li>
<li>这样整个查询过程的流程就变成了：<ol>
<li>从索引 (city,name) 找到第一个满足 city&#x3D;’杭州’条件的主键 id；</li>
<li>到主键 id 索引取出整行，取 name、city、age 三个字段的值，作为结果集的一部分直接返回；</li>
<li>从索引 (city,name) 取下一个记录主键 id；</li>
<li>重复步骤 2、3，直到查到第 1000 条记录，或者是不满足 city&#x3D;’杭州’条件时循环结束</li>
</ol>
</li>
<li>覆盖索引是指，索引上的信息足够满足查询请求，不需要再<br>回到主键索引上去取数据。按照覆盖索引的概念，可以再优化一下这个查询语句的执行流程。可以创建一个 city、name 和 age 的联合索引；对于 city 字段的值相同的行来说，还是按照 name 字段的值递增排序的，此时的查询语句也就不再需要排序了。这样整个查询语句的执行流程就变成了：<ol>
<li>从索引 (city,name,age) 找到第一个满足 city&#x3D;’杭州’条件的记录，取出其中的 city、name 和 age 这三个字段的值，作为结果集的一部分直接返回；</li>
<li>从索引 (city,name,age) 取下一个记录，同样取出这三个字段的值，作为结果集的一部分直接返回；</li>
<li>重复执行步骤 2，直到查到第 1000 条记录，或者是不满足 city&#x3D;’杭州’条件时循环结束。</li>
</ol>
</li>
</ul>
</li>
<li><p>总结：order by的执行算法流程，需要排序的字段会通过sort_buffer进行排序，分为全字段排序和rowid排序；</p>
<ul>
<li>全字段排序主要分为7个步骤：1.初始化sort_buffer；2.通过索引查找第一个满足要求的主键id；3.通过主键id取出整行，取出需要的字段放入sort_buffer；4.从索引中取出下一个id；5.重复上述34步骤知道不满足查询条件；6.对sort_buffer中的字段按照排序字段进行快速排序（可能sort_buffer不够大，则需要临时文件进行归并排序，取决于sort_buffer_size和排序所需内存）；7.按照要求返回结果</li>
<li>rowid排序是为了解决全字段排序对于单行字段很大使得内存能存放下的字段很少导致排序性能降低的问题；其只将要排序的字段和主键id放如排序字段，然后增加了一步回表操作</li>
<li>如果内存足够大会优先选择全字段排序，尽量减少磁盘访问；也可以给需要排序的字段增加索引（这样原本就是有序的了，其中还可以利用覆盖索引），但是需要维护索引，权衡利弊</li>
</ul>
</li>
</ul>
<h4 id="17丨如何正确地显示随机消息？"><a href="#17丨如何正确地显示随机消息？" class="headerlink" title="17丨如何正确地显示随机消息？"></a>17丨如何正确地显示随机消息？</h4><p>问题背景：有一个随机显示单词的功能，也就是根据每个用户的级别有一个单词表，然后这个用户每次访问首页的时候，都会随机滚动显示三个单词。他们发现随着单词表变大，选单词这个逻辑变得越来越慢，甚至影响到了首页的打开速度。</p>
<ul>
<li><p>内存临时表</p>
<ul>
<li>用 order by rand() 来实现这个逻辑。<code>select word from words order by rand() limit 3;</code></li>
<li>随机排序取前 3 个。虽然这个 SQL 语句写法很简单，但执行流程却有点复杂的。</li>
<li>explain 命令Extra 字段显示 Using temporary，表示的是需要使用临时表；Using filesort，表示的是需要执行排序操作。因此这个 Extra 的意思就是，需要临时表，并且需要在临时表上排序</li>
<li>对于内存表，回表过程只是简单地根据数据行的位置，直接访问内存得到数据，根本不会导致多访问磁盘。优化器没有了这一层顾虑，那么它会优先考虑的，就是用于排序的行越小越好了，所以，MySQL 这时就会选择 rowid 排序。</li>
<li>这条语句的执行流程是这样的：<ol>
<li>创建一个临时表。这个临时表使用的是 memory 引擎，表里有两个字段，第一个字段是double 类型，为了后面描述方便，记为字段 R，第二个字段是 varchar(64) 类型，记为字段 W。并且，这个表没有建索引。</li>
<li>从 words 表中，按主键顺序取出所有的 word 值。对于每一个 word 值，调用 rand()函数生成一个大于 0 小于 1 的随机小数，并把这个随机小数和 word 分别存入临时表的R 和 W 字段中，到此，扫描行数是 10000。</li>
<li>现在临时表有 10000 行数据了，接下来要在这个没有索引的内存临时表上，按照字段R 排序。</li>
<li>初始化 sort_buffer。sort_buffer 中有两个字段，一个是 double 类型，另一个是整型。</li>
<li>从内存临时表中一行一行地取出 R 值和位置信息，分别存入 sort_buffer 中的两个字段里。这个过程要对内存临时表做全表扫描，此时扫描行数增加 10000，变成了 20000。</li>
<li>在 sort_buffer 中根据 R 的值进行排序。注意，这个过程没有涉及到表操作，所以不会增加扫描行数。</li>
<li>排序完成后，取出前三个结果的位置信息，依次到内存临时表中取出 word 值，返回给客户端。这个过程中，访问了表的三行数据，总扫描行数变成了 20003。</li>
</ol>
</li>
<li>MySQL 的表是用什么方法来定位“一行数据”的<ul>
<li>如果创建的表没有主键，或者把一个表的主键删掉了，那么 InnoDB 会自己生成一个长度为 6 字节的 rowid 来作为主键。这也就是排序模式里面，rowid 名字的来历。实际上它表示的是：每个引擎用来唯一标识数据行的信息。</li>
<li>对于有主键的 InnoDB 表来说，这个 rowid 就是主键 ID；</li>
<li>对于没有主键的 InnoDB 表来说，这个 rowid 就是由系统生成的；</li>
</ul>
</li>
<li>order by rand() 使用了内存临时表，内存临时表排序的时候使用了 rowid 排序方法。</li>
</ul>
</li>
<li><p>磁盘临时表</p>
<ul>
<li>tmp_table_size 这个配置限制了内存临时表的大小，默认值是 16M。如果临时表大小超过了 tmp_table_size，那么内存临时表就会转成磁盘临时表。磁盘临时表使用的引擎默认是 InnoDB，是由参数 internal_tmp_disk_storage_engine 控制的。当使用磁盘临时表的时候，对应的就是一个没有显式索引的 InnoDB 表的排序过程</li>
<li>这个 SQL 语句的排序没有用到临时文件，采用是 MySQL 5.6 版本引入的一个新的排序算法，即：优先队列排序算法<ul>
<li>如果使用归并排序算法的话，虽然最终也能得到前 3 个值，但是这个算法结束后，已经将 10000 行数据都排好序了。</li>
<li>优先队列算法，就可以精确地只得到三个最小值</li>
</ul>
</li>
<li>OPTIMIZER_TRACE 结果中，filesort_priority_queue_optimization 这个部分的chosen &#x3D; true，就表示使用了优先队列排序算法，这个过程不需要临时文件，因此对应的number_of_tmp_files 是 0</li>
<li>不论是使用哪种类型的临时表，order by rand() 这种写法都会让计算过程非常复杂，需要大量的扫描行数，因此排序过程的资源消耗也会很大</li>
</ul>
</li>
<li><p>随机排序方法</p>
<ul>
<li><p>如果只随机选择 1 个 word 值，可以怎么做呢？</p>
<ol>
<li>取得这个表的主键 id 的最大值 M 和最小值 N;</li>
<li>用随机函数生成一个最大值到最小值之间的数 X &#x3D; (M-N)*rand() + N;</li>
<li>取不小于 X 的第一个 ID 的行</li>
</ol>
<ul>
<li>这个方法效率很高，因为取 max(id) 和 min(id) 都是不需要扫描索引的，而第三步的select 也可以用索引快速定位，可以认为就只扫描了 3 行。但实际上，这个算法本身并不严格满足题目的随机要求，因为 ID 中间可能有空洞，因此选择不同行的概率不一样，不是真正的随机</li>
</ul>
</li>
<li><p>为了得到严格随机的结果，可以用下面这个流程:</p>
<ol>
<li>取得整个表的行数，并记为 C。</li>
<li>取得 Y &#x3D; floor(C * rand())。 floor 函数在这里的作用，就是取整数部分。</li>
<li>再用 limit Y,1 取得一行。</li>
</ol>
<ul>
<li>跟直接 order by rand() 比起来，执行代价还是小很多的</li>
</ul>
</li>
<li><p>随机取 3 个 word 值呢？</p>
<ol>
<li>取得整个表的行数，记为 C；</li>
<li>根据相同的随机方法得到 Y1、Y2、Y3；</li>
<li>再执行三个 limit Y, 1 语句得到三行数据。</li>
</ol>
<ul>
<li>总扫描行数是 C+(Y1+1)+(Y2+1)+(Y3+1)，实际上它还是可以继续优化，来进一步减少扫描行数的。</li>
</ul>
</li>
</ul>
</li>
<li><p>总结：介绍从表中选取随机值的方法</p>
<ul>
<li>第一种方法，内存临时表：直接使用order by rand() ，这个语句需要Using Temporary和Using filesort，其查询代价往往较大，需要进行全表扫描，对每个数据调用rand()然后借助sort_buffer进行排序操作（rowid归并排序），然后借助位置信息定位该数据 </li>
<li>第二种方法，磁盘临时表：如果临时表大小超过了tmp_table_size则内存临时表会转化为磁盘临时表，并且对max_length_for_sort_data进行限定，进行rowid排序，但是这个过程并不会使用零食文件，因为其采用了优先队列算法；但是如果需要维护的堆超过sort_buffer_size则只能使用归并算法</li>
<li>随机排序方法：根据主键id的最大值和最小值利用随机函数生成一个范围内的值，然后取第一个不小于该数的ID行，但是该方法仅适用于主键id连续的场景，一旦主键id间隔大就不能保证随机性了；为此可以利用这个表的行数（全表扫描一次）取得一个随机数floor(C*rand())，再用limit Y,1（需要让代码配合拼接SQL语句）取得一行</li>
<li>尽量让业务逻辑写在业务代码中，让数据库只做“读写数据”的事情</li>
</ul>
</li>
</ul>
<h4 id="18丨为什么这些SQL语句逻辑相同，性能却差异巨大？"><a href="#18丨为什么这些SQL语句逻辑相同，性能却差异巨大？" class="headerlink" title="18丨为什么这些SQL语句逻辑相同，性能却差异巨大？"></a>18丨为什么这些SQL语句逻辑相同，性能却差异巨大？</h4><ul>
<li><p>条件字段函数操作</p>
<ul>
<li>如果对字段做了函数计算，就用不上索引了，这是 MySQL 的规定</li>
<li>B+ 树提供的快速定位能力，来源于同一层兄弟节点的有序性。如果计算函数的话在树的第一层就不知道该怎么办了</li>
<li>对索引字段做函数操作，可能会破坏索引值的有序性，因此优化器就决定放弃走树搜索功能。</li>
<li>需要注意的是，优化器并不是要放弃使用这个索引。放弃了树搜索功能，优化器可以选择遍历主键索引，也可以选择遍历索引</li>
</ul>
</li>
<li><p>隐式类型转换</p>
<ul>
<li><p>数据类型转换的规则是什么？</p>
<p>看 select “10” &gt; 9 的结果：</p>
<ol>
<li>如果规则是“将字符串转成数字”，那么就是做数字比较，结果应该是 1；</li>
<li>如果规则是“将数字转成字符串”，那么就是做字符串比较，结果应该是 0。</li>
</ol>
<p>在 MySQL 中，字符串和数字做比较的话，是将字符串转换成数字。</p>
</li>
<li><p>隐式类型转换相当于进行了CAST函数运算</p>
</li>
</ul>
</li>
<li><p>隐式字符编码转换</p>
<ul>
<li>两个表的字符集不同，一个是 utf8，一个是 utf8mb4，所以做表连接查询的时候用不上关联字段的索引</li>
<li>字符集 utf8mb4 是 utf8 的超集，所以当这两个类型的字符串在做比较的时候，MySQL 内部的操作是，先把 utf8 字符串转成 utf8mb4 字符集，再做比较。</li>
<li>字符集不同只是条件之一，连接过程中要求在被驱动表的索引字段上加函数操作，是直接导致对被驱动表做全表扫描的原因。</li>
</ul>
</li>
<li><p>总结：三个例子导致索引失效，其实最后都是因为对索引进行了函数操作，可能破坏了索引值的有序性，因此优化器决定，放弃走树搜索功能</p>
<ul>
<li>第一个例子就是直接显示进行函数操作，或者进行加法等操作，都会导致索引失效</li>
<li>第二个例子是隐式类型转换，针对字符串和数字的比较MySQL会讲字符串转换为数字，对于该情况可以针对查询的元素进行类型转换，保证索引不需要进行转换</li>
<li>第三个例子是隐式字符编码转换，针对该情况也是可以提前进行编码转换，保证索引有效</li>
</ul>
</li>
</ul>
<h4 id="19丨为什么我只查一行的语句，也执行这么慢？"><a href="#19丨为什么我只查一行的语句，也执行这么慢？" class="headerlink" title="19丨为什么我只查一行的语句，也执行这么慢？"></a><strong>19丨为什么我只查一行的语句，也执行这么慢？</strong></h4><ul>
<li><p>查询长时间不返回</p>
<ul>
<li>一般碰到这种情况的话，大概率是表 t 被锁住了。接下来分析原因的时候，一般都是首先执行一下 show processlist 命令，看看当前语句处于什么状态。</li>
<li>等 MDL 锁<ul>
<li>使用 show processlist 命令查看 Waiting for table metadata lock</li>
<li>出现这个状态表示的是，现在有一个线程正在表 t 上请求或者持有 MDL 写锁，把 select语句堵住了。</li>
<li>这类问题的处理方式，就是找到谁持有 MDL 写锁，然后把它 kill 掉。通过查询 sys.schema_table_lock_waits 这张表，就可以直接找出造成阻塞的process id，把这个连接用 kill 命令断开即可。</li>
</ul>
</li>
<li>等 flush<ul>
<li>这个线程的状态是 Waiting for table flush表示的是，现在有一个线程正要对表 t 做 flush 操作。</li>
<li>出现 Waiting for table flush 状态的可能情况是：有一个 flush tables 命令被别的语句堵住了，然后它又堵住了 select 语句</li>
</ul>
</li>
<li>等行锁<ul>
<li>由于访问 id&#x3D;1 这个记录时要加读锁，如果这时候已经有一个事务在这行记录上持有一个写锁，select 语句就会被堵住。</li>
<li>session A 启动了事务，占有写锁，还不提交，是导致 session B 被堵住的原因。如果用的是 MySQL 5.7 版<br>本，可以通过 sys.innodb_lock_waits 表查到</li>
<li>KILL 4 才有效，也就是说直接断开这个连接。这里隐含的一个逻辑就是，连接被断开的时候，会自动回滚这个连接里面正在执行的线程，也就释放了 id&#x3D;1 上的行锁</li>
</ul>
</li>
</ul>
</li>
<li><p>第二类：查询慢</p>
<ul>
<li>select * from t where c&#x3D;50000 limit 1;<ul>
<li>由于字段 c 上没有索引，这个语句只能走 id 主键顺序扫描，因此需要扫描 5 万行。可以看一下慢查询日志，Rows_examined 显示扫描了 50000 行，坏查询不一定是慢查询。这个例子里面只有 10 万行记录，数据量大起来的话，执行时间就线性涨上去了</li>
</ul>
</li>
<li>带 lock in share mode 的 SQL 语句，是当前读，因此会直接读到 1000001 这个结果，所以速度很快；而 select * from t where id&#x3D;1 这个语句，是一致性读，因此需要从1000001 开始，依次执行 undo log，执行了 100 万次以后，才将 1 这个结果返回。</li>
</ul>
</li>
<li><p>总结复习：几个执行查一行可能被锁住和执行慢的例子</p>
<ul>
<li>查询长时间不范围大概率是该表被锁住了，一般都是执行show processlist命令查看语句当前的状态；主要有这几种场景：等MDL锁（Waiting for table metadata lock）会把select语句堵住，处理方式就是找到谁持有MDL写锁然后把他kill掉；等flush（waiting for table flush），一个flush table指令被别的语句堵住了，然后其又堵住了select语句；等行锁，针对这个场景需要直接断开这个连接；</li>
<li>select *** in share mode 是当前读，因此不受其他事务的影响，速度很快，而普通的select语句是一致性读，对于双事务的场景，可能会出现另一个事务操作很多的情况，因此该select语句需要依次执行undolog，然后才返回查找的结果</li>
</ul>
</li>
</ul>
<h4 id="20丨幻读是什么，幻读有什么问题？"><a href="#20丨幻读是什么，幻读有什么问题？" class="headerlink" title="20丨幻读是什么，幻读有什么问题？"></a>20丨幻读是什么，幻读有什么问题？</h4><p>分析表除了主键 id 外，还有一个索引 c，初始化语句在表中插入了 6 行数据。(0,0,0),(5,5,5),(10,10,10),(15,15,15),(20,20,20),(25,25,25);</p>
<ul>
<li><p>幻读是什么？</p>
<ul>
<li>幻读指的是一个事务在前后两次查询同一个范围的时候，后一次查询看到了前一次查询没有看到的行。</li>
<li>在可重复读隔离级别下，普通的查询是快照读，是不会看到别的事务插入的数据的。因此，幻读在“当前读”下才会出现。 session B 的修改结果，被 session A 之后的 select 语句用“当前读”看到，不能称为幻读。<strong>幻读仅专指“新插入的行”</strong></li>
</ul>
</li>
<li><p>幻读有什么问题？</p>
<ul>
<li>首先是语义上的。session A 在 T1 时刻就声明了，“我要把所有 d&#x3D;5 的行锁住，不准别的事务进行读写操作”。而实际上，这个语义被破坏了。</li>
<li>其次，是数据一致性的问题。锁的设计是为了保证数据的一致性。而这个一致性，不止是数据库内部数据状态在此刻的一致性，还包含了数据和日志在逻辑上的一致性。</li>
<li>即使把所有的记录都加上锁，还是阻止不了新插入的记录，这也是为什么“幻读”会被单独拿出来解决的原因。</li>
</ul>
</li>
<li><p>如何解决幻读？</p>
<ul>
<li>产生幻读的原因是，行锁只能锁住行，但是新插入记录这个动作，要更新的是记录之间的“间隙”。因此，为了解决幻读问题，InnoDB 只好引入新的锁，也就是间隙锁 (Gap Lock)<ul>
<li>间隙锁，锁的就是两个值之间的空隙。比如表 t，初始化插入了 6 个记录，这就产生了 7 个间隙。</li>
<li>执行 select * from t where d&#x3D;5 for update 的时候，就不止是给数据库中已有的 6 个记录加上了行锁，还同时加了 7 个间隙锁。这样就确保了无法再插入新的记录。</li>
<li>间隙锁和行锁合称 next-key lock，每个 next-key lock 是前开后闭区间。表 t 初始化以后，如果用 select * from t for update 要把整个表所有记录锁起来，就形成了 7 个 next-key lock，分别是 (-∞,0]、(0,5]、(5,10]、(10,15]、(15,20]、(20, 25]、(25, +supremum]。</li>
</ul>
</li>
<li>数据行是可以加上锁的实体，数据行之间的间隙，也是可以加上锁的实体。但是间隙锁跟之前碰到过的锁都不太一样。跟行锁有冲突关系的是“另外一个行锁”。间隙锁不一样，跟间隙锁存在冲突关系的，是“往这个间隙中插入一个记录”这个操作。间隙锁之间都不存在冲突关系。</li>
<li>间隙锁和 next-key lock 的引入，帮我们解决了幻读的问题，但同时也带来了一些“困扰”。<ul>
<li>间隙锁的引入，可能会导致同样的语句锁住更大的范围，这其实是影响了并发度的。</li>
</ul>
</li>
<li>间隙锁是在可重复读隔离级别下才会生效的。所以如果把隔离级别设置为读提交的话，就没有间隙锁了。但同时要解决可能出现的数据和日志不一致问题，需要把binlog 格式设置为 row。<ul>
<li>如果读提交隔离级别够用，也就是说，业务不需要可重复读的保证，这样考虑到读提交下操作数据的锁范围更小（没有间隙锁），这个选择是合理的。</li>
</ul>
</li>
</ul>
</li>
<li><p>总结复习：幻读观念的介绍，间隙锁next-key lock的引入</p>
<ul>
<li>幻读是指一个事务在前后两次查询同一个范围的时候，后一次查询看到了前一次查询没有看到的行</li>
<li>可重复隔离级别下，普通查询时快照读，幻读在“当前读”情况下才会出现</li>
<li>幻读可能导致数据一致性问题，即使把所有记录都加上锁还是无法阻止新插入的记录</li>
<li>产生幻读的原因是行锁只能锁住行，而新插入的记录在记录之间的间隙，因此需要引入新的锁，也就是间隙锁；跟间隙锁存在冲突关系的是“往这个间隙插入一个记录”这个操作，间隙锁之间不存在冲突关系</li>
<li>间隙锁和行锁统称next-key lock，但是引入其也会导致一定问题，可能会导致同样的语句锁住更大的范围，会影响并发度；间隙锁是在可重复读隔离级别下才生效的，如果是读提交级别就没有间隙锁了，为了解决数据和日志不一致的问题，可以采用读提交+binlog格式为row</li>
</ul>
</li>
</ul>
<h4 id="21丨为什么我只改一行的语句，锁这么多？"><a href="#21丨为什么我只改一行的语句，锁这么多？" class="headerlink" title="21丨为什么我只改一行的语句，锁这么多？"></a>21丨为什么我只改一行的语句，锁这么多？</h4><ul>
<li><p>加锁规则：两个“原则”、两个“优化”和一个“bug”。</p>
<ul>
<li>原则 1：加锁的基本单位是 next-key lock。next-key lock 是前开后闭区间。</li>
<li>原则 2：查找过程中访问到的对象才会加锁。</li>
<li>优化 1：索引上的等值查询，给唯一索引加锁的时候，next-key lock 退化为行锁。</li>
<li>优化 2：索引上的等值查询，向右遍历时且最后一个值不满足等值条件的时候，nextkey lock 退化为间隙锁。</li>
<li>一个 bug：唯一索引上的范围查询会访问到不满足条件的第一个值为止。</li>
</ul>
</li>
<li><p>锁是加在索引上的；如果要用 lock in share mode 来给行加读锁避免数据被更新的话，就必须得绕过覆盖索引的优化，在查询字段中加入索引中不存在的字段。</p>
</li>
<li><p>在删除数据的时候尽量加 limit。这样不仅可以控制删除数据的条数，让操作更安全，还可以减小加锁的范围</p>
</li>
<li><p>在读提交隔离级别下还有一个优化，即：语句执行过程中加上的行锁，在语句执行完成后，就要把“不满足条件的行”上的行锁直接释放了，不需要等到事务提交。读提交隔离级别下，锁的范围更小，锁的时间更短，这也是不少业务都默认使用读提交隔离级别的原因</p>
</li>
</ul>
<h4 id="22丨MySQL有哪些“饮鸩止渴”提高性能的方法？"><a href="#22丨MySQL有哪些“饮鸩止渴”提高性能的方法？" class="headerlink" title="22丨MySQL有哪些“饮鸩止渴”提高性能的方法？"></a>22丨MySQL有哪些“饮鸩止渴”提高性能的方法？</h4><ul>
<li><p>短连接风暴</p>
<ul>
<li>正常的短连接模式就是连接到数据库后，执行很少的 SQL 语句就断开，下次需要的时候再重连。如果使用的是短连接，在业务高峰期的时候，就可能出现连接数突然暴涨的情况</li>
<li>在数据库压力比较小的时候，这些额外的成本并不明显。但是，短连接模型存在一个风险，就是一旦数据库处理得慢一些，连接数就会暴涨。</li>
<li>max_connections 参数，用来控制一个 MySQL 实例同时存在的连接数的上限，超过这个值，系统就会拒绝接下来的连接请求，并报错提示“Too many connections”。对于被拒绝连接的请求来说，从业务角度看就是数据库不可用。</li>
<li>在机器负载比较高的时候，处理现有请求的时间变长，每个连接保持的时间也更长。这时，再有新建连接的话，就可能会超过 max_connections 的限制。</li>
<li>第一种方法：先处理掉那些占着连接但是不工作的线程。<ul>
<li>max_connections 的计算，不是看谁在 running，是只要连着就占用一个计数位置。对于那些不需要保持的连接，可以通过 kill connection 主动踢掉。这个行为跟事先设置wait_timeout 的效果是一样的。设置 wait_timeout 参数表示的是，一个线程空闲wait_timeout 这么多秒之后，就会被 MySQL 直接断开连接。但是需要注意，在 show processlist 的结果里，踢掉显示为 sleep 的线程，可能是有损的</li>
<li>从服务端断开连接使用的是 kill connection + id 的命令， 一个客户端处于 sleep 状态时，它的连接被服务端主动断开后，这个客户端并不会马上知道。直到客户端在发起下一个请求的时候，才会收到这样的报错“ERROR 2013 (HY000): Lost connection to MySQL server during query”。有的应用端收到这个错误后，不重新连接，而是直接用这个已经不能用的句柄重试查询。这会导致从应用端看上去，“MySQL 一直没恢复”。</li>
</ul>
</li>
<li>第二种方法：减少连接过程的消耗。<ul>
<li>有的业务代码会在短时间内先大量申请数据库连接做备用，如果现在数据库确认是被连接行为打挂了，那么一种可能的做法，是让数据库跳过权限验证阶段。</li>
<li>跳过权限验证的方法是：重启数据库，并使用–skip-grant-tables 参数启动。这样，整个MySQL 会跳过所有的权限验证阶段，包括连接过程和语句执行过程在内。</li>
</ul>
</li>
</ul>
</li>
<li><p>慢查询性能问题</p>
<ul>
<li>导致慢查询的第一种可能是，索引没有设计好。<ul>
<li>这种场景一般就是通过紧急创建索引来解决。MySQL 5.6 版本以后，创建索引都支持Online DDL 了，对于那种高峰期数据库已经被这个语句打挂了的情况，最高效的做法就是直接执行 alter table 语句，比较理想的是能够在备库先执行</li>
</ul>
</li>
<li>导致慢查询的第二种可能是，语句没写好。<ul>
<li>可以通过改写 SQL 语句来处理。MySQL 5.7 提供了 query_rewrite 功能，可以把输入的一种语句改写成另外一种模式。</li>
</ul>
</li>
<li>导致慢查询的第三种可能，就是MySQL 选错了索引。<ul>
<li>应急方案就是给这个语句加上 force index。</li>
<li>同样地，使用查询重写功能，给原来的语句加上 force index，也可以解决这个问题。</li>
</ul>
</li>
<li>通过下面这个过程，可以预先发现问题。<ol>
<li>上线前，在测试环境，把慢查询日志（slow log）打开，并且把 long_query_time 设置<br>成 0，确保每个语句都会被记录入慢查询日志；</li>
<li>在测试表里插入模拟线上的数据，做一遍回归测试；</li>
<li>观察慢查询日志里每类语句的输出，特别留意 Rows_examined 字段是否与预期一致。</li>
</ol>
</li>
</ul>
</li>
<li><p>QPS 突增问题</p>
<ul>
<li>有时候由于业务突然出现高峰，或者应用程序 bug，导致某个语句的 QPS 突然暴涨，也可能导致 MySQL 压力过大，影响服务。</li>
<li>一种是由全新业务的 bug 导致的。假设 DB 运维是比较规范的，也就是说白名单是一个个加的。这种情况下，如果你能够确定业务方会下掉这个功能，只是时间上没那么快，那么就可以从数据库端直接把白名单去掉。</li>
<li>如果这个新功能使用的是单独的数据库用户，可以用管理员账号把这个用户删掉，然后断开现有连接。这样，这个新功能的连接不成功，由它引发的 QPS 就会变成 0。</li>
<li>如果这个新增的功能跟主体功能是部署在一起的，那么只能通过处理语句来限制。这时可以使用上面提到的查询重写功能，把压力最大的 SQL 语句直接重写成”select 1”返回。可能存在两个副作用：<ul>
<li>如果别的功能里面也用到了这个 SQL 语句模板，会有误伤；</li>
<li>很多业务并不是靠这一个语句就能完成逻辑的，所以如果单独把这一个语句以 select 1的结果返回的话，可能会导致后面的业务逻辑一起失败。</li>
</ul>
</li>
</ul>
</li>
<li><p>总结复习：MySQL在业务高峰期的一些紧急处理手段</p>
<ul>
<li>面对短连接风暴这种场景，MySQL 建立连接的过程，成本是很高的，尽量不要取调整max_connections 的值，因为可能会进一步加大系统的负载将大量的资源耗费在权限验证等逻辑上，可能使得已经连接的线程拿不到 CPU 资源去执行业务的SQL。可以先处理掉那些占着连接但是不工作的线程或者（利用show processlist 的结果和information_schema 库的 innodb_trx 表进行选择）减少连接过程的消耗（跳过权限验证阶段），但这两个方案都是有损的</li>
<li>针对慢查询性能问题，需要分析是由哪种情况产生的慢查询：索引没有设计好（最高效的做法就是直接执行 alter table 语句）；SQL 语句没写好（使用query_rewrite 功能）；MySQL 选错了索引（应急方案就是给这个语句加上 force index）</li>
<li>针对QPS突增问题，最理想的情况是让业务把这个功能下掉，服务自然就会恢复，下掉一个功能则不同背景有不同的方法：由全新业务的 bug 导致的（从数据库端直接把白名单去掉）；这个新功能使用的是单独的数据库用户（用管理员账号把这个用户删掉，然后断开现有连接）；这个新增的功能跟主体功能是部署在一起的（只能通过处理语句来限制，如把压力最大的 SQL 语句直接重写成”select 1”返回）</li>
</ul>
</li>
</ul>
<h4 id="23丨MySQL是怎么保证数据不丢的？"><a href="#23丨MySQL是怎么保证数据不丢的？" class="headerlink" title="23丨MySQL是怎么保证数据不丢的？"></a>23丨MySQL是怎么保证数据不丢的？</h4><ul>
<li><p>binlog 的写入机制</p>
<ul>
<li>binlog 的写入逻辑比较简单：事务执行过程中，先把日志写到 binlog cache，事务提交的时候，再把 binlog cache 写到 binlog 文件中。<ul>
<li>一个事务的 binlog 是不能被拆开的，因此不论这个事务多大，也要确保一次性写入。这就涉及到了 binlog cache 的保存问题。</li>
<li>系统给 binlog cache 分配了一片内存，每个线程一个，参数 binlog_cache_size 用于控制单个线程内 binlog cache 所占内存的大小。如果超过了这个参数规定的大小，就要暂存到磁盘。</li>
<li>事务提交的时候，执行器把 binlog cache 里的完整事务写入到 binlog 中，并清空 binlog cache。</li>
</ul>
</li>
<li>每个线程有自己 binlog cache，但是共用同一份 binlog 文件<ul>
<li>write，指的就是指把日志写入到文件系统的 page cache，并没有把数据持久化到磁盘，所以速度比较快</li>
<li>fsync，才是将数据持久化到磁盘的操作。一般情况下，我们认为 fsync 才占磁盘的 IOPS。</li>
<li>write 和 fsync 的时机，是由参数 sync_binlog 控制的：<ul>
<li>sync_binlog&#x3D;0 的时候，表示每次提交事务都只 write，不 fsync；</li>
<li>sync_binlog&#x3D;1 的时候，表示每次提交事务都会执行 fsync；</li>
<li>sync_binlog&#x3D;N(N&gt;1) 的时候，表示每次提交事务都 write，但累积 N 个事务后才fsync。</li>
</ul>
</li>
<li>在出现 IO 瓶颈的场景里，将 sync_binlog 设置成一个比较大的值，可以提升性能；但是，将 sync_binlog 设置为 N，对应的风险是：如果主机发生异常重启，会丢失最近 N个事务的 binlog 日志。</li>
</ul>
</li>
</ul>
</li>
<li><p>redo log的写入机制</p>
<ul>
<li><p>redo log buffer 里面的内容，是不是每次生成后都要直接持久化到磁盘呢？</p>
<ul>
<li>不需要。如果事务执行期间 MySQL 发生异常重启，那这部分日志就丢了。由于事务并没有提交，所以这时日志丢了也不会有损失。</li>
</ul>
</li>
<li><p>事务还没提交的时候，redo log buffer 中的部分日志有没有可能被持久化到磁盘呢？</p>
<ul>
<li><p>确实会有。要从 redo log 可能存在的三种状态说起。这三种状态分别是：</p>
<ol>
<li>存在 redo log buffer 中，物理上是在 MySQL 进程内存中；</li>
<li>写到磁盘 (write)，但是没有持久化（fsync)，物理上是在文件系统的 page cache 里面；</li>
<li>持久化到磁盘，对应的是 hard disk。</li>
</ol>
</li>
<li><p>日志写到 redo log buffer 是很快的，wirte 到 page cache 也差不多，但是持久化到磁盘的速度就慢多了。</p>
</li>
<li><p>为了控制 redo log 的写入策略，InnoDB 提供了 innodb_flush_log_at_trx_commit 参数，它有三种可能取值：</p>
<ol>
<li>设置为 0 的时候，表示每次事务提交时都只是把 redo log 留在 redo log buffer 中 ;</li>
<li>设置为 1 的时候，表示每次事务提交时都将 redo log 直接持久化到磁盘；</li>
<li>设置为 2 的时候，表示每次事务提交时都只是把 redo log 写到 page cache。</li>
</ol>
</li>
<li><p>InnoDB 有一个后台线程，每隔 1 秒，就会把 redo log buffer 中的日志，调用 write 写到文件系统的 page cache，然后调用 fsync 持久化到磁盘。</p>
</li>
<li><p>事务执行中间过程的 redo log 也是直接写在 redo log buffer 中的，这些 redo log也会被后台线程一起持久化到磁盘。也就是说，一个没有提交的事务的 redo log，也是可能已经持久化到磁盘的；除了后台线程每秒一次的轮询操作外，还有两种场景会让一个没有提交的事务的redo log 写入到磁盘中。</p>
<ul>
<li>一种是，redo log buffer 占用的空间即将达到 innodb_log_buffer_size 一半的时候，后台线程会主动写盘。注意，由于这个事务并没有提交，所以这个写盘动作只是write，而没有调用 fsync，也就是只留在了文件系统的 page cache。</li>
<li>另一种是，并行的事务提交的时候，顺带将这个事务的 redo log buffer 持久化到磁盘。假设一个事务 A 执行到一半，已经写了一些 redo log 到 buffer 中，这时候有另外一个线程的事务 B 提交，如果 innodb_flush_log_at_trx_commit 设置的是 1，那么按照这个参数的逻辑，事务 B 要把 redo log buffer 里的日志全部持久化到磁盘。这时候，就会带上事务 A 在 redo log buffer 里的日志一起持久化到磁盘。</li>
</ul>
</li>
</ul>
</li>
<li><p>两阶段提交的时候，时序上 redo log 先 prepare， 再写binlog，最后再把 redo log commit。如果把 innodb_flush_log_at_trx_commit 设置成 1，那么 redo log 在 prepare 阶段就要持久化一次，因为有一个崩溃恢复逻辑是要依赖于 prepare 的 redo log，再加上 binlog来恢复的。</p>
<ul>
<li>每秒一次后台轮询刷盘，再加上崩溃恢复这个逻辑，InnoDB 就认为 redo log 在 commit的时候就不需要 fsync 了，只会 write 到文件系统的 page cache 中就够了。</li>
<li>通常说 MySQL 的“双 1”配置，指的就是 sync_binlog 和innodb_flush_log_at_trx_commit 都设置成 1。也就是说，一个事务完整提交前，需要等待两次刷盘，一次是 redo log（prepare 阶段），一次是 binlog。</li>
</ul>
</li>
<li><p>组提交（group commit）机制</p>
<ul>
<li>日志逻辑序列号（log sequence number，LSN）<ul>
<li>LSN是单调递增的，用来对应 redo log 的一个个写入点。每次写入长度为 length 的 redolog， LSN 的值就会加上 length。</li>
<li>LSN 也会写到 InnoDB 的数据页中，来确保数据页不会被多次执行重复的 redo log。</li>
</ul>
</li>
<li>一次组提交里面，组员越多，节约磁盘 IOPS 的效果越好。但如果只有单线程压测，那就只能老老实实地一个事务对应一次持久化操作了。</li>
<li>在并发更新场景下，第一个事务写完 redo log buffer 以后，接下来这个 fsync 越晚调用，组员可能越多，节约 IOPS 的效果就越好。为了让一次 fsync 带的组员更多，MySQL 有一个很有趣的优化：拖时间。</li>
<li>实际上，写 binlog 是分成两步的：<ol>
<li>先把 binlog 从 binlog cache 中写到磁盘上的 binlog 文件；</li>
<li>调用 fsync 持久化。</li>
</ol>
</li>
<li>MySQL 为了让组提交的效果更好，把 redo log 做 fsync 的时间拖到了步骤 1 之后，这么一来，binlog 也可以组提交了。<ul>
<li>binlog 的 write 和 fsync 间的间隔时间短，导致能集合到一起持久化的 binlog 比较少，因此 binlog 的组提交的效果通常不如 redo log的效果那么好。</li>
<li>想提升 binlog 组提交的效果，可以通过设置 binlog_group_commit_sync_delay（延迟多少微秒后才调用 fsync）和 binlog_group_commit_sync_no_delay_count （累积多少次以后才调用fsync）来实现，这两个条件是或的关系，也就是说只要有一个满足条件就会调用 fsync。</li>
</ul>
</li>
</ul>
</li>
<li><p>WAL 机制主要得益于两个方面：</p>
<ol>
<li>redo log 和 binlog 都是顺序写，磁盘的顺序写比随机写速度要快；</li>
<li>组提交机制，可以大幅度降低磁盘的 IOPS 消耗。</li>
</ol>
</li>
</ul>
</li>
<li><p>如果你的 MySQL 现在出现了性能瓶颈，而且瓶颈在 IO 上，可以通过哪些方法来提升性能呢？</p>
<ul>
<li>设置 binlog_group_commit_sync_delay 和binlog_group_commit_sync_no_delay_count 参数，减少 binlog 的写盘次数。这个方法是基于“额外的故意等待”来实现的，因此可能会增加语句的响应时间，但没有丢<br>失数据的风险。</li>
<li>将 sync_binlog 设置为大于 1 的值（比较常见是 100 ~ 1000）。这样做的风险是，主机掉电时会丢 binlog 日志。</li>
<li>将 innodb_flush_log_at_trx_commit 设置为 2。这样做的风险是，主机掉电的时候会丢数据。</li>
<li>不建议把 innodb_flush_log_at_trx_commit 设置成 0。因为把这个参数设置成 0，表示 redo log 只保存在内存中，这样的话 MySQL 本身异常重启也会丢数据，风险太大。而redo log 写到文件系统的 page cache 的速度也是很快的，所以将这个参数设置成 2 跟设置成 0 其实性能差不多，但这样做 MySQL 异常重启时就不会丢数据了，相比之下风险会更小。</li>
</ul>
</li>
<li><p>执行一个 update 语句以后，再去执行 hexdump 命令直接查看 ibd 文件内容，为什么没有看到数据有改变呢？</p>
<ul>
<li>这可能是因为 WAL 机制的原因。update 语句执行完成后，InnoDB 只保证写完了redo log、内存，可能还没来得及将数据写到磁盘。</li>
</ul>
</li>
<li><p>为什么 binlog cache 是每个线程自己维护的，而 redo log buffer 是全局共用的？</p>
<ul>
<li>MySQL 这么设计的主要原因是，binlog 是不能“被打断的”。一个事务的 binlog必须连续写，因此要整个事务完成后，再一起写到文件里。</li>
<li>而 redo log 并没有这个要求，中间有生成的日志可以写到 redo log buffer 中。redo log buffer 中的内容还能“搭便车”，其他事务提交的时候可以被一起写到磁盘中。</li>
</ul>
</li>
<li><p>事务执行期间，还没到提交阶段，如果发生 crash 的话，redo log 肯定丢了，这会不会导致主备不一致呢？</p>
<ul>
<li>不会。因为这时候 binlog 也还在 binlog cache 里，没发给备库。crash 以后 redolog 和 binlog 都没有了，从业务角度看这个事务也没有提交，所以数据是一致的。</li>
</ul>
</li>
<li><p>如果 binlog 写完盘以后发生 crash，这时候还没给客户端答复就重启了。等客户端再重连进来，发现事务已经提交成功了，这是不是 bug？</p>
<ul>
<li>不是。可以设想一下更极端的情况，整个事务都提交成功了，redo log commit 完成了，备库也收到 binlog 并执行了。但是主库和客户端网络断开了，导致事务成功的包返回不回去，这时候客户端也会收到“网络断开”的异常。这种也只能算是事务成功的，不能认为是bug。</li>
<li>实际上数据库的 crash-safe 保证的是：<ul>
<li>如果客户端收到事务成功的消息，事务就一定持久化了；</li>
<li>如果客户端收到事务失败（比如主键冲突、回滚等）的消息，事务就一定失败了；</li>
<li>如果客户端收到“执行异常”的消息，应用需要重连后通过查询当前状态来继续后续的逻辑。此时数据库只需要保证内部（数据和日志之间，主库和备库之间）一致就可以了。</li>
</ul>
</li>
</ul>
</li>
<li><p>第23讲复习，只要 redo log 和 binlog 保证持久化到磁盘，就能确保 MySQL 异常重启后，数据可以恢复。那么MySQL 是怎么保证 redo log 和 binlog 是完整的</p>
<ul>
<li><p>binlog 的写入机制：事务执行过程中，先把日志写到 binlog cache，事务提交的时候，再把 binlog cache 写到 binlog 文件中。一个事务的 binlog 是不能被拆开的，因此不论这个事务多大，也要确保一次性写入。这就涉及到了 binlog cache 的保存问题。系统给 binlog cache 分配了一片内存，每个线程一个，参数 binlog_cache_size 用于控制单个线程内 binlog cache 所占内存的大小</p>
<ul>
<li>每个线程有自己 binlog cache，但是共用同一份 binlog 文件</li>
<li>write （把日志写入到文件系统的 page cache）和 fsync （将数据持久化到磁盘的操作）的时机，是由参数 sync_binlog 控制的：<ul>
<li>sync_binlog&#x3D;0 的时候，表示每次提交事务都只 write，不 fsync；</li>
<li>sync_binlog&#x3D;1 的时候，表示每次提交事务都会执行 fsync；</li>
<li>sync_binlog&#x3D;N(N&gt;1) 的时候，表示每次提交事务都 write，但累积 N 个事务后才fsync。</li>
</ul>
</li>
<li>在出现 IO 瓶颈的场景里，将 sync_binlog 设置成一个比较大的值，可以提升性能</li>
</ul>
</li>
<li><p>redo log的写入机制：</p>
<ul>
<li>事务在执行过程中，生成的 redo log 是要先写到 redo log buffer，redo log buffer 里面的内容不需要每次生成后都要直接持久化到磁盘，如果事务执行期间 MySQL 发生异常重启，那这部分日志就丢了。由于事务并没有提交，所以这时日志丢了也不会有损失</li>
<li>事务还没提交的时候确实会有redo log buffer 中的部分日志被持久化到磁盘；这需要从redo log 可能存在的三种状态说起：存在 redo log buffer 中；写到磁盘 (write)，但是没有持久化（fsync)；持久化到磁盘；innodb_flush_log_at_trx_commit 用于控制redo log 的写入策略：<ul>
<li>设置为 0 的时候，表示每次事务提交时都只是把 redo log 留在 redo log buffer 中 </li>
<li>设置为 1 的时候，表示每次事务提交时都将 redo log 直接持久化到磁盘；</li>
<li>设置为 2 的时候，表示每次事务提交时都只是把 redo log 写到 page cache</li>
</ul>
</li>
<li>InnoDB 有一个后台线程，每隔 1 秒，就会把 redo log buffer 中的日志，调用 write 写到文件系统的 page cache，然后调用 fsync 持久化到磁盘。事务执行中间过程的 redo log 也是直接写在 redo log buffer 中的，这些 redo log也会被后台线程一起持久化到磁盘。也就是说，一个没有提交的事务的 redo log，也是可<br>能已经持久化到磁盘的</li>
<li>redo log buffer 占用的空间即将达到 innodb_log_buffer_size 一半的时候，后台线程会主动写盘。注意，由于这个事务并没有提交，所以这个写盘动作只是write，而没有调用 fsync，也就是只留在了文件系统的 page cache</li>
<li>并行的事务提交的时候，顺带将这个事务的 redo log buffer 持久化到磁盘</li>
</ul>
</li>
<li><p>MySQL 的“双 1”配置，指的就是 sync_binlog 和innodb_flush_log_at_trx_commit 都设置成 1。也就是说，一个事务完整提交前，需要等待两次刷盘，一次是 redo log（prepare 阶段），一次是 binlog；使用组提交（group commit）机制节约磁盘 IOPS</p>
</li>
<li><p>WAL 机制主要得益于两个方面：</p>
<ol>
<li>redo log 和 binlog 都是顺序写，磁盘的顺序写比随机写速度要快；</li>
<li>组提交机制，可以大幅度降低磁盘的 IOPS 消耗。</li>
</ol>
</li>
<li><p>如果你的 MySQL 现在出现了性能瓶颈，而且瓶颈在 IO 上，可以通过哪些方法来提升性能呢？</p>
<ol>
<li>设置 binlog_group_commit_sync_delay 和binlog_group_commit_sync_no_delay_count 参数，减少 binlog 的写盘次数（提升 binlog 组提交的效果）。这个方法是基于“额外的故意等待”来实现的，因此可能会增加语句的响应时间，但没有丢失数据的风险。</li>
<li>将 sync_binlog 设置为大于 1 的值（比较常见是 100~1000）。这样做的风险是，主机掉电时会丢 binlog 日志。</li>
<li>将 innodb_flush_log_at_trx_commit 设置为 2。这样做的风险是，主机掉电的时候会丢数据。</li>
</ol>
</li>
<li><p>为什么 binlog cache 是每个线程自己维护的，而 redo log buffer 是全局共用的？</p>
<p>MySQL 这么设计的主要原因是，binlog 是不能“被打断的”。一个事务的 binlog必须连续写，因此要整个事务完成后，再一起写到文件里。而 redo log 并没有这个要求，中间有生成的日志可以写到 redo log buffer 中。redo log buffer 中的内容还能“搭便车”，其他事务提交的时候可以被一起写到磁盘中。</p>
</li>
<li><p>事务执行期间，还没到提交阶段，如果发生 crash 的话，redo log 肯定丢了，这会不会导致主备不一致呢？</p>
<p>不会。因为这时候 binlog 也还在 binlog cache 里，没发给备库。crash 以后 redolog 和 binlog 都没有了，从业务角度看这个事务也没有提交，所以数据是一致的</p>
</li>
<li><p>数据库的 crash-safe 保证的是：</p>
<ol>
<li>如果客户端收到事务成功的消息，事务就一定持久化了</li>
<li>如果客户端收到事务失败（比如主键冲突、回滚等）的消息，事务就一定失败了</li>
<li>如果客户端收到“执行异常”的消息，应用需要重连后通过查询当前状态来继续后续的逻辑。此时数据库只需要保证内部（数据和日志之间，主库和备库之间）一致就可以了</li>
</ol>
</li>
</ul>
</li>
<li><p>第24讲复习，MySQL binlog的格式和一些基本机制，binlog 在 MySQL 的各种高可用方案上扮演了重要角色</p>
<ul>
<li>MySQL 主备的基本原理：主库接收到客户端的更新请求后，执行内部事务的更新逻辑，同时写 binlog，备库 B 跟主库 A 之间维持了一个长连接。主库 A 内部有一个线程，专门用于服务备库 B的这个长连接。一个事务日志同步的完整过程是这样的：<ul>
<li>在备库 B 上通过 change master 命令，设置与主库相关的各种参数</li>
<li>在备库 B 上执行 start slave 命令，这时候备库会启动两个线程，io_thread<br>和 sql_thread。其中 io_thread 负责与主库建立连接。</li>
<li>主库 A 校验完用户名、密码后，开始按照备库 B 传过来的位置，从本地读取 binlog，发给 B</li>
<li>备库 B 拿到 binlog 后，写到本地文件，称为中转日志（relay log）</li>
<li>sql_thread 读取中转日志，解析出日志里的命令，并执行</li>
</ul>
</li>
<li>binlog 的三种格式对比：statement，row，mixed。<ul>
<li>对于delete语句，当 binlog 设置的是statement 格式，并且语句中有 limit，所以这个命令可能是 unsafe 的，很可能会出现主备数据不一致的情况。由于 statement 格式下，记录到 binlog 里的是语句原文，因此可能会出现主库执行这条 SQL 语句和备库执行这条 SQL 语句的时候使用的索引不同</li>
<li>与 statement 格式的 binlog 相比，前后的 BEGIN 和 COMMIT 是一样的。但是，row 格式的 binlog 里没有了 SQL 语句的原文，而是替换成了两个 event：Table_map 和 Delete_rows。借助 mysqlbinlog 工具，进一步解析和查看 binlog 中的内容：当 binlog_format 使用 row 格式的时候，binlog 里面记录了真实删除行的主键 id，不会有主备删除不同行的问题。</li>
<li>row 格式的缺点是，很占空间。比如用一个 delete 语句删掉 10 万行数据，用<br>statement 的话就是一个 SQL 语句被记录到 binlog 中，占用几十个字节的空间。但如果用 row 格式的 binlog，就要把这 10 万条记录都写到 binlog 中。这样做，不仅会占用更大的空间，同时写 binlog 也要耗费 IO 资源，影响执行速度；因此MySQL 就取了个折中方案，也就是有了 mixed 格式的 binlog。MySQL 自己会判断这条 SQL 语句是否可能引起主备不一致，如果有可能，就用row 格式，否则就用 statement 格式。</li>
</ul>
</li>
<li>现在越来越多的场景要求把 MySQL 的 binlog 格式设置成 row。这么做可以很方便的恢复数据，比如假设执行的是 delete 语句，row 格式的 binlog 也会把被删掉的行的整行信息保存起来。所以，如果在执行完一条 delete 语句以后，发现删错数据了，可以直接把 binlog 中记录的 delete 语句转成 insert，把被错删的数据插入回去就可以恢复了</li>
<li>重放 binlog 数据的时候用 mysqlbinlog 解析出日志，然后把里面的 statement 语句直接拷贝出来执行，这个操作是有风险的，因为有些语句的执行结果是依赖于上下文命令的，直接执行的结果很可能是错误的。所以，用 binlog 来恢复数据的标准做法是，用 mysqlbinlog 工具解析出来，然后把解析结果整个发给 MySQL 执行。</li>
<li>循环复制问题：对于双M结构，业务逻辑在节点 A 上更新了一条语句，然后再把生成的 binlog 发给节点 B，节点 B 执行完这条更新语句后也会生成 binlog。那么，如果节点 A 同时是节点 B 的备库，相当于又把节点 B 新生成的 binlog 拿过来执行了一次，然后节点 A 和 B 间，会不断地循环执行这个更新语句，也就是循环复制。可以用下面的逻辑，来解决两个节点间的循环复制的问题：<ol>
<li>规定两个库的 server id 必须不同，如果相同，则它们之间不能设定为主备关系；</li>
<li>一个备库接到 binlog 并在重放的过程中，生成与原 binlog 的 server id 相同的新的binlog；</li>
<li>每个库在收到从自己的主库发过来的日志后，先判断 server id，如果跟自己的相同，表示这个日志是自己生成的，就直接丢弃这个日志</li>
</ol>
</li>
<li>什么时候会把线上生产库设置成“非双 1”：<ol>
<li>业务高峰期。一般如果有预知的高峰期，DBA 会有预案，把主库设置成“非双 1”</li>
<li>备库延迟，为了让备库尽快赶上主库。@永恒记忆和 @Second Sight 提到了这个场景。</li>
<li>用备份恢复主库的副本，应用 binlog 的过程，这个跟上一种场景类似。</li>
<li>批量导入数据的时候。</li>
</ol>
</li>
</ul>
</li>
<li><p>第25讲复习，MySQL 高可用系统的基础——主备切换逻辑，几种会导致主备延迟的情况，以及相应的改进方向；可靠性优先和可用性优先策略的区别</p>
<ul>
<li><p>主备延迟：同一个事务，在备库执行完成的时间和主库执行完成的时间之间的差值；主备库机器的系统时间设置不一致，不会导致主备延迟的值不准（备库在执行<br>seconds_behind_master 计算的时候会自动扣掉与主库的系统时间的差值）；网络正常情况下，主备延迟的主要来源是备库接收完 binlog 和执行完这个事务之间的时间差；主备延迟最直接的表现是，备库消费中转日志（relay log）的速度，比主库生产binlog 的速度要慢。</p>
</li>
<li><p>主备延迟的来源：1. 有些部署条件下，备库所在机器的性能要比主库所在的机器性能差（更新过程中也会触发大量的读操作，当备库主机上的多个备库都在争抢资源的时候，就可能会导致主备延迟）；2. 备库的压力大（备库上的查询耗费了大量的 CPU 资源，影响了同步速度，一般采用一主多从或者通过 binlog 输出到外部系统）；3. 大事务（主库上必须等事务执行完成才会写入 binlog，典型场景：不要一次性地用 delete 语句删除太多数据；大表DDL）4. 主备延迟还有一个大方向的原因，就是备库的并行复制能力</p>
</li>
<li><p>可靠性优先策略：双 M 结构下主备库的切换首先判断备库的seconds_behind_master是否小于某个值，小于则把主库改为只读状态，然后判断备库的 seconds_behind_master 的值，直到这个值变成 0 ，再将备库 B 改成可读写状态，把业务请求切到备库</p>
<ul>
<li>这个切换流程中是有不可用时间的，在这个不可用状态中，比较耗费时间的是等待备库sbm为0，可能需要耗费好几秒的时间。这也是为什么先做判断，确保 seconds_behind_master 的值足够小</li>
</ul>
</li>
<li><p>可用性优先策略：不等主备数据同步，直接把连接切到备库 ，并且让备库可以读写，那么系统几乎就没有不可用时间了，如果binlog_format&#x3D;mixed可能会导致主备数据不一致，如果设置 binlog_format&#x3D;row，两边的主备同步的应用线程会报错 duplicate key error 并停止</p>
<ul>
<li>使用 row 格式的 binlog 时，数据不一致的问题更容易被发现</li>
<li>有没有哪种情况数据的可用性优先级更高呢？：如果数据不一致可以通过 binlog 来修补，而这个短暂的不一致也不会引发业务问题，且业务系统依赖于这个库的写入逻辑，如果这个库不可写，会导致线上的业务操作无法执行</li>
</ul>
</li>
<li><p>在满足数据可靠性的前提下，MySQL 高可用系统的可用性，是依赖于主备延迟的。延迟的时间越小，在主库故障的时候，服务恢复需要的时间就越短，可用性就越高</p>
</li>
</ul>
</li>
<li><p>第26讲复习，介绍MySQL的各种多线程复制策略，单线程复制的能力全面低于多线程复制，对于更新压力较大的主库，备库是可能一直追不上主库的</p>
<ul>
<li><p>主备的并行复制能力要关注的是客户端写入主库和备库上 sql_thread 执行中转日志（relay log）。在主库上，影响并发度的原因就是各种锁了。由于 InnoDB 引擎支持行锁，除了所有并发事务都在更新同一行（热点行）这种极端场景外，它对业务并发度的支持还是很友好的；而日志在备库上的执行，如果是用单线程的话，就会导致备库应用日志不够快，造成主备延迟</p>
</li>
<li><p>coordinator 就是原来的 sql_thread, 不过现在它不再直接更新数据了，只负责读取中转日志和分发事务。真正更新日志的，变成了 worker 线程。而 work 线程的个数，就是由参数 slave_parallel_workers 决定的</p>
</li>
<li><p>coordinator 在分发的时候，需要满足以下这两个基本要求：</p>
<ul>
<li><p>不能造成更新覆盖。这就要求更新同一行的两个事务，必须被分发到同一个 worker中。</p>
</li>
<li><p>同一个事务不能被拆开，必须放到同一个 worker 中。</p>
</li>
</ul>
</li>
<li><p><strong>MySQL 5.5 版本的并行复制策略</strong>：官方是不支持并行复制的，主要根据业务需求自己做的按表分发策略和按行分发策略</p>
<ul>
<li><p><strong>按表分发事务</strong>的基本思路是，如果两个事务更新不同的表，它们就可以并行。因为数据是存储在表里的，所以按表分发，可以保证两个 worker 不会更新同一行。当然，如果有跨表的事务，还是要把两张表放在一起考虑的；每个 worker 线程对应一个 hash 表，用于保存当前正在这个 worker 的“执行队列”里的事务所涉及的表。hash 表的 key 是“库名. 表名”，value 是一个数字，表示队列中有多少个事务修改这个表；每个事务在分发的时候，跟所有 worker 的冲突关系包括以下三种情况：</p>
<ol>
<li>如果跟所有 worker 都不冲突，coordinator 线程就会把这个事务分配给最空闲的woker;</li>
<li>如果跟多于一个 worker 冲突，coordinator 线程就进入等待状态，直到和这个事务存在冲突关系的 worker 只剩下 1 个；</li>
<li>如果只跟一个 worker 冲突，coordinator 线程就会把这个事务分配给这个存在冲突关系的 worker。</li>
</ol>
<p>按表分发的方案，在多个表负载均匀的场景里应用效果很好。但是，如果碰到热点表，比如所有的更新事务都会涉及到某一个表的时候，所有事务都会被分配到同一个 worker中，就变成单线程复制</p>
</li>
<li><p><strong>按行复制</strong>的核心思路是：如果两个事务没有更新相同的行，它们在备库上可以并行执行，这个模式要求binlog 格式必须是 row。为每个 worker，分配一个 hash 表。只是要实现按行分发，这时候的 key，就必须是“库名 + 表名 + 唯一键的值”。这个“唯一键”只有主键 id 还是不够的，还需要考虑唯一键；相比于按表并行分发策略，按行并行策略在决定线程分发的时候，需要消耗更多的计算资源</p>
</li>
<li><p>这两个方案其实都有一些约束条件：</p>
<ol>
<li>要能够从 binlog 里面解析出表名、主键值和唯一索引的值。也就是说，主库的 binlog格式必须是 row；</li>
<li>表必须有主键；</li>
<li>不能有外键。表上如果有外键，级联更新的行不会记录在 binlog 中，这样冲突检测就不准确。</li>
</ol>
</li>
<li><p>对比按表分发和按行分发这两个方案的话，按行分发策略的并行度更高。不过，如果是要操作很多行的大事务的话，按行分发的策略有两个问题：耗费内存和耗费 CPU（解析 binlog，然后计算 hash 值，对于大事务，这个成本还是很高的）</p>
</li>
</ul>
</li>
<li><p><strong>MySQL 5.6 版本的并行复制策略</strong>：官方 MySQL5.6 版本，支持了并行复制，只是支持的粒度是按库并行；这个策略的并行效果，取决于压力模型。如果在主库上有多个 DB，并且各个 DB 的压力均衡，使用这个策略的效果会很好；相比于按表和按行分发，这个策略有两个优势：</p>
<ol>
<li>构造 hash 值的时候很快，只需要库名；而且一个实例上 DB 数也不会很多，不会出现需要构造 100 万个项这种情况。</li>
<li>不要求 binlog 的格式。因为 statement 格式的 binlog 也可以很容易拿到库名。</li>
</ol>
<p>但是，如果主库上的表都放在同一个 DB 里面，这个策略就没有效果了；或者如果不同DB 的热点不同，比如一个是业务逻辑库，一个是系统配置库，那也起不到并行的效果</p>
</li>
<li><p><strong>MariaDB 的并行复制策略：</strong>利用了redo log 组提交 (group commit) 优化的特性：</p>
<ul>
<li>能够在同一组里提交的事务，一定不会修改同一行；</li>
<li>主库上可以并行执行的事务，备库上也一定是可以并行执行的。</li>
</ul>
<p>之前业界的思路都是在“分析 binlog，并拆分到 worker”上。而 MariaDB 的这个策略，目标是“模拟主库的并行模式“，但它并没有实现“真正的模拟主库并发度”这个目标，在备库上执行的时候，要等第一组事务完全执行完成后，第二组事务才能开始执行，这样系统的吞吐量就不够；另外，这个方案很容易被大事务拖后腿</p>
</li>
<li><p><strong>MySQL 5.7 的并行复制策略</strong>：同时处于 prepare 状态的事务，在备库执行时是可以并行的；处于 prepare 状态的事务，与处于 commit 状态的事务之间，在备库执行时也是可以并行的。利用binlog 的组提交的两个参数用来制造更多的“同时处于 prepare 阶段的事务”。这样就增加了备库复制的并行度</p>
</li>
<li><p><strong>MySQL 5.7.22 的并行复制策略</strong>：基于 WRITESET 的并行复制，新增了一个参数 binlog-transaction-dependency-tracking，用来控制是否启用这个新策略。这个参数的可选值有以下三种：</p>
<ul>
<li>COMMIT_ORDER，表示的就是前面介绍的，根据同时进入 prepare 和 commit 来判断是否可以并行的策略。</li>
<li>WRITESET，表示的是对于事务涉及更新的每一行，计算出这一行的 hash 值，组成集合writeset。如果两个事务没有操作相同的行，也就是说它们的 writeset 没有交集，就可以并行。</li>
<li>WRITESET_SESSION，是在 WRITESET 的基础上多了一个约束，即在主库上同一个线程先后执行的两个事务，在备库执行的时候，要保证相同的先后顺序。</li>
</ul>
<p>跟基于 MySQL 5.5 版本的按行分发的策略是差不多的。不过，MySQL 官方的这个实现还是有很大的优势：</p>
<ul>
<li>writeset 是在主库生成后直接写入到 binlog 里面的，这样在备库执行的时候，不需要解析 binlog 内容（event 里的行数据），节省了很多计算量；</li>
<li>不需要把整个事务的 binlog 都扫一遍才能决定分发到哪个 worker，更省内存；</li>
<li>由于备库的分发策略不依赖于 binlog 内容，所以 binlog 是 statement 格式也是可以的。</li>
</ul>
<p>对于“表上没主键”和“外键约束”的场景，WRITESET 策略也是没法并行的，也会暂时退化为单线程模型。</p>
</li>
<li><p>大事务不仅会影响到主库，也是造成备库复制延迟的主要原因之一。因此，在平时的开发工作中，建议尽量减少大事务操作，把大事务拆成小事务。官方 MySQL5.7 版本新增的备库并行策略，修改了 binlog 的内容，也就是说 binlog 协议并不是向上兼容的，在主备切换、版本升级的时候需要把这个因素也考虑进</p>
</li>
<li><p>什么情况下，备库的主备延迟会表现为一个 45 度的线段？</p>
<ul>
<li>一种是大事务（包括大表 DDL、一个事务操作很多行）；</li>
<li>还有一种情况比较隐蔽，就是备库起了一个长事务，这时候主库对表 做了一个加字段操作，即使这个表很小，这个 DDL 在备库应用的时候也<br>会被堵住，也不能看到这个现象</li>
</ul>
</li>
</ul>
</li>
<li><p>第27讲复习，一主多从的主备切换流程，为了解决从库找新主库的位点的痛点问题，引入了 GTID 模式</p>
<ul>
<li><p>一主多从的设置，一般用于读写分离，主库负责所有的写入和一部分读，其他的读请求则由从库分担。在一主多从架构下，主库故障后就需要发生主备切换，相比一主一备的切换流程多了从库重新指向的这个过程，所以主备切换的复杂性也相应增加了</p>
</li>
<li><p><strong>基于位点的主备切换：</strong>需要同步主库对应的文件名和日志偏移量（同步位点），这个位点很难精确取到，只能取一个大概位置；考虑到切换过程中不能丢数据，所以找位点的时候，总是要找一个“稍微往前”的，然后再通过判断跳过那些在从库 B 上已经执行过的事务；然而如果在主库传完binlog给备库和从库后立马崩溃了，就会导致从库同步线程出现了主键冲突，然后停止同步。通常情况下，在切换任务的时候，要先主动跳过这些错误，有两种常用的方法：</p>
<ul>
<li>主动跳过一个事务，可能会不止重复执行一个事务，所以需要在从库刚开始接到新主库时，持续观察，每次碰到这些错误就停下来，执行一次跳过命令，直到不再出现停下来的情况，以此来跳过可能涉及的所有事务</li>
<li>设置 slave_skip_errors 参数，直接设置跳过指定的错误；在执行主备切换时经常会遇到两类错误：1062 错误是插入数据时唯一键冲突；1032 错误是删除数据时找不到行。可以把 slave_skip_errors 设置为 “1032,1062”，这样中间碰到这两个错误时就直接跳过（需要确定是无损的）。执行一段时间之后，还需要把这个参数设置为空</li>
</ul>
</li>
<li><p><strong>GTID</strong> 的全称是 Global Transaction Identifier，也就是全局事务 ID，是一个事务在提交的时候生成的，是这个事务的唯一标识。它由两部分组成，格式是：</p>
<ul>
<li>server_uuid 是一个实例第一次启动时自动生成的，是一个全局唯一的值；</li>
<li>gno 是一个整数，初始值是 1，每次提交事务的时候分配给这个事务，并加 1</li>
</ul>
<p>MySQL 里面的transaction_id 就是指事务 id，其是在事务执行过程中分配的，如果这个事务回滚了，事务 id 也会递增，而 gno 是在事务提交的时候才会分配，从效果上看，GTID 往往是连续的，因此用 gno 来表示更容易理解</p>
</li>
<li><p>在 GTID 模式下，每个事务都会跟一个 GTID 一一对应。这个 GTID 有两种生成方式，而使用哪种方式取决于 session 变量 gtid_next 的值:</p>
<ul>
<li>如果 gtid_next&#x3D;automatic，代表使用默认值</li>
<li>如果 gtid_next 是一个指定的 GTID 的值，那么就有两种可能：<br>a. 如果 current_gtid 已经存在于实例的 GTID 集合中，接下来执行的这个事务会直接被系统忽略；<br>b. 如果 current_gtid 没有存在于实例的 GTID 集合中，就将这个 current_gtid 分配给接下来要执行的事务，也就是说系统不需要给这个事务生成新的 GTID，因此 gno 也不用加 1</li>
<li>一个 current_gtid 只能给一个事务使用。这个事务提交后，如果要执行下一个事务，就要执行 set 命令，把 gtid_next 设置成另外一个 gtid 或者 automatic。每个 MySQL 实例都维护了一个 GTID 集合，用来对应“这个实例执行过的所有事务”</li>
</ul>
</li>
<li><p><strong>基于 GTID 的主备切换</strong>：在基于 GTID 的主备关系里，系统认为只要建立主备关系，就必须保证主库发给备库的日志是完整的。因此，如果实例 B 需要的日志已经不存在，A’就拒绝把日志发给 B；这跟基于位点的主备协议不同。基于位点的协议，是由备库决定的，备库指定哪个位点，主库就发哪个位点，不做日志的完整性判断</p>
</li>
<li><p>GTID 和在线 DDL：业务高峰期的慢查询性能问题，分析到如果是由于索引缺失引起的性能问题，可以通过在线加索引来解决。但是考虑到要避免新增索引对主库性能造成的影响，可以先在备库加索引，然后再切换。在双 M 结构下，备库执行的 DDL 语句也会传给主库，为了避免传回后对主库造成影响，要通过 set sql_log_bin&#x3D;off 关掉 binlog。</p>
</li>
</ul>
</li>
<li><p>第28讲复习，一主多从做读写分离时，可能碰到过期读的原因，以及几种应对的方案</p>
<ul>
<li><p>读写分离的主要目标就是分摊主库的压力；可以由客户端（client）主动做负载均衡，这种模式下一般会把数据库的连接信息放在客户端的连接层，由客户端来选择后端数据库进行查询；也可以在 MySQL 和客户端之间加入一个中间代理层 proxy，客户端只连接proxy， 由 proxy 根据请求类型和上下文决定请求的分发路由</p>
<ul>
<li>客户端直连方案，因为少了一层 proxy 转发，所以查询性能稍微好一点，并且整体架构简单，排查问题更方便。但是由于要了解后端部署细节，所以在出现主备切换、库迁移等操作的时候，客户端都会感知到，并且需要调整数据库连接信息</li>
<li>带 proxy 的架构，对客户端比较友好。客户端不需要关注后端细节，连接维护、后端信息维护等工作，都是由 proxy 完成的。但对后端维护团队的要求会更高</li>
</ul>
</li>
<li><p>由于主从可能存在延迟，客户端执行完一个更新事务后马上发起查询，如果查询选择的是从库的话，就有可能读到刚刚的事务更新之前的状态，称为过期读；</p>
</li>
<li><p><strong>强制走主库方案：</strong>将查询请求做分类，对于必须要拿到最新结果的请求，强制将其发到主库上，对于可以读到旧数据的请求，才将其发到从库上</p>
</li>
<li><p><strong>Sleep 方案</strong>：主库更新后，读从库之前先 sleep 一下。具体的方案就是，类似于执行一条 select sleep(1) 命令，这个方案假设大多数情况下主备延迟在 1 秒之内，做一个 sleep 可以有很大概率拿到最新的数据；这个方案存在的问题就是不精确，如果这个查询请求本来 0.5 秒就可以在从库上拿到正确结果，也会等 1 秒，如果延迟超过 1 秒，还是会出现过期读</p>
</li>
<li><p><strong>判断主备无延迟方案</strong>：</p>
<ul>
<li>show slave status 结果里的seconds_behind_master（单位是秒） 参数的值，可以用来衡量主备延迟时间的长短，因此可以在每次从库执行查询请求前，先判断是否已经等于 0；等到这个参数变为0 才能执行查询请求。</li>
<li><strong>对比位点确保主备无延迟</strong>：如果 Master_Log_File 和 Relay_Master_Log_File、Read_Master_Log_Pos 和Exec_Master_Log_Pos 这两组值完全相同，就表示接收到的日志已经同步完成</li>
<li><strong>对比 GTID 集合确保主备无延迟：</strong>Auto_Position&#x3D;1 ，表示这对主备关系使用了 GTID 协议。Retrieved_Gtid_Set，是备库收到的所有日志的 GTID 集合；Executed_Gtid_Set，是备库所有已经执行完成的 GTID 集合。如果这两个集合相同，也表示备库接收到的日志都已经同步完成</li>
</ul>
</li>
<li><p>一个事务的 binlog 在主备库之间的状态：1.主库执行完成，写入 binlog，并反馈给客户端；2.binlog 被从主库发送给备库，备库收到；3.在备库执行 binlog 完成。有一部分日志，处于客户端已经收到提交确认，而备库还没收到日志的状态。要解决这个问题，就要引入半同步复制，也就是 semi-sync replication。</p>
</li>
<li><p><strong>配合 semi-sync：</strong>semi-sync 做了这样的设计：</p>
<ol>
<li>事务提交的时候，主库把 binlog 发给从库；</li>
<li>从库收到 binlog 以后，发回给主库一个 ack，表示收到了；</li>
<li>主库收到这个 ack 以后，才能给客户端返回“事务完成”的确认。</li>
</ol>
<p>启用了 semi-sync，就表示所有给客户端发送过确认的事务，都确保了备库已经收到了这个日志；semi-sync 配合前面关于位点的判断，就能够确定在从库上执行的查询请求，可以避免过期读。但是semi-sync 配合判断主备无延迟方案，存在两个问题：</p>
<ol>
<li>一主多从的时候，在某些从库执行查询请求会存在过期读的现象；</li>
<li>在持续延迟的情况下，可能出现过度等待的问题。</li>
</ol>
</li>
<li><p><strong>主库位点方案</strong>：<code>select master_pos_wait(file, pos[, timeout])；</code>它是在从库执行的；参数 file 和 pos 指的是主库上的文件名和位置；timeout 可选，设置为正整数 N 表示这个函数最多等待 N 秒</p>
<ul>
<li>这个命令正常返回的结果是一个正整数 M，表示从命令开始执行，到应用完 file 和 pos 表示的 binlog 位置，执行了多少事务。如果执行期间，备库同步线程发生异常，则返回 NULL；如果等待超过 N 秒，就返回 -1；如果刚开始执行的时候，就发现已经执行过这个位置了，则返回 0</li>
<li>如果返回值是 &gt;&#x3D;0 的正整数，则在这个从库执行查询语句；否则，到主库执行查询语句</li>
</ul>
</li>
<li><p><strong>GTID 方案</strong>：<code>select wait_for_executed_gtid_set(gtid_set, 1);</code>等待，直到这个库执行的事务中包含传入的 gtid_set，返回 0；超时返回 1；</p>
<ul>
<li>怎么能够让 MySQL 在执行事务后，返回包中带上 GTID 呢？：只需要将参数 session_track_gtids 设置为 OWN_GTID，然后通过 API 接口mysql_session_track_get_first 从返回包解析出 GTID 的值即可</li>
</ul>
</li>
<li><p>在实际应用中，这几个方案是可以混合使用的。过期读在本质上是由一写多读导致的。在实际应用中，可能会有别的不需要等待就可以水平扩展的数据库方案，但这往往是用牺牲写性能换来的，也就是需要在读性能和写性能中取权衡。</p>
</li>
</ul>
</li>
<li><p>第29讲复习，检测一个 MySQL 实例健康状态的几种方法</p>
<ul>
<li><strong>select 1 判断：</strong>select 1 成功返回，只能说明这个库的进程还在，并不能说明主库没问题；因为在线程进入锁等待以后，并发线程的计数会减一，也就是说等行锁（也包括间隙锁）的线程是不算在 innodb_thread_concurrency 设置的并发线程数里面的；因为进入锁等待的线程已经不吃 CPU 了，而且这么设计才能避免整个系统锁死；但如果它在真正地执行查询还是要算进并发线程的计数的</li>
<li><strong>查表判断</strong>：一般的做法是，在系统库（mysql 库）里创建一个表，比如命名为health_check，里面只放一行数据，然后定期执行；但是空间满了以后，这种方法又会变得不好使</li>
<li><strong>更新判断：</strong>常见做法是放一个 timestamp 字段，用来表示最后一次执行检测的时间；但是，如果主库 A 和备库 B 都用相同的更新命令，就可能出现行冲突，也就是可能会导致主备同步停止。所以 mysql.health_check 这个表就不能只有一行数据了，应存入多行数据，并用 A、B 的 server_id 做主键。不过这依然会存在“判定慢”的问题<ul>
<li>所有的检测逻辑都需要一个超时时间 N。执行一条 update 语句，超过 N 秒后还不返回，就认为系统不可用；但检测使用的 update 命令，需要的资源很少，所以可能在拿到 IO 资源的时候就可以提交成功，并且在超时时间 N 秒未到达之前就返回给了检测系统；</li>
<li>上面说的所有方法，都是基于外部检测的。外部检测天然有一个问题，就是随机性，外部检测都需要定时轮询，所以系统可能已经出问题了，但是却需要等到下一个检测发起执行语句的时候，才有可能发现问题</li>
</ul>
</li>
<li><strong>内部统计</strong>：MySQL 5.6 版本以后提供的 performance_schema 库，就在file_summary_by_event_name 表里统计了每次 IO 请求的时间；每一次操作数据库，performance_schema 都需要额外地统计这些信息，所以打开这个统计功能是有性能损耗的，建议只打开自己需要的项进行统计</li>
</ul>
</li>
</ul>
<h4 id="第30讲，用动态的观点看锁"><a href="#第30讲，用动态的观点看锁" class="headerlink" title="第30讲，用动态的观点看锁"></a>第30讲，用动态的观点看锁</h4><ul>
<li><p>两个“原则”、两个“优化”和一个“bug”：</p>
<ul>
<li>原则 1：加锁的基本单位是 next-key lock。</li>
<li>原则 2：查找过程中访问到的对象才会加锁。</li>
<li>优化 1：索引上的等值查询，给唯一索引加锁的时候，next-key lock 退化为行锁。</li>
<li>优化 2：索引上的等值查询，向右遍历时且最后一个值不满足等值条件的时候，nextkey lock 退化为间隙锁。</li>
<li>一个 bug：唯一索引上的范围查询会访问到不满足条件的第一个值为止。</li>
</ul>
</li>
<li><p>不等号条件里的等值查询：通过树搜索的方式定位记录的时候，用的是“等值查询”的方法</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> t <span class="keyword">where</span> id<span class="operator">&gt;</span><span class="number">9</span> <span class="keyword">and</span> id<span class="operator">&lt;</span><span class="number">12</span> <span class="keyword">order</span> <span class="keyword">by</span> id <span class="keyword">desc</span> <span class="keyword">for</span> <span class="keyword">update</span>;</span><br></pre></td></tr></table></figure>

<ul>
<li>查询语句的语义是 order by id desc，要拿到满足条件的所有行，优化器必须先找到“第一个 id&lt;12 的值”；这个过程是通过索引树的搜索过程得到的，在引擎内部，其实是要找到 id&#x3D;12 的这个值，只是最终没找到，但找到了 (10,15) 这个间隙</li>
<li>然后向左遍历，在遍历过程中，就不是等值查询了，会扫描到 id&#x3D;5 这一行，所以会加一个 next-key lock (0,5]</li>
</ul>
</li>
<li><p>等值查询的过程：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">select</span> id <span class="keyword">from</span> t <span class="keyword">where</span> c <span class="keyword">in</span>(<span class="number">5</span>,<span class="number">20</span>,<span class="number">10</span>) lock <span class="keyword">in</span> share mode;</span><br></pre></td></tr></table></figure>

<ul>
<li>这条语句在索引 c 上加的三个记录锁的顺序是：先加 c&#x3D;5的记录锁，再加 c&#x3D;10 的记录锁，最后加 c&#x3D;20 的记录锁</li>
<li>这些锁是“在执行过程中一个一个加的”，而不是一次性加上去的。</li>
</ul>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">select</span> id <span class="keyword">from</span> t <span class="keyword">where</span> c <span class="keyword">in</span>(<span class="number">5</span>,<span class="number">20</span>,<span class="number">10</span>) <span class="keyword">order</span> <span class="keyword">by</span> c <span class="keyword">desc</span> <span class="keyword">for</span> <span class="keyword">update</span>;</span><br></pre></td></tr></table></figure>

<ul>
<li>由于语句里面是 order by c desc， 这三个记录锁的加锁顺序，是先锁 c&#x3D;20，然后 c&#x3D;10，最后是 c&#x3D;5</li>
<li>也就是说，这两条语句要加锁相同的资源，但是加锁顺序相反。当这两条语句并发执行的时候，就可能出现死锁</li>
</ul>
</li>
<li><p>怎么看死锁？</p>
<ul>
<li>执行 show engine innodb status 命令得到的部分输出里的LATESTDETECTED DEADLOCK，就是记录的最后一次死锁信息</li>
<li>由于锁是一个个加的，要避免死锁，对同一组资源，要按照尽量相同的顺序访问；</li>
<li>在发生死锁的时刻，for update 这条语句占有的资源更多，回滚成本更大，所以InnoDB 选择了回滚成本更小的 lock in share mode 语句，来回滚。</li>
</ul>
</li>
<li><p>怎么看锁等待？</p>
<ul>
<li>show engine innodb status 的结果，锁信息是在这个命令输出结果的 TRANSACTIONS 这一节</li>
<li>所谓“间隙”，其实根本就是由“这个间隙右边的那个记录”定义的。（可能由于记录的删除导致锁的范围突然扩大）</li>
</ul>
</li>
<li><p>一个空表就只有一个间隙，加锁的范围就是 next-key lock (-∞, supremum]</p>
</li>
</ul>
<h4 id="31-误删数据后除了跑路，还能怎么办？"><a href="#31-误删数据后除了跑路，还能怎么办？" class="headerlink" title="31 | 误删数据后除了跑路，还能怎么办？"></a>31 | 误删数据后除了跑路，还能怎么办？</h4><ul>
<li>使用 delete 语句误删数据行；<ul>
<li>可以用 Flashback 工具通过闪回把数据恢复回来，修改 binlog 的内容，拿回原库重放。而能够使用这个方案的前提是，需要确保 binlog_format&#x3D;row 和 binlog_row_image&#x3D;FULL</li>
<li>如果误删数据涉及到了多个事务的话，需要将事务的顺序调过来再执行</li>
<li>不建议你直接在主库上执行这些操作，因为一个在执行线上逻辑的主库，数据状态的变更往往是有关联的。恢复数据比较安全的做法，是恢复出一个备份，或者找一个从库作为临时库，在这个临时库上执行这些操作，然后再将确认过的临时库的数据，恢复回主库</li>
<li>事前预防：<ul>
<li>把 sql_safe_updates 参数设置为 on；忘记在 delete 或者 update语句中写 where 条件，或者 where 条件里面没有包含索引字段的话，这条语句的执行<br>就会报错</li>
<li>代码上线前，必须经过 SQL 审计</li>
</ul>
</li>
<li>delete 全表是很慢的，需要生成回滚日志、写 redo、写 binlog。所以，从性能角度考虑，应该优先考虑使用 truncate table 或者 drop table 命令。</li>
</ul>
</li>
<li>使用 drop table 或者 truncate table 语句误删数据表；<ul>
<li>即使配置了 binlog_format&#x3D;row，执行这三个命令时，记录的 binlog 还是 statement 格式。binlog 里面就只有一个 truncate&#x2F;drop 语句，这些信息是恢复不出数据的。</li>
</ul>
</li>
<li>使用 drop database 语句误删数据库；<ul>
<li>这种情况下，要想恢复数据，就需要使用全量备份，加增量日志的方式</li>
<li>使用 mysqlbinlog 方法恢复数据还是不够快，主要原因有两个：<ul>
<li>如果是误删表，最好就是只恢复出这张表，也就是只重放这张表的操作，但是mysqlbinlog 工具并不能指定只解析一个表的日志；</li>
<li>用 mysqlbinlog 解析出日志应用，应用日志的过程就只能是单线程</li>
</ul>
</li>
<li>一种加速的方法是，在用备份恢复出临时实例之后，将这个临时实例设置成线上备库的从库</li>
<li>虽然我们可以通过利用并行复制来加速恢复数据的过程，但是这个方案仍然存在“恢复时间不可控”的问题。<strong>可以考虑搭建延迟复制的备库</strong></li>
<li>一般的主备复制结构存在的问题是，如果主库上有个表被误删了，这个命令很快也会被发给所有从库，进而导致所有从库的数据表也都一起被误删了;延迟复制的备库是一种特殊的备库，通过 CHANGE MASTER TO MASTER_DELAY &#x3D; N 命令，可以指定这个备库持续保持跟主库有 N 秒的延迟。</li>
</ul>
</li>
<li>使用 rm 命令误删整个 MySQL 实例<ul>
<li>只要不是恶意地把整个集群删除，而只是删掉了其中某一个节点的数据的话，HA 系统就会开始工作，选出一个新的主库，从而保证整个集群的正常工作</li>
<li>只需要在这个节点上把数据恢复回来，再接入整个集群。</li>
</ul>
</li>
</ul>
<h4 id="32-为什么还有kill不掉的语句？"><a href="#32-为什么还有kill不掉的语句？" class="headerlink" title="32 | 为什么还有kill不掉的语句？"></a>32 | 为什么还有kill不掉的语句？</h4><ul>
<li><p>在 MySQL 中有两个 kill 命令：一个是 kill query + 线程 id，表示终止这个线程中正在执行的语句；一个是 kill connection + 线程 id，这里 connection 可缺省，表示断开这个线程的连接，当然如果这个线程有语句正在执行，也是要先停止正在执行的语句的</p>
<ul>
<li>使用了 kill 命令，却没能断开这个连接。再执行 show processlist 命令，看到这条语句的 Command 列显示的是Killed</li>
<li>大多数情况下，kill query&#x2F;connection 命令是有效的。比如，执行一个查询的过程中，发现执行时间太久，要放弃继续查询，这时我们就可以用 kill query 命令，终止这条查询语句</li>
<li>语句处于锁等待的时候，直接使用 kill 命令也是有效的</li>
</ul>
</li>
<li><p>收到 kill 以后，线程做什么？</p>
<ul>
<li>当对一个表做增删改查操作时，会在表上加 MDL 读锁。所以，session B 虽然处于 blocked 状态(死锁)，但还是拿着一个 MDL 读锁的。如果线程被 kill 的时候，就直接终止，那之后这个 MDL 读锁就没机会被释放了</li>
<li>kill 并不是马上停止的意思，而是告诉执行线程说，这条语句已经不需要继续执行了，可以开始“执行停止的逻辑了（跟 Linux 的 kill 命令类似，kill -N pid 并不是让进程直接停止，而是给进程发一个信号，然后进程处理这个信号，进入终止逻辑）</li>
<li>实现上，当用户执行 kill query thread_id_B 时，MySQL 里处理 kill 命令的线程做了两件事：<ul>
<li>把 session B 的运行状态改成 THD::KILL_QUERY</li>
<li>给 session B 的执行线程发一个信号</li>
</ul>
</li>
<li>一个语句执行过程中有多处“埋点”，在这些“埋点”的地方判断线程状态，如果发现线程状态是 THD::KILL_QUERY，才开始进入语句终止逻辑</li>
<li>如果处于等待状态，必须是一个可以被唤醒的等待，否则根本不会执行到“埋点”处；</li>
<li>语句从开始进入终止逻辑，到终止逻辑完全完成，是有一个过程的</li>
</ul>
</li>
<li><p>执行 show processlist 的时候，有一个特别的逻辑：如果一个线程的状态是 KILL_CONNECTION，就把 Command 列显示成 Killed。即使是客户端退出了，这个线程的状态仍然是在等待中</p>
</li>
<li><p>kill 无效的情况</p>
<ul>
<li>线程没有执行到判断线程状态的逻辑；</li>
<li>终止逻辑耗时较长。<ul>
<li>超大事务执行期间被 kill。这时候，回滚操作需要对事务执行期间生成的所有新数据版本做回收操作，耗时很长。</li>
<li>大查询回滚。如果查询过程中生成了比较大的临时文件，加上此时文件系统压力大，删除临时文件可能需要等待 IO 资源，导致耗时较长。</li>
<li>DDL 命令执行到最后阶段，如果被 kill，需要删除中间过程的临时文件，也可能受 IO 资源影响耗时较久。</li>
</ul>
</li>
<li>发现一个线程处于 Killed 状态，可以做的事情就是，通过影响系统环境，让这个 Killed 状态尽快结束</li>
</ul>
</li>
<li><p>两个关于客户端的误解</p>
<ul>
<li><p>如果库里面的表特别多，连接就会很慢</p>
<ul>
<li>每个客户端在和服务端建立连接的时候，需要做的事情就是 TCP握手、用户校验、获取权限。但这几个操作，显然跟库里面表的个数无关</li>
<li>当使用默认参数连接的时候，MySQL 客户端会提供一个本地库名和表名补全的功能。为了实现这个功能，客户端在连接成功后，需要多做一些操作，其中在本地构建哈希表的操作耗时较长</li>
</ul>
<p>感知到的连接过程慢，其实并不是连接慢，也不是服务端慢，而是客户端慢</p>
<ul>
<li>如果自动补全功能用得并不多，建议你每次使用的时候都默认加 -A；</li>
</ul>
</li>
<li><p>加–quick(或者简写为 -q) 参数，也可以跳过这个阶段。但是，这个–quick 是一个更容易引起误会的参数，也是关于客户端常见的一个误解。</p>
</li>
<li><p>MySQL 客户端发送请求后，接收服务端返回结果的方式有两种：</p>
<ol>
<li>一种是本地缓存，也就是在本地开一片内存，先把结果存起来。如果你用 API 开发，对应的就是 mysql_store_result 方法。</li>
<li>另一种是不缓存，读一个处理一个。如果你用 API 开发，对应的就是 mysql_use_result方法。</li>
</ol>
<p>如果加上–quick 参数，就会使用第二种不缓存的方式。采用不缓存的方式时，如果本地处理得慢，就会导致服务端发送结果被阻塞，因此会让服务端变慢</p>
</li>
</ul>
</li>
</ul>
<h4 id="33-我查这么多数据，会不会把数据库内存打爆？"><a href="#33-我查这么多数据，会不会把数据库内存打爆？" class="headerlink" title="33 | 我查这么多数据，会不会把数据库内存打爆？"></a>33 | 我查这么多数据，会不会把数据库内存打爆？</h4><ul>
<li><p>我的主机内存只有 100G，现在要对一个 200G 的大表做全表扫描，会不会把数据库主机的内存用光了？</p>
<ul>
<li>逻辑备份的时候，可不就是做整库扫描吗？如果这样就会把内存吃光，逻辑备份不是早就挂了</li>
<li>对大表做全表扫描，看来应该是没问题的</li>
</ul>
</li>
<li><p>全表扫描对 server 层的影响</p>
<ul>
<li>InnoDB 的数据是保存在主键索引上的，所以全表扫描实际上是直接扫描表t 的主键索引。这条查询语句由于没有其他的判断条件，所以查到的每一行都可以直接放到结果集里面，然后返回给客户端</li>
<li>实际上，服务端并不需要保存一个完整的结果集。取数据和发数据的流程是这样的：<ul>
<li>获取一行，写到 net_buffer 中,这块内存的大小是由参数 net_buffer_length 定义</li>
<li>重复获取行，直到 net_buffer 写满，调用网络接口发出去。</li>
<li>如果发送成功，就清空 net_buffer，然后继续取下一行，并写入 net_buffer</li>
<li>如果发送函数返回 EAGAIN 或 WSAEWOULDBLOCK，就表示本地网络栈（socket send buffer）写满了，进入等待。直到网络栈重新可写，再继续发送</li>
</ul>
</li>
<li><strong>MySQL 是“边读边发的”</strong>，看到 State 的值一直处于“Sending to client”，就表示服务器端的网络栈写满</li>
<li>对于正常的线上业务来说，如果一个查询的返回结果不会很多的话，都建议你使用mysql_store_result 这个接口，直接把查询结果保存到本地内存</li>
<li>如果你在自己负责维护的 MySQL 里看到很多个线程都处于“Sending to client”这个状态，就意味着你要让业务开发同学优化查询结果</li>
</ul>
</li>
<li><p>与“Sending to client”长相很类似的一个状态是“Sending data”</p>
<ul>
<li>实际上，一个查询语句的状态变化是这样的<ul>
<li>MySQL 查询语句进入执行阶段后，首先把状态设置成“Sending data”；</li>
<li>然后，发送执行结果的列相关的信息（meta data) 给客户端；</li>
<li>再继续执行语句的流程；</li>
<li>执行完成后，把状态设置成空字符串</li>
</ul>
</li>
<li>“Sending data”并不一定是指“正在发送数据”，而可能是处于执行器过程中的任意阶段。比如，你可以构造一个锁等待的场景，就能看到 Sending data 状态。</li>
</ul>
</li>
<li><p>全表扫描对 InnoDB 的影响</p>
<ul>
<li><p>内存的数据页是在 Buffer Pool (BP) 中管理的，在 WAL 里 Buffer Pool 起到了加速更新的作用。而实际上，Buffer Pool 还有一个更重要的作用，就是加速查询；</p>
</li>
<li><p>由于有 WAL 机制，当事务提交的时候，磁盘上的数据页是旧的，那如果这时候马上有一个查询要来读这个数据页，是不是要马上把 redo log应用到数据页呢？</p>
<ul>
<li>不需要。因为这时候内存数据页的结果是最新的，直接读内存页就可以了;查询根本不需要读磁盘，直接从内存拿结果，速度是很快的。</li>
</ul>
</li>
<li><p>而 Buffer Pool 对查询的加速效果，依赖于一个重要的指标，即：内存命中率；可以在 show engine innodb status 结果中，查看一个系统当前的 BP 命中率</p>
</li>
<li><p>innodb_buffer_pool_size 小于磁盘的数据量是很常见的。如果一个 Buffer Pool 满了，而又要从磁盘读入一个数据页，那肯定是要淘汰一个旧数据页的。InnoDB 内存管理用的是最近最少使用 (Least Recently Used, LRU) 算法，这个算法的核心就是淘汰最久未使用的数据。按照传统LRU扫描的话会把当前的 Buffer Pool 里的数据全部淘汰掉，存入扫描过程中访问到的数据页的内容，从而导致Buffer Pool 的内存命中率急剧下降，磁盘压力增加，SQL 语句响应变慢</p>
</li>
<li><p>InnoDB 对 LRU 算法做了改进：</p>
<ul>
<li>在 InnoDB 实现上，按照 5:3 的比例把整个 LRU 链表分成了 young 区域和 old 区域；处于 old 区域的数据页，每次被访问的时候都要做下面这个判断：</li>
<li>若这个数据页在 LRU 链表中存在的时间超过了 1 秒，就把它移动到链表头部；</li>
<li>如果这个数据页在 LRU 链表中存在的时间短于 1 秒，位置保持不变。1 秒这个时间，是由参数 innodb_old_blocks_time 控制的。其默认值是 1000，单位毫秒</li>
</ul>
</li>
<li><p>虽然也用到了 Buffer Pool，但是对 young 区域完全没有影响，从而保证了 Buffer Pool 响应正常业务的查询命中率</p>
</li>
</ul>
</li>
</ul>
<h4 id="34-到底可不可以使用join？"><a href="#34-到底可不可以使用join？" class="headerlink" title="34 | 到底可不可以使用join？"></a>34 | 到底可不可以使用join？</h4><ul>
<li><p>Index Nested-Loop Join：在形式上，这个过程就跟写程序时的嵌套查询类似，并且可以用上被驱动表的索引，简称 NLJ；假设驱动表的行数是 N，执行过程就要扫描驱动表 N 行，然后对于每一行，到被驱动表上匹配一次。显然，N 对扫描行数的影响更大，因此应该让小表来做驱动表。</p>
</li>
<li><p>对于“可以使用被驱动表的索引”，使用 join 语句，性能比强行拆成多个单表执行 SQL 语句的性能要好；如果使用 join 语句的话，需要让小表做驱动表。</p>
</li>
<li><p>Simple Nested-Loop Join，对于被驱动表没有索引的情况，会对其进行全表扫描，复杂度很高</p>
</li>
<li><p>Block Nested-Loop Join，算法的流程是这样的：</p>
<ul>
<li>表 t1 的数据读入线程内存 join_buffer 中，由于我们这个语句中写的是 select *，因此是把整个表 t1 放入了内存；</li>
<li>扫描表 t2，把表 t2 中的每一行取出来，跟 join_buffer 中的数据做对比，满足 join 条件的，作为结果集的一部分返回。</li>
<li>Block Nested-Loop Join算法的判断是内存操作，速度上会快很多，性能也更好</li>
<li>选择大表还是小表做驱动表，执行耗时是一样的。如果放不下表 t1的所有数据话就分段放。内存判断次数是不受选择哪个表作为驱动表影响的。而考虑到扫描行数，在 M 和 N大小确定的情况下，N 小一些，整个算式的结果会更小。所以结论是，应该让小表当驱动表</li>
</ul>
</li>
<li><p>如果使用 Block Nested-Loop Join 算法，扫描行数就会过多。尤其是在大表上的 join操作，这样可能要扫描被驱动表很多次，会占用大量的系统资源。所以这种 join 尽量不要用。在判断要不要使用 join 语句时，就是看 explain 结果里面，Extra 字段里面有没有出现“Block Nested Loop”字样</p>
</li>
<li><p>如果要使用 join，应该选择大表做驱动表还是选择小表做驱动表？</p>
<ul>
<li>如果是 Index Nested-Loop Join 算法，应该选择小表做驱动表；</li>
<li>如果是 Block Nested-Loop Join 算法：<ul>
<li>在 join_buffer_size 足够大的时候，是一样的；</li>
<li>在 join_buffer_size 不够大的时候（这种情况更常见），应该选择小表做驱动表。</li>
</ul>
</li>
</ul>
</li>
<li><p>在 join_buffer_size 足够大的时候，是一样的；<br>在 join_buffer_size 不够大的时候（这种情况更常见），应该选择小表做驱动表。</p>
</li>
<li><p>在决定哪个表做驱动表的时候，应该是两个表按照各自的条件过滤，过滤完成之后，计算参与 join 的各个字段的总数据量，数据量小的那个表，就是“小表”，应该作为驱动表。</p>
</li>
</ul>
<h4 id="35-join语句怎么优化？"><a href="#35-join语句怎么优化？" class="headerlink" title="35 | join语句怎么优化？"></a>35 | join语句怎么优化？</h4><ul>
<li><p>Multi-Range Read 优化 (MRR)。这个优化的主要目的是尽量使用顺序读盘。因为大多数的数据都是按照主键递增顺序插入得到的，所以我们可以认为，如果按照主键的递增顺序查询的话，对磁盘的读比较接近顺序读，能够提升读性能；语句的执行流程变成了这样：</p>
<ol>
<li>根据索引 a，定位到满足条件的记录，将 id 值放入 read_rnd_buffer 中 ;</li>
<li>将 read_rnd_buffer 中的 id 进行递增排序；</li>
<li>排序后的 id 数组，依次到主键 id 索引中查记录，并作为结果返回。</li>
</ol>
</li>
<li><p>MRR 能够提升性能的核心在于，这条查询语句在索引 a 上做的是一个范围查询（也就是说，这是一个多值查询），可以得到足够多的主键 id。这样通过排序以后，再去主键索引查数据，才能体现出“顺序性”的优势。</p>
</li>
<li><p>MySQL 在 5.6 版本后开始引入的 Batched Key Access(BKA) 算法了。这个 BKA 算法，其实就是对 NLJ 算法的优化。</p>
<ul>
<li>NLJ 算法执行的逻辑是：从驱动表 t1，一行行地取出 a 的值，再到被驱动表 t2 去做join。也就是说，对于表 t2 来说，每次都是匹配一个值。这时，MRR 的优势就用不上了。</li>
<li>既然如此，就把表 t1 的数据取出来一部分，先放到一个临时内存join_buffer；join_buffer 在 BNL 算法里的作用，是暂存驱动表的数据</li>
</ul>
</li>
<li><p>使用 Block Nested-Loop Join(BNL) 算法时，可能会对被驱动表做多次扫描。如果这个被驱动表是一个大的冷数据表，除了会导致IO 压力大以外，这个语句执行时间超过 1 秒，就会在再次扫描冷表的时候，把冷表的数据页移到 LRU 链表头部；如果这个冷表很大，就会出现另外一种情况：业务正常访问的数据页，没有机会进入young 区域；大表 join 操作虽然对 IO 有影响，但是在语句执行结束后，对 IO 的影响也就结束了。但是，对 Buffer Pool 的影响就是持续性的，需要依靠后续的查询请求慢慢恢复内存命中率。</p>
</li>
<li><p>优化的常见做法是，给被驱动表的 join 字段加上索引，把 BNL 算法转成 BKA 算法。可以直接在被驱动表上建索引，对于一些不适合在被驱动表上建索引的情况可以考虑使用临时表；不论是在原表上加索引，还是用有索引的临时表，我们的思路都是让 join 语句能够用上被驱动表上的索引，来触发 BKA 算法，提升查询性能</p>
</li>
<li><p>MySQL 目前的版本还不支持 hash join，但可以配合应用端自己模拟出来，理论上效果要好于临时表的方案。</p>
</li>
</ul>
<h4 id="36-为什么临时表可以重名？"><a href="#36-为什么临时表可以重名？" class="headerlink" title="36 | 为什么临时表可以重名？"></a>36 | 为什么临时表可以重名？</h4><ul>
<li><p>内存表，指的是使用 Memory 引擎的表，建表语法是 create table …engine&#x3D;memory。这种表的数据都保存在内存里，系统重启的时候会被清空，但是表结构还在；而临时表，可以使用各种引擎类型 。如果是使用 InnoDB 引擎或者 MyISAM 引擎的临时表，写数据的时候是写到磁盘上的。当然，临时表也可以使用 Memory 引擎。</p>
</li>
<li><p>临时表的特性：</p>
<ul>
<li>建表语法是 create temporary table …。</li>
<li>一个临时表只能被创建它的 session 访问，对其他线程不可见。所以在这个 session 结束的时候，会自动删除临时表。也正是由于这个特性，临时表就特别适合join 优化这种场景<ul>
<li>不同 session 的临时表是可以重名的，如果有多个 session 同时执行 join 优化，不需要担心表名重复导致建表失败的问题。</li>
<li>不需要担心数据删除问题。如果使用普通表，在流程执行过程中客户端发生了异常断开，或者数据库发生异常重启，还需要专门来清理中间过程中生成的数据表。而临时表由于会自动回收，所以不需要这个额外的操作</li>
</ul>
</li>
<li>临时表可以与普通表同名。</li>
<li>session A 内有同名的临时表和普通表的时候，show create 语句，以及增删改查语句访<br>问的是临时表。</li>
<li>show tables 命令不显示临时表。</li>
</ul>
</li>
<li><p>由于不用担心线程之间的重名冲突，临时表经常会被用在复杂查询的优化过程中。其中，分库分表系统的跨库查询就是一个典型的使用场景。一般分库分表的场景，就是要把一个逻辑上的大表分散到不同的数据库实例上</p>
<ul>
<li>由于查询条件里面没有用到分区字段 f，只能到所有的分区中去查找满足条件的所有行，然后统一做 order by 的操作；第一种思路是，在 proxy 层的进程代码中实现排序。这种方式的优势是处理速度快，拿到分库的数据以后，直接在内存中参与计算。另一种思路就是，把各个分库拿到的数据，汇总到一个 MySQL 实例的一个表中，然后在这个汇总实例上做逻辑操作</li>
</ul>
</li>
<li><p>为什么临时表可以重名？</p>
<ul>
<li>MySQL 要给InnoDB 表创建一个 frm 文件保存表结构定义，还要有地方保存表数据。这个 frm 文件放在临时文件目录下，文件名的后缀是.frm，前缀是“#sql{进程 id}_{线程id}_ 序列号”</li>
<li>MySQL 维护数据表，除了物理上要有文件外，内存里面也有一套机制区别不同的表，每个表都对应一个 table_def_key。一个普通表的 table_def_key 的值是由“库名 + 表名”得到的而对于临时表，table_def_key 在“库名 + 表名”基础上，又加入了“server_id+thread_id”。</li>
</ul>
</li>
<li><p>在 session 结束的时候，对链表里的每个临时表，执行 “DROP TEMPORARY TABLE + 表名”操作，binlog 中也记录了 DROP TEMPORARY TABLE 这条命令</p>
<ul>
<li>如果关于临时表的操作都不记录，那么在备库就只有 create table t_normal 表和 insert into t_normal select * from temp_t 这两个语句的 binlog 日志，备库在执行到 insert into t_normal 的时候，就会报错“表 temp_t 不存在”</li>
<li>如果当前的 binlog_format&#x3D;row，那么跟临时表有关的语句，就不会记录到binlog 里。也就是说，只在 binlog_format&#x3D;statment&#x2F;mixed 的时候，binlog 中才会记录临时表的操作。</li>
<li>drop table 命令记录 binlog 的时候，就必须对语句做改写。“&#x2F;* generated by server *&#x2F;”说明了这是一个被服务端改写过的命令。</li>
</ul>
</li>
<li><p>主库上不同的线程创建同名的临时表是没关系的，但是传到备库执行是怎么处理的呢？</p>
<ul>
<li>MySQL 在记录 binlog 的时候，会把主库执行这个语句的线程 id 写到 binlog 中。这样，在备库的应用线程就能够知道执行每个语句的主库线程 id，并利用这个线程 id 来构造临时表的 table_def_key</li>
<li>由于 table_def_key 不同，所以这两个表在备库的应用线程里面是不会冲突的</li>
</ul>
</li>
</ul>
<h4 id="37-什么时候会使用内部临时表？"><a href="#37-什么时候会使用内部临时表？" class="headerlink" title="37 | 什么时候会使用内部临时表？"></a>37 | 什么时候会使用内部临时表？</h4><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">(<span class="keyword">select</span> <span class="number">1000</span> <span class="keyword">as</span> f) <span class="keyword">union</span> (<span class="keyword">select</span> id <span class="keyword">from</span> t1 <span class="keyword">order</span> <span class="keyword">by</span> id <span class="keyword">desc</span> limit <span class="number">2</span>);</span><br></pre></td></tr></table></figure>

<ul>
<li>这个语句的执行流程是这样的：<ol>
<li>创建一个内存临时表，这个临时表只有一个整型字段 f，并且 f 是主键字段。</li>
<li>执行第一个子查询，得到 1000 这个值，并存入临时表中。</li>
<li>执行第二个子查询：拿到第一行 id&#x3D;1000，试图插入临时表中。但由于 1000 这个值已经存在于临时表了，违反了唯一性约束，所以插入失败，然后继续执行；取到第二行 id&#x3D;999，插入临时表成功。</li>
<li>从临时表中按行取出数据，返回结果，并删除临时表，结果中包含两行数据分别是 1000<br>和 999。</li>
</ol>
</li>
</ul>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">select</span> id<span class="operator">%</span><span class="number">10</span> <span class="keyword">as</span> m, <span class="built_in">count</span>(<span class="operator">*</span>) <span class="keyword">as</span> c <span class="keyword">from</span> t1 <span class="keyword">group</span> <span class="keyword">by</span> m;</span><br></pre></td></tr></table></figure>

<ul>
<li><p>这个语句的执行流程是这样的：</p>
<ol>
<li><p>创建内存临时表，表里有两个字段 m 和 c，主键是 m；</p>
</li>
<li><p>扫描表 t1 的索引 a，依次取出叶子节点上的 id 值，计算 id%10 的结果，记为 x；</p>
<p>如果临时表中没有主键为 x 的行，就插入一个记录 (x,1);<br>如果表中有主键为 x 的行，就将 x 这一行的 c 值加 1；</p>
</li>
<li><p>遍历完成后，再根据字段 m 做排序，得到结果集返回给客户端。</p>
</li>
</ol>
</li>
<li><p>不论是使用内存临时表还是磁盘临时表，group by 逻辑都需要构造一个带唯一索引的表，执行代价都是比较高的。如果表的数据量比较大， group by 语句执行起来就会很慢；如果可以确保输入的数据是有序的，那么计算 group by 的时候，就只需要从左到右，顺序扫描，依次累加</p>
</li>
<li><p>在 group by 语句中加入 SQL_BIG_RESULT 这个提示（hint），就可以告诉优化器：这个语句涉及的数据量很大，请直接用磁盘临时表；MySQL 的优化器一看，磁盘临时表是 B+ 树存储，存储效率不如数组来得高。既然数据量很大，从磁盘空间考虑直接用数组来存</p>
</li>
<li><p>MySQL 什么时候会使用内部临时表？</p>
<ol>
<li>如果语句执行过程可以一边读数据，一边直接得到结果，是不需要额外内存的，否则就需要额外的内存，来保存中间结果；</li>
<li>join_buffer 是无序数组，sort_buffer 是有序数组，临时表是二维表结构；</li>
<li>如果执行逻辑需要用到二维表特性，就会优先考虑使用临时表。union 需要用到唯一索引约束， group by 还需要用到另外一个字段来存累积计数。</li>
</ol>
</li>
<li><p>如果对 group by 语句的结果没有排序要求，要在语句后面加 order by null；</p>
</li>
<li><p>尽量让 group by 过程用上表的索引，确认方法是 explain 结果里没有 Using temporary 和 Using filesort；</p>
</li>
<li><p>如果 group by 需要统计的数据量不大，尽量只使用内存临时表；也可以通过适当调大tmp_table_size 参数，来避免用到磁盘临时表；</p>
</li>
<li><p>如果数据量实在太大，使用 SQL_BIG_RESULT 这个提示，来告诉优化器直接使用排序算<br>法得到 group by 的结果。</p>
</li>
</ul>
<h4 id="38-都说InnoDB好，那还要不要使用Memory引擎？"><a href="#38-都说InnoDB好，那还要不要使用Memory引擎？" class="headerlink" title="38 | 都说InnoDB好，那还要不要使用Memory引擎？"></a>38 | 都说InnoDB好，那还要不要使用Memory引擎？</h4><ul>
<li><p>内存表的数据组织结构</p>
<ul>
<li>InnoDB 表的数据就放在主键索引树上，主键索引是 B+ 树，所以主键索引上的值是有序存储的，称为索引组织表（Index Organizied Table）</li>
<li>Memory 引擎的数据和索引是分开的，数据部分以数组的方式单独存放，而主键 id 索引里，存的是每个数据的位置。主键 id 是 hash 索引，可以看到索引上的 key 并不是有序的，称为堆组织表（Heap Organizied Table）</li>
</ul>
</li>
<li><p>两个引擎之间的不同：</p>
<ul>
<li>InnoDB 表的数据总是有序存放的，而内存表的数据就是按照写入顺序存放的；</li>
<li>当数据文件有空洞的时候，InnoDB 表在插入新数据的时候，为了保证数据有序性，只能在固定的位置写入新值，而内存表找到空位就可以插入新值；</li>
<li>数据位置发生变化的时候，InnoDB 表只需要修改主键索引，而内存表需要修改所有索引；</li>
<li>InnoDB 表用主键索引查询时需要走一次索引查找，用普通索引查询的时候，需要走两次索引查找。而内存表没有这个区别，所有索引的“地位”都是相同的。</li>
<li>InnoDB 支持变长数据类型，不同记录的长度可能不同；内存表不支持 Blob 和 Text 字段，并且即使定义了 varchar(N)，实际也当作 char(N)，也就是固定长度字符串来存储，因此内存表的每行数据长度相同</li>
</ul>
</li>
<li><p>内存表的优势是速度快，其中的一个原因就是 Memory 引擎支持 hash 索引。当然，更重要的原因是，内存表的所有数据都保存在内存，而内存的读写速度总是比磁盘快</p>
</li>
<li><p>不建议在生产环境上使用内存表。这里的原因主要包括两个方面：</p>
<ul>
<li>锁粒度问题：内存表不支持行锁，只支持表锁。因此，一张表只要有更新，就会堵住其他所有在这个表上的读写操作。跟行锁比起来，表锁对并发访问的支持不够好。所以，内存表的锁粒度问题，决定了它在处理并发事务的时候，性能也不会太好。</li>
<li>数据持久化问题：数据库重启的时候，所有的内存表都会被清空，在高可用架构下，内存表的这个特点会导致主备同步停止。当然，如果这时候发生主备切换的话，客户端会看到，表 t1的数据“丢失”了；在备库重启的时候，备库 binlog 里的 delete 语句就会传到主库，然后把主库内存表的内容删除。这样你在使用的时候就会发现，主库的内存表数据突然被清空了</li>
</ul>
</li>
<li><p>用户临时表，在数据量可控，不会耗费过多内存的情况下，可以考虑使用内存表。内存临时表刚好可以无视内存表的两个不足，主要是下面的三个原因：</p>
<ul>
<li>临时表不会被其他线程访问，没有并发性的问题；</li>
<li>临时表重启后也是需要删除的，清空数据这个问题不存在；</li>
<li>备库的临时表也不会影响主库的用户线程。</li>
</ul>
</li>
</ul>
<h4 id="39-自增主键为什么不是连续的？"><a href="#39-自增主键为什么不是连续的？" class="headerlink" title="39 | 自增主键为什么不是连续的？"></a>39 | 自增主键为什么不是连续的？</h4><ul>
<li><p>自增值保存在哪儿？</p>
<ul>
<li>表的结构定义存放在后缀名为.frm 的文件中，但是并不会保存自增值</li>
<li>不同的引擎对于自增值的保存策略不同。<ul>
<li>MyISAM 引擎的自增值保存在数据文件中。</li>
<li>InnoDB 引擎的自增值，其实是保存在了内存里：在 MySQL 5.7 及之前的版本，自增值保存在内存里，并没有持久化。每次重启后，第一次打开表的时候，都会去找自增值的最大值 max(id)，然后将 max(id)+1 作为这个表当前的自增值。在 MySQL 8.0 版本，将自增值的变更记录在了 redo log 中，重启的时候依靠 redo log 恢复重启之前的值</li>
</ul>
</li>
</ul>
</li>
<li><p>自增值修改机制</p>
<ul>
<li>在 MySQL 里面，如果字段 id 被定义为 AUTO_INCREMENT，在插入一行数据的时候，自增值的行为如下：<ul>
<li>如果插入数据时 id 字段指定为 0、null 或未指定值，那么就把这个表当前的AUTO_INCREMENT 值填到自增字段；</li>
<li>如果插入数据时 id 字段指定了具体的值，就直接使用语句里指定的值。</li>
</ul>
</li>
<li>根据要插入的值和当前自增值的大小关系，自增值的变更结果也会有所不同。假设，某次要插入的值是 X，当前的自增值是 Y。<ul>
<li>如果 X&lt;Y，那么这个表的自增值不变；</li>
<li>如果 X≥Y，就需要把当前自增值修改为新的自增值。</li>
</ul>
</li>
<li>新的自增值生成算法是：从 auto_increment_offset 开始，以auto_increment_increment 为步长，持续叠加，直到找到第一个大于 X 的值，作为新的自增值。</li>
<li>当 auto_increment_offset 和 auto_increment_increment 都是 1 的时候，新的自增值生成逻辑很简单，就是：<ul>
<li>如果准备插入的值 &gt;&#x3D; 当前自增值，新的自增值就是“准备插入的值 +1”；</li>
<li>否则，自增值不变。</li>
</ul>
</li>
</ul>
</li>
<li><p>自增值的修改时机</p>
<ul>
<li><strong>唯一键冲突是导致自增主键 id 不连续的第一种原因</strong></li>
<li><strong>事务回滚也会产生类似的现象，这就是第二种原因</strong>；出现唯一键冲突或者回滚的时候，MySQL 没有把表 t 的自增值改回<br>去，这么设计是为了提升性能<ul>
<li>如果允许事务把自增 id 回退，插入语句可能出现主键冲突，为了解决这个冲突需要每次申请 id 之前，先判断表里面是否已经存在这个 id，成本很高；或者把自增 id 的锁范围扩大，必须等到一个事务执行完成并提交，这会导致锁的粒度太大，系统并发能力大大下降</li>
</ul>
</li>
</ul>
</li>
<li><p>自增锁的优化</p>
<ul>
<li>在 MySQL 5.0 版本的时候，自增锁的范围是语句级别。也就是说，如果一个语句申请了一个表自增锁，这个锁会等语句执行结束以后才释放。显然，这样设计会影响并发度。</li>
<li>MySQL 5.1.22 版本引入了一个新策略，新增参数 innodb_autoinc_lock_mode，默认值是 1。<ul>
<li>这个参数的值被设置为 0 时，表示采用之前 MySQL 5.0 版本的策略，即语句执行结束后才释放锁；</li>
<li>这个参数的值被设置为 1 时：<ul>
<li>普通 insert 语句，自增锁在申请之后就马上释放；</li>
<li>类似 insert … select 这样的批量插入数据的语句，自增锁还是要等语句结束后才被释放；</li>
</ul>
</li>
<li>这个参数的值被设置为 2 时，所有的申请自增主键的动作都是申请后就释放锁。</li>
</ul>
</li>
<li>在生产上，尤其是有 insert … select 这种批量插入数据的场景时，从并发插入数据性能的角度考虑，建议这样设置：innodb_autoinc_lock_mode&#x3D;2 ，并且binlog_format&#x3D;row. 这样做，既能提升并发性，又不会出现数据一致性问题。</li>
</ul>
</li>
<li><p>对于批量插入数据的语句，MySQL 有一个批量申请自增 id 的策略：同一个语句去申请自增 id，每次申请到的自增 id 个数都是上一次的两倍，这是<strong>主键 id 出现自增 id 不连续的第三种原因</strong>。</p>
</li>
</ul>
<h4 id="40-insert语句的锁为什么这么多？"><a href="#40-insert语句的锁为什么这么多？" class="headerlink" title="40 | insert语句的锁为什么这么多？"></a>40 | insert语句的锁为什么这么多？</h4><ul>
<li>执行 insert … select 的时候，对目标表也不是锁全表，而是只锁住需要访问的资源；而如果是一边遍历数据，一边更新数据的情况，如果读出来的数据直接写回原表，就可能在遍历过程中，读到刚刚插入的记录，新插入的记录如果参与计算逻辑，就跟语义不符</li>
<li>insert发生唯一键冲突的时候，并不只是简单地报错返回，还在冲突的索引上加了锁，这样做可以避免这一行被别的事务删掉；主键索引或者唯一索引冲突加的都是 next-key lock。在有多个唯一索引的表中并发插入数据时，会出现死锁</li>
<li>insert into … on duplicate key update 这个语义的逻辑是，插入一行数据，如果碰到唯一键约束，就执行后面的更新语句。注意，如果有多个列违反了唯一性约束，就会按照索引的顺序，修改跟第一个索引冲突的行。</li>
<li>insert … select 是很常见的在两个表之间拷贝数据的方法。需要注意，在可重复读隔离级别下，这个语句会给 select 的表里扫描到的记录和间隙加读锁，而如果 insert 和 select 的对象是同一个表，则有可能会造成循环写入。这种情况下，需要引入用户临时表来做优化；insert 语句如果出现唯一键冲突，会在冲突的唯一值上加共享的 next-key lock(S 锁)。因此，碰到由于唯一键约束导致报错后，要尽快提交或回滚事务，避免加锁时间过长。</li>
</ul>
<h4 id="45-自增id用完怎么办？"><a href="#45-自增id用完怎么办？" class="headerlink" title="45 | 自增id用完怎么办？"></a>45 | 自增id用完怎么办？</h4><ul>
<li>MySQL 里有很多自增的 id，每个自增 id 都是定义了初始值，然后不停地往上加步长。虽然自然数是没有上限的，但是在计算机里，只要定义了表示这个数的字节长度，那它就有上限。比如，无符号整型 (unsigned int) 是 4 个字节，上限就是 2^32^ -1</li>
<li>表定义的自增值达到上限后的逻辑是：再申请下一个 id 时，得到的值保持不变，报主键冲突错误</li>
<li>如果你创建的 InnoDB 表没有指定主键，那么 InnoDB 会给你创建一个不可见的，长度为6 个字节的 row_id。InnoDB 维护了一个全局的 dict_sys.row_id 值，所有无主键的InnoDB 表，每插入一行数据，都将当前的 dict_sys.row_id 值作为要插入数据的 row_id，然后把 dict_sys.row_id 的值加 1。<ul>
<li>row_id 写入表中的值范围，是从 0 到 2^48^-1；</li>
<li>当 dict_sys.row_id&#x3D;2^48^ 时，如果再有插入数据的行为要来申请 row_id，拿到以后再取最后 6 个字节的话就是 0。写入表的 row_id 是从 0 开始到 2^48^ -1。达到上限后，下一个值就是 0，然后继续循环。</li>
<li>如果表中已经存在 row_id&#x3D;N 的行，新写入的行就会覆盖原有的行；还是应该在 InnoDB 表中主动创建自增主键。因为，表自增 id 到达上限后，再插入数据时报主键冲突错误，是更能被接受的。毕竟覆盖数据，就意味着数据丢失，影响的是数据可靠性；报主键冲突，是插入失败，影响的是可用性。而一般情况下，可靠性优先于可用性。</li>
</ul>
</li>
<li>MySQL 内部维护了一个全局变量 global_query_id，每次执行语句的时候将它赋值给Query_id，然后给这个变量加 1。如果当前语句是这个事务执行的第一条语句，那么MySQL 还会同时把 Query_id 赋值给这个事务的 Xid。<ul>
<li>global_query_id 是一个纯内存变量，重启之后就清零了。所以在同一个数据库实例中，不同事务的 Xid 也是有可能相同的</li>
<li>MySQL 重启之后会重新生成新的 binlog 文件，这就保证了，同一个 binlog 文件里，Xid 一定是惟一的。</li>
<li>如果global_query_id 达到上限后，就会继续从 0 开始计数。从理论上讲，还是就会出现同一个 binlog 里面出现相同 Xid 的场景。global_query_id 定义的长度是 8 个字节，这个自增值的上限是 2^64^ -1。这个值太大了，可以认为这个可能性只会存在于理论上</li>
</ul>
</li>
<li>InnoDB 内部维护了一个 max_trx_id 全局变量，每次需要申请一个新的 trx_id 时，就获得max_trx_id 的当前值，然后并将 max_trx_id 加 1。<ul>
<li>InnoDB 数据可见性的核心思想是：每一行数据都记录了更新它的 trx_id，当一个事务读到一行数据的时候，判断这个数据是否可见的方法，就是通过事务的一致性视图与这行数据的trx_id 做对比。</li>
<li>这个数字是每次查询的时候由系统临时计算出来的。它的算法是：把当前事务的 trx变量的指针地址转成整数，再加上 2^48^, 保证只读事务显示的 trx_id 值比较大，正常情况下就会区<br>别于读写事务的 id。</li>
<li>只读事务不分配 trx_id，有什么好处呢？<ul>
<li>可以减小事务视图里面活跃事务数组的大小</li>
<li>可以减少 trx_id 的申请次数</li>
</ul>
</li>
<li>max_trx_id 会持久化存储，重启也不会重置为 0，那么从理论上讲，只要一个MySQL 服务跑得足够久，就可能出现 max_trx_id 达到 2 -1 的上限，然后从 0 开始的情况。当达到这个状态后，MySQL 就会持续出现一个脏读的 bug</li>
</ul>
</li>
<li>线程 id 是 MySQL 中最常见的一种自增 id。thread_id 的逻辑很好理解：系统保存了一个全局变量 thread_id_counter，每新建一个连接，就将 thread_id_counter 赋值给这个新连接的线程变量。thread_id_counter 定义的大小是 4 个字节，因此达到 2 -1 后，它就会重置为 0，然后继续增加。<ul>
<li>但是，不会在 show processlist 里看到两个相同的 thread_id，这是因为 MySQL 设计了一个唯一数组的逻辑</li>
</ul>
</li>
</ul>
</article><div class="post-tools" id="post-tools"><div class="post-tools-left"><div class="rewardLeftButton"><div class="post-reward" onclick="anzhiyu.addRewardMask()"><div class="reward-button button--animated" title="赞赏作者"><i class="anzhiyufont anzhiyu-icon-hand-heart-fill"></i>打赏作者</div><div class="reward-main"><div class="reward-all"><span class="reward-title">感谢你赐予我前进的力量</span><ul class="reward-group"><li class="reward-item"><a href="https://acallcf.oss-cn-qingdao.aliyuncs.com/images/202307192211377.png" target="_blank"><img class="post-qr-code-img" src="https://acallcf.oss-cn-qingdao.aliyuncs.com/images/202307192211377.png" alt="wechat"/></a><div class="post-qr-code-desc">wechat</div></li><li class="reward-item"><a href="https://acallcf.oss-cn-qingdao.aliyuncs.com/images/202307192207910.png" target="_blank"><img class="post-qr-code-img" src="https://acallcf.oss-cn-qingdao.aliyuncs.com/images/202307192207910.png" alt="alipayautoh"/></a><div class="post-qr-code-desc">alipayautoh</div></li></ul><a class="reward-main-btn" href="/about/#about-reward" target="_blank"><div class="reward-text">赞赏者名单</div><div class="reward-dec">因为你们的支持让我意识到写文章的价值🙏</div></a></div></div></div><div id="quit-box" onclick="anzhiyu.removeRewardMask()" style="display: none"></div></div><div class="shareRight"><div class="share-link mobile"><div class="share-qrcode"><div class="share-button" title="使用手机访问这篇文章"><i class="anzhiyufont anzhiyu-icon-qrcode"></i></div><div class="share-main"><div class="share-main-all"><div id="qrcode" title="http://acall.love/2023/05/05/2.%E6%9E%81%E5%AE%A2%E4%B8%93%E6%A0%8F%E7%AC%94%E8%AE%B0/"></div><div class="reward-dec">使用手机访问这篇文章</div></div></div></div></div><div class="share-link weibo"><a class="share-button" target="_blank" href="https://service.weibo.com/share/share.php?title=undefined&amp;url=http://acall.love/2023/05/05/2.%E6%9E%81%E5%AE%A2%E4%B8%93%E6%A0%8F%E7%AC%94%E8%AE%B0/&amp;pic=undefined" rel="external nofollow noreferrer noopener"><i class="anzhiyufont anzhiyu-icon-weibo"></i></a></div><div class="share-link copyurl"><div class="share-button" id="post-share-url" title="复制链接" onclick="rm.copyPageUrl()"><i class="anzhiyufont anzhiyu-icon-link"></i></div></div></div></div><div class="post-tools-right"><div class="tag_share"><div class="post-meta__box"><div class="post-meta__box__tag-list"><a class="post-meta__box__tags" href="/tags/C/"><span class="tags-punctuation"> <i class="anzhiyufont anzhiyu-icon-tag"></i></span>C++<span class="tagsPageCount">23</span></a><a class="post-meta__box__tags" href="/tags/%E5%90%8E%E7%AB%AF%E5%BC%80%E5%8F%91/"><span class="tags-punctuation"> <i class="anzhiyufont anzhiyu-icon-tag"></i></span>后端开发<span class="tagsPageCount">22</span></a></div></div></div><div class="post_share"><div class="social-share" data-image="https://acallcf.oss-cn-qingdao.aliyuncs.com/images/d6g1gl.webp" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://npm.elemecdn.com/butterfly-extsrc@1.1.3/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"/><script src="https://npm.elemecdn.com/butterfly-extsrc@1.1.3/sharejs/dist/js/social-share.min.js" defer="defer"></script></div></div></div><div class="post-copyright"><i class="anzhiyufont anzhiyu-icon-copyright"></i><div class="post-copyright__author"><a class="post-copyright__original" title="该文章为原创文章，注意版权协议" href="http://acall.love/2023/05/05/2.%E6%9E%81%E5%AE%A2%E4%B8%93%E6%A0%8F%E7%AC%94%E8%AE%B0/">原创</a><a class="post-copyright-title"><span>2.极客笔记</span></a></div><div class="post-copyright-info-box"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"></span><a class="link" href="http://acall.love">🎵张小佑♪</a></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a class="link" href="http://acall.love/2023/05/05/2.%E6%9E%81%E5%AE%A2%E4%B8%93%E6%A0%8F%E7%AC%94%E8%AE%B0/">http://acall.love/2023/05/05/2.%E6%9E%81%E5%AE%A2%E4%B8%93%E6%A0%8F%E7%AC%94%E8%AE%B0/</a></span><span class="copy-button" onclick="rm.copyPageUrl('http://acall.love/2023/05/05/2.%E6%9E%81%E5%AE%A2%E4%B8%93%E6%A0%8F%E7%AC%94%E8%AE%B0/')"><i class="anzhiyufont anzhiyu-icon-copy"></i></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="http://acall.love" target="_blank">♪张小佑</a>！</span></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/2023/05/01/1.%E4%B8%AA%E4%BA%BA%E9%97%AE%E9%A2%98%E6%95%B4%E7%90%86/"><img class="prev-cover" src="https://acallcf.oss-cn-qingdao.aliyuncs.com/images/p9918p.webp" onerror="onerror=null;src='/img/404.jpg'" alt="cover of previous post"><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">1.个人问题</div></div></a></div><div class="next-post pull-right"><a href="/2023/05/10/%E7%A7%8B%E6%8B%9B%E7%BB%8F%E9%AA%8C%E6%80%BB%E7%BB%93%E8%B4%B4/"><img class="next-cover" src="https://acallcf.oss-cn-qingdao.aliyuncs.com/images/l8zo2l.webp" onerror="onerror=null;src='/img/404.jpg'" alt="cover of next post"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">秋招经验贴</div></div></a></div></nav><div class="relatedPosts"><div class="headline"><i class="anzhiyufont anzhiyu-icon-thumbs-up fa-fw" style="font-size: 1.5rem; margin-right: 4px"></i><span>相关推荐</span></div><div class="relatedPosts-list"><div><a href="/2023/06/05/2.C++%20%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/" title="2.C++读书笔记"><img class="cover" src="https://acallcf.oss-cn-qingdao.aliyuncs.com/images/gp5k23.webp" alt="cover"><div class="content is-center"><div class="date"><i class="anzhiyufont anzhiyu-icon-calendar-days fa-fw"></i> 2023-06-05</div><div class="title">2.C++读书笔记</div></div></a></div><div><a href="/2023/05/01/1.%E4%B8%AA%E4%BA%BA%E9%97%AE%E9%A2%98%E6%95%B4%E7%90%86/" title="1.个人问题"><img class="cover" src="https://acallcf.oss-cn-qingdao.aliyuncs.com/images/p9918p.webp" alt="cover"><div class="content is-center"><div class="date"><i class="anzhiyufont anzhiyu-icon-calendar-days fa-fw"></i> 2023-05-01</div><div class="title">1.个人问题</div></div></a></div><div><a href="/2023/06/01/1.C++%E5%B2%97%E4%BD%8D%E9%9D%A2%E8%AF%95%E7%9C%9F%E9%A2%98%E5%AE%9D%E5%85%B8/" title="1.C++岗位面试真题宝典"><img class="cover" src="https://acallcf.oss-cn-qingdao.aliyuncs.com/images/iTab-p92mj3%20(2).webp" alt="cover"><div class="content is-center"><div class="date"><i class="anzhiyufont anzhiyu-icon-calendar-days fa-fw"></i> 2023-06-01</div><div class="title">1.C++岗位面试真题宝典</div></div></a></div><div><a href="/2023/06/10/3.C++%20%E9%9D%A2%E8%AF%95%E7%AA%81%E7%A0%B4/" title="3.面试突破"><img class="cover" src="https://acallcf.oss-cn-qingdao.aliyuncs.com/images/d6g1gl.webp" alt="cover"><div class="content is-center"><div class="date"><i class="anzhiyufont anzhiyu-icon-calendar-days fa-fw"></i> 2023-06-10</div><div class="title">3.面试突破</div></div></a></div><div><a href="/2023/01/05/day02%E7%AC%94%E8%AE%B0/" title="2.C++入门"><img class="cover" src="https://acallcf.oss-cn-qingdao.aliyuncs.com/images/001.png" alt="cover"><div class="content is-center"><div class="date"><i class="anzhiyufont anzhiyu-icon-calendar-days fa-fw"></i> 2023-01-05</div><div class="title">2.C++入门</div></div></a></div><div><a href="/2023/01/10/day03%E7%AC%94%E8%AE%B0/" title="3.C++入门"><img class="cover" src="https://acallcf.oss-cn-qingdao.aliyuncs.com/images/1pqq1w.webp" alt="cover"><div class="content is-center"><div class="date"><i class="anzhiyufont anzhiyu-icon-calendar-days fa-fw"></i> 2023-01-10</div><div class="title">3.C++入门</div></div></a></div></div></div></div><div class="aside-content" id="aside-content"><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="anzhiyufont anzhiyu-icon-bars"></i><span>文章目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%9E%81%E5%AE%A2%E4%B8%93%E6%A0%8F%E7%AC%94%E8%AE%B0"><span class="toc-number">1.</span> <span class="toc-text">极客专栏笔记</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Redis%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF%E4%B8%8E%E5%AE%9E%E6%88%98"><span class="toc-number">1.1.</span> <span class="toc-text">Redis核心技术与实战</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%BC%80%E7%AF%87%E8%AF%8D-%E8%BF%99%E6%A0%B7%E5%AD%A6Redis%EF%BC%8C%E6%89%8D%E8%83%BD%E6%8A%80%E9%AB%98%E4%B8%80%E7%AD%B9"><span class="toc-number">1.1.1.</span> <span class="toc-text">开篇词 | 这样学Redis，才能技高一筹</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#02-%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%EF%BC%9A%E5%BF%AB%E9%80%9F%E7%9A%84Redis%E6%9C%89%E5%93%AA%E4%BA%9B%E6%85%A2%E6%93%8D%E4%BD%9C%EF%BC%9F"><span class="toc-number">1.1.2.</span> <span class="toc-text">02-数据结构：快速的Redis有哪些慢操作？</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#03-%E9%AB%98%E6%80%A7%E8%83%BDIO%E6%A8%A1%E5%9E%8B%EF%BC%9A%E4%B8%BA%E4%BB%80%E4%B9%88%E5%8D%95%E7%BA%BF%E7%A8%8BRedis%E8%83%BD%E9%82%A3%E4%B9%88%E5%BF%AB%EF%BC%9F"><span class="toc-number">1.1.3.</span> <span class="toc-text">03-高性能IO模型：为什么单线程Redis能那么快？</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#04-AOF%E6%97%A5%E5%BF%97%EF%BC%9A%E5%AE%95%E6%9C%BA%E4%BA%86%EF%BC%8CRedis%E5%A6%82%E4%BD%95%E9%81%BF%E5%85%8D%E6%95%B0%E6%8D%AE%E4%B8%A2%E5%A4%B1%EF%BC%9F"><span class="toc-number">1.1.4.</span> <span class="toc-text">04 | AOF日志：宕机了，Redis如何避免数据丢失？</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#05-%E5%86%85%E5%AD%98%E5%BF%AB%E7%85%A7%EF%BC%9A%E5%AE%95%E6%9C%BA%E5%90%8E%EF%BC%8CRedis%E5%A6%82%E4%BD%95%E5%AE%9E%E7%8E%B0%E5%BF%AB%E9%80%9F%E6%81%A2%E5%A4%8D%EF%BC%9F"><span class="toc-number">1.1.5.</span> <span class="toc-text">05 | 内存快照：宕机后，Redis如何实现快速恢复？</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#06-%E6%95%B0%E6%8D%AE%E5%90%8C%E6%AD%A5%EF%BC%9A%E4%B8%BB%E4%BB%8E%E5%BA%93%E5%A6%82%E4%BD%95%E5%AE%9E%E7%8E%B0%E6%95%B0%E6%8D%AE%E4%B8%80%E8%87%B4%EF%BC%9F"><span class="toc-number">1.1.6.</span> <span class="toc-text">06 | 数据同步：主从库如何实现数据一致？</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#07-%E5%93%A8%E5%85%B5%E6%9C%BA%E5%88%B6%EF%BC%9A%E4%B8%BB%E5%BA%93%E6%8C%82%E4%BA%86%EF%BC%8C%E5%A6%82%E4%BD%95%E4%B8%8D%E9%97%B4%E6%96%AD%E6%9C%8D%E5%8A%A1%EF%BC%9F"><span class="toc-number">1.1.7.</span> <span class="toc-text">07 | 哨兵机制：主库挂了，如何不间断服务？</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#08-%E5%93%A8%E5%85%B5%E9%9B%86%E7%BE%A4%EF%BC%9A%E5%93%A8%E5%85%B5%E6%8C%82%E4%BA%86%EF%BC%8C%E4%B8%BB%E4%BB%8E%E5%BA%93%E8%BF%98%E8%83%BD%E5%88%87%E6%8D%A2%E5%90%97%EF%BC%9F"><span class="toc-number">1.1.8.</span> <span class="toc-text">08 | 哨兵集群：哨兵挂了，主从库还能切换吗？</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#09-%E5%88%87%E7%89%87%E9%9B%86%E7%BE%A4%EF%BC%9A%E6%95%B0%E6%8D%AE%E5%A2%9E%E5%A4%9A%E4%BA%86%EF%BC%8C%E6%98%AF%E8%AF%A5%E5%8A%A0%E5%86%85%E5%AD%98%E8%BF%98%E6%98%AF%E5%8A%A0%E5%AE%9E%E4%BE%8B%EF%BC%9F"><span class="toc-number">1.1.9.</span> <span class="toc-text">09 | 切片集群：数据增多了，是该加内存还是加实例？</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#10-%E7%AC%AC1%EF%BD%9E9%E8%AE%B2%E8%AF%BE%E5%90%8E%E6%80%9D%E8%80%83%E9%A2%98%E7%AD%94%E6%A1%88%E5%8F%8A%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98%E7%AD%94%E7%96%91"><span class="toc-number">1.1.10.</span> <span class="toc-text">10 | 第1～9讲课后思考题答案及常见问题答疑</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#11%E4%B8%A8%E2%80%9C%E4%B8%87%E9%87%91%E6%B2%B9%E2%80%9D%E7%9A%84String%EF%BC%8C%E4%B8%BA%E4%BB%80%E4%B9%88%E4%B8%8D%E5%A5%BD%E7%94%A8%E4%BA%86%EF%BC%9F"><span class="toc-number">1.1.11.</span> <span class="toc-text">11丨“万金油”的String，为什么不好用了？</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#12-%E6%9C%89%E4%B8%80%E4%BA%BF%E4%B8%AAkeys%E8%A6%81%E7%BB%9F%E8%AE%A1%EF%BC%8C%E5%BA%94%E8%AF%A5%E7%94%A8%E5%93%AA%E7%A7%8D%E9%9B%86%E5%90%88%EF%BC%9F"><span class="toc-number">1.1.12.</span> <span class="toc-text">12 | 有一亿个keys要统计，应该用哪种集合？</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#13-GEO%E6%98%AF%E4%BB%80%E4%B9%88%EF%BC%9F%E8%BF%98%E5%8F%AF%E4%BB%A5%E5%AE%9A%E4%B9%89%E6%96%B0%E7%9A%84%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B%E5%90%97%EF%BC%9F"><span class="toc-number">1.1.13.</span> <span class="toc-text">13 | GEO是什么？还可以定义新的数据类型吗？</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#14-%E5%A6%82%E4%BD%95%E5%9C%A8Redis%E4%B8%AD%E4%BF%9D%E5%AD%98%E6%97%B6%E9%97%B4%E5%BA%8F%E5%88%97%E6%95%B0%E6%8D%AE%EF%BC%9F"><span class="toc-number">1.1.14.</span> <span class="toc-text">14 | 如何在Redis中保存时间序列数据？</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#15%E4%B8%A8%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97%E7%9A%84%E8%80%83%E9%AA%8C%EF%BC%9ARedis%E6%9C%89%E5%93%AA%E4%BA%9B%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88%EF%BC%9F"><span class="toc-number">1.1.15.</span> <span class="toc-text">15丨消息队列的考验：Redis有哪些解决方案？</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#16%E4%B8%A8%E5%BC%82%E6%AD%A5%E6%9C%BA%E5%88%B6%EF%BC%9A%E5%A6%82%E4%BD%95%E9%81%BF%E5%85%8D%E5%8D%95%E7%BA%BF%E7%A8%8B%E6%A8%A1%E5%9E%8B%E7%9A%84%E9%98%BB%E5%A1%9E%EF%BC%9F"><span class="toc-number">1.1.16.</span> <span class="toc-text">16丨异步机制：如何避免单线程模型的阻塞？</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#17%E4%B8%A8%E4%B8%BA%E4%BB%80%E4%B9%88CPU%E7%BB%93%E6%9E%84%E4%B9%9F%E4%BC%9A%E5%BD%B1%E5%93%8DRedis%E7%9A%84%E6%80%A7%E8%83%BD%EF%BC%9F"><span class="toc-number">1.1.17.</span> <span class="toc-text">17丨为什么CPU结构也会影响Redis的性能？</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#18%E4%B8%A8%E6%B3%A2%E5%8A%A8%E7%9A%84%E5%93%8D%E5%BA%94%E5%BB%B6%E8%BF%9F%EF%BC%9A%E5%A6%82%E4%BD%95%E5%BA%94%E5%AF%B9%E5%8F%98%E6%85%A2%E7%9A%84Redis%EF%BC%9F%EF%BC%88%E4%B8%8A%EF%BC%89"><span class="toc-number">1.1.18.</span> <span class="toc-text">18丨波动的响应延迟：如何应对变慢的Redis？（上）</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#19%E4%B8%A8%E6%B3%A2%E5%8A%A8%E7%9A%84%E5%93%8D%E5%BA%94%E5%BB%B6%E8%BF%9F%EF%BC%9A%E5%A6%82%E4%BD%95%E5%BA%94%E5%AF%B9%E5%8F%98%E6%85%A2%E7%9A%84Redis%EF%BC%9F%EF%BC%88%E4%B8%8B%EF%BC%89"><span class="toc-number">1.1.19.</span> <span class="toc-text">19丨波动的响应延迟：如何应对变慢的Redis？（下）</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#20-%E5%88%A0%E9%99%A4%E6%95%B0%E6%8D%AE%E5%90%8E%EF%BC%8C%E4%B8%BA%E4%BB%80%E4%B9%88%E5%86%85%E5%AD%98%E5%8D%A0%E7%94%A8%E7%8E%87%E8%BF%98%E6%98%AF%E5%BE%88%E9%AB%98%EF%BC%9F"><span class="toc-number">1.1.20.</span> <span class="toc-text">20 | 删除数据后，为什么内存占用率还是很高？</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#21%E4%B8%A8%E7%BC%93%E5%86%B2%E5%8C%BA%EF%BC%9A%E4%B8%80%E4%B8%AA%E5%8F%AF%E8%83%BD%E5%BC%95%E5%8F%91%E2%80%9C%E6%83%A8%E6%A1%88%E2%80%9D%E7%9A%84%E5%9C%B0%E6%96%B9"><span class="toc-number">1.1.21.</span> <span class="toc-text">21丨缓冲区：一个可能引发“惨案”的地方</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#22%E4%B8%A8%E7%AC%AC11%EF%BD%9E21%E8%AE%B2%E8%AF%BE%E5%90%8E%E6%80%9D%E8%80%83%E9%A2%98%E7%AD%94%E6%A1%88%E5%8F%8A%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98%E7%AD%94%E7%96%91"><span class="toc-number">1.1.22.</span> <span class="toc-text">22丨第11～21讲课后思考题答案及常见问题答疑</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#23%E4%B8%A8%E6%97%81%E8%B7%AF%E7%BC%93%E5%AD%98%EF%BC%9ARedis%E6%98%AF%E5%A6%82%E4%BD%95%E5%B7%A5%E4%BD%9C%E7%9A%84%EF%BC%9F"><span class="toc-number">1.1.23.</span> <span class="toc-text">23丨旁路缓存：Redis是如何工作的？</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#24%E4%B8%A8%E6%9B%BF%E6%8D%A2%E7%AD%96%E7%95%A5%EF%BC%9A%E7%BC%93%E5%AD%98%E6%BB%A1%E4%BA%86%E6%80%8E%E4%B9%88%E5%8A%9E%EF%BC%9F"><span class="toc-number">1.1.24.</span> <span class="toc-text">24丨替换策略：缓存满了怎么办？</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#25%E4%B8%A8%E7%BC%93%E5%AD%98%E5%BC%82%E5%B8%B8%EF%BC%88%E4%B8%8A%EF%BC%89%EF%BC%9A%E5%A6%82%E4%BD%95%E8%A7%A3%E5%86%B3%E7%BC%93%E5%AD%98%E5%92%8C%E6%95%B0%E6%8D%AE%E5%BA%93%E7%9A%84%E6%95%B0%E6%8D%AE%E4%B8%8D%E4%B8%80%E8%87%B4%E9%97%AE%E9%A2%98%EF%BC%9F"><span class="toc-number">1.1.25.</span> <span class="toc-text">25丨缓存异常（上）：如何解决缓存和数据库的数据不一致问题？</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#26%E4%B8%A8%E7%BC%93%E5%AD%98%E5%BC%82%E5%B8%B8%EF%BC%88%E4%B8%8B%EF%BC%89%EF%BC%9A%E5%A6%82%E4%BD%95%E8%A7%A3%E5%86%B3%E7%BC%93%E5%AD%98%E9%9B%AA%E5%B4%A9%E3%80%81%E5%87%BB%E7%A9%BF%E3%80%81%E7%A9%BF%E9%80%8F%E9%9A%BE%E9%A2%98%EF%BC%9F"><span class="toc-number">1.1.26.</span> <span class="toc-text">26丨缓存异常（下）：如何解决缓存雪崩、击穿、穿透难题？</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#27%E4%B8%A8%E7%BC%93%E5%AD%98%E8%A2%AB%E6%B1%A1%E6%9F%93%E4%BA%86%EF%BC%8C%E8%AF%A5%E6%80%8E%E4%B9%88%E5%8A%9E%EF%BC%9F"><span class="toc-number">1.1.27.</span> <span class="toc-text">27丨缓存被污染了，该怎么办？</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#28%E4%B8%A8Pika%E5%A6%82%E4%BD%95%E5%9F%BA%E4%BA%8ESSD%E5%AE%9E%E7%8E%B0%E5%A4%A7%E5%AE%B9%E9%87%8FRedis%EF%BC%9F"><span class="toc-number">1.1.28.</span> <span class="toc-text">28丨Pika如何基于SSD实现大容量Redis？</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#29%E4%B8%A8%E6%97%A0%E9%94%81%E7%9A%84%E5%8E%9F%E5%AD%90%E6%93%8D%E4%BD%9C%EF%BC%9ARedis%E5%A6%82%E4%BD%95%E5%BA%94%E5%AF%B9%E5%B9%B6%E5%8F%91%E8%AE%BF%E9%97%AE%EF%BC%9F"><span class="toc-number">1.1.29.</span> <span class="toc-text">29丨无锁的原子操作：Redis如何应对并发访问？</span></a></li><li class="toc-item toc-level-4"><a class="toc-link"><span class="toc-number">1.1.30.</span> <span class="toc-text"></span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%9C%9F%E4%B8%AD%E6%B5%8B%E8%AF%95%E9%A2%98"><span class="toc-number">1.1.31.</span> <span class="toc-text">期中测试题</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#MySQL45%E8%AE%B2"><span class="toc-number">1.2.</span> <span class="toc-text">MySQL45讲</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#01-%E5%9F%BA%E7%A1%80%E6%9E%B6%E6%9E%84%EF%BC%9A%E4%B8%80%E6%9D%A1SQL%E6%9F%A5%E8%AF%A2%E8%AF%AD%E5%8F%A5%E6%98%AF%E5%A6%82%E4%BD%95%E6%89%A7%E8%A1%8C%E7%9A%84%EF%BC%9F"><span class="toc-number">1.2.1.</span> <span class="toc-text">01 | 基础架构：一条SQL查询语句是如何执行的？</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#02-%E6%97%A5%E5%BF%97%E7%B3%BB%E7%BB%9F%EF%BC%9A%E4%B8%80%E6%9D%A1SQL%E6%9B%B4%E6%96%B0%E8%AF%AD%E5%8F%A5%E6%98%AF%E5%A6%82%E4%BD%95%E6%89%A7%E8%A1%8C%E7%9A%84%EF%BC%9F"><span class="toc-number">1.2.2.</span> <span class="toc-text">02 | 日志系统：一条SQL更新语句是如何执行的？</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#03-%E4%BA%8B%E5%8A%A1%E9%9A%94%E7%A6%BB%EF%BC%9A%E4%B8%BA%E4%BB%80%E4%B9%88%E4%BD%A0%E6%94%B9%E4%BA%86%E6%88%91%E8%BF%98%E7%9C%8B%E4%B8%8D%E8%A7%81%EF%BC%9F"><span class="toc-number">1.2.3.</span> <span class="toc-text">03 | 事务隔离：为什么你改了我还看不见？</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#04-%E6%B7%B1%E5%85%A5%E6%B5%85%E5%87%BA%E7%B4%A2%E5%BC%95%EF%BC%88%E4%B8%8A%EF%BC%89"><span class="toc-number">1.2.4.</span> <span class="toc-text">04 | 深入浅出索引（上）</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#05-%E6%B7%B1%E5%85%A5%E6%B5%85%E5%87%BA%E7%B4%A2%E5%BC%95%EF%BC%88%E4%B8%8B%EF%BC%89"><span class="toc-number">1.2.5.</span> <span class="toc-text">05 | 深入浅出索引（下）</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#06-%E5%85%A8%E5%B1%80%E9%94%81%E5%92%8C%E8%A1%A8%E9%94%81-%EF%BC%9A%E7%BB%99%E8%A1%A8%E5%8A%A0%E4%B8%AA%E5%AD%97%E6%AE%B5%E6%80%8E%E4%B9%88%E6%9C%89%E8%BF%99%E4%B9%88%E5%A4%9A%E9%98%BB%E7%A2%8D%EF%BC%9F"><span class="toc-number">1.2.6.</span> <span class="toc-text">06 | 全局锁和表锁 ：给表加个字段怎么有这么多阻碍？</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#07%E4%B8%A8%E8%A1%8C%E9%94%81%E5%8A%9F%E8%BF%87%EF%BC%9A%E6%80%8E%E4%B9%88%E5%87%8F%E5%B0%91%E8%A1%8C%E9%94%81%E5%AF%B9%E6%80%A7%E8%83%BD%E7%9A%84%E5%BD%B1%E5%93%8D%EF%BC%9F"><span class="toc-number">1.2.7.</span> <span class="toc-text">07丨行锁功过：怎么减少行锁对性能的影响？</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#08%E4%B8%A8%E4%BA%8B%E5%8A%A1%E5%88%B0%E5%BA%95%E6%98%AF%E9%9A%94%E7%A6%BB%E7%9A%84%E8%BF%98%E6%98%AF%E4%B8%8D%E9%9A%94%E7%A6%BB%E7%9A%84%EF%BC%9F"><span class="toc-number">1.2.8.</span> <span class="toc-text">08丨事务到底是隔离的还是不隔离的？</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#09-%E6%99%AE%E9%80%9A%E7%B4%A2%E5%BC%95%E5%92%8C%E5%94%AF%E4%B8%80%E7%B4%A2%E5%BC%95%EF%BC%8C%E5%BA%94%E8%AF%A5%E6%80%8E%E4%B9%88%E9%80%89%E6%8B%A9%EF%BC%9F"><span class="toc-number">1.2.9.</span> <span class="toc-text">09 | 普通索引和唯一索引，应该怎么选择？</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#10%E4%B8%A8MySQL%E4%B8%BA%E4%BB%80%E4%B9%88%E6%9C%89%E6%97%B6%E5%80%99%E4%BC%9A%E9%80%89%E9%94%99%E7%B4%A2%E5%BC%95%EF%BC%9F"><span class="toc-number">1.2.10.</span> <span class="toc-text">10丨MySQL为什么有时候会选错索引？</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#11%E4%B8%A8%E6%80%8E%E4%B9%88%E7%BB%99%E5%AD%97%E7%AC%A6%E4%B8%B2%E5%AD%97%E6%AE%B5%E5%8A%A0%E7%B4%A2%E5%BC%95%EF%BC%9F"><span class="toc-number">1.2.11.</span> <span class="toc-text">11丨怎么给字符串字段加索引？</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#12-%E4%B8%BA%E4%BB%80%E4%B9%88%E6%88%91%E7%9A%84MySQL%E4%BC%9A%E2%80%9C%E6%8A%96%E2%80%9D%E4%B8%80%E4%B8%8B%EF%BC%9F"><span class="toc-number">1.2.12.</span> <span class="toc-text">12 | 为什么我的MySQL会“抖”一下？</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#13%E4%B8%A8%E4%B8%BA%E4%BB%80%E4%B9%88%E8%A1%A8%E6%95%B0%E6%8D%AE%E5%88%A0%E6%8E%89%E4%B8%80%E5%8D%8A%EF%BC%8C%E8%A1%A8%E6%96%87%E4%BB%B6%E5%A4%A7%E5%B0%8F%E4%B8%8D%E5%8F%98%EF%BC%9F"><span class="toc-number">1.2.13.</span> <span class="toc-text">13丨为什么表数据删掉一半，表文件大小不变？</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#14%E4%B8%A8count%E8%BF%99%E4%B9%88%E6%85%A2%EF%BC%8C%E6%88%91%E8%AF%A5%E6%80%8E%E4%B9%88%E5%8A%9E%EF%BC%9F"><span class="toc-number">1.2.14.</span> <span class="toc-text">14丨count这么慢，我该怎么办？</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#15%E4%B8%A8%E7%AD%94%E7%96%91%E6%96%87%E7%AB%A0%EF%BC%88%E4%B8%80%EF%BC%89%EF%BC%9A%E6%97%A5%E5%BF%97%E5%92%8C%E7%B4%A2%E5%BC%95%E7%9B%B8%E5%85%B3%E9%97%AE%E9%A2%98"><span class="toc-number">1.2.15.</span> <span class="toc-text">15丨答疑文章（一）：日志和索引相关问题</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#16%E4%B8%A8%E2%80%9Corderby%E2%80%9D%E6%98%AF%E6%80%8E%E4%B9%88%E5%B7%A5%E4%BD%9C%E7%9A%84%EF%BC%9F"><span class="toc-number">1.2.16.</span> <span class="toc-text">16丨“orderby”是怎么工作的？</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#17%E4%B8%A8%E5%A6%82%E4%BD%95%E6%AD%A3%E7%A1%AE%E5%9C%B0%E6%98%BE%E7%A4%BA%E9%9A%8F%E6%9C%BA%E6%B6%88%E6%81%AF%EF%BC%9F"><span class="toc-number">1.2.17.</span> <span class="toc-text">17丨如何正确地显示随机消息？</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#18%E4%B8%A8%E4%B8%BA%E4%BB%80%E4%B9%88%E8%BF%99%E4%BA%9BSQL%E8%AF%AD%E5%8F%A5%E9%80%BB%E8%BE%91%E7%9B%B8%E5%90%8C%EF%BC%8C%E6%80%A7%E8%83%BD%E5%8D%B4%E5%B7%AE%E5%BC%82%E5%B7%A8%E5%A4%A7%EF%BC%9F"><span class="toc-number">1.2.18.</span> <span class="toc-text">18丨为什么这些SQL语句逻辑相同，性能却差异巨大？</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#19%E4%B8%A8%E4%B8%BA%E4%BB%80%E4%B9%88%E6%88%91%E5%8F%AA%E6%9F%A5%E4%B8%80%E8%A1%8C%E7%9A%84%E8%AF%AD%E5%8F%A5%EF%BC%8C%E4%B9%9F%E6%89%A7%E8%A1%8C%E8%BF%99%E4%B9%88%E6%85%A2%EF%BC%9F"><span class="toc-number">1.2.19.</span> <span class="toc-text">19丨为什么我只查一行的语句，也执行这么慢？</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#20%E4%B8%A8%E5%B9%BB%E8%AF%BB%E6%98%AF%E4%BB%80%E4%B9%88%EF%BC%8C%E5%B9%BB%E8%AF%BB%E6%9C%89%E4%BB%80%E4%B9%88%E9%97%AE%E9%A2%98%EF%BC%9F"><span class="toc-number">1.2.20.</span> <span class="toc-text">20丨幻读是什么，幻读有什么问题？</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#21%E4%B8%A8%E4%B8%BA%E4%BB%80%E4%B9%88%E6%88%91%E5%8F%AA%E6%94%B9%E4%B8%80%E8%A1%8C%E7%9A%84%E8%AF%AD%E5%8F%A5%EF%BC%8C%E9%94%81%E8%BF%99%E4%B9%88%E5%A4%9A%EF%BC%9F"><span class="toc-number">1.2.21.</span> <span class="toc-text">21丨为什么我只改一行的语句，锁这么多？</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#22%E4%B8%A8MySQL%E6%9C%89%E5%93%AA%E4%BA%9B%E2%80%9C%E9%A5%AE%E9%B8%A9%E6%AD%A2%E6%B8%B4%E2%80%9D%E6%8F%90%E9%AB%98%E6%80%A7%E8%83%BD%E7%9A%84%E6%96%B9%E6%B3%95%EF%BC%9F"><span class="toc-number">1.2.22.</span> <span class="toc-text">22丨MySQL有哪些“饮鸩止渴”提高性能的方法？</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#23%E4%B8%A8MySQL%E6%98%AF%E6%80%8E%E4%B9%88%E4%BF%9D%E8%AF%81%E6%95%B0%E6%8D%AE%E4%B8%8D%E4%B8%A2%E7%9A%84%EF%BC%9F"><span class="toc-number">1.2.23.</span> <span class="toc-text">23丨MySQL是怎么保证数据不丢的？</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E7%AC%AC30%E8%AE%B2%EF%BC%8C%E7%94%A8%E5%8A%A8%E6%80%81%E7%9A%84%E8%A7%82%E7%82%B9%E7%9C%8B%E9%94%81"><span class="toc-number">1.2.24.</span> <span class="toc-text">第30讲，用动态的观点看锁</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#31-%E8%AF%AF%E5%88%A0%E6%95%B0%E6%8D%AE%E5%90%8E%E9%99%A4%E4%BA%86%E8%B7%91%E8%B7%AF%EF%BC%8C%E8%BF%98%E8%83%BD%E6%80%8E%E4%B9%88%E5%8A%9E%EF%BC%9F"><span class="toc-number">1.2.25.</span> <span class="toc-text">31 | 误删数据后除了跑路，还能怎么办？</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#32-%E4%B8%BA%E4%BB%80%E4%B9%88%E8%BF%98%E6%9C%89kill%E4%B8%8D%E6%8E%89%E7%9A%84%E8%AF%AD%E5%8F%A5%EF%BC%9F"><span class="toc-number">1.2.26.</span> <span class="toc-text">32 | 为什么还有kill不掉的语句？</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#33-%E6%88%91%E6%9F%A5%E8%BF%99%E4%B9%88%E5%A4%9A%E6%95%B0%E6%8D%AE%EF%BC%8C%E4%BC%9A%E4%B8%8D%E4%BC%9A%E6%8A%8A%E6%95%B0%E6%8D%AE%E5%BA%93%E5%86%85%E5%AD%98%E6%89%93%E7%88%86%EF%BC%9F"><span class="toc-number">1.2.27.</span> <span class="toc-text">33 | 我查这么多数据，会不会把数据库内存打爆？</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#34-%E5%88%B0%E5%BA%95%E5%8F%AF%E4%B8%8D%E5%8F%AF%E4%BB%A5%E4%BD%BF%E7%94%A8join%EF%BC%9F"><span class="toc-number">1.2.28.</span> <span class="toc-text">34 | 到底可不可以使用join？</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#35-join%E8%AF%AD%E5%8F%A5%E6%80%8E%E4%B9%88%E4%BC%98%E5%8C%96%EF%BC%9F"><span class="toc-number">1.2.29.</span> <span class="toc-text">35 | join语句怎么优化？</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#36-%E4%B8%BA%E4%BB%80%E4%B9%88%E4%B8%B4%E6%97%B6%E8%A1%A8%E5%8F%AF%E4%BB%A5%E9%87%8D%E5%90%8D%EF%BC%9F"><span class="toc-number">1.2.30.</span> <span class="toc-text">36 | 为什么临时表可以重名？</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#37-%E4%BB%80%E4%B9%88%E6%97%B6%E5%80%99%E4%BC%9A%E4%BD%BF%E7%94%A8%E5%86%85%E9%83%A8%E4%B8%B4%E6%97%B6%E8%A1%A8%EF%BC%9F"><span class="toc-number">1.2.31.</span> <span class="toc-text">37 | 什么时候会使用内部临时表？</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#38-%E9%83%BD%E8%AF%B4InnoDB%E5%A5%BD%EF%BC%8C%E9%82%A3%E8%BF%98%E8%A6%81%E4%B8%8D%E8%A6%81%E4%BD%BF%E7%94%A8Memory%E5%BC%95%E6%93%8E%EF%BC%9F"><span class="toc-number">1.2.32.</span> <span class="toc-text">38 | 都说InnoDB好，那还要不要使用Memory引擎？</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#39-%E8%87%AA%E5%A2%9E%E4%B8%BB%E9%94%AE%E4%B8%BA%E4%BB%80%E4%B9%88%E4%B8%8D%E6%98%AF%E8%BF%9E%E7%BB%AD%E7%9A%84%EF%BC%9F"><span class="toc-number">1.2.33.</span> <span class="toc-text">39 | 自增主键为什么不是连续的？</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#40-insert%E8%AF%AD%E5%8F%A5%E7%9A%84%E9%94%81%E4%B8%BA%E4%BB%80%E4%B9%88%E8%BF%99%E4%B9%88%E5%A4%9A%EF%BC%9F"><span class="toc-number">1.2.34.</span> <span class="toc-text">40 | insert语句的锁为什么这么多？</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#45-%E8%87%AA%E5%A2%9Eid%E7%94%A8%E5%AE%8C%E6%80%8E%E4%B9%88%E5%8A%9E%EF%BC%9F"><span class="toc-number">1.2.35.</span> <span class="toc-text">45 | 自增id用完怎么办？</span></a></li></ol></li></ol></li></ol></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2022 - 2023 By 🎵张小佑♪</div></div></footer></div></div></div><div id="sidebar"><div id="sidebar-menus"><div class="avatar-img is-center"><img src="https://acallcf.oss-cn-qingdao.aliyuncs.com/images/1.jpg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="sidebar-site-data site-data is-center"><a href="/archives/" title="archive"><div class="headline">文章</div><div class="length-num">23</div></a><a href="/tags/" title="tag"><div class="headline">标签</div><div class="length-num">4</div></a><a href="/categories/" title="category"><div class="headline">分类</div><div class="length-num">2</div></a></div><div class="menus_items"><div class="menus_item"><a class="site-page faa-parent animated-hover" href="javascript:void(0);"><span> 文章</span></a><ul class="menus_item_child" style="left:-79px;"><li><a class="site-page child faa-parent animated-hover" href="/archives/"><i class="anzhiyufont anzhiyu-icon-box-archive faa-tada" style="font-size: 0.9em;"></i><span> 隧道</span></a></li><li><a class="site-page child faa-parent animated-hover" href="/categories/"><i class="anzhiyufont anzhiyu-icon-shapes faa-tada" style="font-size: 0.9em;"></i><span> 分类</span></a></li><li><a class="site-page child faa-parent animated-hover" href="/tags/"><i class="anzhiyufont anzhiyu-icon-tags faa-tada" style="font-size: 0.9em;"></i><span> 标签</span></a></li></ul></div><div class="menus_item"><a class="site-page faa-parent animated-hover" href="javascript:void(0);"><span> 友链</span></a><ul class="menus_item_child" style="left:17px;"><li><a class="site-page child faa-parent animated-hover" href="/comments/"><i class="anzhiyufont anzhiyu-icon-envelope faa-tada" style="font-size: 0.9em;"></i><span> 留言板</span></a></li></ul></div><div class="menus_item"><a class="site-page faa-parent animated-hover" href="javascript:void(0);"><span> 我的</span></a><ul class="menus_item_child" style="left:-79px;"><li><a class="site-page child faa-parent animated-hover" href="/music/"><i class="anzhiyufont anzhiyu-icon-music faa-tada" style="font-size: 0.9em;"></i><span> 音乐馆</span></a></li><li><a class="site-page child faa-parent animated-hover" href="/bangumis/"><i class="anzhiyufont anzhiyu-icon-bilibili faa-tada" style="font-size: 0.9em;"></i><span> 追番页</span></a></li><li><a class="site-page child faa-parent animated-hover" href="/album/"><i class="anzhiyufont anzhiyu-icon-images faa-tada" style="font-size: 0.9em;"></i><span> 相册集</span></a></li></ul></div><div class="menus_item"><a class="site-page faa-parent animated-hover" href="javascript:void(0);"><span> 关于</span></a><ul class="menus_item_child" style="left:-79px;"><li><a class="site-page child faa-parent animated-hover" href="/about/"><i class="anzhiyufont anzhiyu-icon-paper-plane faa-tada" style="font-size: 0.9em;"></i><span> 关于本人</span></a></li><li><a class="site-page child faa-parent animated-hover" href="/essay/"><i class="anzhiyufont anzhiyu-icon-lightbulb faa-tada" style="font-size: 0.9em;"></i><span> 闲言碎语</span></a></li><li><a class="site-page child faa-parent animated-hover" href="/equipment/"><i class="anzhiyufont anzhiyu-icon-dice-d20 faa-tada" style="font-size: 0.9em;"></i><span> 我的装备</span></a></li></ul></div></div></div></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="anzhiyufont anzhiyu-icon-book-open"></i></button><button id="translateLink" type="button" title="简繁转换">简</button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="anzhiyufont anzhiyu-icon-circle-half-stroke"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="anzhiyufont anzhiyu-icon-arrows-left-right"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="anzhiyufont anzhiyu-icon-gear"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="anzhiyufont anzhiyu-icon-list-ul"></i></button><button id="go-up" type="button" title="回到顶部"><i class="anzhiyufont anzhiyu-icon-arrow-up"></i></button></div></div><div id="nav-music"><a id="nav-music-hoverTips" onclick="anzhiyu.musicToggle()" accesskey="m">播放音乐</a><div id="console-music-bg"></div><meting-js id="8152976493" server="netease" type="playlist" mutex="true" preload="none" theme="var(--anzhiyu-main)" data-lrctype="0" order="random"></meting-js></div><div id="rightMenu"><div class="rightMenu-group rightMenu-small"><div class="rightMenu-item" id="menu-backward"><i class="anzhiyufont anzhiyu-icon-arrow-left"></i></div><div class="rightMenu-item" id="menu-forward"><i class="anzhiyufont anzhiyu-icon-arrow-right"></i></div><div class="rightMenu-item" id="menu-refresh"><i class="anzhiyufont anzhiyu-icon-arrow-rotate-right" style="font-size: 1rem;"></i></div><div class="rightMenu-item" id="menu-top"><i class="anzhiyufont anzhiyu-icon-arrow-up"></i></div></div><div class="rightMenu-group rightMenu-line rightMenuPlugin"><div class="rightMenu-item" id="menu-copytext"><i class="anzhiyufont anzhiyu-icon-copy"></i><span>复制选中文本</span></div><div class="rightMenu-item" id="menu-pastetext"><i class="anzhiyufont anzhiyu-icon-paste"></i><span>粘贴文本</span></div><a class="rightMenu-item" id="menu-commenttext"><i class="anzhiyufont anzhiyu-icon-comment-medical"></i><span>引用到评论</span></a><div class="rightMenu-item" id="menu-newwindow"><i class="anzhiyufont anzhiyu-icon-window-restore"></i><span>新窗口打开</span></div><div class="rightMenu-item" id="menu-copylink"><i class="anzhiyufont anzhiyu-icon-link"></i><span>复制链接地址</span></div><div class="rightMenu-item" id="menu-copyimg"><i class="anzhiyufont anzhiyu-icon-images"></i><span>复制此图片</span></div><div class="rightMenu-item" id="menu-downloadimg"><i class="anzhiyufont anzhiyu-icon-download"></i><span>下载此图片</span></div><div class="rightMenu-item" id="menu-newwindowimg"><i class="anzhiyufont anzhiyu-icon-window-restore"></i><span>新窗口打开图片</span></div><div class="rightMenu-item" id="menu-search"><i class="anzhiyufont anzhiyu-icon-magnifying-glass"></i><span>站内搜索</span></div><div class="rightMenu-item" id="menu-searchBaidu"><i class="anzhiyufont anzhiyu-icon-magnifying-glass"></i><span>百度搜索</span></div><div class="rightMenu-item" id="menu-music-toggle"><i class="anzhiyufont anzhiyu-icon-play"></i><span>播放音乐</span></div><div class="rightMenu-item" id="menu-music-back"><i class="anzhiyufont anzhiyu-icon-backward"></i><span>切换到上一首</span></div><div class="rightMenu-item" id="menu-music-forward"><i class="anzhiyufont anzhiyu-icon-forward"></i><span>切换到下一首</span></div><div class="rightMenu-item" id="menu-music-playlist" onclick="window.open(&quot;https://y.qq.com/n/ryqq/playlist/8802438608&quot;, &quot;_blank&quot;);" style="display: none;"><i class="anzhiyufont anzhiyu-icon-radio"></i><span>查看所有歌曲</span></div><div class="rightMenu-item" id="menu-music-copyMusicName"><i class="anzhiyufont anzhiyu-icon-copy"></i><span>复制歌名</span></div></div><div class="rightMenu-group rightMenu-line rightMenuOther"><a class="rightMenu-item menu-link" id="menu-randomPost"><i class="anzhiyufont anzhiyu-icon-shuffle"></i><span>随便逛逛</span></a><a class="rightMenu-item menu-link" href="/categories/"><i class="anzhiyufont anzhiyu-icon-cube"></i><span>博客分类</span></a><a class="rightMenu-item menu-link" href="/tags/"><i class="anzhiyufont anzhiyu-icon-tags"></i><span>文章标签</span></a></div><div class="rightMenu-group rightMenu-line rightMenuOther"><a class="rightMenu-item" id="menu-copy" href="javascript:void(0);"><i class="anzhiyufont anzhiyu-icon-copy"></i><span>复制地址</span></a><a class="rightMenu-item" id="menu-commentBarrage" href="javascript:void(0);"><i class="anzhiyufont anzhiyu-icon-message"></i><span class="menu-commentBarrage-text">关闭热评</span></a><a class="rightMenu-item" id="menu-darkmode" href="javascript:void(0);"><i class="anzhiyufont anzhiyu-icon-circle-half-stroke"></i><span class="menu-darkmode-text">深色模式</span></a><a class="rightMenu-item" id="menu-translate" href="javascript:void(0);"><i class="anzhiyufont anzhiyu-icon-language"></i><span>轉為繁體</span></a></div></div><div id="rightmenu-mask"></div><div id="he-plugin-simple"></div><script>var WIDGET = {
  "CONFIG": {
    "modules": "0124",
    "background": "2",
    "tmpColor": "FFFFFF",
    "tmpSize": "16",
    "cityColor": "FFFFFF",
    "citySize": "16",
    "aqiColor": "E8D87B",
    "aqiSize": "16",
    "weatherIconSize": "24",
    "alertIconSize": "18",
    "padding": "10px 10px 10px 10px",
    "shadow": "0",
    "language": "auto",
    "borderRadius": "20",
    "fixed": "true",
    "vertical": "top",
    "horizontal": "left",
    "left": "20",
    "top": "7.1",
    "key": "df245676fb434a0691ead1c63341cd94"
  }
}
</script><link rel="stylesheet" href="https://widget.qweather.net/simple/static/css/he-simple.css?v=1.4.0"/><script src="https://widget.qweather.net/simple/static/js/he-simple.js?v=1.4.0"></script><div><script src="https://npm.elemecdn.com/hexo-theme-anzhiyu@1.4.0/source/js/utils.js"></script><script src="https://npm.elemecdn.com/hexo-theme-anzhiyu@1.4.0/source/js/main.js"></script><script src="https://npm.elemecdn.com/hexo-theme-anzhiyu@1.4.0/source/js/tw_cn.js"></script><script src="https://npm.elemecdn.com/@fancyapps/ui@4.0.31/dist/fancybox.umd.js"></script><script src="https://npm.elemecdn.com/instant.page@5.1.1/instantpage.js" type="module"></script><script src="https://npm.elemecdn.com/node-snackbar@0.1.16/dist/snackbar.min.js"></script><script>function panguFn () {
  if (typeof pangu === 'object') pangu.autoSpacingPage()
  else {
    getScript('https://npm.elemecdn.com/pangu@4.0.7/dist/browser/pangu.min.js')
      .then(() => {
        pangu.autoSpacingPage()
      })
  }
}

function panguInit () {
  if (false){
    GLOBAL_CONFIG_SITE.isPost && panguFn()
  } else {
    panguFn()
  }
}

document.addEventListener('DOMContentLoaded', panguInit)</script><canvas id="universe"></canvas><script async src="https://npm.elemecdn.com/anzhiyu-theme-static@1.0.0/dark/dark.js"></script><script>// 消除控制台打印
var HoldLog = console.log;
console.log = function () {};
let now1 = new Date();
queueMicrotask(() => {
  const Log = function () {
    HoldLog.apply(console, arguments);
  }; //在恢复前输出日志
  const grt = new Date("09/01/2022 00:00:00"); //此处修改你的建站时间或者网站上线时间
  now1.setTime(now1.getTime() + 250);
  const days = (now1 - grt) / 1000 / 60 / 60 / 24;
  const dnum = Math.floor(days);
  const ascll = [
    `欢迎使用安知鱼!`,
    `生活明朗, 万物可爱`,
    `
        
       █████╗ ███╗   ██╗███████╗██╗  ██╗██╗██╗   ██╗██╗   ██╗
      ██╔══██╗████╗  ██║╚══███╔╝██║  ██║██║╚██╗ ██╔╝██║   ██║
      ███████║██╔██╗ ██║  ███╔╝ ███████║██║ ╚████╔╝ ██║   ██║
      ██╔══██║██║╚██╗██║ ███╔╝  ██╔══██║██║  ╚██╔╝  ██║   ██║
      ██║  ██║██║ ╚████║███████╗██║  ██║██║   ██║   ╚██████╔╝
      ╚═╝  ╚═╝╚═╝  ╚═══╝╚══════╝╚═╝  ╚═╝╚═╝   ╚═╝    ╚═════╝
        
        `,
    "已上线",
    dnum,
    "天",
    "©2022 By 安知鱼 1.4.0",
  ];
  const ascll2 = [`NCC2-036`, `调用前置摄像头拍照成功，识别为【小笨蛋】.`, `Photo captured: `, `🤪`];

  setTimeout(
    Log.bind(
      console,
      `\n%c${ascll[0]} %c ${ascll[1]} %c ${ascll[2]} %c${ascll[3]}%c ${ascll[4]}%c ${ascll[5]}\n\n%c ${ascll[6]}\n`,
      "color:#3b70fc",
      "",
      "color:#3b70fc",
      "color:#3b70fc",
      "",
      "color:#3b70fc",
      ""
    )
  );
  setTimeout(
    Log.bind(
      console,
      `%c ${ascll2[0]} %c ${ascll2[1]} %c \n${ascll2[2]} %c\n${ascll2[3]}\n`,
      "color:white; background-color:#4fd953",
      "",
      "",
      'background:url("https://npm.elemecdn.com/anzhiyu-blog@1.1.6/img/post/common/tinggge.gif") no-repeat;font-size:450%'
    )
  );

  setTimeout(Log.bind(console, "%c WELCOME %c 你好，小笨蛋.", "color:white; background-color:#4f90d9", ""));

  setTimeout(
    console.warn.bind(
      console,
      "%c ⚡ Powered by 安知鱼 %c 你正在访问 🎵张小佑♪ 的博客.",
      "color:white; background-color:#f0ad4e",
      ""
    )
  );

  setTimeout(Log.bind(console, "%c W23-12 %c 你已打开控制台.", "color:white; background-color:#4f90d9", ""));

  setTimeout(
    console.warn.bind(console, "%c S013-782 %c 你现在正处于监控中.", "color:white; background-color:#d9534f", "")
  );
});</script><script async src="/anzhiyu/random.js"></script><div class="js-pjax"><input type="hidden" name="page-type" id="page-type" value="post"></div><script async data-pjax src="https://npm.elemecdn.com/anzhiyu-theme-static@1.0.1/bubble/bubble.js"></script><script>var visitorMail = "visitor@anheyu.com";</script><script>//动态标题
let leaveTitle = '♪张小佑 - 分享思考与科技生活';
let backTitle = '♪张小佑 - 分享思考与科技生活';
let OriginTitile = document.title
let titleTime
document.addEventListener('visibilitychange', function () {
  if (document.hidden) {
    //离开当前页面时标签显示内容
    document.title = leaveTitle
    clearTimeout(titleTime)
  } else {
    //返回当前页面时标签显示内容
    document.title = backTitle + OriginTitile
    //两秒后变回正常标题
    titleTime = setTimeout(function () {
      document.title = OriginTitile
    }, 2000)
  }
})</script><script async data-pjax src="https://npm.elemecdn.com/anzhiyu-theme-static@1.0.0/waterfall/waterfall.js"></script><script src="https://lf3-cdn-tos.bytecdntp.com/cdn/expire-1-M/qrcodejs/1.0.0/qrcode.min.js"></script><script>// 初始化函数
let rm = {};

//禁止图片与超链接拖拽
let aElements = document.getElementsByTagName("a");
for (let i = 0; i < aElements.length; i++) {
  aElements[i].setAttribute("draggable", "false");
  let imgElements = aElements[i].getElementsByTagName("img");
  for (let j = 0; j < imgElements.length; j++) {
    imgElements[j].setAttribute("draggable", "false");
  }
}

// 显示菜单
rm.showRightMenu = function (isTrue, x = 0, y = 0) {
  console.info(x, y)
  let rightMenu = document.getElementById("rightMenu");
  rightMenu.style.top = x + "px";
  rightMenu.style.left = y + "px";
  if (isTrue) {
    rightMenu.style.display = "block";
    stopMaskScroll();
  } else {
    rightMenu.style.display = "none";
  }
};

// 隐藏菜单
rm.hideRightMenu = function () {
  rm.showRightMenu(false);
  let rightMenuMask = document.querySelector("#rightmenu-mask");
  rightMenuMask.style.display = "none";
};

// 尺寸
let rmWidth = document.getElementById("rightMenu").offsetWidth;
let rmHeight = document.getElementById("rightMenu").offsetHeight;

// 重新定义尺寸
rm.reloadrmSize = function () {
  rightMenu.style.visibility = "hidden";
  rightMenu.style.display = "block";
  // 获取宽度和高度
  rmWidth = document.getElementById("rightMenu").offsetWidth;
  rmHeight = document.getElementById("rightMenu").offsetHeight;
  rightMenu.style.visibility = "visible";
};

// 获取点击的href
let domhref = "";
let domImgSrc = "";
let globalEvent = null;

var oncontextmenuFunction = function (event) {
  if (document.body.clientWidth > 768) {
    let pageX = event.clientX + 10; //加10是为了防止显示时鼠标遮在菜单上
    let pageY = event.clientY;

    //其他额外菜单
    const $rightMenuOther = document.querySelector(".rightMenuOther");
    const $rightMenuPlugin = document.querySelector(".rightMenuPlugin");
    const $rightMenuCopyText = document.querySelector("#menu-copytext");
    const $rightMenuPasteText = document.querySelector("#menu-pastetext");
    const $rightMenuCommentText = document.querySelector("#menu-commenttext");
    const $rightMenuNewWindow = document.querySelector("#menu-newwindow");
    const $rightMenuNewWindowImg = document.querySelector("#menu-newwindowimg");
    const $rightMenuCopyLink = document.querySelector("#menu-copylink");
    const $rightMenuCopyImg = document.querySelector("#menu-copyimg");
    const $rightMenuDownloadImg = document.querySelector("#menu-downloadimg");
    const $rightMenuSearch = document.querySelector("#menu-search");
    const $rightMenuSearchBaidu = document.querySelector("#menu-searchBaidu");
    const $rightMenuMusicToggle = document.querySelector("#menu-music-toggle");
    const $rightMenuMusicBack = document.querySelector("#menu-music-back");
    const $rightMenuMusicForward = document.querySelector("#menu-music-forward");
    const $rightMenuMusicPlaylist = document.querySelector("#menu-music-playlist");
    const $rightMenuMusicCopyMusicName = document.querySelector("#menu-music-copyMusicName");

    let href = event.target.href;
    let imgsrc = event.target.currentSrc;

    // 判断模式 扩展模式为有事件
    let pluginMode = false;
    $rightMenuOther.style.display = "block";
    globalEvent = event;

    // 检查是否需要复制 是否有选中文本
    if (selectTextNow && window.getSelection()) {
      pluginMode = true;
      $rightMenuCopyText.style.display = "block";
      $rightMenuCommentText.style.display = "block";
      $rightMenuSearch.style.display = "block";
      $rightMenuSearchBaidu.style.display = "block";
    } else {
      $rightMenuCopyText.style.display = "none";
      $rightMenuCommentText.style.display = "none";
      $rightMenuSearchBaidu.style.display = "none";
      $rightMenuSearch.style.display = "none";
    }

    //检查是否右键点击了链接a标签
    if (href) {
      pluginMode = true;
      $rightMenuNewWindow.style.display = "block";
      $rightMenuCopyLink.style.display = "block";
      domhref = href;
    } else {
      $rightMenuNewWindow.style.display = "none";
      $rightMenuCopyLink.style.display = "none";
    }

    //检查是否需要复制图片
    if (imgsrc) {
      pluginMode = true;
      $rightMenuCopyImg.style.display = "block";
      $rightMenuDownloadImg.style.display = "block";
      $rightMenuNewWindowImg.style.display = "block";
      document.getElementById("rightMenu").style.width="12rem"
      domImgSrc = imgsrc;
    } else {
      $rightMenuCopyImg.style.display = "none";
      $rightMenuDownloadImg.style.display = "none";
      $rightMenuNewWindowImg.style.display = "none";
    }

    // 判断是否为输入框
    if (event.target.tagName.toLowerCase() === "input" || event.target.tagName.toLowerCase() === "textarea") {
      pluginMode = true;
      $rightMenuPasteText.style.display = "block";
    } else {
      $rightMenuPasteText.style.display = "none";
    }
    const navMusicEl = document.querySelector("#nav-music");
    //判断是否是音乐
    if (navMusicEl && navMusicEl.contains(event.target)) {
      pluginMode = true;
      $rightMenuMusicToggle.style.display = "block";
      $rightMenuMusicBack.style.display = "block";
      $rightMenuMusicForward.style.display = "block";
      $rightMenuMusicPlaylist.style.display = "block";
      $rightMenuMusicCopyMusicName.style.display = "block";
    } else {
      $rightMenuMusicToggle.style.display = "none";
      $rightMenuMusicBack.style.display = "none";
      $rightMenuMusicForward.style.display = "none";
      $rightMenuMusicPlaylist.style.display = "none";
      $rightMenuMusicCopyMusicName.style.display = "none";
    }

    // 如果不是扩展模式则隐藏扩展模块
    if (pluginMode) {
      $rightMenuOther.style.display = "none";
      $rightMenuPlugin.style.display = "block";
    } else {
      $rightMenuPlugin.style.display = "none";
    }

    rm.reloadrmSize();

    // 鼠标默认显示在鼠标右下方，当鼠标靠右或靠下时，将菜单显示在鼠标左方\上方
    if (pageX + rmWidth > window.innerWidth) {
      pageX -= rmWidth + 10;
    }
    if (pageY + rmHeight > window.innerHeight) {
      pageY -= pageY + rmHeight - window.innerHeight;
    }

    rm.showRightMenu(true, pageY, pageX);
    document.getElementById("rightmenu-mask").style.display = "flex";
    return false;
  }
};

// 监听右键初始化
window.oncontextmenu = oncontextmenuFunction

// 下载图片状态
rm.downloadimging = false;

// 复制图片到剪贴板
rm.writeClipImg = function (imgsrc) {
  console.log("按下复制");
  rm.hideRightMenu();
  anzhiyu.snackbarShow("正在下载中，请稍后", false, 10000);
  if (rm.downloadimging == false) {
    rm.downloadimging = true;
    setTimeout(function () {
      copyImage(imgsrc);
      anzhiyu.snackbarShow("复制成功！图片已添加盲水印，请遵守版权协议");
      rm.downloadimging = false;
    }, "10000");
  }
};

function imageToBlob(imageURL) {
  const img = new Image();
  const c = document.createElement("canvas");
  const ctx = c.getContext("2d");
  img.crossOrigin = "";
  img.src = imageURL;
  return new Promise(resolve => {
    img.onload = function () {
      c.width = this.naturalWidth;
      c.height = this.naturalHeight;
      ctx.drawImage(this, 0, 0);
      c.toBlob(
        blob => {
          // here the image is a blob
          resolve(blob);
        },
        "image/png",
        0.75
      );
    };
  });
}

async function copyImage(imageURL) {
  const blob = await imageToBlob(imageURL);
  const item = new ClipboardItem({ "image/png": blob });
  navigator.clipboard.write([item]);
}

rm.copyUrl = function (id) {
  const input = document.createElement("input"); // Create a new <input> element
  input.id = "copyVal"; // Set the id of the new element to "copyVal"
  document.body.appendChild(input); // Append the new element to the end of the <body> element
  
  const text = id;
  input.value = text;
  input.select();
  input.setSelectionRange(0, input.value.length);
  document.execCommand("copy");
  
  input.remove(); // Remove the <input> element from the DOM
};

function stopMaskScroll() {
  if (document.getElementById("rightmenu-mask")) {
    let xscroll = document.getElementById("rightmenu-mask");
    xscroll.addEventListener(
      "mousewheel",
      function (e) {
        //阻止浏览器默认方法
        rm.hideRightMenu();
        // e.preventDefault();
      },
      { passive: true }
    );
  }
  if (document.getElementById("rightMenu")) {
    let xscroll = document.getElementById("rightMenu");
    xscroll.addEventListener(
      "mousewheel",
      function (e) {
        //阻止浏览器默认方法
        rm.hideRightMenu();
        // e.preventDefault();
      },
      { passive: true }
    );
  }
}

rm.rightmenuCopyText = function (txt) {
  if (navigator.clipboard) {
    navigator.clipboard.writeText(txt);
  }
  rm.hideRightMenu();
};

rm.copyPageUrl = function (url) {
  if (!url) {
    url = window.location.href;
  }
  rm.copyUrl(url);
  anzhiyu.snackbarShow("复制本页链接地址成功", false, 2000);
  rm.hideRightMenu();
};

rm.sharePage = function () {
  var content = window.location.href;
  rm.copyUrl(url);
  anzhiyu.snackbarShow("复制本页链接地址成功", false, 2000);
  rm.hideRightMenu();
};

// 复制当前选中文本
var selectTextNow = "";
document.onmouseup = document.ondblclick = selceText;

function selceText() {
  var txt;
  if (document.selection) {
    txt = document.selection.createRange().text;
  } else {
    txt = window.getSelection().toString();
  }
  selectTextNow = txt !== "" ? txt : "";
}

// 读取剪切板
rm.readClipboard = function () {
  if (navigator.clipboard) {
    navigator.clipboard.readText().then(clipText => rm.insertAtCaret(globalEvent.target, clipText));
  }
};

// 粘贴文本到焦点
rm.insertAtCaret = function (elemt, value) {
  const startPos = elemt.selectionStart,
    endPos = elemt.selectionEnd;
  if (document.selection) {
    elemt.focus();
    var sel = document.selection.createRange();
    sel.text = value;
    elemt.focus();
  } else {
    if (startPos || startPos == "0") {
      var scrollTop = elemt.scrollTop;
      elemt.value = elemt.value.substring(0, startPos) + value + elemt.value.substring(endPos, elemt.value.length);
      elemt.focus();
      elemt.selectionStart = startPos + value.length;
      elemt.selectionEnd = startPos + value.length;
      elemt.scrollTop = scrollTop;
    } else {
      elemt.value += value;
      elemt.focus();
    }
  }
};

//粘贴文本
rm.pasteText = function () {
  const result = rm.readClipboard() || "";
  rm.hideRightMenu();
};

//引用到评论
rm.rightMenuCommentText = function (txt) {
  rm.hideRightMenu();
  const postCommentDom = document.getElementById("post-comment");
  var domTop = postCommentDom.offsetTop;
  window.scrollTo(0, domTop - 80);
  if (txt == "undefined" || txt == "null") txt = "好棒！";
  function setText() {
    setTimeout(() => {
      var input = document.getElementsByClassName("el-textarea__inner")[0];
      if (!input) setText();
      let evt = document.createEvent("HTMLEvents");
      evt.initEvent("input", true, true);
      let inputValue = replaceAll(txt, "\n", "\n> ");
      input.value = "> " + inputValue + "\n\n";
      input.dispatchEvent(evt);
      input.focus();
      input.setSelectionRange(-1, -1);
      if (document.getElementById("comment-tips")) {
        document.getElementById("comment-tips").classList.add("show");
      }
    }, 100);
  }
  setText();
};

//替换所有内容
function replaceAll(string, search, replace) {
  return string.split(search).join(replace);
}

// 百度搜索
rm.searchBaidu = function () {
  anzhiyu.snackbarShow("即将跳转到百度搜索", false, 2000);
  setTimeout(function () {
    window.open("https://www.baidu.com/s?wd=" + selectTextNow);
  }, "2000");
  rm.hideRightMenu();
};

//分享链接
rm.copyLink = function () {
  rm.rightmenuCopyText(domhref);
  anzhiyu.snackbarShow("已复制链接地址");
};

function addRightMenuClickEvent() {
  // 添加点击事件
  document.getElementById("menu-backward").addEventListener("click", function () {
  window.history.back();
    rm.hideRightMenu();
  });

  document.getElementById("menu-forward").addEventListener("click", function () {
    window.history.forward();
    rm.hideRightMenu();
  });

  document.getElementById("menu-refresh").addEventListener("click", function () {
    window.location.reload();
  });

  document.getElementById("menu-top").addEventListener("click", function () {
    anzhiyu.scrollToDest(0, 500);
    rm.hideRightMenu();
  });

  const menuLinks = document.querySelectorAll(".menu-link");
  menuLinks.forEach(function (link) {
    link.addEventListener("click", rm.hideRightMenu);
  });

  document.getElementById("menu-darkmode").addEventListener("click", anzhiyu.switchDarkMode);

  document.getElementById("menu-home") && document.getElementById("menu-home").addEventListener("click", function () {
    window.location.href = window.location.origin;
  });

  document.getElementById("menu-randomPost").addEventListener("click", function () {
    toRandomPost();
  });

  document.getElementById("menu-commentBarrage").addEventListener("click", anzhiyu.switchCommentBarrage);

  document.getElementById("rightmenu-mask").addEventListener("click", rm.hideRightMenu);

  document.getElementById("rightmenu-mask").addEventListener("contextmenu", function (event) {
    rm.hideRightMenu();
    event.preventDefault(); // Prevent the default context menu from appearing
  });

  document.getElementById("menu-copy").addEventListener("click", rm.copyPageUrl);

  document.getElementById("menu-pastetext").addEventListener("click", rm.pasteText);

  document.getElementById("menu-copytext").addEventListener("click", function () {
    rm.rightmenuCopyText(selectTextNow);
    anzhiyu.snackbarShow("复制成功，复制和转载请标注本文地址");
  });

  document.getElementById("menu-commenttext").addEventListener("click", function () {
    rm.rightMenuCommentText(selectTextNow);
  });

  document.getElementById("menu-newwindow").addEventListener("click", function () {
    window.open(domhref, "_blank");
    rm.hideRightMenu();
  });

  document.getElementById("menu-copylink").addEventListener("click", rm.copyLink);

  document.getElementById("menu-downloadimg").addEventListener("click", function () {
    anzhiyu.downloadImage(domImgSrc, "anzhiyu");
  });

  document.getElementById("menu-newwindowimg").addEventListener("click", function () {
    window.open(domImgSrc, "_blank");
    rm.hideRightMenu();
  });

  document.getElementById("menu-copyimg").addEventListener("click", function () {
    rm.writeClipImg(domImgSrc);
  });

  document.getElementById("menu-searchBaidu").addEventListener("click", rm.searchBaidu);

  //音乐
  document.getElementById("menu-music-toggle").addEventListener("click", anzhiyu.musicToggle);

  document.getElementById("menu-music-back").addEventListener("click", anzhiyu.musicSkipBack);

  document.getElementById("menu-music-forward").addEventListener("click", anzhiyu.musicSkipForward);

  document.getElementById("menu-music-copyMusicName").addEventListener("click", function () {
    rm.rightmenuCopyText(anzhiyu.musicGetName());
    anzhiyu.snackbarShow("复制歌曲名称成功", false, 3000);
  });

}

addRightMenuClickEvent();</script><script data-pjax>var themeColorMeta = document.querySelector('meta[name="theme-color"]');
var pageHeaderEl = document.getElementById("page-header");
var navMusicEl = document.getElementById("nav-music");
var consoleEl = document.getElementById("console");
// 已随机的歌曲
var selectRandomSong = [];
// 音乐默认声音大小
var musicVolume = 0.8;
// 是否切换了周杰伦音乐列表
var changeMusicListFlag = false;
// 当前默认播放列表
var defaultPlayMusicList = [];

document.getElementById("page-name").innerText = document.title.split(" | ♪张小佑")[0];
anzhiyu.initIndexEssay();
anzhiyu.changeTimeInEssay();
anzhiyu.removeBodyPaceClass();
anzhiyu.qrcodeCreate();
anzhiyu.changeTimeInAlbumDetail();
anzhiyu.reflashEssayWaterFall();
anzhiyu.sayhi();
anzhiyu.stopImgRightDrag();
anzhiyu.addNavBackgroundInit();
anzhiyu.setValueToBodyType();
anzhiyu.catalogActive();
anzhiyu.tagsPageActive();
anzhiyu.categoriesBarActive();
anzhiyu.topCategoriesBarScroll();
anzhiyu.switchRightClickMenuHotReview();
anzhiyu.getCustomPlayList();
anzhiyu.addEventListenerConsoleMusicList(false);
setTimeout(() => {
  if (typeof addFriendLinksInFooter === "function") {
    addFriendLinksInFooter();
  }
}, 200)</script><link rel="stylesheet" href="https://npm.elemecdn.com/anzhiyu-theme-static@1.1.4/icon/ali_iconfont_css.css"><link rel="stylesheet" href="https://npm.elemecdn.com/anzhiyu-theme-static@1.0.0/aplayer/APlayer.min.css" media="print" onload="this.media='all'"><script src="https://npm.elemecdn.com/anzhiyu-blog-static@1.0.1/js/APlayer.min.js"></script><script src="https://npm.elemecdn.com/hexo-anzhiyu-music@1.0.1/assets/js/Meting2.min.js"></script><script src="https://npm.elemecdn.com/pjax@0.2.8/pjax.min.js"></script><script>let pjaxSelectors = ["head > title","#config-diff","#body-wrap","#rightside-config-hide","#rightside-config-show",".js-pjax"]

var pjax = new Pjax({
  elements: 'a:not([target="_blank"])',
  selectors: pjaxSelectors,
  cacheBust: false,
  analytics: false,
  scrollRestoration: false
})

document.addEventListener('pjax:send', function () {
  // removeEventListener scroll 
  window.tocScrollFn && window.removeEventListener('scroll', window.tocScrollFn)
  window.scrollCollect && window.removeEventListener('scroll', scrollCollect)

  document.getElementById('rightside').style.cssText = "opacity: ''; transform: ''"
  
  if (window.aplayers) {
    for (let i = 0; i < window.aplayers.length; i++) {
      if (!window.aplayers[i].options.fixed) {
        window.aplayers[i].destroy()
      }
    }
  }

  typeof typed === 'object' && typed.destroy()

  //reset readmode
  const $bodyClassList = document.body.classList
  $bodyClassList.contains('read-mode') && $bodyClassList.remove('read-mode')
})

document.addEventListener('pjax:complete', function () {
  window.refreshFn()

  document.querySelectorAll('script[data-pjax]').forEach(item => {
    const newScript = document.createElement('script')
    const content = item.text || item.textContent || item.innerHTML || ""
    Array.from(item.attributes).forEach(attr => newScript.setAttribute(attr.name, attr.value))
    newScript.appendChild(document.createTextNode(content))
    item.parentNode.replaceChild(newScript, item)
  })

  GLOBAL_CONFIG.islazyload && window.lazyLoadInstance.update()

  typeof chatBtnFn === 'function' && chatBtnFn()
  typeof panguInit === 'function' && panguInit()

  // google analytics
  typeof gtag === 'function' && gtag('config', '', {'page_path': window.location.pathname});

  // baidu analytics
  typeof _hmt === 'object' && _hmt.push(['_trackPageview',window.location.pathname]);

  typeof loadMeting === 'function' && document.getElementsByClassName('aplayer').length && loadMeting()

  // prismjs
  typeof Prism === 'object' && Prism.highlightAll()
})

document.addEventListener('pjax:error', (e) => {
  if (e.request.status === 404) {
    pjax.loadUrl('/404.html')
  }
})</script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><script charset="UTF-8" src="https://npm.elemecdn.com/anzhiyu-theme-static@1.1.5/accesskey/accesskey.js"></script></div><script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body></html>